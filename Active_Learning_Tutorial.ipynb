{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Active Learning Tutorial",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nHFkUgEJokz"
      },
      "source": [
        "copy of [this site](https://github.com/orico/ActiveLearningFrameworkTutorial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x19OpFguwPXR"
      },
      "source": [
        "We start with all the needed dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qylS2W3h-3d6"
      },
      "source": [
        "## **Active Learning Tutorial**\n",
        "\n",
        "These days we are exposed to an abundance of unlabeled data either from the Internet or from some other source such as academia or business worlds. Due to the fact that unlabeled data is relatively easy to acquire and is expensive to label, companies usually employ an expert or several employees whose purpose is to label data [1]. Consider the following situation, a data-driven medical company has a lot of MRI scans and they need to employ an expert that will help them interpret these scans. The company has limited resources and they cant interpret or label all of their data; this is the point where they decide to use active-learning (AL). The promise of AL is that by iteratively increasing the size of our carefully selected labeled data, it is possible to achieve similar (or greater [2]) performance to using a fully supervised data-set with a fraction of the cost or time that it takes to label all the data. AL is considered to be a semi-supervised method, between unsupervised and fully supervised in terms of the amount of labeled data, i.e., for unsupervised data we use 0% labeled samples and for fully supervised we use 100% labeled samples. Therefore, the decision of how much data to use or alternatively how much performance is required from the model relies on a resource management decision, in other words it can be a business decision. \n",
        "\n",
        "There are three scenarios for AL: \n",
        "1. Membership query synthesis, i.e., a generated sample is sent to an oracle for labeling.\n",
        "2. Stream-Based selective sampling, i.e, each sample is considered separately - in our case for lable-querying or rejection. Similarly to online-learning, the data is not saved, there are no assumptions on data distribution, and therefore it is adaptive to change. \n",
        "3. Pool-Based sampling, i.e., sampled are chosen from a pool of unlabeled data for the purpose of labeling [3]. \n",
        "In this tutorial we use the third scenario.\n",
        "\n",
        "The following pseudo algorithm represents the learning process, as written in the code, for pool-based sampling:\n",
        "1. Divide the data to a 'pool' and a test-set\n",
        "2. Select 'k' samples from the pool for the initial train-set and label them, the remaining data will be the validation-set\n",
        "3. Normalize all the sets\n",
        "4. Train the Model using the train-set, with balanced weights.\n",
        "5. Use the trained model with the validation-set, get probabilities per sample.\n",
        "6. Use the trained model with the test-set, get performance measures.\n",
        "7. Select 'k' most-informative samples based on per-sample-probabilities, i.e., those that the model was most uncertain about regarding their labelling.\n",
        "8. Move these 'k' samples from the validation set to the train-set and query their labels.\n",
        "9. Inverse normalization for all the data-sets\n",
        "10. Stop according to the stop criterion, otherwise go to 3. \n",
        "\n",
        "There are a few things to note before going forward: \n",
        "1. The fully-supervised performance of a chosen algorithm is usually the upper bound, therefore it is advisable to try several algorithms.\n",
        "2. Normalization for all sets must be inversed and normalized again after we remove samples from the validation set, because our sample distribution changed in both the new validation and new train-sets.\n",
        "2. The sample selection function relies on test-sample probabilities derived from the trained model, therefore we can only use algorithms that provide access to sample probabilities.\n",
        "3. 'k' is a hyper parameter\n",
        "\n",
        "Our most important tool in AL method is the sample selection function, this is the only point where we influence the learning process and it crucial to use the right method. This area is a hot research topic and there are many studies that propose competing selection functions. \n",
        "In this tutorial I propose four known selection functions:\n",
        "1. Random selection - we select 'k' random samples from the validation set.\n",
        "2. Entropy selection - we select 'k' samples with the highest entropy, i.e., with high uncertainty.\n",
        "3. Margin selection - we select 'k' samples with the lowest difference between the two highest class probabilities, i.e., a higher figure will be given for samples whose model was very certain about a single class and lower to samples whose class probabilities are very similar. \n",
        "\n",
        "The code provided [here](https://github.com/orico/ActiveLearningFrameworkTutorial) utilizes a modular architecture in terms of selecting various learning algorithms and selection functions and can be used as a base for other model-function comparisons.\n",
        "\n",
        "We compare several learning algorithms, such as support vector machine (SVM) with a linear kernel, random forest (RF) and logistic regression (LOG). Each algorithm was executed with all of the selection functions using all 'k' = [10,25,50,125,250], accumulating a total of 80 experiments. Due to the random nature of some of the algorithms and the selection functions, it is advisable to run repeated experiments in the code in order to calculate a statistical significant result. However, running times are long and I have chosen to run the experiment only once for each combination of (model,function,k).\n",
        "\n",
        "The following is an explanation of the code and its class architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MWwUTInv-oj"
      },
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, \\\n",
        "    GradientBoostingClassifier\n",
        "\n",
        "max_queried = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFIsF1wvzCg"
      },
      "source": [
        "We start by downloading our data and splitting it to train and test, according to known MNIST definitions 60K/10K split. later the train-set will be split to train and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ojzg4Gjwpgh"
      },
      "source": [
        "trainset_size = 60000  # ie., testset_size = 10000\n",
        "\n",
        "def download():\n",
        "    mnist = fetch_openml('mnist_784') # 包含data，target数据\n",
        "    X = mnist.data.astype('float64') # 转换格式\n",
        "    y = mnist.target\n",
        "    print ('MNIST:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "    return (X_train_full, y_train_full, X_test, y_test) # 本身就是tuple形式，加括号只是为了更加清晰"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrb6IW2ExGST"
      },
      "source": [
        "We create a modular class representation, 'BaseModel' is a base model for the class architecture, you can implement new models and use them interchangeably or in addition to all other models.\n",
        "our current implementations include SVM, logistic regression, random forest and gradient boosting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2coy8C7xGqS"
      },
      "source": [
        "class BaseModel(object): # 用于使模型的结构清晰统一\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
        "                              class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Multinominal Logistic Regression' \n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training multinomial logistic regression')\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight,\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X51UCCeEzqb9"
      },
      "source": [
        "Our 'TrainModel' class accepts one of the previously in defined learning algorithms, trains using the training set and gets performance measurements from the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEcquMhTzqlC"
      },
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
        "        print ('Val   set:', X_val.shape)\n",
        "        print ('Test  set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "\n",
        "    def get_test_accuracy(self, i, y_test): \n",
        "        # 这里的classification_report()和confusion_matrix()没太清楚作用\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
        "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYar8S_jyYQ9"
      },
      "source": [
        "We create a modular selection function class representation, 'BaseSelectionFunction' is a base class for various sample selection methods. Using this architecture, you can implement new selection methods and use them in addition or instead of previous methods, for experimental purposes. Our current implementations include random-selection, entropy-selection, margin sampling-selection and minimum standard deviation-selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni-E8tN7yYX2"
      },
      "source": [
        "class BaseSelectionFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select(self):\n",
        "        pass\n",
        "\n",
        "# 这里的probas_val是什么?是每个样本在每个类的概率形成的矩阵么?\n",
        "class RandomSelection(BaseSelectionFunction):\n",
        "#随机无重复挑选\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        random_state = check_random_state(0)\n",
        "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
        "\n",
        "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(BaseSelectionFunction):\n",
        "#熵最优挑选,熵是某种状态的信息量,或者某个变量的信息量\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSamplingSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
        "        values = rev[:, 0] - rev[:, 1]\n",
        "        selection = np.argsort(values)[:initial_labeled_samples]\n",
        "        return selection\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym7QEvD0yI9Z"
      },
      "source": [
        "We have a class that is used to normalize using a MinMax Scaler in the range of [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aRcKj4D0SQJ"
      },
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        # 这是如何做到inverse的呢? \n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl_AfuOx0fkM"
      },
      "source": [
        "Initially we would like to get a random sampling from the unlabeled data-pool, this is done using random.choice without replacement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1GJB6Kb0e54"
      },
      "source": [
        "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(trainset_size,\n",
        "                                   initial_labeled_samples,\n",
        "                                   replace=False)\n",
        "    print ()\n",
        "    print ('initial random chosen samples', permutation.shape),\n",
        "#            permutation)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    bin_count = np.bincount(y_train.astype('int64')) # what bincount and unique do? and it is necessary?\n",
        "    unique = np.unique(y_train.astype('int64'))\n",
        "    print (\n",
        "        'initial train set:',\n",
        "        X_train.shape,\n",
        "        y_train.shape,\n",
        "        'unique(labels):',\n",
        "        bin_count,\n",
        "        unique,\n",
        "        )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeRHks3K0wQO"
      },
      "source": [
        "This is the main class that initiates the active-learning process according to the algorithm described in the introduction. In short, we select 'k' random samples, train a model, select the most informative samples, remove from the validation set, query their labels and retrain using those samples until reaching the stop criteria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRtOTPPvyJGx"
      },
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "# 第一次打标签数量、模型、样本挑选方式\n",
        "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
        "        self.initial_labeled_samples = initial_labeled_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_k_random_samples(self.initial_labeled_samples,\n",
        "                                 X_train_full, y_train_full)\n",
        "        self.queried = self.initial_labeled_samples # 每次打标签数量和初始打标签数量相同\n",
        "        self.samplecount = [self.initial_labeled_samples] # 这里只是下标还是直接就是样本？\n",
        "\n",
        "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full) #　为什么创建一个空数组，而非直接赋值呢？\n",
        "        X_val = np.delete(X_val, permutation, axis=0)# 0表示按照列删除,那样本就是一列一个的格式了.\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        print ()\n",
        "\n",
        "        # normalize data\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
        "        # print(fpfn)\n",
        "        # self.fpfncount = []\n",
        "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
        "\n",
        "        while self.queried < max_queried:# 设置了最大查询数量为500\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "\n",
        "            probas_val = self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            print ('val predicted:',\n",
        "                   self.clf_model.val_y_predicted.shape,\n",
        "                   self.clf_model.val_y_predicted)\n",
        "            print ('probabilities:', probas_val.shape, '\\n',\n",
        "                   np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "\n",
        "            uncertain_samples = \\\n",
        "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        " \n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # 训练集变化的信息\n",
        "            print ('trainset before', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            print ('trainset after', X_train.shape, y_train.shape)\n",
        "            self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            bin_count = np.bincount(y_train.astype('int64'))\n",
        "            unique = np.unique(y_train.astype('int64'))\n",
        "            print (\n",
        "                'updated train set:',\n",
        "                X_train.shape,\n",
        "                y_train.shape,\n",
        "                'unique(labels):',\n",
        "                bin_count,\n",
        "                unique,\n",
        "                )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            print ('val set:', X_val.shape, y_val.shape)# 验证集信息\n",
        "            print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.initial_labeled_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('final active learning accuracies',\n",
        "               self.clf_model.accuracies)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7OZblsL00L2"
      },
      "source": [
        "We download the data, split to train validation and test, we run the experiment by iterating over all of our training algorithms X all of our selection functions X all possible k's in the range of [10,25,50,125,250]. The accuracy results are kept in a dictionary and pickle-saved to a unique file as soon as the model finishes training - this is crucial when using google colaboratory as it tends to disconnect from time to time. We also limit our training to a maximum of 500 queried samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzrAvJz00dk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0d5503c-3fb9-4410-e063-fa6ba05ba9ae"
      },
      "source": [
        "(X, y) = download()\n",
        "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
        "print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "print ('test :', X_test.shape, y_test.shape)\n",
        "classes = len(np.unique(y))\n",
        "print ('unique classes', classes)\n",
        "\n",
        "def pickle_save(fname, data):\n",
        "  filehandler = open(fname,\"wb\")\n",
        "  pickle.dump(data,filehandler)\n",
        "  filehandler.close() \n",
        "  print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "def pickle_load(fname):\n",
        "  print(os.getcwd(), os.listdir())\n",
        "  file = open(fname,'rb')\n",
        "  data = pickle.load(file)\n",
        "  file.close()\n",
        "  print(data)\n",
        "  return data\n",
        "  \n",
        "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    pickle_save(fname, d)\n",
        "                    if count % 5 == 0:\n",
        "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    print ()\n",
        "                    print ('---------------------------- FINISHED ---------------------------')\n",
        "                    print ()\n",
        "    return d\n",
        "\n",
        "\n",
        "max_queried = 500 \n",
        "\n",
        "repeats = 1\n",
        "\n",
        "models = [SvmModel, RfModel, LogModel] \n",
        "\n",
        "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection] \n",
        "\n",
        "Ks = [250,125,50,25,10] \n",
        "\n",
        "d = {}\n",
        "stopped_at = -1 \n",
        "\n",
        "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n",
        "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "print (d)\n",
        "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "print(results)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST: (70000, 784) (70000,)\n",
            "train: (60000, 784) (60000,)\n",
            "test : (10000, 784) (10000,)\n",
            "unique classes 10\n",
            "stopping at: 500\n",
            "Count = 1, using model = SvmModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [18 22 24 33 17 20 32 26 28 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.731 s \n",
            "\n",
            "Accuracy rate for 84.690000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.92       980\n",
            "           1       0.89      0.94      0.92      1135\n",
            "           2       0.91      0.77      0.83      1032\n",
            "           3       0.78      0.84      0.81      1010\n",
            "           4       0.86      0.80      0.83       982\n",
            "           5       0.75      0.76      0.75       892\n",
            "           6       0.90      0.92      0.91       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.79      0.80      0.80       974\n",
            "           9       0.76      0.82      0.79      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    0   15    6    0   37   26    3   10    5]\n",
            " [   0 1071    4    8    0    4    0    2   46    0]\n",
            " [   9   21  794   80   17    5   28   20   38   20]\n",
            " [   1    9   16  847    2   96    3   16   15    5]\n",
            " [   2   12    5    0  787    5    9    5    9  148]\n",
            " [   4   19    8   74   13  675   17    4   52   26]\n",
            " [  25    6    8    3    5   11  885    1   13    1]\n",
            " [   1   21   14    2   16    4    0  925    9   36]\n",
            " [   7   27    2   52    8   52   14    7  782   23]\n",
            " [   2   13    9   12   72   10    2   45   19  825]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [46 46 49 61 40 39 58 48 59 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.468 s \n",
            "\n",
            "Accuracy rate for 86.840000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       980\n",
            "           1       0.91      0.96      0.94      1135\n",
            "           2       0.85      0.81      0.83      1032\n",
            "           3       0.84      0.84      0.84      1010\n",
            "           4       0.89      0.86      0.87       982\n",
            "           5       0.77      0.81      0.79       892\n",
            "           6       0.90      0.92      0.91       958\n",
            "           7       0.92      0.85      0.88      1028\n",
            "           8       0.84      0.81      0.82       974\n",
            "           9       0.80      0.86      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    8    4    0   20   17    1    2    0]\n",
            " [   0 1094    7    3    0    3    1    0   27    0]\n",
            " [   8   30  832   58    6   17   21   21   32    7]\n",
            " [   1    4   20  848    3   85    3   14   24    8]\n",
            " [   1    7   15    1  841    6   13    0    5   93]\n",
            " [  10    8    8   54   11  725   21    5   37   13]\n",
            " [   2    3   31    1    8   26  881    0    6    0]\n",
            " [   1   16   32    1   17    6    0  876   10   69]\n",
            " [   8   28    6   31   11   49   20    9  791   21]\n",
            " [   6    8   16   14   46    8    1   30   12  868]]\n",
            "--------------------------------\n",
            "final active learning accuracies [84.69, 86.83999999999999]\n",
            "saved Active-learning-experiment-1.pkl /content ['.config', 'Active-learning-experiment-1.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 2, using model = SvmModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [13 11 12 13 17 10 17 12  8 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.149 s \n",
            "\n",
            "Accuracy rate for 79.270000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.90      0.75      0.82      1032\n",
            "           3       0.71      0.81      0.76      1010\n",
            "           4       0.72      0.90      0.80       982\n",
            "           5       0.63      0.56      0.60       892\n",
            "           6       0.84      0.89      0.86       958\n",
            "           7       0.80      0.85      0.83      1028\n",
            "           8       0.79      0.61      0.69       974\n",
            "           9       0.82      0.64      0.72      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 864    1    2   13    5   55   31    5    4    0]\n",
            " [   0 1104    4    2    1    8    5    1   10    0]\n",
            " [  45   33  777   38   32    9   44   25   25    4]\n",
            " [  12    7   13  820    5   82    2   45   17    7]\n",
            " [   0    9    4    5  886    0   26    9   10   33]\n",
            " [  36   14    7  147   44  503   23   26   84    8]\n",
            " [  37    6    8    1   21   27  856    1    1    0]\n",
            " [   1   11   27    7   25    1    3  876    5   72]\n",
            " [  46   38   13  111   14   91   19   27  595   20]\n",
            " [  10    9   11   11  203   20   13   80    6  646]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [20 27 22 24 30 20 33 23 25 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.573 s \n",
            "\n",
            "Accuracy rate for 84.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.91      0.83      0.87      1032\n",
            "           3       0.79      0.85      0.82      1010\n",
            "           4       0.79      0.90      0.84       982\n",
            "           5       0.74      0.71      0.73       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.88      0.86      0.87      1028\n",
            "           8       0.85      0.77      0.81       974\n",
            "           9       0.87      0.77      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.84     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 868    1    4    4    0   72   13    2   16    0]\n",
            " [   0 1100    5   15    0    1    5    1    8    0]\n",
            " [  23   30  859   22   18    9   38   16   14    3]\n",
            " [  13   12   19  857    1   44    2   23   33    6]\n",
            " [   2   10    1    4  881    1   24    9    7   43]\n",
            " [  39    4    6  109   25  636   18   11   36    8]\n",
            " [  28    3    5    2   28   20  870    0    2    0]\n",
            " [   2   15   30   11   22    4    1  887    5   51]\n",
            " [  27   24   15   53   12   59   13   15  750    6]\n",
            " [  10    6    3   10  127   14    8   45   14  772]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [37 42 39 35 41 31 49 29 34 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.417 s \n",
            "\n",
            "Accuracy rate for 86.020000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.86      0.88      0.87      1032\n",
            "           3       0.77      0.84      0.81      1010\n",
            "           4       0.82      0.91      0.86       982\n",
            "           5       0.76      0.76      0.76       892\n",
            "           6       0.92      0.91      0.91       958\n",
            "           7       0.91      0.85      0.88      1028\n",
            "           8       0.89      0.75      0.81       974\n",
            "           9       0.86      0.79      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 886    1   10    3    0   56   16    1    7    0]\n",
            " [   0 1110    5   14    0    1    1    0    4    0]\n",
            " [  25    9  911    6   17   10   20   16   11    7]\n",
            " [  10   10   40  848    2   60    0   13   23    4]\n",
            " [   2   11    5    3  890    1   12    8    7   43]\n",
            " [  14    8    8  118   16  679   14    4   22    9]\n",
            " [  17    4   27    1   17   18  873    0    1    0]\n",
            " [   2   18   32   12   26    6    1  878    4   49]\n",
            " [  27   22   22   74   12   56   10    8  728   15]\n",
            " [  14    6    5   16  111   10    4   36    8  799]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [45 55 54 52 56 41 57 40 50 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.086 s \n",
            "\n",
            "Accuracy rate for 86.890000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.85      0.88      0.86      1032\n",
            "           3       0.80      0.86      0.83      1010\n",
            "           4       0.81      0.92      0.86       982\n",
            "           5       0.78      0.80      0.79       892\n",
            "           6       0.93      0.88      0.91       958\n",
            "           7       0.93      0.85      0.89      1028\n",
            "           8       0.87      0.79      0.82       974\n",
            "           9       0.87      0.80      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 890    0   18   11    1   40   11    1    8    0]\n",
            " [   0 1114    5   10    0    1    2    0    3    0]\n",
            " [  23    9  909   13   16   11    9   15   24    3]\n",
            " [   5    5   33  868    3   49    0   13   26    8]\n",
            " [   1    6    6    3  905    3   13    3    3   39]\n",
            " [   6    4    5   96    9  712   16    4   27   13]\n",
            " [  14    4   42    4   21   26  844    0    3    0]\n",
            " [   1   19   30    9   31    7    0  872    8   51]\n",
            " [  21   17   17   55   16   56    9    5  766   12]\n",
            " [  10    8    7   12  109   10    2   25   17  809]]\n",
            "--------------------------------\n",
            "final active learning accuracies [79.27, 84.8, 86.02, 86.89]\n",
            "saved Active-learning-experiment-2.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 3, using model = SvmModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [ 5  5 10  8  4  4  4  5  3  2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.208 s \n",
            "\n",
            "Accuracy rate for 65.330000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       980\n",
            "           1       0.77      0.97      0.85      1135\n",
            "           2       0.72      0.80      0.76      1032\n",
            "           3       0.49      0.69      0.57      1010\n",
            "           4       0.55      0.34      0.42       982\n",
            "           5       0.51      0.44      0.47       892\n",
            "           6       0.67      0.61      0.64       958\n",
            "           7       0.67      0.85      0.75      1028\n",
            "           8       0.83      0.34      0.48       974\n",
            "           9       0.54      0.52      0.53      1009\n",
            "\n",
            "    accuracy                           0.65     10000\n",
            "   macro avg       0.66      0.64      0.63     10000\n",
            "weighted avg       0.66      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    0   20   22    2   38   17    1    3    0]\n",
            " [   0 1096   11    7    5    9    3    4    0    0]\n",
            " [  13   75  827    8    5    8   53   38    4    1]\n",
            " [   2   33  129  701    0   94   15   32    2    2]\n",
            " [   3   37   10   14  334   18  144   44    2  376]\n",
            " [  36   35   21  300   18  391   17   23   43    8]\n",
            " [ 108   60   56   43   73   32  581    1    4    0]\n",
            " [   9   28   27    9   15    7    6  873    0   54]\n",
            " [  10   47   47  279   63  161    6   29  327    5]\n",
            " [  15   18    6   50   88   16   29  250   11  526]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '6' ... '5' '0' '4']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 6 ... 3 6 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [12  9 15 15  6  7 10 14  9  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.232 s \n",
            "\n",
            "Accuracy rate for 74.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.88       980\n",
            "           1       0.88      0.98      0.93      1135\n",
            "           2       0.83      0.78      0.81      1032\n",
            "           3       0.61      0.78      0.68      1010\n",
            "           4       0.74      0.64      0.69       982\n",
            "           5       0.68      0.61      0.64       892\n",
            "           6       0.76      0.80      0.78       958\n",
            "           7       0.61      0.92      0.73      1028\n",
            "           8       0.88      0.56      0.68       974\n",
            "           9       0.78      0.43      0.56      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    0    4   17    0   29   22    4    0    0]\n",
            " [   0 1108    1    9    4    5    3    1    4    0]\n",
            " [  32   35  806   38   13    6   43   42   14    3]\n",
            " [   3   17   83  788    3   61   18   30    7    0]\n",
            " [  18    8    1    8  632   11  105   99    5   95]\n",
            " [  32   14    9  196   22  545   20   23   31    0]\n",
            " [  63   11   13   54   14   30  767    1    5    0]\n",
            " [   2   21   18    5   10    3    5  943    1   20]\n",
            " [  19   36   31  162   35  100    3   43  543    2]\n",
            " [  10    8    4   22  122   12   18  370    6  437]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '6' ... '5' '6' '5']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 6 ... 5 0 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [20 13 19 19 11 11 13 19 15 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.948 s \n",
            "\n",
            "Accuracy rate for 78.690000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.85       980\n",
            "           1       0.94      0.97      0.95      1135\n",
            "           2       0.88      0.81      0.84      1032\n",
            "           3       0.72      0.81      0.76      1010\n",
            "           4       0.78      0.65      0.71       982\n",
            "           5       0.76      0.66      0.71       892\n",
            "           6       0.79      0.83      0.81       958\n",
            "           7       0.68      0.85      0.75      1028\n",
            "           8       0.86      0.71      0.78       974\n",
            "           9       0.71      0.61      0.66      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.78      0.78     10000\n",
            "weighted avg       0.79      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    4   10    0    8   38    6    0    0]\n",
            " [   0 1101    3    5    1    3    3    1   14    4]\n",
            " [  52   10  840   16   20    1   42   30   18    3]\n",
            " [   5    2   56  816    3   72   18   22   12    4]\n",
            " [  27    7    3    1  635   13   81   73    3  139]\n",
            " [  42   11    9  154   21  593   15   15   29    3]\n",
            " [  86    8    7   18    7    9  799    0   23    1]\n",
            " [   4   19   16   10   26    3    3  869    6   72]\n",
            " [  44    9   17   83   18   66    5   25  688   19]\n",
            " [   9    5    2   24   88    9   12  242    4  614]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '6' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 6 ... 5 0 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [23 17 21 22 18 16 20 28 17 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.405 s \n",
            "\n",
            "Accuracy rate for 82.000000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87       980\n",
            "           1       0.94      0.97      0.96      1135\n",
            "           2       0.88      0.78      0.83      1032\n",
            "           3       0.73      0.81      0.77      1010\n",
            "           4       0.81      0.76      0.78       982\n",
            "           5       0.79      0.69      0.74       892\n",
            "           6       0.80      0.92      0.86       958\n",
            "           7       0.78      0.88      0.83      1028\n",
            "           8       0.90      0.64      0.75       974\n",
            "           9       0.76      0.78      0.77      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    5    7    0   11   40    3    0    0]\n",
            " [   0 1106    2   10    2    2    4    1    8    0]\n",
            " [  52   21  802   13   20    3   60   31   12   18]\n",
            " [   2    3   59  823    2   40   31   25   12   13]\n",
            " [  22    6    2    0  743    1   33   44    1  130]\n",
            " [  35   13   10  133   16  615   26   12   26    6]\n",
            " [  29    3    5   16    5    6  886    0    8    0]\n",
            " [   4   13   15   13   25    1    2  901    3   51]\n",
            " [  44   10   10   90   26   88   17   35  626   28]\n",
            " [   8    4    2   16   76    8    5  103    3  784]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '6' ... '5' '6' '5']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 6 ... 5 6 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [24 22 24 31 23 19 25 35 25 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.789 s \n",
            "\n",
            "Accuracy rate for 84.820000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       980\n",
            "           1       0.94      0.97      0.95      1135\n",
            "           2       0.90      0.80      0.84      1032\n",
            "           3       0.79      0.84      0.82      1010\n",
            "           4       0.84      0.83      0.83       982\n",
            "           5       0.84      0.74      0.79       892\n",
            "           6       0.83      0.93      0.88       958\n",
            "           7       0.78      0.91      0.84      1028\n",
            "           8       0.91      0.74      0.82       974\n",
            "           9       0.80      0.75      0.77      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    4    9    0   14   24    4    1    0]\n",
            " [   0 1102    2   11    1    4    4    0    4    7]\n",
            " [  45   15  821    9   19    2   55   34   17   15]\n",
            " [   1    4   47  851    3   32   26   25    8   13]\n",
            " [  12    6    1    0  819    1   28   24    0   91]\n",
            " [  23   12    9  106   19  662   19    8   26    8]\n",
            " [  23    3    8   16    6    7  888    0    7    0]\n",
            " [   3   18   12    6   15    2    2  936    3   31]\n",
            " [  38   12   11   47   24   52   15   31  723   21]\n",
            " [  11    3    2   17   74    9    3  131    3  756]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 0]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [28 28 29 36 31 26 29 38 28 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.506 s \n",
            "\n",
            "Accuracy rate for 86.370000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.90      0.80      0.85      1032\n",
            "           3       0.84      0.84      0.84      1010\n",
            "           4       0.83      0.86      0.85       982\n",
            "           5       0.85      0.79      0.82       892\n",
            "           6       0.85      0.92      0.89       958\n",
            "           7       0.81      0.92      0.86      1028\n",
            "           8       0.89      0.78      0.83       974\n",
            "           9       0.84      0.78      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    7    7    0   10   20    5    0    0]\n",
            " [   0 1108    2    6    1    2    6    0    8    2]\n",
            " [  41   15  828    9   21    2   46   30   22   18]\n",
            " [   2    6   45  848    4   38   18   27   12   10]\n",
            " [  11    6    1    0  844    1   29   18    1   71]\n",
            " [  17   12    5   67   18  702   21   11   33    6]\n",
            " [  23    5    5   11    4   13  886    0   11    0]\n",
            " [   3   17   13    8   12    1    1  945    4   24]\n",
            " [  31   10    8   39   26   47    9   33  756   15]\n",
            " [   8    4    1   14   84    8    2   94    5  789]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '7' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [31 36 35 42 37 30 33 43 33 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.900 s \n",
            "\n",
            "Accuracy rate for 86.890000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.90      0.83      0.86      1032\n",
            "           3       0.83      0.83      0.83      1010\n",
            "           4       0.84      0.87      0.85       982\n",
            "           5       0.84      0.80      0.82       892\n",
            "           6       0.88      0.93      0.90       958\n",
            "           7       0.83      0.92      0.87      1028\n",
            "           8       0.91      0.77      0.83       974\n",
            "           9       0.85      0.79      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    7    6    0   11   14    2    0    0]\n",
            " [   0 1117    2    7    1    2    4    0    1    1]\n",
            " [  41    5  855   10   23    5   34   28   18   13]\n",
            " [   2    5   54  835    2   45   17   25   13   12]\n",
            " [  16    5    0    0  854    1   23    8    1   74]\n",
            " [  20   12    2   71   17  710   18   11   26    5]\n",
            " [  26    5    6   10    4   11  889    0    7    0]\n",
            " [   3   14   15    4   20    1    2  943    3   23]\n",
            " [  25   24   11   51   21   51    6   26  749   10]\n",
            " [  14    4    1   16   74    9    2   87    5  797]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [32 38 41 43 44 34 42 53 40 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.628 s \n",
            "\n",
            "Accuracy rate for 87.120000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       980\n",
            "           1       0.93      0.98      0.96      1135\n",
            "           2       0.91      0.83      0.87      1032\n",
            "           3       0.85      0.82      0.84      1010\n",
            "           4       0.84      0.88      0.86       982\n",
            "           5       0.85      0.78      0.81       892\n",
            "           6       0.88      0.92      0.90       958\n",
            "           7       0.84      0.93      0.88      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.85      0.79      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    7    4    0   12   21    2    3    0]\n",
            " [   0 1113    2    5    0    2    5    1    6    1]\n",
            " [  26   10  860    9   28    7   30   27   23   12]\n",
            " [   3    6   54  829    4   41   16   26   16   15]\n",
            " [   9    6    0    0  869    1   16   12    2   67]\n",
            " [  14   15    1   72   14  694   20   12   45    5]\n",
            " [  29    4    6    0    4   16  885    0   14    0]\n",
            " [   2   14   13    2   12    0    2  952    5   26]\n",
            " [  19   22    6   36   18   44    8   26  781   14]\n",
            " [   9    4    1   16   87    4    6   72   12  798]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [40 43 46 44 50 42 44 60 43 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.895 s \n",
            "\n",
            "Accuracy rate for 87.650000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.91      0.98      0.95      1135\n",
            "           2       0.90      0.82      0.86      1032\n",
            "           3       0.89      0.82      0.85      1010\n",
            "           4       0.85      0.89      0.87       982\n",
            "           5       0.85      0.81      0.83       892\n",
            "           6       0.90      0.91      0.91       958\n",
            "           7       0.86      0.92      0.89      1028\n",
            "           8       0.87      0.82      0.84       974\n",
            "           9       0.84      0.81      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    6    5    0    7   15    2    2    0]\n",
            " [   0 1114    3    1    2    1    4    0    7    3]\n",
            " [  34   12  849    5   27    5   27   26   27   20]\n",
            " [   6   17   52  826    4   40    7   26   18   14]\n",
            " [  13    6    0    0  874    1   14    8    3   63]\n",
            " [  19   20    2   49   13  719   14   11   39    6]\n",
            " [  30    5   10    0    4   18  876    0   15    0]\n",
            " [   4   11   14    1   10    0    2  947    4   35]\n",
            " [  16   27    8   27   13   41    7   24  797   14]\n",
            " [   9    7    0   11   86   10    3   55    8  820]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [44 48 51 50 53 45 51 69 46 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.597 s \n",
            "\n",
            "Accuracy rate for 87.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.91      0.83      0.86      1032\n",
            "           3       0.89      0.82      0.85      1010\n",
            "           4       0.85      0.88      0.87       982\n",
            "           5       0.85      0.80      0.82       892\n",
            "           6       0.89      0.94      0.92       958\n",
            "           7       0.87      0.92      0.89      1028\n",
            "           8       0.87      0.82      0.84       974\n",
            "           9       0.84      0.81      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    6    4    0    7   20    2    3    1]\n",
            " [   0 1113    2    2    3    1    4    0    8    2]\n",
            " [  30   12  853    8   29    3   32   22   24   19]\n",
            " [   3   17   45  828    5   41    8   27   20   16]\n",
            " [  15    7    0    0  869    1   15   10    2   63]\n",
            " [  21   21    3   54   11  713   17   10   35    7]\n",
            " [  17    4    5    0    4   16  901    0   11    0]\n",
            " [   3   10   18    0    9    0    2  950    6   30]\n",
            " [  17   25    9   22   11   44    7   26  794   19]\n",
            " [   9    7    0   11   85   15    3   51    6  822]]\n",
            "--------------------------------\n",
            "final active learning accuracies [65.33, 74.72999999999999, 78.69, 82.0, 84.82, 86.37, 86.89, 87.12, 87.64999999999999, 87.8]\n",
            "saved Active-learning-experiment-3.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 4, using model = SvmModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [3 4 3 5 0 1 1 2 2 4] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.193 s \n",
            "\n",
            "Accuracy rate for 49.040000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.49      0.53       980\n",
            "           1       0.52      0.99      0.68      1135\n",
            "           2       0.64      0.47      0.55      1032\n",
            "           3       0.32      0.81      0.46      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.95      0.12      0.22       892\n",
            "           6       0.79      0.16      0.27       958\n",
            "           7       0.86      0.70      0.77      1028\n",
            "           8       0.49      0.21      0.29       974\n",
            "           9       0.38      0.79      0.51      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.55      0.48      0.43     10000\n",
            "weighted avg       0.55      0.49      0.44     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[ 481    3    1  440    0    0    9    2   24   20]\n",
            " [   0 1122    4    2    0    0    1    0    6    0]\n",
            " [  22  147  489  245    0    0   17   20   75   17]\n",
            " [   0   99   35  821    0    1    4    7   13   30]\n",
            " [  15   99    1  164    0    0    2    8    6  687]\n",
            " [  22  132    1  406    0  109    9   13   76  124]\n",
            " [ 231  114   95  194    0    0  157    8    8  151]\n",
            " [  14  140   23   24    0    0    0  724    6   97]\n",
            " [  30  234  111  188    0    5    1   13  205  187]\n",
            " [  21   82    2   55    0    0    0   51    2  796]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '0' '3' ... '9' '6' '8']\n",
            "probabilities: (59975, 9) \n",
            " [3 0 8 ... 8 3 3]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 6 3 9 1 4 6 7 3 7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.283 s \n",
            "\n",
            "Accuracy rate for 62.350000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78       980\n",
            "           1       0.80      0.96      0.87      1135\n",
            "           2       0.91      0.36      0.52      1032\n",
            "           3       0.49      0.88      0.63      1010\n",
            "           4       1.00      0.03      0.05       982\n",
            "           5       0.67      0.52      0.58       892\n",
            "           6       0.60      0.79      0.68       958\n",
            "           7       0.70      0.80      0.75      1028\n",
            "           8       0.64      0.32      0.42       974\n",
            "           9       0.41      0.72      0.52      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.70      0.62      0.58     10000\n",
            "weighted avg       0.70      0.62      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 779    1    2   20    0   33  123    5    5   12]\n",
            " [   0 1088    0   33    0    8    1    0    5    0]\n",
            " [  25   69  376  155    0   41  149   72   97   48]\n",
            " [   0   12    4  893    0   23    7   16   43   12]\n",
            " [   5   36    0   36   25    1   98   37    7  737]\n",
            " [  26   40    2  220    0  461   81    8    9   45]\n",
            " [ 161   11    7    4    0   11  754    1    0    9]\n",
            " [   5   44    4   29    0    3    4  823    3  113]\n",
            " [   8   35   16  346    0   99   23   68  307   72]\n",
            " [   9   22    0   91    0    5   12  138    3  729]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 9 ... 5 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 6  8  4 13  1  5  9 14  5 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.290 s \n",
            "\n",
            "Accuracy rate for 68.040000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       980\n",
            "           1       0.81      0.97      0.88      1135\n",
            "           2       0.91      0.54      0.68      1032\n",
            "           3       0.58      0.88      0.70      1010\n",
            "           4       1.00      0.02      0.04       982\n",
            "           5       0.80      0.47      0.59       892\n",
            "           6       0.68      0.94      0.79       958\n",
            "           7       0.67      0.86      0.76      1028\n",
            "           8       0.75      0.44      0.56       974\n",
            "           9       0.43      0.73      0.54      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.75      0.67      0.64     10000\n",
            "weighted avg       0.75      0.68      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 874    2    1   22    0    2   57    3    6   13]\n",
            " [   0 1097    0   26    0    6    1    0    5    0]\n",
            " [  25   78  561   76    0    7  120   52   78   35]\n",
            " [   6   17    5  892    0   22   15   13   30   10]\n",
            " [   4   22    5   17   19    0  119   67    6  723]\n",
            " [  59   44    1  223    0  416   73   18   10   48]\n",
            " [  20    9    8    2    0    3  896    1    1   18]\n",
            " [   2   34   15   14    0    0    1  887    2   73]\n",
            " [  11   39   18  227    0   57   32   90  430   70]\n",
            " [   5   17    0   52    0    4    7  190    2  732]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 9 ... 5 6 8]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7 12  8 18  3  6 10 16  8 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.321 s \n",
            "\n",
            "Accuracy rate for 73.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89       980\n",
            "           1       0.78      0.98      0.87      1135\n",
            "           2       0.89      0.57      0.70      1032\n",
            "           3       0.56      0.92      0.69      1010\n",
            "           4       0.95      0.44      0.60       982\n",
            "           5       0.88      0.46      0.61       892\n",
            "           6       0.74      0.92      0.82       958\n",
            "           7       0.77      0.85      0.81      1028\n",
            "           8       0.79      0.50      0.62       974\n",
            "           9       0.56      0.80      0.66      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.78      0.73      0.73     10000\n",
            "weighted avg       0.78      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    1    4   45    0    3   47    2   17    7]\n",
            " [   0 1109    0   17    0    3    0    0    6    0]\n",
            " [  19   84  589  103    3    1  107   33   64   29]\n",
            " [   3   16    4  926    0   15    7   13   16   10]\n",
            " [   5   27   11   27  436    0   80   40    6  350]\n",
            " [  30   66    5  241    1  412   47   14   12   64]\n",
            " [  23   12    3   12    4    0  880    1    0   23]\n",
            " [   3   39   14   30    0    0    0  874    4   64]\n",
            " [   7   45   30  220    4   25   19   58  490   76]\n",
            " [   4   22    2   44   13    8    6  105    2  803]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 9 ... 3 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [10 17 12 22  3  9 13 18  8 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.849 s \n",
            "\n",
            "Accuracy rate for 76.630000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       980\n",
            "           1       0.85      0.98      0.91      1135\n",
            "           2       0.89      0.70      0.79      1032\n",
            "           3       0.59      0.90      0.71      1010\n",
            "           4       0.95      0.45      0.61       982\n",
            "           5       0.85      0.53      0.65       892\n",
            "           6       0.81      0.91      0.86       958\n",
            "           7       0.77      0.88      0.82      1028\n",
            "           8       0.83      0.48      0.61       974\n",
            "           9       0.57      0.84      0.68      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.80      0.76      0.75     10000\n",
            "weighted avg       0.80      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    3   16    0    1   23    0    7    7]\n",
            " [   0 1110    6    9    0    5    0    0    5    0]\n",
            " [  23   29  726   88    1    1   47   50   47   20]\n",
            " [   7   13    8  905    0   30    3   15   13   16]\n",
            " [   6   18   14   22  437    0   78   43    5  359]\n",
            " [  44   56    8  215    1  475   30    8   10   45]\n",
            " [  28   13    8   10    2    3  873    1    1   19]\n",
            " [   4   21   12   15    0    1    0  907    3   65]\n",
            " [  11   33   27  208    4   39   16   69  465  102]\n",
            " [   5   13    3   35   13    7    4   84    2  843]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '3' ... '5' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 9 ... 5 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [11 19 17 27  5 10 14 21 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.819 s \n",
            "\n",
            "Accuracy rate for 78.670000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.82      0.76      0.79      1032\n",
            "           3       0.60      0.89      0.72      1010\n",
            "           4       0.96      0.56      0.71       982\n",
            "           5       0.85      0.53      0.65       892\n",
            "           6       0.84      0.89      0.87       958\n",
            "           7       0.80      0.86      0.83      1028\n",
            "           8       0.83      0.57      0.68       974\n",
            "           9       0.63      0.84      0.72      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.81      0.78      0.78     10000\n",
            "weighted avg       0.81      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    1    4   15    0    1   25    0   11    7]\n",
            " [   0 1101    6   15    0    7    0    1    5    0]\n",
            " [  21   16  780   69    6    1   33   42   42   22]\n",
            " [   6    8   15  897    0   26    1   11   34   12]\n",
            " [   6   15   29   13  553    0   58   25    2  281]\n",
            " [  25   51   13  231    5  472   33   10   10   42]\n",
            " [  27    9   38    5    2    3  856    1    2   15]\n",
            " [   4   20   21   17    1    4    0  886    3   72]\n",
            " [   9   33   40  189    3   33   12   40  560   55]\n",
            " [   6    8    3   37    8    8    3   86    4  846]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [12 20 21 30  6 15 18 23 12 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.583 s \n",
            "\n",
            "Accuracy rate for 79.770000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92       980\n",
            "           1       0.88      0.97      0.92      1135\n",
            "           2       0.82      0.76      0.79      1032\n",
            "           3       0.67      0.89      0.76      1010\n",
            "           4       0.96      0.59      0.73       982\n",
            "           5       0.76      0.65      0.70       892\n",
            "           6       0.86      0.88      0.87       958\n",
            "           7       0.81      0.83      0.82      1028\n",
            "           8       0.87      0.58      0.70       974\n",
            "           9       0.62      0.85      0.72      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.82      0.79      0.79     10000\n",
            "weighted avg       0.82      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    1    2   14    0   19   17    0   10    8]\n",
            " [   0 1099    6   12    0    9    0    2    6    1]\n",
            " [  17   15  789   72    6    6   30   39   37   21]\n",
            " [   3    6   16  898    0   40    1   14   17   15]\n",
            " [   4   20   28   16  575    1   41   30    2  265]\n",
            " [  26   50   14  143    1  579   27    9    5   38]\n",
            " [  25    9   47    6    3   15  843    1    2    7]\n",
            " [   4   18   17   13    1    2    0  856    2  115]\n",
            " [   7   28   43  144    3   81   13   33  569   53]\n",
            " [   4    7    3   32   11   11    3   76    2  860]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59825, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [17 21 24 31  9 17 19 25 15 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.061 s \n",
            "\n",
            "Accuracy rate for 81.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.89      0.98      0.93      1135\n",
            "           2       0.83      0.78      0.81      1032\n",
            "           3       0.73      0.87      0.80      1010\n",
            "           4       0.90      0.63      0.74       982\n",
            "           5       0.81      0.65      0.72       892\n",
            "           6       0.88      0.88      0.88       958\n",
            "           7       0.84      0.84      0.84      1028\n",
            "           8       0.89      0.68      0.77       974\n",
            "           9       0.62      0.87      0.73      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.81      0.81     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    1    3   10    6    8    5    2    6    6]\n",
            " [   0 1112    4    6    0    9    0    0    3    1]\n",
            " [  23   12  805   48   18    6   33   36   27   24]\n",
            " [   5    8   13  882    0   44    2   12   29   15]\n",
            " [   1   19   17    9  618    1   38   13    2  264]\n",
            " [  28   46   13  114   11  582   21   10    9   58]\n",
            " [  32   10   48    5    3   14  840    1    2    3]\n",
            " [   3   17   19   15    2    3    0  859    1  109]\n",
            " [   7   19   37   91    3   39   12   45  661   60]\n",
            " [   8    4    8   24   23   10    2   43    6  881]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 3 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [21 23 24 32 13 20 20 30 15 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.481 s \n",
            "\n",
            "Accuracy rate for 83.590000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.84      0.76      0.79      1032\n",
            "           3       0.76      0.89      0.82      1010\n",
            "           4       0.86      0.79      0.83       982\n",
            "           5       0.83      0.68      0.75       892\n",
            "           6       0.90      0.86      0.88       958\n",
            "           7       0.87      0.83      0.85      1028\n",
            "           8       0.89      0.68      0.77       974\n",
            "           9       0.68      0.89      0.77      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.84      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    2    5    1    4    4    2    6    3]\n",
            " [   0 1112    3    7    0   10    1    0    1    1]\n",
            " [  35   12  782   47   20    4   37   33   26   36]\n",
            " [   5    7   11  894    1   38    2   10   28   14]\n",
            " [   1   17    9    7  776    1   17    4    4  146]\n",
            " [  28   35   14  100   34  607   18    8    6   42]\n",
            " [  30    7   58    3   13   14  827    0    1    5]\n",
            " [   4   23   19    8   12    4    0  853    1  104]\n",
            " [   7   21   35   86    8   44   10   32  662   69]\n",
            " [   6    5    3   20   34    8    0   33    6  894]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59775, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 24 28 34 16 24 24 33 17 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.739 s \n",
            "\n",
            "Accuracy rate for 84.130000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.83      0.77      0.80      1032\n",
            "           3       0.75      0.89      0.81      1010\n",
            "           4       0.85      0.82      0.83       982\n",
            "           5       0.81      0.69      0.75       892\n",
            "           6       0.90      0.88      0.89       958\n",
            "           7       0.90      0.82      0.86      1028\n",
            "           8       0.89      0.69      0.78       974\n",
            "           9       0.71      0.86      0.78      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    1    2    2    2    4    5    2    6    1]\n",
            " [   0 1109    3    8    0    9    0    0    5    1]\n",
            " [  35   10  795   53   18    3   45   21   25   27]\n",
            " [   3    5    8  898    2   42    1    8   27   16]\n",
            " [   2   17   17    3  807    6   19    3    3  105]\n",
            " [  20   36   14  118   36  617   14    6   12   19]\n",
            " [  26    6   52    6    3   18  843    0    2    2]\n",
            " [   3   21   23    6   19    6    0  848    1  101]\n",
            " [   8   10   42   86    7   40   11   21  674   75]\n",
            " [   8    6    3   17   57   17    0   29    5  867]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [23 28 32 35 19 26 27 35 19 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.611 s \n",
            "\n",
            "Accuracy rate for 84.810000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.82      0.81      0.81      1032\n",
            "           3       0.79      0.87      0.83      1010\n",
            "           4       0.83      0.85      0.84       982\n",
            "           5       0.81      0.70      0.75       892\n",
            "           6       0.92      0.87      0.90       958\n",
            "           7       0.91      0.80      0.85      1028\n",
            "           8       0.86      0.74      0.80       974\n",
            "           9       0.74      0.86      0.79      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    1    2    2    3    5    4    2    4    0]\n",
            " [   0 1107    2    7    0    8    0    0   10    1]\n",
            " [  33    8  834   37   25    5   18   21   35   16]\n",
            " [   3    5   13  880    2   40    1   10   42   14]\n",
            " [   2   16   13    1  835    5   27    4    2   77]\n",
            " [  21   37   25  115   26  620   11    5   12   20]\n",
            " [  16    6   64    3    4   24  838    0    3    0]\n",
            " [   3   20   22    6   34    5    0  821    2  115]\n",
            " [   8   11   43   55    5   33   13   16  725   65]\n",
            " [   6    6    4   14   71   16    0   24    4  864]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59725, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [25 33 33 38 27 28 27 36 19 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.698 s \n",
            "\n",
            "Accuracy rate for 84.630000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.82      0.80      0.81      1032\n",
            "           3       0.79      0.87      0.83      1010\n",
            "           4       0.79      0.87      0.83       982\n",
            "           5       0.81      0.70      0.75       892\n",
            "           6       0.94      0.87      0.90       958\n",
            "           7       0.91      0.81      0.86      1028\n",
            "           8       0.87      0.73      0.79       974\n",
            "           9       0.75      0.84      0.79      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    1    2    4    4    7    4    2    3    0]\n",
            " [   0 1112    1    4    1    9    0    0    7    1]\n",
            " [  36    7  825   39   30    6   18   22   33   16]\n",
            " [   4   12   13  875    3   40    1    9   39   14]\n",
            " [   1   16    9    1  853    1   16    4    3   78]\n",
            " [  25   26   20  112   44  628    6    5   10   16]\n",
            " [  17    6   65    2    9   27  830    0    2    0]\n",
            " [   2   28   20    5   41    4    0  833    2   93]\n",
            " [   9   19   49   44   10   42   10   17  710   64]\n",
            " [   6    6    4   15   89   15    0   26    4  844]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [27 36 34 42 30 30 30 43 19 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.778 s \n",
            "\n",
            "Accuracy rate for 85.080000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.82      0.80      0.81      1032\n",
            "           3       0.80      0.86      0.83      1010\n",
            "           4       0.80      0.88      0.84       982\n",
            "           5       0.81      0.71      0.76       892\n",
            "           6       0.92      0.87      0.90       958\n",
            "           7       0.90      0.86      0.88      1028\n",
            "           8       0.88      0.73      0.80       974\n",
            "           9       0.78      0.82      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    1    4    4    2    8    7    4    2    0]\n",
            " [   0 1110    2    6    1    8    0    0    7    1]\n",
            " [  38    7  826   43   29    4   25   13   33   14]\n",
            " [   7   11   14  871    4   39    1   12   38   13]\n",
            " [   2   14    6    1  867    1   19    6    2   64]\n",
            " [  24   24   21  109   38  633    8   10   10   15]\n",
            " [  15    4   65    2   10   26  834    0    2    0]\n",
            " [   5   22   21    4   28    2    0  879    1   66]\n",
            " [  11   22   47   39    9   47   10   16  709   64]\n",
            " [   5    6    5   15   91   15    0   37    4  831]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59675, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [28 37 40 45 31 31 35 46 21 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.296 s \n",
            "\n",
            "Accuracy rate for 85.960000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.83      0.84      0.84      1032\n",
            "           3       0.78      0.87      0.83      1010\n",
            "           4       0.83      0.89      0.86       982\n",
            "           5       0.83      0.71      0.76       892\n",
            "           6       0.94      0.88      0.91       958\n",
            "           7       0.89      0.88      0.88      1028\n",
            "           8       0.89      0.73      0.80       974\n",
            "           9       0.79      0.82      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    1    5    4    4    7    6    2    3    0]\n",
            " [   0 1105    4    8    1    8    0    0    8    1]\n",
            " [  35    5  870   39   24    6    9   15   22    7]\n",
            " [   7    7   12  882    2   37    1   15   34   13]\n",
            " [   1   14    7    1  874    1   17    5    2   60]\n",
            " [  24   28   18  112   33  632    9   10   10   16]\n",
            " [  17    3   55    3    6   24  847    0    2    1]\n",
            " [   5   19   21    3   17    2    0  900    1   60]\n",
            " [   9   19   52   52   15   35   11   14  709   58]\n",
            " [   5    6    4   20   82   11    0   49    3  829]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [31 39 42 51 34 32 37 48 23 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.068 s \n",
            "\n",
            "Accuracy rate for 86.290000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.82      0.84      0.83      1032\n",
            "           3       0.78      0.89      0.83      1010\n",
            "           4       0.82      0.89      0.86       982\n",
            "           5       0.85      0.71      0.78       892\n",
            "           6       0.93      0.88      0.90       958\n",
            "           7       0.91      0.88      0.90      1028\n",
            "           8       0.90      0.73      0.81       974\n",
            "           9       0.82      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    1    6    3    3    8    7    2    3    0]\n",
            " [   0 1102    4   10    2    6    0    0    9    2]\n",
            " [  36    6  867   37   23    6   11   15   24    7]\n",
            " [   5    7   16  895    2   31    0   13   24   17]\n",
            " [   1   17    4    1  873    1   27    6    3   49]\n",
            " [  23   25   17  118   32  637    9    9    8   14]\n",
            " [  18    3   65    2    6   20  840    2    2    0]\n",
            " [   5   18   19    6   18    2    1  907    2   50]\n",
            " [  10   15   58   56   15   26   13   17  714   50]\n",
            " [   6    5    4   22   85   13    0   23    4  847]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [35 43 43 53 36 35 40 51 25 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.905 s \n",
            "\n",
            "Accuracy rate for 86.570000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.84      0.83      0.84      1032\n",
            "           3       0.78      0.88      0.83      1010\n",
            "           4       0.83      0.89      0.86       982\n",
            "           5       0.83      0.73      0.77       892\n",
            "           6       0.93      0.88      0.91       958\n",
            "           7       0.91      0.89      0.90      1028\n",
            "           8       0.90      0.75      0.82       974\n",
            "           9       0.82      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    1    5    3    6    6    8    4    3    0]\n",
            " [   0 1100    3   11    0    7    0    0   12    2]\n",
            " [  35    9  860   43   23    7   10   16   22    7]\n",
            " [   8    9   15  892    0   35    2   14   21   14]\n",
            " [   1   15    4    2  878    2   20    6    3   51]\n",
            " [  21   28   15  108   31  650    8    8   10   13]\n",
            " [  18    3   59    2    7   24  843    1    1    0]\n",
            " [   1   24   19    8   15    2    0  912    2   45]\n",
            " [   8   13   40   54   10   37   13   16  735   48]\n",
            " [   5    5    4   20   85   17    0   25    5  843]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [36 46 46 54 41 37 41 55 27 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.225 s \n",
            "\n",
            "Accuracy rate for 87.180000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94       980\n",
            "           1       0.91      0.96      0.94      1135\n",
            "           2       0.84      0.85      0.84      1032\n",
            "           3       0.80      0.89      0.84      1010\n",
            "           4       0.84      0.90      0.87       982\n",
            "           5       0.84      0.75      0.79       892\n",
            "           6       0.93      0.88      0.91       958\n",
            "           7       0.91      0.89      0.90      1028\n",
            "           8       0.89      0.76      0.82       974\n",
            "           9       0.84      0.85      0.84      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    1    5    3    6    8    7    3    3    0]\n",
            " [   0 1092    4   11    0    8    0    0   18    2]\n",
            " [  30    9  873   37   25    7   11   14   19    7]\n",
            " [   8    8   14  897    3   30    2   11   26   11]\n",
            " [   1   15    4    1  881    1   17    7    3   52]\n",
            " [  18   28   14   91   31  669    8   10   12   11]\n",
            " [  21    3   56    1    6   23  846    1    1    0]\n",
            " [   2   24   19    7   15    1    0  915    2   43]\n",
            " [   8   12   42   48   11   38   14   19  741   41]\n",
            " [   5    5    5   20   72   15    0   24    3  860]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['5' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59575, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [40 49 48 56 43 37 43 61 30 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.120 s \n",
            "\n",
            "Accuracy rate for 87.360000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.84      0.85      0.85      1032\n",
            "           3       0.81      0.89      0.85      1010\n",
            "           4       0.84      0.89      0.86       982\n",
            "           5       0.84      0.75      0.79       892\n",
            "           6       0.92      0.87      0.90       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.90      0.77      0.83       974\n",
            "           9       0.85      0.85      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    5    3    8    8    8    3    4    0]\n",
            " [   0 1108    5    7    0    4    0    0   10    1]\n",
            " [  30    7  880   34   26    7   11   13   19    5]\n",
            " [   7    5   15  899    2   30    2   14   24   12]\n",
            " [   2   16    9    1  870    1   27    4    3   49]\n",
            " [  19   26   14   99   28  666    8   10   12   10]\n",
            " [  19    5   53    0   16   23  838    2    2    0]\n",
            " [   2   19   19    4   14    1    0  926    3   40]\n",
            " [   7   14   43   50   10   38   12   15  752   33]\n",
            " [   4    6    3   19   67   16    0   33    4  857]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [44 52 49 56 44 40 44 63 34 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.911 s \n",
            "\n",
            "Accuracy rate for 87.460000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.84      0.85      0.85      1032\n",
            "           3       0.82      0.89      0.85      1010\n",
            "           4       0.84      0.88      0.86       982\n",
            "           5       0.84      0.75      0.79       892\n",
            "           6       0.93      0.87      0.90       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.90      0.78      0.83       974\n",
            "           9       0.84      0.87      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    1    5    3    6   11    8    4    4    0]\n",
            " [   0 1108    5    8    0    3    0    0   10    1]\n",
            " [  29    7  879   34   26    6   11   13   21    6]\n",
            " [   7    5   15  899    2   30    2   14   24   12]\n",
            " [   1   18    8    1  868    1   24    4    5   52]\n",
            " [  16   26   14   95   31  665    8   11   12   14]\n",
            " [  19    5   53    0   16   24  837    2    2    0]\n",
            " [   2   21   17    4   15    0    0  921    3   45]\n",
            " [   7   13   42   42   11   39   13   14  757   36]\n",
            " [   3    7    3   15   62   13    0   26    6  874]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59525, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [46 57 52 57 46 42 48 65 35 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.169 s \n",
            "\n",
            "Accuracy rate for 87.720000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.89      0.99      0.94      1135\n",
            "           2       0.85      0.85      0.85      1032\n",
            "           3       0.85      0.87      0.86      1010\n",
            "           4       0.84      0.87      0.86       982\n",
            "           5       0.85      0.78      0.81       892\n",
            "           6       0.93      0.87      0.90       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.90      0.80      0.84       974\n",
            "           9       0.84      0.87      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.87      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    5    3    3   12    6    2    6    0]\n",
            " [   0 1120    4    4    0    2    0    0    5    0]\n",
            " [  31   11  879   30   22    6    9   14   23    7]\n",
            " [   8   25   12  878    2   31    2   14   25   13]\n",
            " [   2   21   13    0  850    1   27    5    4   59]\n",
            " [  15   21   18   67   28  695    8   11   15   14]\n",
            " [  19    6   59    0   18   20  832    1    3    0]\n",
            " [   2   22   18    3   14    0    0  921    3   45]\n",
            " [   5   22   27   33   12   37   11   16  776   35]\n",
            " [   3    7    3   15   57   15    0   24    7  878]]\n",
            "--------------------------------\n",
            "final active learning accuracies [49.04, 62.35000000000001, 68.04, 73.72999999999999, 76.63, 78.67, 79.77, 81.73, 83.59, 84.13000000000001, 84.81, 84.63000000000001, 85.08, 85.96000000000001, 86.29, 86.57000000000001, 87.18, 87.36, 87.46000000000001, 87.72]\n",
            "saved Active-learning-experiment-4.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-4.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 5, using model = SvmModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [1 3 0 0 0 0 0 3 2 1] [0 1 7 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.927 s \n",
            "\n",
            "Accuracy rate for 32.900000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.84      0.40       980\n",
            "           1       0.40      0.99      0.57      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.34      0.70      0.46      1028\n",
            "           8       0.29      0.52      0.37       974\n",
            "           9       0.56      0.12      0.20      1009\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.19      0.32      0.20     10000\n",
            "weighted avg       0.19      0.33      0.21     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 819   33    0    0    0    0    0   20  108    0]\n",
            " [   0 1120    0    0    0    0    0    6    9    0]\n",
            " [ 258  342    0    0    0    0    0  211  219    2]\n",
            " [ 143  324    0    0    0    0    0  260  283    0]\n",
            " [ 445  161    0    0    0    0    0  231  111   34]\n",
            " [ 244  235    0    0    0    0    0  149  260    4]\n",
            " [ 462  281    0    0    0    0    0   55  160    0]\n",
            " [ 190   57    0    0    0    0    0  721    6   54]\n",
            " [ 143  184    0    0    0    0    0  136  509    2]\n",
            " [ 421   60    0    0    0    0    0  317   90  121]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['7' '0' '1' ... '7' '0' '8']\n",
            "probabilities: (59990, 5) \n",
            " [1 2 2 ... 1 2 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [1 6 0 2 3 1 0 4 2 1] [0 1 3 4 5 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.803 s \n",
            "\n",
            "Accuracy rate for 42.530000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.72      0.52       980\n",
            "           1       0.50      0.99      0.67      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.30      0.43      0.35      1010\n",
            "           4       0.34      0.74      0.46       982\n",
            "           5       0.36      0.02      0.04       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.51      0.77      0.61      1028\n",
            "           8       0.53      0.40      0.46       974\n",
            "           9       0.86      0.06      0.11      1009\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.38      0.41      0.32     10000\n",
            "weighted avg       0.38      0.43      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 708   24    0  170   39    4    0   15   20    0]\n",
            " [   1 1121    0    2    0    0    0    4    7    0]\n",
            " [ 202  318    0  194   67    0    0  105  146    0]\n",
            " [ 131  214    0  432  127    0    0   56   50    0]\n",
            " [ 101   44    0   73  726    3    0   25    8    2]\n",
            " [  83  141    0  250  210   20    0  144   42    2]\n",
            " [ 419  129    0   74  272    0    0    6   58    0]\n",
            " [  16   62    0   35  111    4    0  793    1    6]\n",
            " [  50  150    0  100  175   12    0   96  391    0]\n",
            " [  25   29    0  118  427   13    0  321   14   62]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['3' '0' '4' ... '7' '0' '7']\n",
            "probabilities: (59980, 8) \n",
            " [5 5 1 ... 5 5 5]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [2 8 0 3 3 2 2 5 3 2] [0 1 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.652 s \n",
            "\n",
            "Accuracy rate for 53.580000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.89      0.66       980\n",
            "           1       0.70      0.97      0.82      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.53      0.42      0.47      1010\n",
            "           4       0.59      0.63      0.61       982\n",
            "           5       0.79      0.18      0.29       892\n",
            "           6       0.60      0.60      0.60       958\n",
            "           7       0.53      0.81      0.64      1028\n",
            "           8       0.37      0.73      0.49       974\n",
            "           9       0.25      0.06      0.10      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.49      0.53      0.47     10000\n",
            "weighted avg       0.49      0.54      0.47     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[ 876    7    0   34    7    4   33    3   14    2]\n",
            " [   1 1105    0    3    0    0   10    2   14    0]\n",
            " [ 152  115    0   67   18    0  260   71  291   58]\n",
            " [ 127   76    0  425   42    0   29   35  261   15]\n",
            " [  44   35    0   10  615   12   15   84  145   22]\n",
            " [ 162   77    0  139   89  158   20   56  172   19]\n",
            " [ 246   23    0    4   78    0  575    2   29    1]\n",
            " [   3   60    0    6   41   10    0  828   13   67]\n",
            " [  52   46    0   77   29    3   17   32  712    6]\n",
            " [  22   24    0   36  125   13    1  446  278   64]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['3' '0' '9' ... '7' '6' '8']\n",
            "probabilities: (59970, 9) \n",
            " [2 2 5 ... 6 3 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 3 10  1  4  3  3  4  6  4  2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.462 s \n",
            "\n",
            "Accuracy rate for 57.120000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.85      0.75       980\n",
            "           1       0.71      0.97      0.82      1135\n",
            "           2       0.95      0.11      0.20      1032\n",
            "           3       0.54      0.41      0.47      1010\n",
            "           4       0.60      0.56      0.58       982\n",
            "           5       0.41      0.37      0.39       892\n",
            "           6       0.55      0.80      0.65       958\n",
            "           7       0.53      0.84      0.65      1028\n",
            "           8       0.48      0.71      0.57       974\n",
            "           9       0.43      0.05      0.09      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.59      0.57      0.52     10000\n",
            "weighted avg       0.59      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 832    3    1   20    6   27   83    3    3    2]\n",
            " [   0 1098    0   19    1    0   11    2    4    0]\n",
            " [  57  120  117   66   18    2  288  108  247    9]\n",
            " [  88   64    2  418   18   35   95   77  208    5]\n",
            " [   3   40    0   12  547  128   36  123   79   14]\n",
            " [ 169   65    1  110   59  332   71   25   57    3]\n",
            " [  36   17    0    2  121    5  763    9    5    0]\n",
            " [   2   57    0   10   19   35    0  864    9   32]\n",
            " [  48   52    0   59   24   23   43   32  690    3]\n",
            " [  17   35    2   61  106  215    3  386  133   51]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['3' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59960, 10) \n",
            " [3 6 7 ... 7 6 8]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 3 12  2  4  4  6  5  7  4  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.192 s \n",
            "\n",
            "Accuracy rate for 64.660000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.82      0.77       980\n",
            "           1       0.79      0.98      0.87      1135\n",
            "           2       0.83      0.19      0.31      1032\n",
            "           3       0.69      0.40      0.50      1010\n",
            "           4       0.60      0.76      0.67       982\n",
            "           5       0.48      0.72      0.58       892\n",
            "           6       0.61      0.89      0.72       958\n",
            "           7       0.66      0.80      0.72      1028\n",
            "           8       0.63      0.66      0.64       974\n",
            "           9       0.56      0.25      0.34      1009\n",
            "\n",
            "    accuracy                           0.65     10000\n",
            "   macro avg       0.66      0.65      0.61     10000\n",
            "weighted avg       0.66      0.65      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 804    2    5   10    2   58   88    3    2    6]\n",
            " [   0 1112    0    5    0    4    9    3    2    0]\n",
            " [  37  104  200   51   15   18  315   77  191   24]\n",
            " [  79   32    5  400   13  230   47   63  132    9]\n",
            " [   2   16   10    3  747   43   34   42   16   69]\n",
            " [ 108   27    4   27   33  639   27   18    5    4]\n",
            " [  10   15    3    2   47   24  850    5    2    0]\n",
            " [   2   41    2   10   44   36    0  824    6   63]\n",
            " [  41   49    1   54   34   91   22   22  640   20]\n",
            " [  12   10   10   17  311  178    6  199   16  250]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59950, 10) \n",
            " [5 5 5 ... 5 6 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 4 12  3  5  5  6  6  9  5  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.142 s \n",
            "\n",
            "Accuracy rate for 69.740000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.91      0.82       980\n",
            "           1       0.78      0.98      0.87      1135\n",
            "           2       0.83      0.32      0.47      1032\n",
            "           3       0.68      0.69      0.68      1010\n",
            "           4       0.63      0.77      0.69       982\n",
            "           5       0.62      0.59      0.60       892\n",
            "           6       0.70      0.86      0.77       958\n",
            "           7       0.68      0.82      0.74      1028\n",
            "           8       0.66      0.62      0.64       974\n",
            "           9       0.66      0.39      0.49      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.69      0.68     10000\n",
            "weighted avg       0.70      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 887    1    3    5    2   43   34    3    1    1]\n",
            " [   0 1112    1   14    0    4    2    1    1    0]\n",
            " [  83  135  334   74   23    9  121   52  187   14]\n",
            " [  18   22   10  692    9  110   25   28   80   16]\n",
            " [   8   15   11    6  753   13   55   49   12   60]\n",
            " [  97   29    6  115   34  527   60   16    3    5]\n",
            " [  12   16   17    0   55   27  824    4    3    0]\n",
            " [   3   36    5   14   43   22    1  842    5   57]\n",
            " [  50   47    5   75   26   51   42   18  607   53]\n",
            " [  20    7    9   23  252   47   11  229   15  396]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['5' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59940, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 5 12  4  7  7  7  9  9  5  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.058 s \n",
            "\n",
            "Accuracy rate for 71.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84       980\n",
            "           1       0.81      0.98      0.88      1135\n",
            "           2       0.84      0.47      0.60      1032\n",
            "           3       0.69      0.81      0.75      1010\n",
            "           4       0.61      0.80      0.69       982\n",
            "           5       0.67      0.54      0.60       892\n",
            "           6       0.67      0.89      0.76       958\n",
            "           7       0.72      0.81      0.76      1028\n",
            "           8       0.76      0.60      0.67       974\n",
            "           9       0.66      0.37      0.47      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.72      0.71      0.70     10000\n",
            "weighted avg       0.72      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    1    0    2    1   29   82    2    1    1]\n",
            " [   0 1111    2   12    1    5    2    0    2    0]\n",
            " [  67  113  483   55   16    4  119   40  124   11]\n",
            " [  11   12   13  820   11   49   14   29   36   15]\n",
            " [   2   13   16    3  783   14   58   28    6   59]\n",
            " [  55   32    7  170   37  481   80   17    5    8]\n",
            " [   6    8   22    1   51   17  850    2    1    0]\n",
            " [   3   36   14    9   44   24    1  836    6   55]\n",
            " [  53   45   10  100   33   40   50   14  583   46]\n",
            " [  21    6    9   19  299   57   22  196    8  372]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['5' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59930, 10) \n",
            " [5 0 9 ... 5 6 6]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 5 13  7  7  8  8 10 10  7  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.741 s \n",
            "\n",
            "Accuracy rate for 73.270000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       980\n",
            "           1       0.82      0.97      0.89      1135\n",
            "           2       0.85      0.60      0.70      1032\n",
            "           3       0.70      0.78      0.74      1010\n",
            "           4       0.63      0.78      0.70       982\n",
            "           5       0.67      0.56      0.61       892\n",
            "           6       0.71      0.89      0.79       958\n",
            "           7       0.68      0.83      0.75      1028\n",
            "           8       0.77      0.66      0.71       974\n",
            "           9       0.68      0.34      0.46      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 852    1    2    2    2   37   81    2    1    0]\n",
            " [   0 1104    6   14    1    6    2    0    2    0]\n",
            " [  42  100  622   36   15   17   57   37   95   11]\n",
            " [   7   15   31  789    6   49   12   29   60   12]\n",
            " [   2   13    8    1  765   10   69   61    5   48]\n",
            " [  51   26   13  173   39  500   61   14    7    8]\n",
            " [   8    9   20    2   45   18  855    1    0    0]\n",
            " [   3   36   12   10   38   14    1  854    5   55]\n",
            " [  44   35   14   83   26   45   42   16  641   28]\n",
            " [  20    7    8   21  272   48   27  247   14  345]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['5' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 9 ... 5 6 5]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 5 13  7  7  9 11 11 12  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.555 s \n",
            "\n",
            "Accuracy rate for 75.630000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       980\n",
            "           1       0.84      0.97      0.90      1135\n",
            "           2       0.85      0.60      0.70      1032\n",
            "           3       0.73      0.77      0.75      1010\n",
            "           4       0.74      0.76      0.75       982\n",
            "           5       0.66      0.62      0.64       892\n",
            "           6       0.72      0.89      0.80       958\n",
            "           7       0.76      0.76      0.76      1028\n",
            "           8       0.79      0.64      0.71       974\n",
            "           9       0.65      0.67      0.66      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 816    1    3    1    1   77   76    1    0    4]\n",
            " [   0 1101    5   13    0    8    2    0    2    4]\n",
            " [  40   94  619   36   16   24   61   36   94   12]\n",
            " [   7   12   28  777    7   55   11   22   56   35]\n",
            " [   2   12    8    0  751    4   53   47    4  101]\n",
            " [  40   14    7  144   30  555   61    7    5   29]\n",
            " [   7    7   21    1   44   23  855    0    0    0]\n",
            " [   3   33   13    6   39   13    1  784    5  131]\n",
            " [  43   34   14   76   17   56   44   14  628   48]\n",
            " [  20    2    9   15  112   29   24  115    6  677]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['5' '0' '9' ... '5' '6' '6']\n",
            "probabilities: (59910, 10) \n",
            " [5 0 9 ... 5 6 5]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7 14  9  8  9 13 11 13  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.308 s \n",
            "\n",
            "Accuracy rate for 76.980000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       980\n",
            "           1       0.85      0.97      0.91      1135\n",
            "           2       0.83      0.64      0.73      1032\n",
            "           3       0.72      0.80      0.76      1010\n",
            "           4       0.75      0.76      0.76       982\n",
            "           5       0.72      0.64      0.68       892\n",
            "           6       0.76      0.89      0.82       958\n",
            "           7       0.75      0.79      0.77      1028\n",
            "           8       0.78      0.64      0.70       974\n",
            "           9       0.69      0.65      0.67      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.77      0.76     10000\n",
            "weighted avg       0.77      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 879    1    2    2    1   40   50    2    1    2]\n",
            " [   0 1102    1   14    0    9    1    0    3    5]\n",
            " [  45   85  662   47   13   22   46   29   75    8]\n",
            " [  11   10   21  804    4   47   10   24   54   25]\n",
            " [   7   12    8    1  746    1   52   58    5   92]\n",
            " [  49   14   13  134   28  571   54    5    9   15]\n",
            " [  11   10   24    1   41   22  849    0    0    0]\n",
            " [   4   28   15    6   33    8    1  814    8  111]\n",
            " [  42   36   37   89   17   51   42    9  620   31]\n",
            " [  22    2   11   14  109   26   19  140   15  651]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 9 ... 5 6 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 8 14 11  9  9 14 11 16  9  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.998 s \n",
            "\n",
            "Accuracy rate for 77.400000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.86       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.82      0.65      0.73      1032\n",
            "           3       0.76      0.78      0.77      1010\n",
            "           4       0.74      0.72      0.73       982\n",
            "           5       0.73      0.69      0.71       892\n",
            "           6       0.79      0.88      0.83       958\n",
            "           7       0.75      0.80      0.78      1028\n",
            "           8       0.76      0.60      0.67       974\n",
            "           9       0.69      0.68      0.69      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.77      0.77     10000\n",
            "weighted avg       0.77      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    1    4    0    1   25   32    3    0    6]\n",
            " [   0 1101    1   10    0    7    1    0    8    7]\n",
            " [  69   76  675   36   13   16   37   24   75   11]\n",
            " [   9   10   21  789    2   65    7   19   67   21]\n",
            " [   9   11    9    2  711    3   44   67    8  118]\n",
            " [  48   12    9  101   31  615   48    7    1   20]\n",
            " [  12    8   27    1   43   22  842    1    0    2]\n",
            " [   7   27   22    3   38    1    1  825   13   91]\n",
            " [  43   32   49   83   22   65   46   14  587   33]\n",
            " [  19    2    8   13  103   21    9  134   13  687]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['5' '0' '4' ... '5' '6' '6']\n",
            "probabilities: (59890, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [10 15 12  9  9 16 11 16 11 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.753 s \n",
            "\n",
            "Accuracy rate for 78.440000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.81      0.66      0.73      1032\n",
            "           3       0.76      0.78      0.77      1010\n",
            "           4       0.77      0.70      0.73       982\n",
            "           5       0.72      0.70      0.71       892\n",
            "           6       0.81      0.87      0.84       958\n",
            "           7       0.88      0.78      0.83      1028\n",
            "           8       0.74      0.63      0.68       974\n",
            "           9       0.68      0.80      0.73      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    1    8    0    1   26   22    1    1    4]\n",
            " [   0 1101    1   11    0    7    1    0   10    4]\n",
            " [  70   71  680   36   13   15   30   17   87   13]\n",
            " [  13   10   16  787    2   70    9   18   65   20]\n",
            " [  11   11   17    2  688    4   40   24    8  177]\n",
            " [  47   13    7  101   29  625   45    9    4   12]\n",
            " [  11    6   36    2   40   31  830    1    0    1]\n",
            " [   6   28   22    3   28    1    1  801   18  120]\n",
            " [  47   37   41   79   19   66   37   10  613   25]\n",
            " [  21    2   13   13   74   19   12   32   20  803]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59880, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [10 17 12 11 10 18 13 16 11 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.375 s \n",
            "\n",
            "Accuracy rate for 78.470000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.82      0.66      0.73      1032\n",
            "           3       0.76      0.79      0.78      1010\n",
            "           4       0.77      0.70      0.73       982\n",
            "           5       0.72      0.72      0.72       892\n",
            "           6       0.79      0.87      0.83       958\n",
            "           7       0.88      0.78      0.83      1028\n",
            "           8       0.75      0.61      0.67       974\n",
            "           9       0.68      0.79      0.73      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    1    8    1    1   27   23    1    0    3]\n",
            " [   0 1102    1   10    0    8    1    0   10    3]\n",
            " [  68   71  678   38   13   15   32   18   86   13]\n",
            " [  12    9   12  802    3   64    8   16   60   24]\n",
            " [   8   12   18    2  691    8   44   25    8  166]\n",
            " [  47   11    7  100   27  641   36    7    1   15]\n",
            " [   9    7   33    2   44   31  830    1    0    1]\n",
            " [   6   30   21    3   27    1    1  803   17  119]\n",
            " [  48   35   42   83   22   70   49   10  592   23]\n",
            " [  17    2   10   11   75   25   25   31   20  793]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59870, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [12 18 14 11 10 20 13 19 11 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.146 s \n",
            "\n",
            "Accuracy rate for 79.150000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.81      0.67      0.74      1032\n",
            "           3       0.78      0.79      0.78      1010\n",
            "           4       0.76      0.70      0.73       982\n",
            "           5       0.73      0.76      0.75       892\n",
            "           6       0.80      0.86      0.83       958\n",
            "           7       0.88      0.79      0.83      1028\n",
            "           8       0.75      0.61      0.67       974\n",
            "           9       0.70      0.79      0.74      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    1   10    2    1   17   22    1    0    3]\n",
            " [   0 1102    1   10    0    8    1    0   10    3]\n",
            " [  63   71  693   35   13   12   26   20   86   13]\n",
            " [  11    7   19  797    3   71    6   16   58   22]\n",
            " [   6   12   17    2  689    8   43   36    9  160]\n",
            " [  39   10    7   75   26  678   37    7    1   12]\n",
            " [  11    6   35    3   44   29  828    1    0    1]\n",
            " [   5   29   19    3   27    3    1  812   16  113]\n",
            " [  46   32   43   84   23   73   48    9  593   23]\n",
            " [  15    2    8   11   76   27   26   24   20  800]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59860, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [14 19 14 12 13 21 13 19 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.884 s \n",
            "\n",
            "Accuracy rate for 79.230000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.82      0.67      0.74      1032\n",
            "           3       0.79      0.78      0.78      1010\n",
            "           4       0.75      0.73      0.74       982\n",
            "           5       0.74      0.75      0.75       892\n",
            "           6       0.81      0.86      0.83       958\n",
            "           7       0.89      0.79      0.84      1028\n",
            "           8       0.75      0.60      0.67       974\n",
            "           9       0.69      0.80      0.74      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    1   10    1    1   17   21    1    0    3]\n",
            " [   0 1104    1    9    2    7    1    0    9    2]\n",
            " [  60   71  692   35   13   14   26   19   86   16]\n",
            " [  15    9   19  789    3   66    6   16   58   29]\n",
            " [   3   11   19    2  712    3   33   26    6  167]\n",
            " [  45   13    7   69   23  672   37    7    1   18]\n",
            " [  14    6   33    2   49   29  823    1    0    1]\n",
            " [   4   30   19    2   29    3    1  814   18  108]\n",
            " [  46   35   43   85   34   71   43    8  586   23]\n",
            " [  14    2    4   11   80   26   25   24   17  806]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [17 20 15 13 13 24 13 19 12 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.849 s \n",
            "\n",
            "Accuracy rate for 79.620000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87       980\n",
            "           1       0.85      0.98      0.91      1135\n",
            "           2       0.81      0.70      0.75      1032\n",
            "           3       0.80      0.81      0.80      1010\n",
            "           4       0.77      0.71      0.74       982\n",
            "           5       0.76      0.75      0.76       892\n",
            "           6       0.82      0.86      0.84       958\n",
            "           7       0.90      0.79      0.84      1028\n",
            "           8       0.76      0.59      0.67       974\n",
            "           9       0.68      0.80      0.73      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.79      0.79     10000\n",
            "weighted avg       0.80      0.80      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    1   11    0    1   18   19    2    0    3]\n",
            " [   0 1117    1    6    1    5    1    0    4    0]\n",
            " [  62   71  723   30    8   12   18   16   84    8]\n",
            " [  13   19   14  814    3   49    8   15   49   26]\n",
            " [   4   10   23    1  696    3   31   24    6  184]\n",
            " [  48   13   10   68   21  673   38    3    2   16]\n",
            " [  14   11   36    0   45   29  821    0    0    2]\n",
            " [   4   31   18    2   23    7    1  812   17  113]\n",
            " [  54   35   51   80   34   71   40    8  578   23]\n",
            " [  13    4    8   16   76   22   25   25   17  803]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59840, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [20 23 15 14 14 24 13 20 12 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.243 s \n",
            "\n",
            "Accuracy rate for 79.870000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88       980\n",
            "           1       0.85      0.99      0.91      1135\n",
            "           2       0.82      0.70      0.76      1032\n",
            "           3       0.82      0.80      0.81      1010\n",
            "           4       0.77      0.70      0.73       982\n",
            "           5       0.78      0.75      0.76       892\n",
            "           6       0.84      0.85      0.84       958\n",
            "           7       0.87      0.79      0.83      1028\n",
            "           8       0.77      0.60      0.67       974\n",
            "           9       0.67      0.81      0.74      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.79     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    2    1    0    8   14    1    0    0]\n",
            " [   0 1118    1    5    0    4    1    0    5    1]\n",
            " [  67   73  721   27    8    9   18   20   81    8]\n",
            " [  13   18   14  812    2   48    9   19   52   23]\n",
            " [   3   10   20    0  683    1   21   32    5  207]\n",
            " [  59   12    9   63   23  668   35    4    2   17]\n",
            " [  16   10   33    1   51   27  814    5    0    1]\n",
            " [   9   29   17    4   18    4    0  813   20  114]\n",
            " [  54   39   52   69   31   73   37   12  582   25]\n",
            " [  18    4    7   13   72   17   21   25   10  822]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59830, 10) \n",
            " [5 0 9 ... 5 6 5]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [21 23 18 14 14 24 14 22 13 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.153 s \n",
            "\n",
            "Accuracy rate for 80.430000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88       980\n",
            "           1       0.85      0.99      0.91      1135\n",
            "           2       0.80      0.71      0.75      1032\n",
            "           3       0.82      0.80      0.81      1010\n",
            "           4       0.78      0.72      0.75       982\n",
            "           5       0.79      0.75      0.77       892\n",
            "           6       0.85      0.86      0.85       958\n",
            "           7       0.87      0.79      0.83      1028\n",
            "           8       0.80      0.61      0.69       974\n",
            "           9       0.69      0.82      0.75      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    0    3    1    0    8   14    1    0    0]\n",
            " [   0 1119    1    6    0    4    1    1    3    0]\n",
            " [  75   73  731   26    8    8   25   22   54   10]\n",
            " [  14   17   13  810    3   48    9   19   54   23]\n",
            " [   2    9   20    0  710    1   23   34    5  178]\n",
            " [  58   12    8   61   24  669   35    4    4   17]\n",
            " [  17   10   23    1   52   26  822    6    0    1]\n",
            " [   9   30   18    3   17    4    0  809   17  121]\n",
            " [  43   42   84   62   31   63   24   10  591   24]\n",
            " [  19    4   11   13   71   16   14   22   10  829]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59820, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [22 23 19 15 16 24 16 23 14 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.769 s \n",
            "\n",
            "Accuracy rate for 81.500000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88       980\n",
            "           1       0.86      0.99      0.92      1135\n",
            "           2       0.83      0.74      0.78      1032\n",
            "           3       0.82      0.80      0.81      1010\n",
            "           4       0.81      0.75      0.78       982\n",
            "           5       0.80      0.75      0.77       892\n",
            "           6       0.84      0.91      0.87       958\n",
            "           7       0.88      0.79      0.83      1028\n",
            "           8       0.82      0.63      0.71       974\n",
            "           9       0.70      0.81      0.75      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    3    2    1    8   18    1    0    0]\n",
            " [   0 1118    1    6    0    4    1    0    4    1]\n",
            " [  72   59  762   21    7    7   30   23   39   12]\n",
            " [  14   16   12  809    3   53   10   18   54   21]\n",
            " [   4    8   18    0  732    0   29   26    7  158]\n",
            " [  57   13   10   62   25  668   32    4    3   18]\n",
            " [  14   10   18    1   13   25  872    4    0    1]\n",
            " [   9   29   22    3   24    4    0  807   16  114]\n",
            " [  35   41   67   68   25   53   29   11  617   28]\n",
            " [  20    4    7   13   70   17   19   26   15  818]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['5' '0' '9' ... '5' '6' '2']\n",
            "probabilities: (59810, 10) \n",
            " [5 0 9 ... 5 6 2]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [23 24 20 17 16 24 18 24 14 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.091 s \n",
            "\n",
            "Accuracy rate for 81.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.96      0.88       980\n",
            "           1       0.86      0.98      0.92      1135\n",
            "           2       0.85      0.74      0.79      1032\n",
            "           3       0.79      0.83      0.81      1010\n",
            "           4       0.82      0.73      0.77       982\n",
            "           5       0.84      0.75      0.79       892\n",
            "           6       0.84      0.94      0.88       958\n",
            "           7       0.88      0.79      0.83      1028\n",
            "           8       0.83      0.60      0.70       974\n",
            "           9       0.69      0.83      0.76      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.82      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    3    2    2    7   18    4    0    0]\n",
            " [   0 1117    5    5    0    3    1    1    3    0]\n",
            " [  73   60  759   24    6    5   35   20   38   12]\n",
            " [  22   14   12  837    1   38    6   15   48   17]\n",
            " [   4    8   18    2  715    0   29   23    5  178]\n",
            " [  54   12    9   67   22  668   30    7    5   18]\n",
            " [  15    7   11    1   11   13  897    3    0    0]\n",
            " [   6   29   21    3   24    2    0  811   15  117]\n",
            " [  34   42   53  103   24   45   45   13  587   28]\n",
            " [  16    4    6   17   64   15   13   27    9  838]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 6 2]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [23 25 20 18 17 24 18 26 17 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.043 s \n",
            "\n",
            "Accuracy rate for 82.430000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.86      0.72      0.79      1032\n",
            "           3       0.83      0.82      0.82      1010\n",
            "           4       0.82      0.77      0.79       982\n",
            "           5       0.84      0.73      0.78       892\n",
            "           6       0.86      0.93      0.89       958\n",
            "           7       0.87      0.80      0.83      1028\n",
            "           8       0.76      0.67      0.71       974\n",
            "           9       0.72      0.84      0.78      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    2    2    3    7   15    3    1    0]\n",
            " [   0 1104    5    4    0    3    1    0   17    1]\n",
            " [  76   58  748   19   12    5   33   19   51   11]\n",
            " [  23   16   13  825    2   38    3   15   63   12]\n",
            " [   1    7    7    1  758    4   20   27    3  154]\n",
            " [  50   10    9   54   28  652   27   16   29   17]\n",
            " [  15    7   12    1   11   14  894    3    1    0]\n",
            " [   4   26   20    5   26    2    0  823   22  100]\n",
            " [  26   36   49   70   25   37   45   11  649   26]\n",
            " [  17    4    5   13   61   14    6   32   14  843]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['5' '0' '9' ... '5' '6' '2']\n",
            "probabilities: (59790, 10) \n",
            " [5 0 9 ... 5 6 2]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [23 26 22 18 18 24 19 28 17 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.646 s \n",
            "\n",
            "Accuracy rate for 82.790000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.86      0.73      0.79      1032\n",
            "           3       0.83      0.81      0.82      1010\n",
            "           4       0.86      0.80      0.83       982\n",
            "           5       0.85      0.74      0.79       892\n",
            "           6       0.86      0.92      0.89       958\n",
            "           7       0.81      0.80      0.81      1028\n",
            "           8       0.77      0.67      0.71       974\n",
            "           9       0.74      0.84      0.79      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.82     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    1    2    2    6   17    8    1    0]\n",
            " [   0 1104    5    4    0    3    1    1   17    0]\n",
            " [  66   59  754   19    7    5   31   27   51   13]\n",
            " [  23   15   14  821    2   36    3   25   60   11]\n",
            " [   0    6   11    1  788    1   18   37    1  119]\n",
            " [  48   11   11   55   27  657   28   11   27   17]\n",
            " [  15    7   15    1   12   14  886    7    1    0]\n",
            " [   4   25   15    5   23    3    0  827   19  107]\n",
            " [  24   34   51   69   24   39   46   12  648   27]\n",
            " [  16    4    4   14   30   10    5   60   15  851]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59780, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [24 27 22 18 20 27 19 30 18 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.271 s \n",
            "\n",
            "Accuracy rate for 83.450000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       980\n",
            "           1       0.87      0.98      0.92      1135\n",
            "           2       0.86      0.73      0.79      1032\n",
            "           3       0.84      0.82      0.83      1010\n",
            "           4       0.85      0.81      0.83       982\n",
            "           5       0.85      0.74      0.79       892\n",
            "           6       0.86      0.92      0.89       958\n",
            "           7       0.83      0.84      0.84      1028\n",
            "           8       0.79      0.68      0.73       974\n",
            "           9       0.77      0.84      0.80      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    2    2    3    4   17   11    2    0]\n",
            " [   0 1107    5    4    0    3    1    1   14    0]\n",
            " [  65   59  758   20    8    5   31   27   48   11]\n",
            " [  24   15   15  827    2   36    4   22   52   13]\n",
            " [   0    7   10    1  800    1   19   34    4  106]\n",
            " [  47   10   11   50   29  656   28   17   27   17]\n",
            " [  14    7   16    1   11   16  886    6    1    0]\n",
            " [   1   25   14    4   13    2    0  866   18   85]\n",
            " [  24   36   46   67   24   39   43   11  659   25]\n",
            " [  16    4    4   14   46    9    5   50   14  847]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59770, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [24 28 24 20 20 28 20 30 20 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.785 s \n",
            "\n",
            "Accuracy rate for 83.870000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.90       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.84      0.78      0.81      1032\n",
            "           3       0.85      0.80      0.82      1010\n",
            "           4       0.86      0.81      0.83       982\n",
            "           5       0.86      0.73      0.79       892\n",
            "           6       0.86      0.92      0.89       958\n",
            "           7       0.83      0.84      0.83      1028\n",
            "           8       0.79      0.70      0.75       974\n",
            "           9       0.77      0.84      0.80      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    3    1    3    2   17   11    2    0]\n",
            " [   0 1106    5    5    0    3    1    1   14    0]\n",
            " [  37   57  800   16    8    5   29   30   40   10]\n",
            " [  21   12   29  811    1   39    4   22   58   13]\n",
            " [   0    7   12    1  798    1   22   33    3  105]\n",
            " [  45   12   16   51   30  652   24   18   26   18]\n",
            " [  16    8   18    0   12   16  881    6    1    0]\n",
            " [   1   24   14    2   13    2    0  867   21   84]\n",
            " [  21   35   47   58   21   29   42   11  685   25]\n",
            " [  17    4    4   14   46    9    4   50   14  847]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59760, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [25 32 26 20 20 29 20 32 20 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.207 s \n",
            "\n",
            "Accuracy rate for 83.930000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       980\n",
            "           1       0.87      0.98      0.92      1135\n",
            "           2       0.83      0.81      0.82      1032\n",
            "           3       0.85      0.79      0.82      1010\n",
            "           4       0.86      0.81      0.83       982\n",
            "           5       0.87      0.72      0.79       892\n",
            "           6       0.86      0.91      0.89       958\n",
            "           7       0.83      0.84      0.84      1028\n",
            "           8       0.80      0.70      0.75       974\n",
            "           9       0.77      0.84      0.80      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    2    1    3    4   17    8    1    0]\n",
            " [   0 1108    5    5    0    2    1    1   13    0]\n",
            " [  26   55  832   12    8    4   25   29   32    9]\n",
            " [  26   13   36  801    1   36    4   22   59   12]\n",
            " [   0    7   11    1  796    1   23   35    2  106]\n",
            " [  44   13   18   51   31  646   25   18   27   19]\n",
            " [  15    9   26    0   10   15  876    6    1    0]\n",
            " [   3   24   15    2   13    0    0  868   17   86]\n",
            " [  20   39   54   54   21   29   43   12  677   25]\n",
            " [  15    4    8   14   45    8    5   50   14  846]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [26 33 27 21 22 31 20 33 21 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.940 s \n",
            "\n",
            "Accuracy rate for 83.870000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       980\n",
            "           1       0.88      0.98      0.92      1135\n",
            "           2       0.83      0.80      0.82      1032\n",
            "           3       0.84      0.80      0.82      1010\n",
            "           4       0.85      0.85      0.85       982\n",
            "           5       0.82      0.71      0.76       892\n",
            "           6       0.88      0.90      0.89       958\n",
            "           7       0.84      0.84      0.84      1028\n",
            "           8       0.80      0.68      0.74       974\n",
            "           9       0.77      0.83      0.80      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.83     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    1    2    1    2    7   11    7    1    0]\n",
            " [   0 1107    4    5    0    4    1    1   13    0]\n",
            " [  28   56  825   15    9    6   23   27   33   10]\n",
            " [  22   14   31  811    0   37    3   22   54   16]\n",
            " [   1    5    8    1  831    7   18   18    3   90]\n",
            " [  49    8   17   65   19  636   23   18   36   21]\n",
            " [  16    9   29    0   22   19  861    2    0    0]\n",
            " [   3   24   15    2   16    2    0  866   17   83]\n",
            " [  22   37   52   47   21   54   39   12  667   23]\n",
            " [  17    4    8   15   53    7    4   53   13  835]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59740, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [26 33 30 23 22 33 20 35 22 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.329 s \n",
            "\n",
            "Accuracy rate for 84.100000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.82      0.83      0.82      1032\n",
            "           3       0.83      0.82      0.83      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.79      0.73      0.76       892\n",
            "           6       0.89      0.89      0.89       958\n",
            "           7       0.85      0.84      0.84      1028\n",
            "           8       0.80      0.67      0.73       974\n",
            "           9       0.78      0.83      0.81      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    1    4    1    1   11   10    6    1    0]\n",
            " [   0 1100    3    5    0    4    1    1   21    0]\n",
            " [  33   32  859   17    8    4   16   24   33    6]\n",
            " [  18   14   24  826    1   37    5   23   48   14]\n",
            " [   2    5   19    1  825    6   17   17    4   86]\n",
            " [  43    4   14   74   11  655   22   20   28   21]\n",
            " [  16    5   42    0   16   26  850    2    1    0]\n",
            " [   3   25   13    3   18    3    0  866   18   79]\n",
            " [  22   35   65   47   18   72   31   12  649   23]\n",
            " [  18    3    9   16   53    7    3   53   12  835]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59730, 10) \n",
            " [3 0 9 ... 5 6 7]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [26 33 30 24 22 34 21 37 24 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.788 s \n",
            "\n",
            "Accuracy rate for 84.570000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.82      0.83      0.83      1032\n",
            "           3       0.85      0.82      0.83      1010\n",
            "           4       0.87      0.84      0.86       982\n",
            "           5       0.79      0.74      0.76       892\n",
            "           6       0.89      0.90      0.89       958\n",
            "           7       0.86      0.85      0.86      1028\n",
            "           8       0.81      0.69      0.74       974\n",
            "           9       0.78      0.83      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    1    6    1    1   10   10    5    1    0]\n",
            " [   0 1098    3    5    0    4    1    1   23    0]\n",
            " [  33   33  856   13    7    6   15   26   34    9]\n",
            " [  13   13   25  825    1   39    5   24   47   18]\n",
            " [   2    4   20    1  825    9   16   13    4   88]\n",
            " [  42    3   12   74    8  660   26   18   24   25]\n",
            " [  16    5   36    0   16   25  858    1    1    0]\n",
            " [   3   27   14    3   19    1    0  877   11   73]\n",
            " [  21   31   62   31   16   74   29   11  673   26]\n",
            " [  18    3    7   16   51    7    3   46   18  840]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59720, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [26 34 31 25 23 34 22 40 25 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.372 s \n",
            "\n",
            "Accuracy rate for 84.600000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.83      0.82      0.82      1032\n",
            "           3       0.85      0.82      0.84      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.79      0.74      0.76       892\n",
            "           6       0.89      0.90      0.90       958\n",
            "           7       0.86      0.85      0.85      1028\n",
            "           8       0.81      0.69      0.75       974\n",
            "           9       0.78      0.84      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    1    4    1    2   10    9    6    1    0]\n",
            " [   0 1100    4    3    0    4    1    2   21    0]\n",
            " [  35   34  850   13    6    6   17   25   37    9]\n",
            " [  12   10   29  827    1   40    4   24   46   17]\n",
            " [   1    7   18    1  822    8   18   14    5   88]\n",
            " [  42    4   14   73    9  659   26   16   24   25]\n",
            " [  16    4   32    0   16   25  863    1    1    0]\n",
            " [   2   36   14    3   16    2    0  873    7   75]\n",
            " [  20   30   60   32   14   75   27   13  675   28]\n",
            " [  17    7    4   16   52    7    2   43   16  845]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59710, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [29 34 32 26 24 34 23 40 26 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.583 s \n",
            "\n",
            "Accuracy rate for 84.540000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.82      0.83      0.82      1032\n",
            "           3       0.85      0.82      0.84      1010\n",
            "           4       0.89      0.83      0.86       982\n",
            "           5       0.79      0.74      0.76       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.86      0.85      0.85      1028\n",
            "           8       0.80      0.68      0.74       974\n",
            "           9       0.77      0.85      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    5    1    2   10    8    6    2    0]\n",
            " [   0 1096    4    3    0    4    1    2   25    0]\n",
            " [  33   31  856   14    6    6   14   25   37   10]\n",
            " [  12   10   29  829    1   39    4   23   46   17]\n",
            " [   1    7   21    1  811    7   12   15    5  102]\n",
            " [  41    3   13   73    9  657   29   17   26   24]\n",
            " [  16    4   34    0   15   25  862    1    1    0]\n",
            " [   1   33   14    4   12    1    0  875    7   81]\n",
            " [  20   34   66   31   15   74   28   13  667   26]\n",
            " [  16    7    4   16   42    7    3   42   17  855]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [30 36 33 27 25 35 23 41 26 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.054 s \n",
            "\n",
            "Accuracy rate for 84.480000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.92       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.82      0.83      0.82      1032\n",
            "           3       0.85      0.82      0.84      1010\n",
            "           4       0.88      0.83      0.85       982\n",
            "           5       0.78      0.74      0.76       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.86      0.85      0.85      1028\n",
            "           8       0.81      0.68      0.74       974\n",
            "           9       0.76      0.84      0.80      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    4    1    1   14    9    5    2    0]\n",
            " [   0 1096    4    3    0    4    1    2   25    0]\n",
            " [  33   29  856   14    8    7   14   25   37    9]\n",
            " [  13    7   27  833    1   39    4   24   45   17]\n",
            " [   1    8   21    1  816    8   12   13    4   98]\n",
            " [  36    3   15   78   12  656   25   16   24   27]\n",
            " [  15    4   34    0   15   27  861    1    1    0]\n",
            " [   1   32   14    3   12    3    0  873    7   83]\n",
            " [  20   34   66   33   14   73   27   14  666   27]\n",
            " [  16    7    5   15   51    7    3   44   14  847]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59690, 10) \n",
            " [3 0 9 ... 5 6 7]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [31 36 34 29 26 35 24 44 27 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.762 s \n",
            "\n",
            "Accuracy rate for 85.220000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.83      0.84      0.83      1032\n",
            "           3       0.85      0.84      0.85      1010\n",
            "           4       0.88      0.83      0.85       982\n",
            "           5       0.80      0.74      0.77       892\n",
            "           6       0.89      0.90      0.90       958\n",
            "           7       0.85      0.86      0.85      1028\n",
            "           8       0.86      0.72      0.78       974\n",
            "           9       0.76      0.84      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    5    1    1   14   10    4    2    0]\n",
            " [   0 1101    3    4    0    4    1    2   20    0]\n",
            " [  32   25  866   18    8    8   14   26   25   10]\n",
            " [  12    7   20  852    0   38    3   28   31   19]\n",
            " [   1    6   18    0  815    8   14   15    4  101]\n",
            " [  40    3   16   79   12  658   25   16   17   26]\n",
            " [  15    4   36    0   14   28  860    0    1    0]\n",
            " [   1   27   15    4   13    4    0  881    6   77]\n",
            " [  20   21   61   27   15   54   31   14  703   28]\n",
            " [  15    6    9   17   49    7    3   47   13  843]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59680, 10) \n",
            " [3 0 9 ... 5 6 7]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [31 37 34 31 28 36 25 45 28 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.191 s \n",
            "\n",
            "Accuracy rate for 85.400000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.82      0.83      0.83      1032\n",
            "           3       0.84      0.85      0.84      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.81      0.73      0.77       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.85      0.86      0.86      1028\n",
            "           8       0.86      0.73      0.79       974\n",
            "           9       0.78      0.84      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    1    6    1    0   13   10    6    1    0]\n",
            " [   0 1102    3    4    0    4    1    1   20    0]\n",
            " [  32   25  860   17    9    6   14   32   28    9]\n",
            " [  12    6   22  859    1   40    5   22   28   15]\n",
            " [   1    5   20    0  824    7   10   17    4   94]\n",
            " [  38    3   16   92   12  653   27   13   18   20]\n",
            " [  16    3   31    0   17   24  864    2    1    0]\n",
            " [   1   25   15    5   13    3    0  880    7   79]\n",
            " [  19   23   61   29   13   51   26   13  711   28]\n",
            " [  15    6   10   17   52    7    1   44   12  845]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59670, 10) \n",
            " [3 0 4 ... 5 6 7]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [33 39 35 32 29 37 26 46 28 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.869 s \n",
            "\n",
            "Accuracy rate for 85.520000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.83      0.83      0.83      1032\n",
            "           3       0.83      0.86      0.84      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.81      0.73      0.77       892\n",
            "           6       0.89      0.90      0.90       958\n",
            "           7       0.85      0.86      0.86      1028\n",
            "           8       0.88      0.73      0.80       974\n",
            "           9       0.78      0.83      0.80      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    5    1    0   14   11    7    0    0]\n",
            " [   0 1113    3    4    0    4    1    1    9    0]\n",
            " [  34   24  861   21    7    6   14   31   24   10]\n",
            " [  13    5   19  865    1   39    5   23   26   14]\n",
            " [   1    5   20    0  821    7   11   16    5   96]\n",
            " [  38    3   15   96   12  650   30   13   14   21]\n",
            " [  16    3   31    0   15   23  866    3    1    0]\n",
            " [   1   26   14    7   19    2    0  882    5   72]\n",
            " [  22   21   57   30   14   48   30   13  712   27]\n",
            " [  17    5   10   16   53    8    2   45   12  841]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59660, 10) \n",
            " [3 0 9 ... 5 6 7]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [33 39 35 32 32 38 28 47 29 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.111 s \n",
            "\n",
            "Accuracy rate for 85.460000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.83      0.83      0.83      1032\n",
            "           3       0.83      0.86      0.84      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.81      0.73      0.77       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.86      0.85      0.86      1028\n",
            "           8       0.89      0.72      0.79       974\n",
            "           9       0.78      0.84      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    4    1    0   14   10    7    0    0]\n",
            " [   0 1112    3    4    0    5    1    1    9    0]\n",
            " [  34   24  860   21    9    6   14   30   25    9]\n",
            " [  13    5   18  864    3   39    5   22   25   16]\n",
            " [   1    4   20    0  827    7   12   12    5   94]\n",
            " [  39    1   16   96   14  653   28   13   14   18]\n",
            " [  16    3   32    0   14   24  864    3    1    1]\n",
            " [   1   26   15    7   20    2    0  878    4   75]\n",
            " [  21   26   61   35   14   52   29   13  697   26]\n",
            " [  17    5   10   16   53    8    1   44    7  848]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [33 39 36 33 33 39 31 49 29 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.409 s \n",
            "\n",
            "Accuracy rate for 85.770000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.83      0.84      0.83      1032\n",
            "           3       0.83      0.86      0.85      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.82      0.75      0.78       892\n",
            "           6       0.90      0.92      0.91       958\n",
            "           7       0.86      0.85      0.86      1028\n",
            "           8       0.89      0.71      0.79       974\n",
            "           9       0.78      0.84      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.85     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    1    4    1    0   14    8    7    0    0]\n",
            " [   0 1110    5    3    0    5    2    1    9    0]\n",
            " [  32   23  865   15    9    5   19   28   24   12]\n",
            " [  14    5   21  866    3   34    5   22   25   15]\n",
            " [   1    4   18    0  823    7   19   12    5   93]\n",
            " [  36    2   14   92   14  669   23   13   11   18]\n",
            " [  17    3   30    0   13   15  877    2    1    0]\n",
            " [   1   26   16    6   21    2    0  876    6   74]\n",
            " [  22   23   66   38   14   56   24   12  694   25]\n",
            " [  16    5    8   17   53    8    0   43    7  852]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['3' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59640, 10) \n",
            " [3 0 4 ... 5 6 7]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [35 39 36 34 33 41 33 50 30 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.837 s \n",
            "\n",
            "Accuracy rate for 85.710000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.92       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.82      0.83      0.83      1032\n",
            "           3       0.84      0.85      0.84      1010\n",
            "           4       0.86      0.84      0.85       982\n",
            "           5       0.82      0.76      0.79       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.86      0.85      0.86      1028\n",
            "           8       0.88      0.72      0.79       974\n",
            "           9       0.78      0.85      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    4    1    1   15    9    6    0    0]\n",
            " [   0 1108    5    3    0    5    2    1   11    0]\n",
            " [  31   21  860   15    9    4   20   28   32   12]\n",
            " [  15    5   21  856    3   43    6   21   25   15]\n",
            " [   1    4   18    0  823    8   18   12    4   94]\n",
            " [  30    2   19   89   15  674   23   12   11   17]\n",
            " [  17    3   31    0   14   15  875    2    1    0]\n",
            " [   1   27   16    5   21    3    0  875    6   74]\n",
            " [  23   20   64   37   14   51   23   11  704   27]\n",
            " [  17    6    8   15   52    7    0   45    6  853]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59630, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [35 39 37 36 34 41 33 52 30 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.389 s \n",
            "\n",
            "Accuracy rate for 86.070000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.82      0.84      0.83      1032\n",
            "           3       0.84      0.88      0.86      1010\n",
            "           4       0.86      0.84      0.85       982\n",
            "           5       0.84      0.74      0.79       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.86      0.86      1028\n",
            "           8       0.89      0.73      0.80       974\n",
            "           9       0.79      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    5    1    1   14    9    6    1    0]\n",
            " [   0 1109    3    4    0    5    2    0   11    1]\n",
            " [  28   21  868   18   10    4   18   24   31   10]\n",
            " [  18    5   19  886    2   23    5   22   19   11]\n",
            " [   1    4   19    0  823    5   20   13    4   93]\n",
            " [  31    2   20   96   16  664   22   13   11   17]\n",
            " [  17    3   33    0   14   16  872    2    1    0]\n",
            " [   0   27   16    5   18    3    0  884    6   69]\n",
            " [  23   20   59   36   14   52   26   12  707   25]\n",
            " [  15    7   11   15   54    8    0   42    6  851]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59620, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [36 43 38 36 34 42 33 52 32 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.829 s \n",
            "\n",
            "Accuracy rate for 85.970000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.93      0.97      0.95      1135\n",
            "           2       0.83      0.85      0.84      1032\n",
            "           3       0.84      0.88      0.86      1010\n",
            "           4       0.87      0.82      0.85       982\n",
            "           5       0.83      0.74      0.78       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.86      0.86      0.86      1028\n",
            "           8       0.87      0.73      0.79       974\n",
            "           9       0.78      0.85      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    1    5    0    1   14    9    6    2    0]\n",
            " [   0 1106    3    4    0    4    2    0   15    1]\n",
            " [  23   19  877   19    9    4   17   24   29   11]\n",
            " [  18    5   20  885    2   22    5   21   21   11]\n",
            " [   1    5   20    0  810    5   21   13    4  103]\n",
            " [  31    2   18   98   16  658   20   13   20   16]\n",
            " [  17    2   34    0   14   15  873    2    1    0]\n",
            " [   0   26   17    5   18    4    0  883    5   70]\n",
            " [  24   22   52   34   14   56   28   13  707   24]\n",
            " [  15    7   12   13   46    8    1   46    5  856]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59610, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [36 46 38 37 37 42 35 53 32 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.445 s \n",
            "\n",
            "Accuracy rate for 86.010000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.83      0.85      0.84      1032\n",
            "           3       0.84      0.87      0.85      1010\n",
            "           4       0.87      0.83      0.85       982\n",
            "           5       0.84      0.73      0.78       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.87      0.86      0.86      1028\n",
            "           8       0.88      0.73      0.80       974\n",
            "           9       0.78      0.85      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    1    6    0    3   14   12    7    2    0]\n",
            " [   0 1109    3    4    0    4    2    0   12    1]\n",
            " [  23   18  878   19    9    3   19   23   29   11]\n",
            " [  18    5   20  883    2   22    7   20   21   12]\n",
            " [   1    6   17    0  819    4   16   12    4  103]\n",
            " [  31    2   16   98   14  653   28   14   20   16]\n",
            " [  17    2   35    0   15   12  875    1    1    0]\n",
            " [   0   26   17    5   15    4    0  887    5   69]\n",
            " [  24   21   53   35   16   58   22   12  708   25]\n",
            " [  15    7   12   13   49    6    1   47    5  854]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [36 47 39 38 38 42 37 54 34 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.219 s \n",
            "\n",
            "Accuracy rate for 86.290000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.83      0.86      0.85      1032\n",
            "           3       0.84      0.87      0.86      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.84      0.73      0.78       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.87      0.87      0.87      1028\n",
            "           8       0.87      0.74      0.80       974\n",
            "           9       0.80      0.85      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    1    8    0    2   16   12    4    2    0]\n",
            " [   0 1110    2    4    0    4    2    1   12    0]\n",
            " [  19   18  889   18   10    2   19   22   27    8]\n",
            " [  18    4   23  878    2   22    9   21   22   11]\n",
            " [   1    6   16    0  820    5   14   16    4  100]\n",
            " [  30    2   21   87   17  653   26   12   29   15]\n",
            " [  17    3   39    0   16   10  871    0    2    0]\n",
            " [   0   27   18    5   15    4    0  894    7   58]\n",
            " [  20   26   43   38   15   50   27   11  720   24]\n",
            " [  17    7   11   12   46    7    2   43    5  859]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59590, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [37 48 39 38 39 45 37 56 36 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.323 s \n",
            "\n",
            "Accuracy rate for 86.180000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       980\n",
            "           1       0.92      0.97      0.95      1135\n",
            "           2       0.83      0.84      0.83      1032\n",
            "           3       0.84      0.85      0.85      1010\n",
            "           4       0.87      0.84      0.85       982\n",
            "           5       0.84      0.76      0.80       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.88      0.88      1028\n",
            "           8       0.84      0.74      0.79       974\n",
            "           9       0.81      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    8    0    3   16   12    4    1    0]\n",
            " [   0 1105    2    4    1    4    2    0   17    0]\n",
            " [  19   22  869   16   11    2   18   20   48    7]\n",
            " [  18    5   21  861    1   27   10   20   38    9]\n",
            " [   1    7   17    0  824    5   10   14    3  101]\n",
            " [  30    2   16   90   14  675   25   13   17   10]\n",
            " [  16    3   39    0   14   11  873    0    2    0]\n",
            " [   2   25   17    5   15    2    0  903    6   53]\n",
            " [  19   27   53   36   15   50   24   11  721   18]\n",
            " [  16    7   11   11   49    7    0   49    8  851]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59580, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [38 50 40 39 39 47 38 57 37 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.769 s \n",
            "\n",
            "Accuracy rate for 86.490000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.84      0.85      0.84      1032\n",
            "           3       0.86      0.85      0.85      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.83      0.78      0.81       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.88      0.88      1028\n",
            "           8       0.85      0.74      0.79       974\n",
            "           9       0.81      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    8    0    2   18   12    4    1    0]\n",
            " [   0 1105    3    4    0    3    2    1   17    0]\n",
            " [  19   22  874   16   10    6   17   26   35    7]\n",
            " [  22    5   20  857    1   30   10   19   36   10]\n",
            " [   1    7   14    0  828    6   10   12    4  100]\n",
            " [  29    2   13   74   11  699   23   12   18   11]\n",
            " [  16    3   37    0   14   13  873    0    2    0]\n",
            " [   1   26   16    5   12    2    0  908    6   52]\n",
            " [  19   28   50   30   15   60   24   12  718   18]\n",
            " [  16    7   11   11   49    6    1   48    8  852]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59570, 10) \n",
            " [5 0 4 ... 5 6 7]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [41 50 41 41 41 47 38 58 38 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.991 s \n",
            "\n",
            "Accuracy rate for 86.640000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.97      0.95      1135\n",
            "           2       0.85      0.84      0.85      1032\n",
            "           3       0.86      0.86      0.86      1010\n",
            "           4       0.88      0.85      0.86       982\n",
            "           5       0.84      0.77      0.81       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.88      0.88      1028\n",
            "           8       0.85      0.76      0.80       974\n",
            "           9       0.81      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    7    0    2   15   12    4    1    0]\n",
            " [   0 1105    3    3    0    4    2    1   17    0]\n",
            " [  13   24  871   17    9   10   17   27   37    7]\n",
            " [  23    5   17  865    1   24    9   19   37   10]\n",
            " [   2    7   14    0  831    7   10   12    3   96]\n",
            " [  39    2   11   75   11  691   20   12   20   11]\n",
            " [  19    3   40    0   13   12  868    1    2    0]\n",
            " [   0   26   17    5   12    1    0  909    6   52]\n",
            " [  20   24   36   32   14   55   23   12  740   18]\n",
            " [  13    7   12   12   55    5    1   51    8  845]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['5' '0' '4' ... '5' '6' '7']\n",
            "probabilities: (59560, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [43 52 41 42 41 49 40 58 38 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.041 s \n",
            "\n",
            "Accuracy rate for 86.640000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.85      0.84      0.85      1032\n",
            "           3       0.86      0.86      0.86      1010\n",
            "           4       0.88      0.85      0.86       982\n",
            "           5       0.84      0.77      0.80       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.88      0.87      1028\n",
            "           8       0.85      0.76      0.81       974\n",
            "           9       0.81      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    1    7    0    2   15   12    4    0    0]\n",
            " [   0 1105    3    3    1    3    2    1   17    0]\n",
            " [  13   24  871   18    9   10   17   27   36    7]\n",
            " [  24    5   17  865    1   26    9   19   34   10]\n",
            " [   2    7   14    0  830    5   10   15    3   96]\n",
            " [  39    2   11   75   11  690   21   11   21   11]\n",
            " [  19    3   40    0   13   12  868    1    2    0]\n",
            " [   0   26   17    5   12    1    0  909    6   52]\n",
            " [  20   24   36   29   14   57   22   12  742   18]\n",
            " [  13    7   12   12   55    5    1   51    8  845]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [44 55 43 43 42 49 40 60 38 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.625 s \n",
            "\n",
            "Accuracy rate for 86.540000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.85      0.84      0.85      1032\n",
            "           3       0.85      0.86      0.86      1010\n",
            "           4       0.88      0.85      0.86       982\n",
            "           5       0.84      0.76      0.80       892\n",
            "           6       0.90      0.91      0.91       958\n",
            "           7       0.87      0.88      0.87      1028\n",
            "           8       0.85      0.76      0.80       974\n",
            "           9       0.82      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    7    0    2   15   12    3    0    0]\n",
            " [   0 1103    3    3    0    3    1    1   21    0]\n",
            " [  11   23  870   19    9   10   17   27   39    7]\n",
            " [  24    8   18  865    1   25    9   19   34    7]\n",
            " [   1    9   15    0  831    5   10   15    2   94]\n",
            " [  47    4   10   76   11  682   20   11   21   10]\n",
            " [  18    2   40    0   14   12  869    1    2    0]\n",
            " [   0   23   19    6   12    1    0  909    6   52]\n",
            " [  19   25   36   30   14   58   22   12  740   18]\n",
            " [  14    7    9   13   55    5    1   52    8  845]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59540, 10) \n",
            " [5 0 9 ... 5 6 5]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [44 58 43 44 44 49 40 62 40 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.044 s \n",
            "\n",
            "Accuracy rate for 86.640000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.85      0.85      0.85      1032\n",
            "           3       0.86      0.85      0.86      1010\n",
            "           4       0.87      0.84      0.86       982\n",
            "           5       0.83      0.78      0.80       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.86      0.77      0.81       974\n",
            "           9       0.81      0.83      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    7    0    1   16   12    3    0    0]\n",
            " [   0 1105    4    3    0    3    1    1   18    0]\n",
            " [  11   27  874   17    9   10   17   27   33    7]\n",
            " [  21    9   16  863    1   30    9   20   34    7]\n",
            " [   1   10   18    0  826    6    9   15    4   93]\n",
            " [  45    4   10   70   11  692   21   11   17   11]\n",
            " [  18    2   40    0   15   12  868    1    2    0]\n",
            " [   0   23   19    4   14    1    0  909    5   53]\n",
            " [  21   19   34   30   12   54   25   11  747   21]\n",
            " [  14    7   10   15   56    5    1   56    5  840]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59530, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [44 60 44 45 45 49 43 62 41 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.102 s \n",
            "\n",
            "Accuracy rate for 86.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.84      0.84      0.84      1032\n",
            "           3       0.87      0.85      0.86      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.84      0.77      0.81       892\n",
            "           6       0.89      0.92      0.90       958\n",
            "           7       0.87      0.88      0.88      1028\n",
            "           8       0.87      0.77      0.81       974\n",
            "           9       0.81      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    1    6    0    1   16   14    5    0    0]\n",
            " [   0 1108    3    2    0    3    1    1   17    0]\n",
            " [  13   25  870   16    8    9   24   23   34   10]\n",
            " [  21    8   21  859    1   28   13   20   32    7]\n",
            " [   1    9   16    0  828    6    9   11    3   99]\n",
            " [  46    4    8   70   12  691   22   11   18   10]\n",
            " [  15    3   33    0   13   11  881    1    1    0]\n",
            " [   0   21   25    2   13    1    0  905    5   56]\n",
            " [  20   19   35   30   13   51   27   10  748   21]\n",
            " [  15    5   16   14   49    6    2   52    4  846]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['5' '0' '9' ... '5' '6' '5']\n",
            "probabilities: (59520, 10) \n",
            " [5 0 9 ... 5 6 5]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [44 60 45 46 45 52 45 62 44 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.486 s \n",
            "\n",
            "Accuracy rate for 86.890000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.84      0.85      0.85      1032\n",
            "           3       0.85      0.86      0.86      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.85      0.78      0.81       892\n",
            "           6       0.89      0.92      0.91       958\n",
            "           7       0.87      0.88      0.87      1028\n",
            "           8       0.88      0.77      0.82       974\n",
            "           9       0.81      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    6    0    1   17   14    5    1    0]\n",
            " [   0 1109    3    2    0    2    1    1   17    0]\n",
            " [  12   25  875   13    8   10   23   24   33    9]\n",
            " [  19    9   20  871    1   25   13   20   25    7]\n",
            " [   1    9   20    0  824    5   10   12    2   99]\n",
            " [  40    4    9   86   11  692   20   10   11    9]\n",
            " [  14    3   33    0   13   11  882    1    1    0]\n",
            " [   0   22   25    2   13    1    0  903    6   56]\n",
            " [  17   19   32   40   15   45   24   10  752   20]\n",
            " [  15    6   16   13   49    8    2   52    3  845]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['5' '0' '9' ... '5' '6' '7']\n",
            "probabilities: (59510, 10) \n",
            " [5 0 9 ... 5 6 7]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [46 62 48 46 45 52 46 62 44 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.662 s \n",
            "\n",
            "Accuracy rate for 87.020000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.84      0.85      0.85      1032\n",
            "           3       0.85      0.86      0.86      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.85      0.78      0.81       892\n",
            "           6       0.89      0.92      0.91       958\n",
            "           7       0.88      0.88      0.88      1028\n",
            "           8       0.89      0.77      0.83       974\n",
            "           9       0.81      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    6    0    1   17   14    5    1    0]\n",
            " [   0 1114    3    2    0    2    1    1   12    0]\n",
            " [  12   25  877   13    8    9   23   25   32    8]\n",
            " [  19    9   20  871    1   25   13   19   25    8]\n",
            " [   1    9   19    0  820    5   10   12    2  104]\n",
            " [  40    4    9   86   10  692   20   10   11   10]\n",
            " [  14    3   33    0   13   11  882    1    1    0]\n",
            " [   0   23   25    2   12    1    0  908    6   51]\n",
            " [  17   20   31   40   15   44   25   10  751   21]\n",
            " [  14    5   16   13   50    9    2   46    3  851]]\n",
            "--------------------------------\n",
            "final active learning accuracies [32.9, 42.53, 53.580000000000005, 57.120000000000005, 64.66, 69.74000000000001, 71.8, 73.27, 75.63, 76.98, 77.4, 78.44, 78.47, 79.14999999999999, 79.23, 79.62, 79.86999999999999, 80.43, 81.5, 81.73, 82.43, 82.78999999999999, 83.45, 83.87, 83.93, 83.87, 84.1, 84.57000000000001, 84.6, 84.54, 84.48, 85.22, 85.39999999999999, 85.52, 85.46000000000001, 85.77, 85.71, 86.07000000000001, 85.97, 86.00999999999999, 86.29, 86.18, 86.49, 86.64, 86.64, 86.53999999999999, 86.64, 86.72999999999999, 86.89, 87.02]\n",
            "saved Active-learning-experiment-5.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-5.pkl', 'sample_data']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 6, using model = SvmModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [25 25 27 23 30 26 18 26 26 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.690 s \n",
            "\n",
            "Accuracy rate for 83.660000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93       980\n",
            "           1       0.87      0.98      0.92      1135\n",
            "           2       0.82      0.83      0.82      1032\n",
            "           3       0.86      0.81      0.83      1010\n",
            "           4       0.72      0.91      0.80       982\n",
            "           5       0.77      0.74      0.76       892\n",
            "           6       0.93      0.81      0.87       958\n",
            "           7       0.88      0.85      0.86      1028\n",
            "           8       0.86      0.78      0.82       974\n",
            "           9       0.78      0.68      0.73      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    1    6    1    1   24   13    2    1    4]\n",
            " [   0 1108    2    9    0    3    3    0    9    1]\n",
            " [  18   22  857   20   27   10    9   26   40    3]\n",
            " [  14    6   35  815    2   80    4   16   15   23]\n",
            " [   2   12   14    1  893    0   10    5    5   40]\n",
            " [  21   45   13   43   27  661   12   25   29   16]\n",
            " [  18   13   64    0   49   18  780    6    9    1]\n",
            " [   1   23   26    3   24    0    0  878    6   67]\n",
            " [   9   23   14   53   10   47    9    8  760   41]\n",
            " [  11   14   20    4  211   13    1   37   11  687]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [38 36 51 50 53 67 54 43 48 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.011 s \n",
            "\n",
            "Accuracy rate for 86.140000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.80      0.84      0.82      1032\n",
            "           3       0.82      0.82      0.82      1010\n",
            "           4       0.85      0.89      0.87       982\n",
            "           5       0.78      0.82      0.80       892\n",
            "           6       0.92      0.89      0.91       958\n",
            "           7       0.91      0.85      0.88      1028\n",
            "           8       0.90      0.71      0.80       974\n",
            "           9       0.82      0.83      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    8    5    4   22    6    1    2    1]\n",
            " [   0 1118    6    3    0    1    4    1    2    0]\n",
            " [  18   22  871   15   10   14   35   25   20    2]\n",
            " [  10    7   38  829    1   76    5   23   11   10]\n",
            " [   1    3   41    0  870    3    7    2    4   51]\n",
            " [  17    5   12   61   12  735   11    4   23   12]\n",
            " [  23    3   36    1   16   19  854    0    6    0]\n",
            " [   2   21   26    3   23    1    1  872    4   75]\n",
            " [  15   26   36   77    9   72    6    8  696   29]\n",
            " [  13    9   18   14   81    5    0   26    5  838]]\n",
            "--------------------------------\n",
            "final active learning accuracies [83.66, 86.14]\n",
            "saved Active-learning-experiment-6.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 7, using model = SvmModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [16 15 19  9 13  6 15  8  8 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.555 s \n",
            "\n",
            "Accuracy rate for 75.740000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       980\n",
            "           1       0.84      0.97      0.90      1135\n",
            "           2       0.75      0.79      0.77      1032\n",
            "           3       0.76      0.75      0.75      1010\n",
            "           4       0.68      0.89      0.77       982\n",
            "           5       0.93      0.40      0.56       892\n",
            "           6       0.84      0.84      0.84       958\n",
            "           7       0.92      0.62      0.74      1028\n",
            "           8       0.75      0.57      0.65       974\n",
            "           9       0.58      0.76      0.65      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.78      0.75      0.75     10000\n",
            "weighted avg       0.78      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    1   25    1    2    1   30    1    2    2]\n",
            " [   0 1104   14    2    2    0    5    0    6    2]\n",
            " [  46   19  811   31   25    3   52    6   16   23]\n",
            " [  37   17   42  753   10   10    6    2   23  110]\n",
            " [   3    6   12    3  876    0   24    0    4   54]\n",
            " [ 130   37   19  114   87  353   19    6  107   20]\n",
            " [  36   13   52    7   26    0  806    0   18    0]\n",
            " [  10   47   20    2   81    0    1  638    0  229]\n",
            " [  36   39   83   72   36   11   12    9  553  123]\n",
            " [  15   24    3    9  152    1    1   29   10  765]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 0]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [19 18 27 28 19 37 25 20 34 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.254 s \n",
            "\n",
            "Accuracy rate for 84.410000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.91      0.95      0.93      1135\n",
            "           2       0.81      0.82      0.82      1032\n",
            "           3       0.78      0.82      0.80      1010\n",
            "           4       0.82      0.89      0.86       982\n",
            "           5       0.80      0.77      0.79       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.86      0.83      0.84      1028\n",
            "           8       0.84      0.78      0.81       974\n",
            "           9       0.81      0.71      0.76      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    0    9    3    2   21   14    2    2    1]\n",
            " [   0 1076   28    7    0    4    5    7    6    2]\n",
            " [  32   19  846   15   14   12   30   18   39    7]\n",
            " [   8   22   20  825    2   55    2   11   40   25]\n",
            " [   1    9   21    1  878    2   12    4    4   50]\n",
            " [  16    7    7  101    7  688   16    5   36    9]\n",
            " [  16    3   31    6   18    9  873    0    2    0]\n",
            " [   2   15   43   26   27    1    0  852    5   57]\n",
            " [  13   12   11   55   17   57   19   13  756   21]\n",
            " [  11   22   28   21  104   10    1   80   11  721]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '4' '0']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 4 0]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [26 31 42 37 33 50 33 32 50 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.002 s \n",
            "\n",
            "Accuracy rate for 86.760000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.94      0.96      0.95      1135\n",
            "           2       0.83      0.86      0.85      1032\n",
            "           3       0.84      0.81      0.82      1010\n",
            "           4       0.86      0.90      0.88       982\n",
            "           5       0.79      0.79      0.79       892\n",
            "           6       0.92      0.92      0.92       958\n",
            "           7       0.89      0.88      0.89      1028\n",
            "           8       0.83      0.79      0.81       974\n",
            "           9       0.83      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    0    5    3    1   14   11    6    2    0]\n",
            " [   0 1088    4    5    1    1    4    1   30    1]\n",
            " [  12   16  889    9   16    6   14   21   47    2]\n",
            " [  14    8   28  814    1   79    3    8   26   29]\n",
            " [   2    3   17    2  880    1    8    2    2   65]\n",
            " [  19    8    6   77   11  701   13    4   40   13]\n",
            " [  13    3   30    2    9   15  885    0    1    0]\n",
            " [   3   16   49    9   19    0    0  902    4   26]\n",
            " [  10    8   20   32   13   63   21    9  770   28]\n",
            " [   8   10   19   15   73   11    0   56    8  809]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [40 36 52 49 46 70 38 46 64 59] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.774 s \n",
            "\n",
            "Accuracy rate for 87.860000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       980\n",
            "           1       0.95      0.97      0.96      1135\n",
            "           2       0.86      0.88      0.87      1032\n",
            "           3       0.87      0.80      0.83      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.79      0.82      0.80       892\n",
            "           6       0.93      0.91      0.92       958\n",
            "           7       0.90      0.91      0.91      1028\n",
            "           8       0.86      0.78      0.82       974\n",
            "           9       0.86      0.82      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    2    2    2    5    9    6    0    0]\n",
            " [   0 1096    1    4    0    6    4    2   22    0]\n",
            " [  23    8  904   10   15    2   14   15   37    4]\n",
            " [  22    5   31  813    1   85    2    7   25   19]\n",
            " [   1    2   18    2  900    1    2    6    3   47]\n",
            " [  25    5   10   55    9  731   13    6   26   12]\n",
            " [  22    4   26    1   15   22  867    0    1    0]\n",
            " [   2   11   27    9   12    0    0  935    6   26]\n",
            " [  10   15   21   28   16   70   19    9  763   23]\n",
            " [   6    5   12   15   83    8    1   52    4  823]]\n",
            "--------------------------------\n",
            "final active learning accuracies [75.74, 84.41, 86.76, 87.86]\n",
            "saved Active-learning-experiment-7.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 8, using model = SvmModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [4 6 4 8 4 7 5 5 3 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.166 s \n",
            "\n",
            "Accuracy rate for 66.580000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.80       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.93      0.49      0.65      1032\n",
            "           3       0.61      0.77      0.68      1010\n",
            "           4       0.52      0.41      0.46       982\n",
            "           5       0.57      0.76      0.65       892\n",
            "           6       0.96      0.64      0.77       958\n",
            "           7       0.66      0.84      0.74      1028\n",
            "           8       0.87      0.33      0.48       974\n",
            "           9       0.50      0.64      0.56      1009\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.71      0.66      0.66     10000\n",
            "weighted avg       0.71      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 719    1    5  108    0  121    8   12    1    5]\n",
            " [   0 1126    0    2    0    3    1    1    2    0]\n",
            " [  36  202  510   94   38   13    8   89   12   30]\n",
            " [   0   41    3  778    6   47    0   98   27   10]\n",
            " [   2   56    1    0  403    2    4   80    0  434]\n",
            " [   3   61    1   90   25  679    2   10    2   19]\n",
            " [  20   70    9   41   66   80  614   10    0   48]\n",
            " [   2   67    0    0   14    6    0  860    3   76]\n",
            " [  15  134   14  153   24  214    1   59  321   39]\n",
            " [  11   23    6    9  203   21    0   86    2  648]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '7' ... '5' '6' '5']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [11  6  8 13 14  8 13  6 12  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.353 s \n",
            "\n",
            "Accuracy rate for 80.080000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       980\n",
            "           1       0.81      0.98      0.89      1135\n",
            "           2       0.91      0.59      0.72      1032\n",
            "           3       0.69      0.89      0.78      1010\n",
            "           4       0.65      0.87      0.74       982\n",
            "           5       0.88      0.62      0.73       892\n",
            "           6       0.89      0.87      0.88       958\n",
            "           7       0.91      0.82      0.86      1028\n",
            "           8       0.82      0.73      0.77       974\n",
            "           9       0.74      0.65      0.69      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.82      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    1    7    6   14    3    2    2    5    1]\n",
            " [   0 1110    2    6    0    0    6    0   11    0]\n",
            " [  29   81  610  112   52    0   60   25   38   25]\n",
            " [   9   14   10  902    6   16    5   15   27    6]\n",
            " [   3   15    1    2  854    1    9    1    8   88]\n",
            " [  58   34    2  131   45  553   10    6   34   19]\n",
            " [  35    9    8    5   46   22  830    0    3    0]\n",
            " [   5   54   12    9   27    3    0  843   11   64]\n",
            " [  14   34   13  113   21   22   11    8  712   26]\n",
            " [  14   16    3   15  246    6    1   30   23  655]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '4' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [14 11 17 18 20 14 17 10 16 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.233 s \n",
            "\n",
            "Accuracy rate for 81.420000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       980\n",
            "           1       0.88      0.98      0.93      1135\n",
            "           2       0.87      0.81      0.84      1032\n",
            "           3       0.74      0.88      0.81      1010\n",
            "           4       0.65      0.86      0.74       982\n",
            "           5       0.85      0.67      0.75       892\n",
            "           6       0.92      0.88      0.90       958\n",
            "           7       0.95      0.72      0.82      1028\n",
            "           8       0.87      0.73      0.79       974\n",
            "           9       0.67      0.61      0.64      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    8    1    9    3    2    5    8    4]\n",
            " [   0 1114    5    6    1    2    4    0    3    0]\n",
            " [  40   24  835   32   25    1   36    5   15   19]\n",
            " [   6    9   29  893   11   37    1    3   16    5]\n",
            " [   4   12    4    0  846    4    7    1    3  101]\n",
            " [  54   18   18  110   47  602    5    8   26    4]\n",
            " [  44    5   15    4   26   21  839    0    0    4]\n",
            " [   4   42   23   23   41    1    1  745    9  139]\n",
            " [  22   32   20   94   22   23   18    4  711   28]\n",
            " [  16   10    7   42  264   11    0   17   25  617]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15 11 21 25 23 24 22 15 24 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.472 s \n",
            "\n",
            "Accuracy rate for 85.280000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       980\n",
            "           1       0.93      0.97      0.95      1135\n",
            "           2       0.88      0.85      0.86      1032\n",
            "           3       0.76      0.82      0.79      1010\n",
            "           4       0.78      0.92      0.85       982\n",
            "           5       0.76      0.78      0.77       892\n",
            "           6       0.92      0.88      0.90       958\n",
            "           7       0.90      0.85      0.87      1028\n",
            "           8       0.87      0.74      0.80       974\n",
            "           9       0.86      0.74      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    7    2    8    9    7    5    1    2]\n",
            " [   0 1105    1   10    0    3    7    2    7    0]\n",
            " [  23   23  873   24   20    4   14   16   30    5]\n",
            " [   4    4   17  833    3  109    2   15   21    2]\n",
            " [   4    5    5    0  908    8    9    6    4   33]\n",
            " [  34    8   10   86   17  692    9   10   21    5]\n",
            " [  40    3   30    3   29    8  844    0    0    1]\n",
            " [   3   19   22   33   20    0    2  871    8   50]\n",
            " [  21   16   25   68   17   61   23    7  717   19]\n",
            " [  11    8    4   34  143   11    0   36   16  746]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [18 13 21 34 25 35 24 21 30 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.174 s \n",
            "\n",
            "Accuracy rate for 86.690000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.90      0.81      0.85      1032\n",
            "           3       0.80      0.84      0.82      1010\n",
            "           4       0.80      0.91      0.85       982\n",
            "           5       0.77      0.79      0.78       892\n",
            "           6       0.93      0.89      0.91       958\n",
            "           7       0.90      0.89      0.90      1028\n",
            "           8       0.87      0.79      0.83       974\n",
            "           9       0.87      0.79      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    0    5    4   12   21    8    3    2    0]\n",
            " [   0 1111    2    4    0    5    5    1    7    0]\n",
            " [  20   28  838   33   24    8   18   18   40    5]\n",
            " [   5    2   10  850    2  105    2   16   14    4]\n",
            " [   5    0    2    0  896    3   10    3    3   60]\n",
            " [  26    5   11   65   13  705   11    3   36   17]\n",
            " [  30    3   22    6   24   17  854    0    2    0]\n",
            " [   4   17   14   23   28    2    1  917    5   17]\n",
            " [  16   16   20   51   19   45   12    9  772   14]\n",
            " [  12    6    5   23   97   10    0   47    8  801]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [21 16 24 39 31 43 26 23 37 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.980 s \n",
            "\n",
            "Accuracy rate for 87.000000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       980\n",
            "           1       0.93      0.97      0.95      1135\n",
            "           2       0.90      0.81      0.85      1032\n",
            "           3       0.81      0.85      0.83      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.79      0.78      0.79       892\n",
            "           6       0.92      0.90      0.91       958\n",
            "           7       0.92      0.86      0.89      1028\n",
            "           8       0.82      0.81      0.81       974\n",
            "           9       0.85      0.85      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    6    4    7   14   27    2    1    0]\n",
            " [   0 1106    2    2    1    3    4    2   14    1]\n",
            " [  20   35  836   34   19    5   16   17   44    6]\n",
            " [   5    3   15  858    0   60    2   16   43    8]\n",
            " [   4    5    4    1  893    3   12    2    1   57]\n",
            " [  18    5   14   67   15  698    7    2   59    7]\n",
            " [  20    4   18    4   15   31  864    0    2    0]\n",
            " [   5   15   17   19   26    1    1  886    6   52]\n",
            " [   9   14   11   53   14   55    7    9  785   17]\n",
            " [  11    7    4   17   66   10    1   31    7  855]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [23 19 34 45 34 50 29 28 41 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.855 s \n",
            "\n",
            "Accuracy rate for 86.340000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.86      0.83      0.85      1032\n",
            "           3       0.82      0.83      0.82      1010\n",
            "           4       0.85      0.89      0.87       982\n",
            "           5       0.74      0.81      0.77       892\n",
            "           6       0.92      0.90      0.91       958\n",
            "           7       0.92      0.83      0.88      1028\n",
            "           8       0.84      0.78      0.81       974\n",
            "           9       0.83      0.83      0.83      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0   12    5   10   14   23    1    0    1]\n",
            " [   0 1109    4    4    0    3    1    1   13    0]\n",
            " [  24   20  859   23   17    6   23   15   41    4]\n",
            " [   6    4   22  834    2   94    2   10   31    5]\n",
            " [   2    6    6    0  874    3   11    3    1   76]\n",
            " [  16    7   20   48   13  725   12    3   41    7]\n",
            " [  13    5   19    4   12   39  864    0    2    0]\n",
            " [   5   17   28   41   22    1    0  858    5   51]\n",
            " [  11   16   14   44   11   82    6   11  755   24]\n",
            " [   8    9   15   17   67   13    2   31    5  842]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [26 21 38 49 37 60 34 32 45 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 32.039 s \n",
            "\n",
            "Accuracy rate for 87.190000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.88      0.84      0.86      1032\n",
            "           3       0.83      0.85      0.84      1010\n",
            "           4       0.88      0.88      0.88       982\n",
            "           5       0.76      0.81      0.79       892\n",
            "           6       0.93      0.91      0.92       958\n",
            "           7       0.93      0.84      0.88      1028\n",
            "           8       0.83      0.79      0.81       974\n",
            "           9       0.84      0.87      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    0    7    5    5   28   14    5    1    0]\n",
            " [   0 1099    4    2    1    3    2    1   23    0]\n",
            " [  21   33  867   18   20    4   21   13   34    1]\n",
            " [   6    4   30  857    1   60    0   11   37    4]\n",
            " [   4    5    8    0  868    2   12    3    4   76]\n",
            " [  12    7   18   52   14  725    7    4   46    7]\n",
            " [  13    4   16    3    9   37  874    0    1    1]\n",
            " [   4   24   22   37   15    0    0  864    6   56]\n",
            " [  12    8   12   45   13   75    8    7  773   21]\n",
            " [   9    7    6   16   42   14    2   26   10  877]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 4 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [27 25 40 57 41 68 34 43 51 64] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.430 s \n",
            "\n",
            "Accuracy rate for 87.950000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.88      0.84      0.86      1032\n",
            "           3       0.84      0.88      0.86      1010\n",
            "           4       0.88      0.89      0.89       982\n",
            "           5       0.79      0.82      0.81       892\n",
            "           6       0.93      0.90      0.92       958\n",
            "           7       0.92      0.86      0.89      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.85      0.87      0.86      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 918    0    3    6    4   28   15    6    0    0]\n",
            " [   0 1108    2    5    0    3    2    0   15    0]\n",
            " [  24   32  866   22   16    3   21   15   31    2]\n",
            " [   9    4   25  891    2   37    0    8   27    7]\n",
            " [   2    4    8    1  872    1   11    6    5   72]\n",
            " [  17    6   16   52   13  734    4    3   40    7]\n",
            " [  15    3   14    7   15   39  863    0    1    1]\n",
            " [   3   27   27   22   13    0    0  888    4   44]\n",
            " [  11   10   13   38   15   71    8    8  778   22]\n",
            " [  13    7    9   15   38   12    2   28    8  877]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '3']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 4 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [32 29 44 61 50 74 37 49 56 68] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 39.276 s \n",
            "\n",
            "Accuracy rate for 88.460000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.89      0.85      0.87      1032\n",
            "           3       0.86      0.89      0.88      1010\n",
            "           4       0.87      0.92      0.89       982\n",
            "           5       0.81      0.82      0.82       892\n",
            "           6       0.93      0.90      0.91       958\n",
            "           7       0.92      0.87      0.89      1028\n",
            "           8       0.85      0.79      0.82       974\n",
            "           9       0.88      0.85      0.87      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    5    2    6   16   14    6    0    0]\n",
            " [   0 1105    3    3    0    2    3    0   19    0]\n",
            " [  15   29  881   14   20    9   20   13   31    0]\n",
            " [   7    5   20  903    3   27    1   11   27    6]\n",
            " [   3    4    4    1  903    3   10    4    7   43]\n",
            " [  17   10   16   43   13  732    7    4   42    8]\n",
            " [  17    5   18    6   14   35  860    0    3    0]\n",
            " [   3   26   25   23   12    1    0  899    4   35]\n",
            " [  14   17   13   35   16   64    6   14  772   23]\n",
            " [  11    9    7   14   56   13    2   31    6  860]]\n",
            "--------------------------------\n",
            "final active learning accuracies [66.58, 80.08, 81.42, 85.28, 86.69, 87.0, 86.33999999999999, 87.19, 87.94999999999999, 88.46000000000001]\n",
            "saved Active-learning-experiment-8.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 9, using model = SvmModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [3 1 6 2 2 2 3 4 0 2] [0 1 2 3 4 5 6 7 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.195 s \n",
            "\n",
            "Accuracy rate for 48.740000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       980\n",
            "           1       0.90      0.44      0.59      1135\n",
            "           2       0.31      0.87      0.46      1032\n",
            "           3       0.63      0.34      0.44      1010\n",
            "           4       0.79      0.23      0.35       982\n",
            "           5       0.49      0.42      0.45       892\n",
            "           6       0.49      0.63      0.55       958\n",
            "           7       0.44      0.85      0.58      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.36      0.34      0.35      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.53      0.48      0.46     10000\n",
            "weighted avg       0.53      0.49      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[713   0  28  11   0 115  94  18   0   1]\n",
            " [  0 501 617   0   0   0  16   1   0   0]\n",
            " [ 16   0 896  14   3  10  70  21   0   2]\n",
            " [ 11  11 314 348   0 129  53  91   0  53]\n",
            " [  2   2  66   4 223   6 104 321   0 254]\n",
            " [ 45  19  57  76   0 373 143  62   0 117]\n",
            " [ 32   4 261  19   3  18 601  20   0   0]\n",
            " [  1   9  66   0   3   2  15 872   0  60]\n",
            " [  6   4 484  78   0 102 104  59   0 137]\n",
            " [  8   5  61   5  51  11  21 500   0 347]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['5' '0' '6' ... '9' '6' '6']\n",
            "probabilities: (59975, 9) \n",
            " [7 0 4 ... 7 7 6]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [6 1 7 5 8 6 6 5 1 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.246 s \n",
            "\n",
            "Accuracy rate for 61.330000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88       980\n",
            "           1       0.94      0.42      0.58      1135\n",
            "           2       0.42      0.79      0.55      1032\n",
            "           3       0.76      0.43      0.55      1010\n",
            "           4       0.67      0.74      0.70       982\n",
            "           5       0.55      0.58      0.57       892\n",
            "           6       0.68      0.85      0.76       958\n",
            "           7       0.83      0.72      0.77      1028\n",
            "           8       0.95      0.11      0.19       974\n",
            "           9       0.37      0.68      0.47      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.71      0.62      0.60     10000\n",
            "weighted avg       0.71      0.61      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[824   0  16   3  17  67  39   0   0  14]\n",
            " [  0 475 561   0   1   1  26   0   0  71]\n",
            " [ 10   1 815  59  52   2  41  11   0  41]\n",
            " [  2   5 196 430   4 230  33  16   5  89]\n",
            " [  1   0   9   0 725   0  27  11   0 209]\n",
            " [  8  15  28  24  26 521 118   3   0 149]\n",
            " [ 22   4  42   0  51  22 815   0   0   2]\n",
            " [  4   4  34   0  15   4  11 741   0 215]\n",
            " [ 12   2 234  47   3  83  80  15 105 393]\n",
            " [ 13   2  11   2 194   9   0  96   0 682]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '6' ... '5' '6' '9']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 6 ... 5 6 6]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 9  2  7  7  9 10  6 10  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.198 s \n",
            "\n",
            "Accuracy rate for 68.510000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89       980\n",
            "           1       0.90      0.52      0.66      1135\n",
            "           2       0.55      0.76      0.64      1032\n",
            "           3       0.76      0.56      0.65      1010\n",
            "           4       0.70      0.70      0.70       982\n",
            "           5       0.60      0.66      0.63       892\n",
            "           6       0.78      0.81      0.79       958\n",
            "           7       0.86      0.72      0.78      1028\n",
            "           8       0.73      0.55      0.63       974\n",
            "           9       0.43      0.69      0.53      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.72      0.69      0.69     10000\n",
            "weighted avg       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[885   0  10   2   9  28  30   0   5  11]\n",
            " [  0 588 382   0   0   9   4   0   3 149]\n",
            " [ 23   6 785  35  45   4  39  13  45  37]\n",
            " [  7  23  92 570   3 215  19  10  27  44]\n",
            " [  1   2   4   1 685   2   8   6  21 252]\n",
            " [ 20  10  12  49  15 590  76   2  49  69]\n",
            " [ 46   5  29   9  42  22 773   0  25   7]\n",
            " [  3   8  24   0   9   9   4 739   2 230]\n",
            " [  8   4  72  73   1  90  35   9 540 142]\n",
            " [  7   6   6  12 167  17   0  79  19 696]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59925, 10) \n",
            " [5 0 4 ... 5 6 9]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [11  5  9  9 11 14  9 12 10 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.203 s \n",
            "\n",
            "Accuracy rate for 76.420000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.84      0.86      0.85      1135\n",
            "           2       0.73      0.78      0.75      1032\n",
            "           3       0.81      0.67      0.73      1010\n",
            "           4       0.78      0.72      0.75       982\n",
            "           5       0.58      0.74      0.65       892\n",
            "           6       0.87      0.89      0.88       958\n",
            "           7       0.91      0.68      0.78      1028\n",
            "           8       0.76      0.59      0.66       974\n",
            "           9       0.57      0.78      0.66      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.78      0.76      0.76     10000\n",
            "weighted avg       0.78      0.76      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[922   0   5   2   9  15  19   0   5   3]\n",
            " [  0 973 138   1   0  15   3   0   5   0]\n",
            " [ 23  26 804  24  37  27  18  11  43  19]\n",
            " [  6  24  48 676   2 168  16  10  24  36]\n",
            " [  1  12   1   1 703  42  11   7  22 182]\n",
            " [ 16   5   3  52  12 657  42   3  53  49]\n",
            " [ 20   6  25   1  13  25 854   0   9   5]\n",
            " [  0  57  27   0  13  17   1 694   3 216]\n",
            " [  6  38  45  69   3 130  14   7 570  92]\n",
            " [ 10  14   5   8 109  31   0  28  15 789]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '7' ... '5' '6' '5']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [12  7 11 10 16 18 11 14 15 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.548 s \n",
            "\n",
            "Accuracy rate for 79.340000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.86      0.96      0.91      1135\n",
            "           2       0.81      0.76      0.78      1032\n",
            "           3       0.85      0.70      0.77      1010\n",
            "           4       0.77      0.90      0.83       982\n",
            "           5       0.63      0.70      0.66       892\n",
            "           6       0.87      0.88      0.88       958\n",
            "           7       0.91      0.68      0.78      1028\n",
            "           8       0.72      0.69      0.70       974\n",
            "           9       0.64      0.73      0.68      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.80      0.79      0.79     10000\n",
            "weighted avg       0.80      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    0   17    1    1   38   11    1    3    4]\n",
            " [   0 1091   16    2    0    6    3    0   17    0]\n",
            " [  29   40  781   29   20   18   19   14   69   13]\n",
            " [   7   21   69  705    2  114   21   11   32   28]\n",
            " [   3    9    3    0  882   17   11    7    6   44]\n",
            " [  20   10    6   34    7  621   45    7  107   35]\n",
            " [  22    8   26    0   20   28  845    1    8    0]\n",
            " [   4   50   17    0   16    5    2  701    5  228]\n",
            " [   6   31   23   45   25  107    9    4  669   55]\n",
            " [  15   13    9    9  167   27    0   23   11  735]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13  7 14 14 17 21 13 17 18 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.154 s \n",
            "\n",
            "Accuracy rate for 81.430000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90       980\n",
            "           1       0.88      0.95      0.91      1135\n",
            "           2       0.80      0.81      0.81      1032\n",
            "           3       0.83      0.77      0.80      1010\n",
            "           4       0.81      0.89      0.85       982\n",
            "           5       0.65      0.71      0.68       892\n",
            "           6       0.87      0.85      0.86       958\n",
            "           7       0.93      0.78      0.85      1028\n",
            "           8       0.76      0.68      0.72       974\n",
            "           9       0.72      0.78      0.75      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 879    0   32    1    1   41   22    0    2    2]\n",
            " [   0 1081    4    5    0    5    5    0   35    0]\n",
            " [  23   35  835   25   14   13   14   13   53    7]\n",
            " [   9   13   41  773    1   94   11   10   26   32]\n",
            " [   2    9    8    0  875   16   11    4    3   54]\n",
            " [  16    7    8   53   12  635   39    5   73   44]\n",
            " [  26    7   47    0   16   41  814    1    6    0]\n",
            " [   2   49   32    2   17    7    4  801    2  112]\n",
            " [  12   18   15   59   23  105   15    4  662   61]\n",
            " [  10    9   20   11  119   18    0   27    7  788]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [14  9 15 17 18 23 16 21 24 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.036 s \n",
            "\n",
            "Accuracy rate for 83.400000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.83      0.80      0.82      1032\n",
            "           3       0.87      0.77      0.82      1010\n",
            "           4       0.83      0.90      0.86       982\n",
            "           5       0.68      0.73      0.70       892\n",
            "           6       0.88      0.89      0.89       958\n",
            "           7       0.90      0.83      0.86      1028\n",
            "           8       0.80      0.73      0.76       974\n",
            "           9       0.76      0.80      0.78      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 884    0   26    1    0   45   21    1    1    1]\n",
            " [   0 1096   12    6    0    5    3    0   13    0]\n",
            " [  29   26  824   19   16   12   18   26   57    5]\n",
            " [   8    9   40  779    1   96   10   15   26   26]\n",
            " [   6    9    2    0  883   15   10    6    3   48]\n",
            " [  21   11    3   43   11  654   40    6   63   40]\n",
            " [  30    9   26    0    9   15  857    4    8    0]\n",
            " [   4   29   33    1   17    4    4  850    2   84]\n",
            " [   6   21   11   38   18  105   14    9  708   44]\n",
            " [  17   11   12   10  106   15    0   28    5  805]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59825, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15 11 16 20 19 29 20 24 26 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.055 s \n",
            "\n",
            "Accuracy rate for 84.620000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.89      0.98      0.94      1135\n",
            "           2       0.86      0.78      0.82      1032\n",
            "           3       0.86      0.76      0.81      1010\n",
            "           4       0.84      0.91      0.87       982\n",
            "           5       0.70      0.80      0.75       892\n",
            "           6       0.87      0.93      0.90       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.84      0.70      0.77       974\n",
            "           9       0.80      0.79      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    0   31    1    0   20   23    2    1    2]\n",
            " [   0 1115    3    5    0    3    5    0    4    0]\n",
            " [  22   37  807   30   15   11   25   37   43    5]\n",
            " [   4    9   30  766    1  117   15   17   24   27]\n",
            " [   5    7    5    0  889   15   12    6    4   39]\n",
            " [  19   13    2   23    4  716   37    4   44   30]\n",
            " [  22    5   14    1    7   15  888    1    5    0]\n",
            " [   3   27   20    2   15    5    3  897    1   55]\n",
            " [   8   27   11   49   19  113   16   10  685   36]\n",
            " [  15   10   15   11  109   14    0   31    5  799]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [19 12 20 22 20 29 23 29 29 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.132 s \n",
            "\n",
            "Accuracy rate for 84.170000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.85      0.82      0.83      1032\n",
            "           3       0.85      0.76      0.80      1010\n",
            "           4       0.83      0.88      0.85       982\n",
            "           5       0.71      0.78      0.74       892\n",
            "           6       0.88      0.92      0.89       958\n",
            "           7       0.85      0.87      0.86      1028\n",
            "           8       0.83      0.72      0.77       974\n",
            "           9       0.81      0.75      0.78      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0   27    2    0   17   16    3    1    0]\n",
            " [   0 1099    0    4    0    3    7   12   10    0]\n",
            " [  11   23  842   28    7   11   25   49   35    1]\n",
            " [   8   12   33  769    3  123   11   18   22   11]\n",
            " [   6    2    8    0  866   15   14   15   11   45]\n",
            " [  22   11    4   37   10  695   35    5   53   20]\n",
            " [  31    3   17    2    4   13  877    4    7    0]\n",
            " [   5   24   17    0   19    5    1  894    1   62]\n",
            " [  13   26   17   51   14   89   14   10  701   39]\n",
            " [  15   10   20   13  125   13    2   44    7  760]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59775, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [20 14 22 23 21 36 23 32 36 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.926 s \n",
            "\n",
            "Accuracy rate for 84.880000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.92       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.84      0.84      0.84      1032\n",
            "           3       0.87      0.73      0.80      1010\n",
            "           4       0.81      0.88      0.84       982\n",
            "           5       0.72      0.87      0.79       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.85      0.87      0.86      1028\n",
            "           8       0.88      0.76      0.82       974\n",
            "           9       0.83      0.70      0.76      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1   26    0    0   15   13    2    1    0]\n",
            " [   0 1113    0    4    0    3    5    7    3    0]\n",
            " [  12   29  864   22    7   12   23   29   31    3]\n",
            " [   9   15   38  737    3  146   11   18   25    8]\n",
            " [   6    2   16    1  868   14   14   22    3   36]\n",
            " [  17    6    5   28    5  776   26    1   23    5]\n",
            " [  32    3   18    2    4   16  873    3    7    0]\n",
            " [   6   19   21    1   19    3    2  890    4   63]\n",
            " [  12   27   11   35   14   80   11   19  739   26]\n",
            " [  15   10   34   13  157   14    1   56    3  706]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [20 15 23 27 24 37 24 36 37 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.400 s \n",
            "\n",
            "Accuracy rate for 85.860000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.91      0.98      0.95      1135\n",
            "           2       0.84      0.84      0.84      1032\n",
            "           3       0.86      0.76      0.81      1010\n",
            "           4       0.86      0.90      0.88       982\n",
            "           5       0.74      0.85      0.79       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.84      0.89      0.86      1028\n",
            "           8       0.89      0.75      0.81       974\n",
            "           9       0.85      0.75      0.80      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    1   23    0    0   18   12    2    1    0]\n",
            " [   0 1113    0    4    0    3    4    6    5    0]\n",
            " [  14   21  870   28   13   14   21   28   20    3]\n",
            " [   9   16   33  770    2  119   10   19   22   10]\n",
            " [   9    3   14    2  881   14   12   20    4   23]\n",
            " [  15    7    4   33    4  762   34    3   24    6]\n",
            " [  31    3   20    1    5   15  871    5    7    0]\n",
            " [   0   18   20    2   11    4    1  911    1   60]\n",
            " [  12   24   16   42    7   73   15   26  726   33]\n",
            " [  12   11   31    9  103   10    1   69    4  759]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59725, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [22 16 23 29 25 41 27 37 44 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.787 s \n",
            "\n",
            "Accuracy rate for 86.730000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.86      0.84      0.85      1032\n",
            "           3       0.87      0.79      0.83      1010\n",
            "           4       0.86      0.90      0.88       982\n",
            "           5       0.77      0.86      0.81       892\n",
            "           6       0.88      0.92      0.90       958\n",
            "           7       0.85      0.89      0.87      1028\n",
            "           8       0.89      0.74      0.80       974\n",
            "           9       0.86      0.78      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    5    1    1   12   16    1    2    0]\n",
            " [   0 1115    0    4    0    3    4    6    3    0]\n",
            " [  16   18  868   27   15   12   23   32   20    1]\n",
            " [  12   14   34  794    1   92    6   21   24   12]\n",
            " [   6    3   13    1  881    8   15   18    6   31]\n",
            " [  15    5    5   30    4  765   31    2   29    6]\n",
            " [  16    3   19    1    7   21  882    6    3    0]\n",
            " [   0   17   22    2   10    4    1  920    3   49]\n",
            " [  11   21   23   37    8   73   29   24  717   31]\n",
            " [  11    9   26   11   96    8    1   56    2  789]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 7 ... 5 6 5]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [23 18 23 32 27 43 28 39 51 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.935 s \n",
            "\n",
            "Accuracy rate for 86.660000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.85      0.82      0.84      1032\n",
            "           3       0.86      0.78      0.82      1010\n",
            "           4       0.86      0.90      0.88       982\n",
            "           5       0.76      0.84      0.80       892\n",
            "           6       0.87      0.92      0.89       958\n",
            "           7       0.86      0.89      0.88      1028\n",
            "           8       0.89      0.76      0.82       974\n",
            "           9       0.86      0.80      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    7    1    1   12   19    2    1    0]\n",
            " [   0 1108    1    4    0    1    4    8    8    1]\n",
            " [  25   20  850   34   12   10   29   29   21    2]\n",
            " [  14    9   38  792    1   96    6   23   22    9]\n",
            " [   8    1   13    1  885    9   16   12    3   34]\n",
            " [  18    9    2   34   10  752   30    1   28    8]\n",
            " [  17    4   21    0    7   24  877    6    2    0]\n",
            " [   2   16   22    2    8    7    1  915    2   53]\n",
            " [   8   20   21   44   17   60   20   21  741   22]\n",
            " [  11   10   21    8   90   13    2   42    3  809]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['5' '0' '9' ... '5' '5' '8']\n",
            "probabilities: (59675, 10) \n",
            " [5 0 9 ... 5 5 8]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [23 20 25 36 29 47 28 42 57 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.096 s \n",
            "\n",
            "Accuracy rate for 87.550000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93       980\n",
            "           1       0.93      0.99      0.96      1135\n",
            "           2       0.87      0.83      0.85      1032\n",
            "           3       0.87      0.83      0.85      1010\n",
            "           4       0.86      0.89      0.87       982\n",
            "           5       0.78      0.84      0.81       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.88      0.89      0.89      1028\n",
            "           8       0.90      0.78      0.84       974\n",
            "           9       0.87      0.83      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.88      0.88      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    4    0    3   18   18    1    1    0]\n",
            " [   0 1119    0    4    0    1    5    1    5    0]\n",
            " [  21   25  855   31   18   11   26   25   17    3]\n",
            " [  12    6   32  839    1   68    7   22   18    5]\n",
            " [   8    2   17    1  878    7   15   12    4   38]\n",
            " [  16    5    3   35   14  749   30    5   28    7]\n",
            " [  15    4   18    0    9   29  874    5    4    0]\n",
            " [   6   13   19    2   11    5    1  915    1   55]\n",
            " [   7   20   14   37   15   60   19   23  757   22]\n",
            " [  13    9   21   12   77   12    1   27    3  834]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '9' ... '5' '5' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [23 20 32 37 32 50 29 46 60 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.215 s \n",
            "\n",
            "Accuracy rate for 87.940000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93       980\n",
            "           1       0.93      0.99      0.96      1135\n",
            "           2       0.87      0.86      0.86      1032\n",
            "           3       0.88      0.83      0.85      1010\n",
            "           4       0.86      0.90      0.88       982\n",
            "           5       0.78      0.85      0.81       892\n",
            "           6       0.89      0.90      0.90       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.92      0.79      0.85       974\n",
            "           9       0.88      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    0    5    1    3   19   18    1    3    0]\n",
            " [   0 1118    1    3    1    1    4    1    6    0]\n",
            " [  17   21  890   28   18   10   19   18    9    2]\n",
            " [  15    6   32  839    2   70    4   23   13    6]\n",
            " [   7    1   13    0  886    7   12   16    4   36]\n",
            " [  17    5    3   39    4  761   28    1   24   10]\n",
            " [  18    5   24    1   10   26  865    6    3    0]\n",
            " [   3   15   24    1    8   10    1  921    0   45]\n",
            " [   6   19   16   40   15   61   20   17  766   14]\n",
            " [  10    8   20    6   84   16    1   40    6  818]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [23 20 38 40 34 51 30 49 64 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.734 s \n",
            "\n",
            "Accuracy rate for 88.740000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.86      0.89      0.87      1032\n",
            "           3       0.88      0.83      0.86      1010\n",
            "           4       0.88      0.91      0.90       982\n",
            "           5       0.78      0.85      0.82       892\n",
            "           6       0.90      0.89      0.90       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.92      0.82      0.87       974\n",
            "           9       0.90      0.83      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 920    0   13    1    1   23   16    1    4    1]\n",
            " [   0 1117    0    5    1    2    3    1    6    0]\n",
            " [  14   18  918   24   12    5   15   19    6    1]\n",
            " [  16    3   26  840    1   75    4   24   15    6]\n",
            " [   6    2   16    0  894    6   14   11    3   30]\n",
            " [  16    4    5   41    3  762   24    1   22   14]\n",
            " [  18    5   36    3    8   29  853    1    5    0]\n",
            " [   3   13   22    0    8   11    2  939    0   30]\n",
            " [   5   17   15   31   14   51   12   20  796   13]\n",
            " [   7    9   20    7   71   12    1   39    8  835]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [24 22 39 44 37 55 33 51 66 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 33.889 s \n",
            "\n",
            "Accuracy rate for 88.910000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.93      0.98      0.96      1135\n",
            "           2       0.87      0.89      0.88      1032\n",
            "           3       0.88      0.83      0.85      1010\n",
            "           4       0.89      0.91      0.90       982\n",
            "           5       0.79      0.85      0.82       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.91      0.82      0.86       974\n",
            "           9       0.89      0.83      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    0   11    1    0   18   18    2    4    1]\n",
            " [   0 1113    1    5    1    2    4    2    7    0]\n",
            " [  14   22  922   15   12    4   19   15    7    2]\n",
            " [  14    3   24  837    1   77    6   19   23    6]\n",
            " [   4    2   15    0  894    7   13    7    3   37]\n",
            " [  13    5    6   46    9  760   18    4   21   10]\n",
            " [  19    5   27    1   10   24  865    2    5    0]\n",
            " [   3   17   26    3    6    8    1  935    0   29]\n",
            " [   5   19   11   34   10   49   12   21  799   14]\n",
            " [   6    9   20    7   62   16    1   40    7  841]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59575, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [26 24 42 45 40 58 34 53 70 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.505 s \n",
            "\n",
            "Accuracy rate for 88.900000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.87      0.90      0.89      1032\n",
            "           3       0.90      0.82      0.86      1010\n",
            "           4       0.88      0.91      0.90       982\n",
            "           5       0.78      0.86      0.82       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.90      0.82      0.86       974\n",
            "           9       0.90      0.83      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    0    8    1    0   18   19    1    2    1]\n",
            " [   0 1109    3    3    1    3    3    1   12    0]\n",
            " [  15   18  932   10   11    3   21   13    8    1]\n",
            " [  13    5   29  824    1   81    5   22   21    9]\n",
            " [   6    3   10    0  896    7   15    8    3   34]\n",
            " [  11    6   10   31   11  764   19    5   30    5]\n",
            " [  20    4   29    0   10   27  864    1    3    0]\n",
            " [   3   14   25    3    5    7    1  935    2   33]\n",
            " [   6   20   11   33    8   48   13   20  803   12]\n",
            " [   8    9   16    6   70   16    2   42    7  833]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [26 24 45 46 42 61 38 55 74 64] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.764 s \n",
            "\n",
            "Accuracy rate for 88.990000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.94      0.97      0.96      1135\n",
            "           2       0.87      0.89      0.88      1032\n",
            "           3       0.91      0.82      0.86      1010\n",
            "           4       0.89      0.90      0.89       982\n",
            "           5       0.80      0.87      0.84       892\n",
            "           6       0.88      0.93      0.90       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.89      0.82      0.85       974\n",
            "           9       0.90      0.83      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    0    8    1    0   17   18    2    4    0]\n",
            " [   0 1105    3    3    1    1    4    5   13    0]\n",
            " [  14   18  923   11    8    3   22   14   18    1]\n",
            " [  14    5   31  826    1   78    5   19   24    7]\n",
            " [   5    3   13    0  883    5   26    5    4   38]\n",
            " [  11    5    5   30   11  775   25    3   26    1]\n",
            " [  12    4   20    3    9   19  887    1    3    0]\n",
            " [   3   14   23    3   10    5    0  934    1   35]\n",
            " [   7   18   14   28   12   48   17   21  795   14]\n",
            " [   9    7   20    7   59   12    2   44    8  841]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59525, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [27 25 48 51 45 66 40 56 76 66] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 39.117 s \n",
            "\n",
            "Accuracy rate for 89.180000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.94      0.97      0.95      1135\n",
            "           2       0.88      0.91      0.89      1032\n",
            "           3       0.91      0.82      0.86      1010\n",
            "           4       0.88      0.90      0.89       982\n",
            "           5       0.80      0.87      0.83       892\n",
            "           6       0.88      0.93      0.90       958\n",
            "           7       0.89      0.90      0.90      1028\n",
            "           8       0.91      0.82      0.86       974\n",
            "           9       0.90      0.85      0.87      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    6    1    0   18   19    1    4    0]\n",
            " [   0 1098    2    2    1    1    4   14   12    1]\n",
            " [  12   19  935    9    9    4   23   12    8    1]\n",
            " [  13    4   35  824    1   77    6   17   26    7]\n",
            " [   7    4   11    0  884    5   25    4    4   38]\n",
            " [  10    3    6   30   14  775   29    4   20    1]\n",
            " [  12    4   13    1    9   23  892    1    3    0]\n",
            " [   3   12   19    5   13    7    1  929    1   38]\n",
            " [   7   17   19   26   13   48   13   21  796   14]\n",
            " [  10    7   18    5   58   12    2   38    5  854]]\n",
            "--------------------------------\n",
            "final active learning accuracies [48.74, 61.33, 68.51, 76.42, 79.34, 81.43, 83.39999999999999, 84.61999999999999, 84.17, 84.88, 85.86, 86.72999999999999, 86.66, 87.55, 87.94, 88.74, 88.91, 88.9, 88.99000000000001, 89.18]\n",
            "saved Active-learning-experiment-9.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 10, using model = SvmModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [0 1 0 0 0 0 2 3 2 2] [1 6 7 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.912 s \n",
            "\n",
            "Accuracy rate for 23.970000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.37      0.10      0.15      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.64      0.58      0.61       958\n",
            "           7       0.27      0.53      0.36      1028\n",
            "           8       0.16      0.77      0.27       974\n",
            "           9       0.20      0.43      0.28      1009\n",
            "\n",
            "    accuracy                           0.24     10000\n",
            "   macro avg       0.16      0.24      0.17     10000\n",
            "weighted avg       0.17      0.24      0.17     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    6    0    0    0    0  189  124  377  284]\n",
            " [   0  111    0    0    0    0    0   23 1001    0]\n",
            " [   0   92    0    0    0    0   94  104  564  178]\n",
            " [   0    6    0    0    0    0    2  253  711   38]\n",
            " [   0   12    0    0    0    0   11  262  106  591]\n",
            " [   0   19    0    0    0    0   11   88  633  141]\n",
            " [   0    1    0    0    0    0  554   55  259   89]\n",
            " [   0   19    0    0    0    0    0  544  154  311]\n",
            " [   0   34    0    0    0    0    7  115  751   67]\n",
            " [   0    1    0    0    0    0    3  442  126  437]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['8' '8' '9' ... '8' '9' '8']\n",
            "probabilities: (59990, 5) \n",
            " [4 2 2 ... 4 2 3]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [0 3 1 0 0 2 4 3 5 2] [1 2 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.766 s \n",
            "\n",
            "Accuracy rate for 34.500000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.47      0.47      0.47      1135\n",
            "           2       0.95      0.10      0.19      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.55      0.40      0.46       892\n",
            "           6       0.42      0.91      0.58       958\n",
            "           7       0.37      0.44      0.40      1028\n",
            "           8       0.21      0.80      0.34       974\n",
            "           9       0.30      0.34      0.32      1009\n",
            "\n",
            "    accuracy                           0.34     10000\n",
            "   macro avg       0.33      0.35      0.28     10000\n",
            "weighted avg       0.33      0.34      0.28     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   1   0   0   0 101 697  23 134  24]\n",
            " [  0 537   0   0   0   0   4   2 592   0]\n",
            " [  0 373 106   0   0  10 152  41 326  24]\n",
            " [  0  53   2   0   0  84  57  91 708  15]\n",
            " [  0  28   1   0   0   0 101 188 223 441]\n",
            " [  0  16   0   0   0 359 115  24 347  31]\n",
            " [  0   8   3   0   0   3 869   1  72   2]\n",
            " [  0  77   0   0   0   2   6 450 252 241]\n",
            " [  0  39   0   0   0  77  23  38 781  16]\n",
            " [  0   9   0   0   0  18  22 364 248 348]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['5' '8' '8' ... '5' '6' '8']\n",
            "probabilities: (59980, 7) \n",
            " [5 4 4 ... 4 3 5]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [1 3 1 1 1 2 5 5 7 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.575 s \n",
            "\n",
            "Accuracy rate for 42.510000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.24      0.38       980\n",
            "           1       0.58      0.44      0.50      1135\n",
            "           2       1.00      0.06      0.12      1032\n",
            "           3       0.87      0.11      0.20      1010\n",
            "           4       0.96      0.04      0.08       982\n",
            "           5       0.83      0.29      0.43       892\n",
            "           6       0.45      0.88      0.60       958\n",
            "           7       0.47      0.75      0.57      1028\n",
            "           8       0.26      0.87      0.40       974\n",
            "           9       0.37      0.58      0.45      1009\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.67      0.43      0.37     10000\n",
            "weighted avg       0.67      0.43      0.37     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[234   1   0   0   0  16 523  20 176  10]\n",
            " [  0 502   0   0   0   0   3  88 541   1]\n",
            " [  2 278  65   3   0   0 240 106 312  26]\n",
            " [  0  14   0 114   0  20  47  76 731   8]\n",
            " [  2   8   0   0  43   0  52 160  48 669]\n",
            " [  0  10   0  12   0 258 124  29 420  39]\n",
            " [ 16   4   0   0   0   1 841   7  83   6]\n",
            " [  0  22   0   0   0   0   6 769  34 197]\n",
            " [  0  19   0   0   0  12  15  67 843  18]\n",
            " [  1   2   0   2   2   3  14 331  72 582]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['5' '6' '4' ... '5' '6' '8']\n",
            "probabilities: (59970, 10) \n",
            " [8 6 7 ... 8 6 8]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [2 3 1 1 2 3 5 9 8 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.439 s \n",
            "\n",
            "Accuracy rate for 50.090000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.45      0.62       980\n",
            "           1       0.61      0.42      0.50      1135\n",
            "           2       1.00      0.05      0.10      1032\n",
            "           3       0.96      0.11      0.21      1010\n",
            "           4       0.93      0.12      0.22       982\n",
            "           5       0.63      0.54      0.58       892\n",
            "           6       0.56      0.84      0.67       958\n",
            "           7       0.59      0.83      0.69      1028\n",
            "           8       0.29      0.85      0.43       974\n",
            "           9       0.43      0.83      0.57      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.70      0.50      0.46     10000\n",
            "weighted avg       0.70      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[442   1   0   0   0 109 277   6  90  55]\n",
            " [  0 482   0   0   0   0   3  88 561   1]\n",
            " [  0 241  56   0   6   4 218 128 340  39]\n",
            " [  0  12   0 116   0  88  42 108 610  34]\n",
            " [  1   8   0   0 121   1  28  53  45 725]\n",
            " [  3   9   0   4   0 482  54  32 235  73]\n",
            " [  9   4   0   0   0  26 802   4  92  21]\n",
            " [  0  20   0   0   0   0   2 850  32 124]\n",
            " [  0  13   0   0   2  42  10  49 825  33]\n",
            " [  2   3   0   1   1  11   7 121  30 833]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59960, 10) \n",
            " [8 6 9 ... 8 6 8]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [3 3 1 1 3 5 8 9 9 8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.175 s \n",
            "\n",
            "Accuracy rate for 53.310000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.62      0.76       980\n",
            "           1       0.62      0.43      0.50      1135\n",
            "           2       1.00      0.06      0.10      1032\n",
            "           3       0.94      0.09      0.17      1010\n",
            "           4       0.82      0.24      0.37       982\n",
            "           5       0.62      0.56      0.59       892\n",
            "           6       0.59      0.88      0.71       958\n",
            "           7       0.63      0.79      0.70      1028\n",
            "           8       0.32      0.87      0.47       974\n",
            "           9       0.42      0.84      0.56      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.69      0.54      0.49     10000\n",
            "weighted avg       0.70      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[608   1   0   1   0  54 243   7  42  24]\n",
            " [  0 483   0   0   0   0   3  91 431 127]\n",
            " [  3 229  57   0  25   4 205 111 368  30]\n",
            " [  2  13   0  95   2 182  28  69 526  93]\n",
            " [  1   7   0   0 235   0  39  69  65 566]\n",
            " [  2   9   0   4  15 500  41  15 198 108]\n",
            " [  3   4   0   0   0  12 843   8  69  19]\n",
            " [  0  20   0   0   0   0   2 817  32 157]\n",
            " [  0  13   0   0   2  41  10  30 845  33]\n",
            " [  3   2   0   1   9  13   6  85  42 848]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 3  4  3  3  4  5  8  9  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.987 s \n",
            "\n",
            "Accuracy rate for 67.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.62      0.76       980\n",
            "           1       0.82      0.96      0.88      1135\n",
            "           2       0.89      0.33      0.48      1032\n",
            "           3       0.87      0.47      0.61      1010\n",
            "           4       0.82      0.48      0.60       982\n",
            "           5       0.69      0.54      0.61       892\n",
            "           6       0.64      0.87      0.74       958\n",
            "           7       0.76      0.78      0.77      1028\n",
            "           8       0.46      0.83      0.60       974\n",
            "           9       0.50      0.87      0.63      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.74      0.67      0.67     10000\n",
            "weighted avg       0.75      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 608    1    0    7    1   54  241    8   41   19]\n",
            " [   0 1088    4    1    0    0    1    8   26    7]\n",
            " [   3  107  338   11   33    3  116   78  322   21]\n",
            " [   1   19   28  470    3   93   19   39  269   69]\n",
            " [   1    7    1    0  467    0   31   19   28  428]\n",
            " [   2   39    4   41   24  481   36   11  144  110]\n",
            " [   3    4    1    1    9   12  838    7   66   17]\n",
            " [   0   33    1    0    8    0    1  799   21  165]\n",
            " [   0   27    1    6    5   39    9   25  813   49]\n",
            " [   2    9    1    2   22   14    8   54   19  878]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59940, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 6  8  4  4  5  5  8  9  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.868 s \n",
            "\n",
            "Accuracy rate for 72.570000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       980\n",
            "           1       0.75      0.98      0.85      1135\n",
            "           2       0.87      0.49      0.63      1032\n",
            "           3       0.84      0.51      0.64      1010\n",
            "           4       0.84      0.55      0.67       982\n",
            "           5       0.73      0.52      0.61       892\n",
            "           6       0.83      0.85      0.84       958\n",
            "           7       0.81      0.76      0.78      1028\n",
            "           8       0.55      0.82      0.66       974\n",
            "           9       0.55      0.86      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.76      0.72      0.72     10000\n",
            "weighted avg       0.76      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    1    0    7    0   34   69    4    6    4]\n",
            " [   0 1113    2    2    0    0    2    1   10    5]\n",
            " [  33  154  504    8   17    2   30   58  219    7]\n",
            " [  20   33   26  519    2   82   12   32  231   53]\n",
            " [  15   20   12    0  541    0   21    8   23  342]\n",
            " [  73   64    6   70   15  468   29    5   83   79]\n",
            " [  13   17   19    2   19   11  810    3   55    9]\n",
            " [  16   40    5    0   14    0    0  781   18  154]\n",
            " [  20   32    2   11    7   35    4   21  800   42]\n",
            " [  17   11    2    2   26    9    4   55   17  866]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59930, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 6  8  5  7  6  9  8 10  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.663 s \n",
            "\n",
            "Accuracy rate for 76.670000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       980\n",
            "           1       0.78      0.98      0.87      1135\n",
            "           2       0.88      0.53      0.67      1032\n",
            "           3       0.79      0.70      0.74      1010\n",
            "           4       0.83      0.63      0.72       982\n",
            "           5       0.71      0.66      0.68       892\n",
            "           6       0.84      0.83      0.84       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.65      0.79      0.71       974\n",
            "           9       0.63      0.84      0.72      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.78      0.76      0.76     10000\n",
            "weighted avg       0.78      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 840    1    0    7    0   60   63    5    1    3]\n",
            " [   0 1113    2    3    0    1    2    0    9    5]\n",
            " [  32  154  552   17   17    3   24   60  166    7]\n",
            " [  15   23   10  710    2  106    5   20   92   27]\n",
            " [  10   15   18    0  621    8   21    5   17  267]\n",
            " [  23   27    7  113   14  588   29   10   44   37]\n",
            " [  13   15   23    4   32   14  798    4   49    6]\n",
            " [  11   39    5    2   16    2    0  827   16  110]\n",
            " [  21   33    4   36    9   42    4   21  768   36]\n",
            " [  14   10    4   11   38    9    4   56   13  850]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['5' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59920, 10) \n",
            " [5 0 3 ... 5 6 8]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 6  8 10  8  7  9  8 11 10 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.430 s \n",
            "\n",
            "Accuracy rate for 77.620000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87       980\n",
            "           1       0.80      0.98      0.88      1135\n",
            "           2       0.75      0.57      0.64      1032\n",
            "           3       0.75      0.73      0.74      1010\n",
            "           4       0.84      0.68      0.75       982\n",
            "           5       0.72      0.63      0.68       892\n",
            "           6       0.84      0.78      0.81       958\n",
            "           7       0.86      0.84      0.85      1028\n",
            "           8       0.66      0.81      0.73       974\n",
            "           9       0.70      0.87      0.78      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.77      0.77     10000\n",
            "weighted avg       0.78      0.78      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 835    0    8   13    1   52   62    5    2    2]\n",
            " [   0 1109    2    2    0    1    2    0   16    3]\n",
            " [  29  135  585   16    6    3   20   55  181    2]\n",
            " [  15   19   21  733    1   91    6   15   96   13]\n",
            " [   1   14   38    1  666    6   14    4   11  227]\n",
            " [  24   22   19  148   12  566   30    8   37   26]\n",
            " [  10    8   87    4   47   14  745    1   39    3]\n",
            " [   7   40    8    2   22    2    0  860   13   74]\n",
            " [  17   29    7   45    4   39    6   17  785   25]\n",
            " [  10   11    7   15   31    9    4   36    8  878]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['5' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59910, 10) \n",
            " [5 0 3 ... 3 6 8]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 8  8 11  8  8 12  9 13 10 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.345 s \n",
            "\n",
            "Accuracy rate for 79.010000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       980\n",
            "           1       0.82      0.98      0.89      1135\n",
            "           2       0.80      0.62      0.70      1032\n",
            "           3       0.76      0.69      0.72      1010\n",
            "           4       0.83      0.69      0.75       982\n",
            "           5       0.69      0.67      0.68       892\n",
            "           6       0.84      0.80      0.82       958\n",
            "           7       0.85      0.87      0.86      1028\n",
            "           8       0.71      0.80      0.75       974\n",
            "           9       0.73      0.86      0.79      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    0    8    6    0   26   51    3    2    1]\n",
            " [   0 1109    1    2    0    3    3    1   14    2]\n",
            " [  22  119  641   10    4    4   31   61  139    1]\n",
            " [  15   19   17  693    0  137   13   17   91    8]\n",
            " [   2   11   41    1  674    9   15    8   10  211]\n",
            " [  31   24   13  134    5  597   23   12   36   17]\n",
            " [  10    3   62    2   65   29  769    0   18    0]\n",
            " [   9   32    8    2   16    1    0  891    5   64]\n",
            " [  18   27    7   40    5   46   10   19  781   21]\n",
            " [  16   10    7   16   42   13    2   32    8  863]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 3 ... 5 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 8  8 12 10  9 14 10 13 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.177 s \n",
            "\n",
            "Accuracy rate for 79.860000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87       980\n",
            "           1       0.86      0.98      0.92      1135\n",
            "           2       0.82      0.69      0.75      1032\n",
            "           3       0.80      0.65      0.72      1010\n",
            "           4       0.84      0.69      0.76       982\n",
            "           5       0.71      0.71      0.71       892\n",
            "           6       0.80      0.80      0.80       958\n",
            "           7       0.88      0.87      0.87      1028\n",
            "           8       0.68      0.83      0.75       974\n",
            "           9       0.73      0.87      0.80      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.79     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 843    0    6    3    1   18   99    2    3    5]\n",
            " [   0 1112    2    3    0    6    2    0    9    1]\n",
            " [  18   73  712   10    7    5   29   41  131    6]\n",
            " [  17    9   17  660    0  124   10   16  147   10]\n",
            " [   2   11   42    3  678   10   13    9   12  202]\n",
            " [  26   17    5   97    8  636   21   10   48   24]\n",
            " [  10    3   66    4   51   41  765    0   18    0]\n",
            " [  11   30   10    3   16    1    0  891    6   60]\n",
            " [  13   26    9   31    6   40   10   17  812   10]\n",
            " [  16   10    3   11   40   14    3   27    8  877]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59890, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 9  8 14 12  9 16 12 14 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.898 s \n",
            "\n",
            "Accuracy rate for 80.840000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.84      0.74      0.79      1032\n",
            "           3       0.71      0.70      0.70      1010\n",
            "           4       0.88      0.67      0.76       982\n",
            "           5       0.72      0.68      0.70       892\n",
            "           6       0.83      0.88      0.85       958\n",
            "           7       0.87      0.88      0.88      1028\n",
            "           8       0.70      0.82      0.75       974\n",
            "           9       0.76      0.81      0.78      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.80     10000\n",
            "weighted avg       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 895    0    6    5    3    7   56    1    3    4]\n",
            " [   0 1105    3    9    0    9    2    0    6    1]\n",
            " [  25   42  762   20    5   10   20   45  100    3]\n",
            " [  27    0   17  702    0   90    6   13  150    5]\n",
            " [   4   11   42    8  654   13   53    6    8  183]\n",
            " [  21    9    7  149    9  603   17    8   51   18]\n",
            " [   9    2   41    2   13   41  841    0    9    0]\n",
            " [  12   30    6    4   13    7    0  907    8   41]\n",
            " [   9   22   12   45    6   47   13   17  796    7]\n",
            " [  21    8    7   40   37   13    7   48    9  819]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59880, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 9  8 14 13 12 17 13 16 12 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.792 s \n",
            "\n",
            "Accuracy rate for 81.820000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.85      0.72      0.78      1032\n",
            "           3       0.74      0.72      0.73      1010\n",
            "           4       0.91      0.73      0.81       982\n",
            "           5       0.74      0.68      0.71       892\n",
            "           6       0.81      0.87      0.84       958\n",
            "           7       0.87      0.90      0.89      1028\n",
            "           8       0.70      0.82      0.75       974\n",
            "           9       0.79      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.81     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    0    6    2    1    8   85    1    2    4]\n",
            " [   0 1098    3    5    0   19    1    0    9    0]\n",
            " [  21   42  748   19    8    7   24   39  119    5]\n",
            " [  30    0   16  726    0   67    4   13  144   10]\n",
            " [   3    7   29    8  720   15   44    4    5  147]\n",
            " [  23   10    6  155   11  609   18    5   43   12]\n",
            " [   9    2   50    2   11   40  836    0    8    0]\n",
            " [   8   30    7    3    5    9    0  923    8   35]\n",
            " [   8   27    9   42    7   36   13   21  799   12]\n",
            " [  18    7    3   16   29   16    8   49   11  852]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59870, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 9  9 15 15 14 20 13 16 13 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.408 s \n",
            "\n",
            "Accuracy rate for 81.890000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89       980\n",
            "           1       0.90      0.97      0.94      1135\n",
            "           2       0.85      0.72      0.78      1032\n",
            "           3       0.74      0.70      0.72      1010\n",
            "           4       0.88      0.75      0.81       982\n",
            "           5       0.75      0.72      0.73       892\n",
            "           6       0.82      0.87      0.84       958\n",
            "           7       0.88      0.89      0.89      1028\n",
            "           8       0.67      0.82      0.74       974\n",
            "           9       0.79      0.83      0.81      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    1    5    2    1   20   83    1    3    3]\n",
            " [   0 1106    2    4    0   10    1    0   12    0]\n",
            " [  18   29  748   23   10   13   17   37  131    6]\n",
            " [  18    2   16  711    0   58    4   13  180    8]\n",
            " [   3    6   29    6  740   10   41    1    3  143]\n",
            " [  13   13    6  152    9  641   17    5   26   10]\n",
            " [   8    3   48    3   18   39  830    0    9    0]\n",
            " [   6   28    7    4    8   13    0  920    8   34]\n",
            " [   8   26   10   35   11   45   11   21  794   13]\n",
            " [  18    9    4   21   40    9    8   51   11  838]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59860, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [11  9 15 16 16 21 15 17 13 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.437 s \n",
            "\n",
            "Accuracy rate for 83.880000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.88      0.71      0.79      1032\n",
            "           3       0.75      0.77      0.76      1010\n",
            "           4       0.86      0.83      0.85       982\n",
            "           5       0.77      0.73      0.75       892\n",
            "           6       0.90      0.88      0.89       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.71      0.81      0.76       974\n",
            "           9       0.84      0.82      0.83      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 918    0    3    5    0   24   25    1    1    3]\n",
            " [   0 1106    2    4    0    9    1    0   12    1]\n",
            " [  28   31  735   22   17    9   11   45  131    3]\n",
            " [  19    2   14  780    2   40    4   13  121   15]\n",
            " [   3    5   19    9  812   15   26    1    4   88]\n",
            " [  15   10    5  146   15  652   11    6   22   10]\n",
            " [  10    3   39    5    9   42  842    0    8    0]\n",
            " [   8   29    8    5    9    7    2  924    8   28]\n",
            " [  16   27    9   38   12   44    4   20  793   11]\n",
            " [  19    8    3   20   63    9    5   44   12  826]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [11 11 15 19 18 22 16 17 13 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.239 s \n",
            "\n",
            "Accuracy rate for 84.030000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.89      0.69      0.78      1032\n",
            "           3       0.73      0.84      0.78      1010\n",
            "           4       0.86      0.82      0.84       982\n",
            "           5       0.78      0.68      0.73       892\n",
            "           6       0.89      0.90      0.89       958\n",
            "           7       0.88      0.89      0.88      1028\n",
            "           8       0.75      0.81      0.78       974\n",
            "           9       0.82      0.82      0.82      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    4    5    0   25   23    1    1    4]\n",
            " [   0 1114    2    2    0    5    5    0    5    2]\n",
            " [  28   25  717   46   15   10   17   40  129    5]\n",
            " [  16    2   15  850    1   25    3   13   71   14]\n",
            " [   4    9   20    8  807   11   30    1    5   87]\n",
            " [  15   13    5  184   15  610    9    7   21   13]\n",
            " [  10    2   26    4    7   43  858    1    7    0]\n",
            " [   7   31    9    3   10    7    3  917    9   32]\n",
            " [  16   24    9   39   14   36   10   18  790   18]\n",
            " [  19    9    3   21   66    7    3   49    9  823]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59840, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [12 12 18 19 19 25 17 17 13 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.128 s \n",
            "\n",
            "Accuracy rate for 84.530000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.89      0.73      0.80      1032\n",
            "           3       0.78      0.83      0.80      1010\n",
            "           4       0.84      0.84      0.84       982\n",
            "           5       0.78      0.74      0.76       892\n",
            "           6       0.89      0.89      0.89       958\n",
            "           7       0.87      0.89      0.88      1028\n",
            "           8       0.77      0.80      0.79       974\n",
            "           9       0.84      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    5    4    0   29   22    1    1    4]\n",
            " [   0 1113    2    3    1    6    4    0    4    2]\n",
            " [  28   27  749   31   17    6   19   42  109    4]\n",
            " [  17    4   14  834    1   43    2   14   68   13]\n",
            " [   4    6   15    8  827   10   33    2    6   71]\n",
            " [  14   12    7  132   15  663   13    8   16   12]\n",
            " [  22    3   24    2    5   40  851    0   11    0]\n",
            " [   6   28   11    2   13    9    6  914    8   31]\n",
            " [  14   36   13   35   16   37    7   17  781   18]\n",
            " [  20    8    2   19   84    9    4   48    8  807]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59830, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [14 12 19 19 19 26 20 19 13 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.644 s \n",
            "\n",
            "Accuracy rate for 84.540000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.88      0.73      0.80      1032\n",
            "           3       0.80      0.81      0.81      1010\n",
            "           4       0.84      0.84      0.84       982\n",
            "           5       0.80      0.77      0.78       892\n",
            "           6       0.85      0.90      0.87       958\n",
            "           7       0.87      0.90      0.88      1028\n",
            "           8       0.79      0.79      0.79       974\n",
            "           9       0.85      0.78      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    0    2    2    0   25   25    1    1    1]\n",
            " [   0 1113    2    3    1    6    5    0    4    1]\n",
            " [  31   28  753   31   16    7   28   27  108    3]\n",
            " [  21    4   14  817    0   55    4   19   64   12]\n",
            " [   3    6   15   10  822    7   40    4    4   71]\n",
            " [  25   11    7   94   13  687   26    7    8   14]\n",
            " [  24    3   31    3    6   23  864    1    3    0]\n",
            " [   7   30   13    2   17    5    4  924    7   19]\n",
            " [  15   35   10   35   14   41   16   21  766   21]\n",
            " [  18   10    4   21   87    8    6   64    6  785]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59820, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [15 13 19 21 20 27 21 19 13 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.523 s \n",
            "\n",
            "Accuracy rate for 84.820000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91       980\n",
            "           1       0.89      0.98      0.94      1135\n",
            "           2       0.88      0.72      0.80      1032\n",
            "           3       0.81      0.83      0.82      1010\n",
            "           4       0.86      0.81      0.83       982\n",
            "           5       0.80      0.78      0.79       892\n",
            "           6       0.86      0.92      0.89       958\n",
            "           7       0.88      0.89      0.89      1028\n",
            "           8       0.79      0.78      0.79       974\n",
            "           9       0.81      0.81      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    1    3    0    0   31   25    2    1    1]\n",
            " [   0 1115    2    3    1    6    3    0    4    1]\n",
            " [  27   38  747   29   15    7   29   24  111    5]\n",
            " [  19    4   13  838    0   51    3   16   57    9]\n",
            " [   4    4   18    2  793    5   40    3    4  109]\n",
            " [  26   10    6   95   12  693   23    8   11    8]\n",
            " [  18    2   26    1    8   21  878    1    3    0]\n",
            " [   6   31   14    1   15    4    3  918    6   30]\n",
            " [  11   33   14   44   12   39   15   17  764   25]\n",
            " [  17   10    4   21   71    6    6   49    5  820]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59810, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [16 14 20 22 21 30 22 19 14 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.064 s \n",
            "\n",
            "Accuracy rate for 84.990000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       980\n",
            "           1       0.89      0.98      0.93      1135\n",
            "           2       0.87      0.76      0.81      1032\n",
            "           3       0.79      0.83      0.81      1010\n",
            "           4       0.86      0.83      0.84       982\n",
            "           5       0.78      0.75      0.77       892\n",
            "           6       0.86      0.91      0.89       958\n",
            "           7       0.89      0.89      0.89      1028\n",
            "           8       0.82      0.78      0.80       974\n",
            "           9       0.83      0.81      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    0    2    0    0   26   22    2    1    1]\n",
            " [   0 1113    2    4    1    9    1    0    2    3]\n",
            " [  27   41  780   27   15    8   32   23   73    6]\n",
            " [  15    4   24  835    0   60    2   14   49    7]\n",
            " [   4    6   18    3  814    5   40    4    2   86]\n",
            " [  23   12    5  112   11  672   18    8   24    7]\n",
            " [  22    5   24    1    6   21  876    0    3    0]\n",
            " [   6   28   24    4   15    8    3  912    4   24]\n",
            " [   9   29   15   40   12   45   22   17  758   27]\n",
            " [  17   10    5   25   74    6    4   50    5  813]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [16 15 20 22 21 33 24 20 14 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.832 s \n",
            "\n",
            "Accuracy rate for 85.110000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91       980\n",
            "           1       0.89      0.98      0.93      1135\n",
            "           2       0.88      0.76      0.82      1032\n",
            "           3       0.81      0.81      0.81      1010\n",
            "           4       0.89      0.83      0.86       982\n",
            "           5       0.77      0.77      0.77       892\n",
            "           6       0.84      0.92      0.88       958\n",
            "           7       0.89      0.88      0.88      1028\n",
            "           8       0.83      0.78      0.80       974\n",
            "           9       0.81      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    0    1    0    0   27   34    2    1    0]\n",
            " [   0 1114    2    5    0    5    3    0    2    4]\n",
            " [  30   37  784   25   13    7   37   23   71    5]\n",
            " [  18    5   24  814    0   76    2   13   48   10]\n",
            " [   4    6   17    0  812    2   37    4    4   96]\n",
            " [  22   13    5   97   11  688   19    5   21   11]\n",
            " [  19    6   21    0    6   23  880    0    3    0]\n",
            " [   7   26   18    4   11    8    3  902    4   45]\n",
            " [   8   33   11   41   13   47   23   15  758   25]\n",
            " [  17    8    5   19   45   12    4   50    5  844]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59790, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [17 15 23 23 22 33 24 20 15 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.040 s \n",
            "\n",
            "Accuracy rate for 85.980000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.88      0.81      0.84      1032\n",
            "           3       0.82      0.82      0.82      1010\n",
            "           4       0.89      0.84      0.86       982\n",
            "           5       0.78      0.77      0.78       892\n",
            "           6       0.87      0.92      0.90       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.85      0.78      0.81       974\n",
            "           9       0.81      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    1    0    0   19   27    1    1    0]\n",
            " [   0 1113    3    3    0    2    3    0    8    3]\n",
            " [  37   18  834   28   15    6   26   20   44    4]\n",
            " [  16    3   22  831    0   73    2   12   33   18]\n",
            " [   4    6   17    2  821    1   32    3    4   92]\n",
            " [  21   14    5   90    8  687   17    4   33   13]\n",
            " [  20    6   15    0    5   24  884    0    4    0]\n",
            " [   5   22   30    3   11    7    1  896    4   49]\n",
            " [   7   35   20   38   11   48   18   17  758   22]\n",
            " [  18    7    5   15   51    9    1   52    8  843]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59780, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [17 15 23 26 23 33 25 20 19 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.781 s \n",
            "\n",
            "Accuracy rate for 86.080000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.89      0.81      0.85      1032\n",
            "           3       0.81      0.83      0.82      1010\n",
            "           4       0.89      0.85      0.87       982\n",
            "           5       0.79      0.77      0.78       892\n",
            "           6       0.87      0.92      0.89       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.86      0.78      0.81       974\n",
            "           9       0.81      0.84      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    0    1    1    0   17   29    1    1    0]\n",
            " [   0 1114    2   10    0    2    1    0    4    2]\n",
            " [  37   19  836   29   13    6   32   19   37    4]\n",
            " [  17    6   18  836    0   69    2   13   33   16]\n",
            " [   4    5   11    1  836    2   26    3    5   89]\n",
            " [  19   14    2   89    8  684   23    4   35   14]\n",
            " [  19    6   17    0   10   21  881    0    4    0]\n",
            " [   5   21   31    8   11    7    0  893    4   48]\n",
            " [  10   40   19   30   11   51   21   15  755   22]\n",
            " [  16    8    4   22   52    9    0   52    3  843]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59770, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [17 15 24 27 24 36 25 22 20 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.704 s \n",
            "\n",
            "Accuracy rate for 86.000000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.90      0.81      0.85      1032\n",
            "           3       0.82      0.82      0.82      1010\n",
            "           4       0.87      0.86      0.87       982\n",
            "           5       0.77      0.79      0.78       892\n",
            "           6       0.89      0.92      0.90       958\n",
            "           7       0.87      0.87      0.87      1028\n",
            "           8       0.86      0.76      0.81       974\n",
            "           9       0.81      0.82      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    0    0    0    0   20   28    1    1    1]\n",
            " [   0 1115    2    9    0    1    2    0    4    2]\n",
            " [  27   18  836   39   13    6   27   20   42    4]\n",
            " [  14    4   15  827    0   79    2   18   33   18]\n",
            " [   4    5   11    2  847    2   19    4    2   86]\n",
            " [  17   15    4   76   12  703   18    3   26   18]\n",
            " [  16    6   19    0   16   20  878    0    3    0]\n",
            " [   6   20   28    8   10    9    0  893    4   50]\n",
            " [  12   35   12   31   13   67   17   23  743   21]\n",
            " [  15    7    2   20   59    8    1   66    2  829]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59760, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [18 16 24 28 24 38 26 22 22 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.607 s \n",
            "\n",
            "Accuracy rate for 86.510000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       980\n",
            "           1       0.90      0.99      0.95      1135\n",
            "           2       0.91      0.81      0.86      1032\n",
            "           3       0.82      0.82      0.82      1010\n",
            "           4       0.87      0.86      0.87       982\n",
            "           5       0.79      0.80      0.79       892\n",
            "           6       0.90      0.92      0.91       958\n",
            "           7       0.87      0.87      0.87      1028\n",
            "           8       0.87      0.78      0.82       974\n",
            "           9       0.81      0.82      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    1    0    0    0   17   22    1    2    1]\n",
            " [   0 1123    2    4    1    2    2    0    0    1]\n",
            " [  31   17  841   38   13    8   23   20   36    5]\n",
            " [  15    7   15  833    0   70    2   18   34   16]\n",
            " [   4    5   11    1  847    5   22    3    4   80]\n",
            " [  18    9    5   74   11  713   19    3   24   16]\n",
            " [  15    7   14    0   19   21  878    0    4    0]\n",
            " [   6   18   29    7   10    9    0  897    3   49]\n",
            " [  10   47    8   32   13   55   12   21  756   20]\n",
            " [  11    7    2   24   60    8    1   65    4  827]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [18 16 25 28 24 38 28 24 25 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.340 s \n",
            "\n",
            "Accuracy rate for 86.450000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.91      0.81      0.86      1032\n",
            "           3       0.84      0.83      0.83      1010\n",
            "           4       0.88      0.85      0.86       982\n",
            "           5       0.78      0.79      0.79       892\n",
            "           6       0.89      0.92      0.90       958\n",
            "           7       0.88      0.87      0.87      1028\n",
            "           8       0.86      0.79      0.82       974\n",
            "           9       0.79      0.83      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    1    0    0    0   19   19    1    3    1]\n",
            " [   0 1113    3    3    1    2    3    0    9    1]\n",
            " [  25   16  836   34   12    9   29   18   47    6]\n",
            " [  15    7   15  839    0   72    2   18   31   11]\n",
            " [   4    5    9    0  832    3   23    4    5   97]\n",
            " [  18    8    4   77   13  707   19    3   20   23]\n",
            " [  14    7   15    0   16   21  883    0    2    0]\n",
            " [   6   17   30    5   12    3    2  890    9   54]\n",
            " [  13   32    7   28   11   60   13   16  770   24]\n",
            " [  13    8    2   18   49    8    3   65    4  839]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59740, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [19 17 26 30 25 39 28 25 26 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.321 s \n",
            "\n",
            "Accuracy rate for 86.750000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.91      0.83      0.87      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.86      0.86      0.86       982\n",
            "           5       0.80      0.77      0.79       892\n",
            "           6       0.89      0.92      0.91       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.87      0.78      0.83       974\n",
            "           9       0.81      0.82      0.81      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    1    1    0    0   13   24    1    5    0]\n",
            " [   0 1120    3    3    1    2    3    0    2    1]\n",
            " [  24   17  853   29   13    8   20   17   45    6]\n",
            " [   9    7   16  864    1   56    2   18   28    9]\n",
            " [   4    5    6    1  846    3   20    4    2   91]\n",
            " [  17    9    5   97   14  691   18    4   17   20]\n",
            " [  15    6   16    2    9   25  882    0    3    0]\n",
            " [   8   17   30    5   14    4    2  896    5   47]\n",
            " [  11   30    6   38   14   56   17   14  764   24]\n",
            " [  17    7    3   20   67    8    2   58    3  824]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59730, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [20 17 27 32 26 40 31 26 26 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.132 s \n",
            "\n",
            "Accuracy rate for 86.510000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.89      0.81      0.85      1032\n",
            "           3       0.82      0.85      0.84      1010\n",
            "           4       0.85      0.86      0.86       982\n",
            "           5       0.81      0.80      0.80       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.86      0.78      0.81       974\n",
            "           9       0.81      0.80      0.81      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    1    1    1    0   12   27    1    2    0]\n",
            " [   0 1120    4    2    1    1    3    0    2    2]\n",
            " [  26   13  839   34   14    8   15   14   64    5]\n",
            " [  10    7   15  862    0   59    2   18   27   10]\n",
            " [   4    5   10    0  845    4   20    5    3   86]\n",
            " [  17    8    5   84   10  713   14    3   19   19]\n",
            " [  14    5   26    2   11   23  876    0    1    0]\n",
            " [   9   16   33    5   16    3    1  894    7   44]\n",
            " [  11   32   10   39   17   53   22   12  756   22]\n",
            " [  17    7    4   18   78    8    2   61    3  811]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59720, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [20 17 29 33 27 41 31 29 26 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.898 s \n",
            "\n",
            "Accuracy rate for 86.180000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.88      0.81      0.85      1032\n",
            "           3       0.83      0.85      0.84      1010\n",
            "           4       0.85      0.86      0.85       982\n",
            "           5       0.80      0.79      0.79       892\n",
            "           6       0.88      0.91      0.90       958\n",
            "           7       0.88      0.88      0.88      1028\n",
            "           8       0.85      0.75      0.79       974\n",
            "           9       0.81      0.81      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    1    1    0   14   29    2    1    1]\n",
            " [   0 1121    4    2    0    1    3    0    2    2]\n",
            " [  25   13  841   29   14    7   16   16   66    5]\n",
            " [  11    9   14  863    3   54    2   17   27   10]\n",
            " [   4    6   13    1  843    2   22    3    4   84]\n",
            " [  17    9    5   89   10  701   19    7   17   18]\n",
            " [  14    4   27    2   17   22  871    0    1    0]\n",
            " [   6   15   29    4   15    1    1  905    6   46]\n",
            " [  12   34   12   36   18   70   20   15  726   31]\n",
            " [  16    6    5   16   74    9    2   62    3  816]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59710, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [21 18 29 34 28 41 32 33 27 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.760 s \n",
            "\n",
            "Accuracy rate for 86.400000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.93       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.91      0.81      0.85      1032\n",
            "           3       0.84      0.86      0.85      1010\n",
            "           4       0.85      0.86      0.85       982\n",
            "           5       0.81      0.79      0.80       892\n",
            "           6       0.89      0.92      0.91       958\n",
            "           7       0.85      0.89      0.87      1028\n",
            "           8       0.85      0.75      0.80       974\n",
            "           9       0.81      0.80      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    1    1    0   10   25    1    0    1]\n",
            " [   0 1118    4    2    0    2    3    2    2    2]\n",
            " [  26   16  832   25   14    7   17   27   64    4]\n",
            " [   9    5   11  869    1   53    1   25   29    7]\n",
            " [   5    5    9    0  846    2   20    6    3   86]\n",
            " [  17   11    7   77   11  703   20    7   23   16]\n",
            " [  13    4   17    2   20   18  883    0    1    0]\n",
            " [   8   15   19    1   20    1    2  914    5   43]\n",
            " [  14   30   12   44   14   70   18   16  732   24]\n",
            " [  19    7    4   17   73    7    2   72    5  803]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [21 18 33 36 30 41 33 33 28 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.314 s \n",
            "\n",
            "Accuracy rate for 86.430000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.90      0.81      0.85      1032\n",
            "           3       0.84      0.86      0.85      1010\n",
            "           4       0.83      0.87      0.85       982\n",
            "           5       0.82      0.78      0.80       892\n",
            "           6       0.89      0.92      0.91       958\n",
            "           7       0.86      0.89      0.87      1028\n",
            "           8       0.84      0.76      0.80       974\n",
            "           9       0.82      0.80      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    1    5    0    0   10   26    1    1    2]\n",
            " [   0 1119    3    1    1    1    4    2    2    2]\n",
            " [  21   16  834   25   16    3   16   28   69    4]\n",
            " [  14    5   18  864    0   47    2   24   30    6]\n",
            " [   4    6   10    0  858    3   19    8    3   71]\n",
            " [  17   10    9   83   15  693   20    7   25   13]\n",
            " [  12    4   16    1   24   17  882    0    2    0]\n",
            " [   7   15   20    2   19    1    1  912    5   46]\n",
            " [  16   29    9   37   19   68   15   13  741   27]\n",
            " [  18    7    5   16   79    6    2   66    4  806]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59690, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [23 18 34 37 30 44 33 35 29 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.258 s \n",
            "\n",
            "Accuracy rate for 86.400000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.90      0.79      0.84      1032\n",
            "           3       0.83      0.86      0.84      1010\n",
            "           4       0.84      0.88      0.86       982\n",
            "           5       0.82      0.78      0.80       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.82      0.78      0.80       974\n",
            "           9       0.82      0.80      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    4    1    0   13   22    1    2    0]\n",
            " [   0 1118    3    2    1    3    2    2    2    2]\n",
            " [  23   17  816   36   15    5   14   26   75    5]\n",
            " [  12    6   14  867    1   38    2   24   39    7]\n",
            " [   3    6   10    0  862    2   19    8    2   70]\n",
            " [  14   10   10   83   11  695   23    5   31   10]\n",
            " [  17    4   19    1   24   19  872    0    2    0]\n",
            " [   8   15   18    2   18    1    1  907    6   52]\n",
            " [  10   30    9   31   18   63   14   12  762   25]\n",
            " [  13    7    6   20   78    5    2   69    5  804]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59680, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [23 20 35 37 30 45 33 36 31 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.063 s \n",
            "\n",
            "Accuracy rate for 86.300000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93       980\n",
            "           1       0.91      0.99      0.95      1135\n",
            "           2       0.89      0.77      0.83      1032\n",
            "           3       0.84      0.87      0.85      1010\n",
            "           4       0.84      0.86      0.85       982\n",
            "           5       0.83      0.79      0.81       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.85      0.88      0.87      1028\n",
            "           8       0.82      0.79      0.80       974\n",
            "           9       0.82      0.80      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    3    1    0   12   23    1    2    1]\n",
            " [   0 1119    3    2    1    3    2    2    1    2]\n",
            " [  24   29  799   32   16    5   16   27   80    4]\n",
            " [  11    8   14  874    1   34    2   24   36    6]\n",
            " [   3    5   13    0  848    1   19   13    3   77]\n",
            " [  15    9    8   77    9  709   21    5   33    6]\n",
            " [  17    5   23    1   26   18  865    0    3    0]\n",
            " [   6   15   17    1   18    1    1  908    5   56]\n",
            " [   7   36    9   26   18   61   12   13  765   27]\n",
            " [  13    6    4   22   73    7    3   72    3  806]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59670, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [24 20 35 38 33 47 34 36 32 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.860 s \n",
            "\n",
            "Accuracy rate for 86.770000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       980\n",
            "           1       0.91      0.99      0.95      1135\n",
            "           2       0.89      0.77      0.83      1032\n",
            "           3       0.83      0.87      0.85      1010\n",
            "           4       0.84      0.89      0.87       982\n",
            "           5       0.84      0.81      0.82       892\n",
            "           6       0.91      0.90      0.91       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.84      0.78      0.81       974\n",
            "           9       0.83      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    2    0    1   13   17    1    2    1]\n",
            " [   0 1120    3    3    1    1    3    2    1    1]\n",
            " [  22   28  798   37   18    7   16   26   77    3]\n",
            " [  12    6   14  879    0   38    2   25   28    6]\n",
            " [   4    4   12    0  873    0   17   10    0   62]\n",
            " [  16   11   10   73   12  719   16    5   24    6]\n",
            " [  17    5   25    0   23   22  863    0    3    0]\n",
            " [   4   15   18    1   17    0    0  908    6   59]\n",
            " [  10   35   12   37   15   54   12   11  764   24]\n",
            " [  14    6    5   23   74    7    2   65    3  810]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59660, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [25 20 37 39 34 49 35 36 33 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.064 s \n",
            "\n",
            "Accuracy rate for 86.700000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.91      0.99      0.95      1135\n",
            "           2       0.89      0.79      0.84      1032\n",
            "           3       0.84      0.87      0.86      1010\n",
            "           4       0.84      0.89      0.86       982\n",
            "           5       0.83      0.81      0.82       892\n",
            "           6       0.91      0.90      0.90       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.84      0.78      0.81       974\n",
            "           9       0.84      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    1    7    0    1   18   22    1    1    0]\n",
            " [   0 1118    3    3    1    2    3    2    2    1]\n",
            " [  17   30  815   34   16    7   13   23   73    4]\n",
            " [  17    5   12  883    1   33    2   24   29    4]\n",
            " [   4    4   12    0  871    0   19   11    2   59]\n",
            " [  21    9    6   73   13  721   17    4   23    5]\n",
            " [  13    5   24    1   24   24  863    0    4    0]\n",
            " [   7   15   17    1   18    0    0  903    6   61]\n",
            " [   8   38   11   32   19   60   11   13  759   23]\n",
            " [  14    6    7   21   76    8    2   64    3  808]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [25 21 37 40 34 50 37 38 36 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.206 s \n",
            "\n",
            "Accuracy rate for 86.820000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.91      0.98      0.95      1135\n",
            "           2       0.89      0.79      0.83      1032\n",
            "           3       0.84      0.87      0.86      1010\n",
            "           4       0.84      0.89      0.86       982\n",
            "           5       0.83      0.81      0.82       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.87      0.88      0.87      1028\n",
            "           8       0.84      0.79      0.82       974\n",
            "           9       0.83      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    1    8    1    1   17   25    1    2    0]\n",
            " [   0 1115    2    4    1    1    3    1    7    1]\n",
            " [  16   29  813   36   16    8   13   23   74    4]\n",
            " [  16    6   15  883    1   34    3   25   23    4]\n",
            " [   4    5   12    0  870    1   20   11    1   58]\n",
            " [  18   11    7   71   13  725   18    4   20    5]\n",
            " [  13    6   24    1   20   19  870    0    5    0]\n",
            " [   7   13   17    1   16    1    2  905    5   61]\n",
            " [   8   27   11   32   20   56   10   11  772   27]\n",
            " [  15    6    7   22   75    8    1   65    5  805]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59640, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [26 21 38 41 35 51 38 40 37 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.082 s \n",
            "\n",
            "Accuracy rate for 86.780000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.89      0.80      0.84      1032\n",
            "           3       0.82      0.87      0.85      1010\n",
            "           4       0.84      0.89      0.86       982\n",
            "           5       0.84      0.80      0.82       892\n",
            "           6       0.91      0.91      0.91       958\n",
            "           7       0.86      0.89      0.88      1028\n",
            "           8       0.86      0.78      0.82       974\n",
            "           9       0.84      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    8    1    0   25   23    1    2    1]\n",
            " [   0 1112    3    4    0    1    2    2   10    1]\n",
            " [  13   28  829   48   18    2   13   24   54    3]\n",
            " [  18    7   16  883    1   27    2   26   25    5]\n",
            " [   5    5   12    0  875    1   16   10    3   55]\n",
            " [  20   13   10   78   15  713   14    4   21    4]\n",
            " [  15    5   26    0   12   25  870    0    5    0]\n",
            " [   5   12   16    3   18    0    1  913    2   58]\n",
            " [  12   31    7   43   22   48   10   13  761   27]\n",
            " [  12    6    6   18   85    7    3   63    6  803]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59630, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [27 21 40 41 36 53 40 40 38 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.935 s \n",
            "\n",
            "Accuracy rate for 86.840000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.88      0.80      0.84      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.84      0.90      0.87       982\n",
            "           5       0.83      0.80      0.82       892\n",
            "           6       0.93      0.91      0.92       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.86      0.79      0.82       974\n",
            "           9       0.84      0.80      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    0    6    1    0   28   15    1    2    0]\n",
            " [   0 1112    3    4    0    1    2    2   10    1]\n",
            " [  17   27  829   47   16    2   10   29   52    3]\n",
            " [  19    7   22  866    1   42    1   25   22    5]\n",
            " [   5    4   12    0  881    0   13   10    3   54]\n",
            " [  20   13   11   71   13  717   16    5   22    4]\n",
            " [  14    4   25    1   15   20  873    0    6    0]\n",
            " [   6   12   22    3   19    0    1  905    2   58]\n",
            " [  10   28   10   42   20   50    9   12  767   26]\n",
            " [  12    6    5   20   86    6    3   59    5  807]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59620, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [27 21 41 42 39 54 40 42 40 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.634 s \n",
            "\n",
            "Accuracy rate for 86.700000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93       980\n",
            "           1       0.91      0.98      0.94      1135\n",
            "           2       0.88      0.80      0.84      1032\n",
            "           3       0.81      0.86      0.84      1010\n",
            "           4       0.83      0.90      0.86       982\n",
            "           5       0.84      0.80      0.82       892\n",
            "           6       0.93      0.91      0.92       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.85      0.78      0.81       974\n",
            "           9       0.85      0.79      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    0    6    1    1   26   15    1    2    1]\n",
            " [   0 1111    3    4    0    1    2    2   11    1]\n",
            " [  18   30  828   42   19    2   11   26   52    4]\n",
            " [  17    5   20  870    1   42    1   26   24    4]\n",
            " [   5    4   13    0  883    1   12   13    1   50]\n",
            " [  18   14    9   70   15  716   16    4   25    5]\n",
            " [  13    5   24    2   19   19  870    0    6    0]\n",
            " [   6   13   22    1   19    0    0  907    2   58]\n",
            " [  10   31   10   55   19   43   11   13  759   23]\n",
            " [  10    6    6   23   88    4    2   61   10  799]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59610, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [27 22 41 44 39 56 41 42 43 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 32.412 s \n",
            "\n",
            "Accuracy rate for 86.930000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.91      0.98      0.95      1135\n",
            "           2       0.89      0.80      0.84      1032\n",
            "           3       0.81      0.86      0.84      1010\n",
            "           4       0.83      0.90      0.86       982\n",
            "           5       0.83      0.80      0.82       892\n",
            "           6       0.92      0.92      0.92       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.86      0.78      0.82       974\n",
            "           9       0.85      0.80      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    6    1    0   27   16    1    2    3]\n",
            " [   0 1114    2    4    0    2    2    2    8    1]\n",
            " [  18   29  827   42   19    2   12   27   52    4]\n",
            " [  18    7   17  867    1   44    1   26   23    6]\n",
            " [   5    5   13    0  882    1   11   12    2   51]\n",
            " [  18   11    9   74   17  718   17    5   21    2]\n",
            " [   9    5   24    2   17   17  881    0    3    0]\n",
            " [   7   12   22    1   19    0    0  908    2   57]\n",
            " [  12   31    8   53   18   46   12   13  764   17]\n",
            " [  12    6    4   20   88    5    2   56    8  808]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [28 22 41 44 41 57 44 44 43 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 33.334 s \n",
            "\n",
            "Accuracy rate for 87.260000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93       980\n",
            "           1       0.91      0.98      0.95      1135\n",
            "           2       0.89      0.81      0.85      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.83      0.81      0.82       892\n",
            "           6       0.91      0.92      0.91       958\n",
            "           7       0.87      0.89      0.88      1028\n",
            "           8       0.86      0.78      0.82       974\n",
            "           9       0.87      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    0    5    1    0   24   19    1    2    3]\n",
            " [   0 1114    2    4    0    1    3    2    8    1]\n",
            " [  15   30  831   41   18    2   13   27   51    4]\n",
            " [  13    7   17  871    1   43    3   25   23    7]\n",
            " [   4    4    9    0  896    1   12    9    1   46]\n",
            " [  22   10    7   68   15  719   22    5   20    4]\n",
            " [  11    5   22    1   10   28  877    0    4    0]\n",
            " [   5   12   22    4   18    0    0  919    2   46]\n",
            " [  11   31   10   54   17   47   16   15  758   15]\n",
            " [  10    6    6   20   84    4    1   54    8  816]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59590, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [29 23 41 44 41 59 45 44 45 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 33.917 s \n",
            "\n",
            "Accuracy rate for 87.620000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.90      0.80      0.85      1032\n",
            "           3       0.83      0.87      0.85      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.84      0.81      0.82       892\n",
            "           6       0.91      0.92      0.91       958\n",
            "           7       0.88      0.89      0.89      1028\n",
            "           8       0.86      0.79      0.82       974\n",
            "           9       0.86      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    5    1    0   12   20    1    2    2]\n",
            " [   0 1114    3    3    1    1    2    1    9    1]\n",
            " [  16   27  829   42   18    4   14   28   50    4]\n",
            " [  13    9   15  878    2   36    4   21   25    7]\n",
            " [   3    3    9    0  899    1   13    7    1   46]\n",
            " [  24   10    7   66   10  720   22    5   19    9]\n",
            " [  11    6   19    1    9   27  882    0    3    0]\n",
            " [   6   13   22    3   17    1    0  918    2   46]\n",
            " [  13   27   11   50   17   47   12   15  765   17]\n",
            " [  10    6    6   19   86    5    1   45   11  820]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59580, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [30 23 42 44 42 60 45 45 48 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 34.420 s \n",
            "\n",
            "Accuracy rate for 87.830000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.90      0.81      0.85      1032\n",
            "           3       0.83      0.87      0.85      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.85      0.81      0.83       892\n",
            "           6       0.91      0.92      0.91       958\n",
            "           7       0.89      0.89      0.89      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.87      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    0    3    1    0    6   20    1    2    2]\n",
            " [   0 1114    3    3    1    1    3    1    8    1]\n",
            " [  11   26  832   42   19    4   15   27   51    5]\n",
            " [  14    9   19  881    2   30    3   21   26    5]\n",
            " [   2    3    6    0  897    0   14    5    2   53]\n",
            " [  25   10    8   66    9  720   22    6   21    5]\n",
            " [  10    5   19    1    9   29  881    0    4    0]\n",
            " [   3   16   21    4   19    1    0  916    4   44]\n",
            " [  10   26   10   47   14   51   13   14  777   12]\n",
            " [   8    6    7   18   87    6    1   44   12  820]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59570, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [30 24 43 46 42 61 45 47 50 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 34.927 s \n",
            "\n",
            "Accuracy rate for 87.760000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.90      0.81      0.86      1032\n",
            "           3       0.82      0.87      0.84      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.85      0.80      0.83       892\n",
            "           6       0.90      0.91      0.91       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.87      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    3    1    0    6   20    1    3    2]\n",
            " [   0 1120    2    3    1    2    3    1    2    1]\n",
            " [  12   26  837   46   20    1   14   26   46    4]\n",
            " [  13    9   13  883    1   32    4   25   27    3]\n",
            " [   2    3    6    0  894    0   15    9    1   52]\n",
            " [  25   10    8   71    9  714   24    5   22    4]\n",
            " [  10    5   21    1   11   30  874    0    6    0]\n",
            " [   5   15   22    3   18    2    0  921    3   39]\n",
            " [  12   27    8   55   15   45   11   12  775   14]\n",
            " [   8    6    5   17   88    6    1   52   12  814]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59560, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [30 24 45 48 43 65 45 47 50 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 36.511 s \n",
            "\n",
            "Accuracy rate for 88.110000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.90      0.82      0.86      1032\n",
            "           3       0.82      0.88      0.85      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.85      0.82      0.83       892\n",
            "           6       0.92      0.91      0.91       958\n",
            "           7       0.89      0.90      0.89      1028\n",
            "           8       0.88      0.79      0.83       974\n",
            "           9       0.87      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    0    3    0    0    7   20    1    2    2]\n",
            " [   0 1120    3    3    1    3    3    1    0    1]\n",
            " [  12   26  850   47   19    2   14   24   33    5]\n",
            " [  13    9   18  886    1   26    2   20   29    6]\n",
            " [   2    3    4    0  904    0   13    6    1   49]\n",
            " [  18   10   10   71    7  727   17    5   22    5]\n",
            " [  11    6   21    2   12   32  868    0    6    0]\n",
            " [   5   14   23    3   19    2    0  921    2   39]\n",
            " [  12   28    7   54   16   56    8    8  772   13]\n",
            " [   8    5    6   16   88    5    1   50   12  818]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [31 24 49 49 44 66 45 47 51 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 36.332 s \n",
            "\n",
            "Accuracy rate for 88.160000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.89      0.83      0.86      1032\n",
            "           3       0.82      0.87      0.85      1010\n",
            "           4       0.84      0.92      0.88       982\n",
            "           5       0.85      0.82      0.83       892\n",
            "           6       0.92      0.91      0.91       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.87      0.80      0.83       974\n",
            "           9       0.88      0.81      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    5    2    0    6   19    1    3    2]\n",
            " [   0 1118    3    3    1    3    4    1    1    1]\n",
            " [  11   26  854   44   21    2   15   21   34    4]\n",
            " [   9    9   21  883    1   26    2   20   33    6]\n",
            " [   2    3    6    0  907    0   13    4    1   46]\n",
            " [  22   10    6   72    6  728   16    6   21    5]\n",
            " [  12    6   21    3   13   31  867    0    5    0]\n",
            " [   4   14   25    3   22    3    0  924    2   31]\n",
            " [  11   27    9   46   16   57    9   10  775   14]\n",
            " [   9    5    6   16   95    5    1   43   11  818]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59540, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [31 24 50 51 44 71 45 47 53 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.593 s \n",
            "\n",
            "Accuracy rate for 88.130000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.89      0.83      0.86      1032\n",
            "           3       0.83      0.86      0.84      1010\n",
            "           4       0.84      0.92      0.88       982\n",
            "           5       0.82      0.83      0.82       892\n",
            "           6       0.92      0.91      0.91       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.88      0.80      0.84       974\n",
            "           9       0.88      0.81      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    0    5    1    0   18   18    1    1    2]\n",
            " [   0 1115    3    4    1    3    3    1    4    1]\n",
            " [   9   25  854   42   22    4   16   21   35    4]\n",
            " [   7    5   18  873    1   47    4   20   29    6]\n",
            " [   3    2    6    0  906    0   12    5    2   46]\n",
            " [  19    8    5   68    7  738   15    5   23    4]\n",
            " [  11    5   24    1   11   33  869    0    4    0]\n",
            " [   4   12   24    3   22    4    0  926    2   31]\n",
            " [  11   30   11   49   14   49    7   10  779   14]\n",
            " [   9    5    6   16   94    4    1   44   11  819]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59530, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [32 24 52 54 44 72 47 47 53 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 38.728 s \n",
            "\n",
            "Accuracy rate for 87.910000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.89      0.82      0.85      1032\n",
            "           3       0.82      0.87      0.84      1010\n",
            "           4       0.84      0.92      0.88       982\n",
            "           5       0.82      0.84      0.83       892\n",
            "           6       0.91      0.91      0.91       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.87      0.79      0.83       974\n",
            "           9       0.88      0.80      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0    7    2    0   19   28    1    1    0]\n",
            " [   0 1114    3    5    1    3    3    1    4    1]\n",
            " [  10   26  845   57   23    3   14   16   35    3]\n",
            " [   7    5   20  877    2   43    5   15   31    5]\n",
            " [   3    2    5    1  906    0   12    6    2   45]\n",
            " [  17    8    5   59    7  748   17    3   24    4]\n",
            " [  10    5   24    2    6   36  871    0    4    0]\n",
            " [   5   11   24    3   19    3    0  926    2   35]\n",
            " [  10   26    9   52   17   53    7   14  770   16]\n",
            " [  11    5    4   14   94    6    2   50   11  812]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59520, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [32 27 53 55 44 73 47 48 53 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 39.556 s \n",
            "\n",
            "Accuracy rate for 88.000000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.92      0.98      0.95      1135\n",
            "           2       0.89      0.82      0.85      1032\n",
            "           3       0.82      0.87      0.84      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.82      0.83      0.83       892\n",
            "           6       0.91      0.91      0.91       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.87      0.79      0.83       974\n",
            "           9       0.88      0.82      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    7    2    0   19   26    1    1    0]\n",
            " [   0 1115    3    4    1    3    2    1    5    1]\n",
            " [  11   26  845   59   21    3   14   15   35    3]\n",
            " [   5    7   23  877    2   40    5   16   31    4]\n",
            " [   3    4    5    1  901    2   12    5    2   47]\n",
            " [  19   10    6   61    7  742   14    3   24    6]\n",
            " [  11    5   24    2    8   37  867    0    4    0]\n",
            " [   5   10   24    3   19    3    0  926    2   36]\n",
            " [  10   25   10   50   17   49    8   15  773   17]\n",
            " [  11    6    4   15   84    5    2   41   11  830]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59510, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [32 27 53 56 45 74 48 48 57 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 40.223 s \n",
            "\n",
            "Accuracy rate for 88.010000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.89      0.82      0.85      1032\n",
            "           3       0.81      0.87      0.84      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.83      0.82      0.83       892\n",
            "           6       0.91      0.90      0.91       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.87      0.80      0.83       974\n",
            "           9       0.88      0.82      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    6    3    0   19   23    1    0    0]\n",
            " [   0 1116    3    3    1    4    0    1    6    1]\n",
            " [  11   25  845   60   22    2   14   15   35    3]\n",
            " [   6    7   19  878    2   39    6   18   32    3]\n",
            " [   3    4    7    1  903    1   14    4    2   43]\n",
            " [  19   11    6   60    8  734   18    3   27    6]\n",
            " [  12    5   24    4    8   35  866    0    4    0]\n",
            " [   5   10   25    2   17    4    0  923    4   38]\n",
            " [   9   22   13   52   16   45    7   12  783   15]\n",
            " [  11    6    5   16   87    4    2   44    9  825]]\n",
            "--------------------------------\n",
            "final active learning accuracies [23.97, 34.5, 42.51, 50.09, 53.31, 67.80000000000001, 72.57000000000001, 76.67, 77.62, 79.01, 79.86, 80.84, 81.82000000000001, 81.89, 83.88, 84.03, 84.53, 84.54, 84.82, 84.99, 85.11, 85.98, 86.08, 86.0, 86.50999999999999, 86.45, 86.75, 86.50999999999999, 86.18, 86.4, 86.42999999999999, 86.4, 86.3, 86.77, 86.7, 86.82, 86.78, 86.83999999999999, 86.7, 86.92999999999999, 87.26, 87.62, 87.83, 87.76, 88.11, 88.16000000000001, 88.13, 87.91, 88.0, 88.01]\n",
            "saved Active-learning-experiment-10.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 11, using model = SvmModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [20 25 25 29 23 23 35 19 23 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.295 s \n",
            "\n",
            "Accuracy rate for 84.140000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.90       980\n",
            "           1       0.92      0.93      0.92      1135\n",
            "           2       0.81      0.78      0.79      1032\n",
            "           3       0.83      0.85      0.84      1010\n",
            "           4       0.78      0.90      0.84       982\n",
            "           5       0.79      0.76      0.77       892\n",
            "           6       0.83      0.94      0.88       958\n",
            "           7       0.88      0.85      0.87      1028\n",
            "           8       0.81      0.73      0.77       974\n",
            "           9       0.86      0.76      0.81      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 888    1    2    5    4   41   32    6    1    0]\n",
            " [   0 1054    1    2    0    3    7    2   63    3]\n",
            " [  45   22  804   35   35    4   41   13   31    2]\n",
            " [   1    6   27  861    3   51    9   15   27   10]\n",
            " [   1    2    2    0  880    0   28    1    2   66]\n",
            " [   8   13   11   82   26  676   37   11   22    6]\n",
            " [   4    2    7    1   18   20  904    0    2    0]\n",
            " [  10   30   43    9   29    2    5  872    8   20]\n",
            " [  15   19   75   34   13   56   23   13  708   18]\n",
            " [  17    2   23   12  114    8    2   53   11  767]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 47  35  36  69  25 104  41  35  54  54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 36.832 s \n",
            "\n",
            "Accuracy rate for 85.280000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.91      0.96      0.93      1135\n",
            "           2       0.85      0.81      0.83      1032\n",
            "           3       0.83      0.85      0.84      1010\n",
            "           4       0.88      0.84      0.86       982\n",
            "           5       0.76      0.74      0.75       892\n",
            "           6       0.87      0.91      0.89       958\n",
            "           7       0.88      0.88      0.88      1028\n",
            "           8       0.80      0.78      0.79       974\n",
            "           9       0.84      0.82      0.83      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    0    2    3    0   50   17    1    1    2]\n",
            " [   0 1087    2    3    0    2    4    1   36    0]\n",
            " [  26   33  838   16   20    6   40   18   29    6]\n",
            " [  10    4   34  858    1   60    2   14   20    7]\n",
            " [   2    4    4    3  822   10   22   12   12   91]\n",
            " [  17   11   15   90    5  656   27    3   67    1]\n",
            " [  25    3   11    3   21   11  871    4    9    0]\n",
            " [   0   21   32   10   12   16    1  904    7   25]\n",
            " [  15   30   38   37    5   32   12   13  761   31]\n",
            " [   3    8    7   13   52   23    1   61   14  827]]\n",
            "--------------------------------\n",
            "final active learning accuracies [84.14, 85.28]\n",
            "saved Active-learning-experiment-11.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 12, using model = SvmModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [16 10 11 13 12  7 11 15 14 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.107 s \n",
            "\n",
            "Accuracy rate for 74.640000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       980\n",
            "           1       0.80      0.91      0.85      1135\n",
            "           2       0.82      0.67      0.74      1032\n",
            "           3       0.73      0.70      0.72      1010\n",
            "           4       0.67      0.77      0.72       982\n",
            "           5       0.69      0.43      0.53       892\n",
            "           6       0.79      0.79      0.79       958\n",
            "           7       0.86      0.82      0.84      1028\n",
            "           8       0.59      0.64      0.61       974\n",
            "           9       0.65      0.74      0.69      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0    1    3    5   11   11   11   12    4]\n",
            " [   0 1029    0    3    3   32    5   23    9   31]\n",
            " [  34   57  695   58   34    0   81   23   32   18]\n",
            " [   4   11   34  711    8   74    5   18   88   57]\n",
            " [   3   16    0    0  758    0   27    2   46  130]\n",
            " [  51   17   10  143   38  385   24    8  168   48]\n",
            " [  58    3    2    7   88   29  758    0    9    4]\n",
            " [   2   43   15    5   19    2    3  842   23   74]\n",
            " [   6   98   82   35   24   23   36   11  622   37]\n",
            " [   8    8    5    8  149    3    4   41   41  742]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 32 50 18 14 23 27 18 36 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.696 s \n",
            "\n",
            "Accuracy rate for 78.970000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.83      0.80      0.82      1032\n",
            "           3       0.78      0.75      0.76      1010\n",
            "           4       0.77      0.80      0.79       982\n",
            "           5       0.74      0.43      0.55       892\n",
            "           6       0.81      0.86      0.84       958\n",
            "           7       0.89      0.82      0.85      1028\n",
            "           8       0.61      0.82      0.70       974\n",
            "           9       0.71      0.69      0.70      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.78      0.78     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 890    0    4   10    1   27   30    7    9    2]\n",
            " [   0 1099    5    1    0    0    1    1   27    1]\n",
            " [  17   15  822   22   19    9   75   12   34    7]\n",
            " [   2    3   37  753    1   26   14   14  137   23]\n",
            " [   2   16    3    0  786    3   14    4   47  107]\n",
            " [  71   16    7  160   18  386   21   12  158   43]\n",
            " [  27    8    8    0   25   41  827    0   22    0]\n",
            " [   1   26   49    0   17    7    2  845   16   65]\n",
            " [  23   30   23   16    7   11   27   11  794   32]\n",
            " [  11   11   27    6  145   11    4   44   55  695]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [28 32 60 25 18 70 35 31 37 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.277 s \n",
            "\n",
            "Accuracy rate for 82.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.83      0.79      0.81      1032\n",
            "           3       0.84      0.78      0.81      1010\n",
            "           4       0.83      0.81      0.82       982\n",
            "           5       0.75      0.74      0.74       892\n",
            "           6       0.86      0.89      0.87       958\n",
            "           7       0.92      0.79      0.85      1028\n",
            "           8       0.72      0.78      0.74       974\n",
            "           9       0.76      0.80      0.78      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    0    5    5    0   49   11    5    6    8]\n",
            " [   0 1097    6    1    0    2    2    2   25    0]\n",
            " [  22   20  818   25   18   12   65    9   37    6]\n",
            " [  13    3   39  785    1   71    4   11   72   11]\n",
            " [   1   10   10    0  795   10   14    2   40  100]\n",
            " [  33   12    7   79    3  662   24    3   58   11]\n",
            " [  17    5    4    1   30   35  851    0   15    0]\n",
            " [   2   30   50    4    8    2    0  817   15  100]\n",
            " [  29   28   37   30   13   30   18   11  756   22]\n",
            " [  15   11    4    7   87   15    1   29   32  808]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [51 40 64 32 32 88 37 42 64 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.110 s \n",
            "\n",
            "Accuracy rate for 82.920000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.85      0.78      0.81      1032\n",
            "           3       0.83      0.74      0.78      1010\n",
            "           4       0.87      0.82      0.84       982\n",
            "           5       0.74      0.73      0.73       892\n",
            "           6       0.88      0.87      0.88       958\n",
            "           7       0.90      0.78      0.83      1028\n",
            "           8       0.69      0.83      0.76       974\n",
            "           9       0.73      0.80      0.77      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    0    1    4    0   32    4    1    2    3]\n",
            " [   0 1102    6    5    1    2    2    2   14    1]\n",
            " [  18   11  801   29   14   23   63    9   58    6]\n",
            " [   7    7   31  745    1   76    4   14  111   14]\n",
            " [   1    8    8    0  803   10   11    5   25  111]\n",
            " [  17   18    6   75    6  647   14    1   85   23]\n",
            " [  30    3    4    3   22   47  838    0    9    2]\n",
            " [  13   17   56    1    6    0    0  801   12  122]\n",
            " [  14   24   16   26    8   38   11   10  813   14]\n",
            " [   7    8    9   11   65    5    0   51   44  809]]\n",
            "--------------------------------\n",
            "final active learning accuracies [74.64, 78.97, 82.8, 82.92]\n",
            "saved Active-learning-experiment-12.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 13, using model = SvmModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [5 4 7 4 6 6 3 5 7 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.197 s \n",
            "\n",
            "Accuracy rate for 62.850000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77       980\n",
            "           1       0.78      0.94      0.85      1135\n",
            "           2       0.47      0.65      0.55      1032\n",
            "           3       0.69      0.46      0.55      1010\n",
            "           4       0.56      0.78      0.65       982\n",
            "           5       0.47      0.52      0.49       892\n",
            "           6       0.88      0.59      0.70       958\n",
            "           7       0.77      0.49      0.60      1028\n",
            "           8       0.74      0.62      0.68       974\n",
            "           9       0.39      0.43      0.41      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.65      0.62      0.63     10000\n",
            "weighted avg       0.66      0.63      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 737    0   58   43   10   97    6    3   20    6]\n",
            " [   0 1072   51    2    3    2    3    0    0    2]\n",
            " [  30  101  668   61   40    7   39    4   80    2]\n",
            " [  15   42   96  466    4  294    2    2   38   51]\n",
            " [  11   29   40   22  770    1    5   17    1   86]\n",
            " [  59   19  122   25   46  462   13    6   53   87]\n",
            " [  59    4  217    1   82   22  563    0   10    0]\n",
            " [   1   43   79    3   23    2    0  501    1  375]\n",
            " [  13   59   50   26   42   78   12    6  608   80]\n",
            " [   9   14   27   27  358   15    0  110   11  438]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 4 ... 3 2 4]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  9  7  4  6 47  3  5  8  4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.667 s \n",
            "\n",
            "Accuracy rate for 66.170000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       980\n",
            "           1       0.64      0.96      0.77      1135\n",
            "           2       0.56      0.57      0.56      1032\n",
            "           3       0.80      0.36      0.50      1010\n",
            "           4       0.60      0.79      0.68       982\n",
            "           5       0.53      0.74      0.62       892\n",
            "           6       0.91      0.55      0.69       958\n",
            "           7       0.87      0.64      0.73      1028\n",
            "           8       0.81      0.58      0.68       974\n",
            "           9       0.48      0.49      0.49      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.70      0.66      0.65     10000\n",
            "weighted avg       0.70      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    0   27    9    2   48    1    1    3    6]\n",
            " [   0 1093    3    1    0   33    3    0    0    2]\n",
            " [  38  240  588   15   36   16   32    3   59    5]\n",
            " [  76  100   47  367    3  333    0    3   32   49]\n",
            " [   4   40   35   12  776    3    6   13    2   91]\n",
            " [  46   20   43   15   18  660    6    0   11   73]\n",
            " [ 102   17  180    0   68   54  530    0    7    0]\n",
            " [   3   67   67    2   19    5    0  655    1  209]\n",
            " [  31  110   31   25   29   74    3    5  568   98]\n",
            " [   9   23   29   13  339   10    0   75   14  497]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 4 ... 5 2 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 8  9  7  9  8 50  6 13 27 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.625 s \n",
            "\n",
            "Accuracy rate for 68.550000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.82       980\n",
            "           1       0.71      0.93      0.81      1135\n",
            "           2       0.65      0.57      0.61      1032\n",
            "           3       0.64      0.36      0.46      1010\n",
            "           4       0.61      0.74      0.67       982\n",
            "           5       0.51      0.75      0.60       892\n",
            "           6       0.91      0.70      0.80       958\n",
            "           7       0.77      0.78      0.77      1028\n",
            "           8       0.67      0.75      0.71       974\n",
            "           9       0.68      0.36      0.47      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.69      0.68      0.67     10000\n",
            "weighted avg       0.69      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    0   25    0    3   76    0    1    1    3]\n",
            " [   0 1061    2    0    0   65    3    0    4    0]\n",
            " [  32  221  587   21   18   32   42    4   66    9]\n",
            " [  90   67   40  363    1  287    3   13  138    8]\n",
            " [   2   12   46   27  727   13    2   72   14   67]\n",
            " [  49    9   20   50    4  665    5    0   76   14]\n",
            " [  64    6  103    1   27   64  675    1   14    3]\n",
            " [   6   50   45   10   38   11    0  806    9   53]\n",
            " [  13   54    7   36   15   79    8   16  733   13]\n",
            " [   6    9   22   59  354   15    0  140   37  367]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '3' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 3 ... 5 2 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 8  9 15 12 20 50 18 21 28 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.291 s \n",
            "\n",
            "Accuracy rate for 73.150000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.72      0.65      0.69      1032\n",
            "           3       0.73      0.43      0.54      1010\n",
            "           4       0.69      0.87      0.77       982\n",
            "           5       0.58      0.69      0.63       892\n",
            "           6       0.88      0.80      0.84       958\n",
            "           7       0.78      0.80      0.79      1028\n",
            "           8       0.69      0.77      0.73       974\n",
            "           9       0.69      0.46      0.55      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 849    0   28    0    8   73    8    2    2   10]\n",
            " [   0 1085    2   22    0   16    4    0    4    2]\n",
            " [  19  186  675    2   21   19   39   11   54    6]\n",
            " [  73   59   67  439    2  213   16   16  120    5]\n",
            " [   1    3   10    9  857    4    3   28   12   55]\n",
            " [  52   12   29   37   11  613   18    6   89   25]\n",
            " [  29    4   53    0   48   46  768    0    8    2]\n",
            " [   2   25   50    8   21    0    0  818   16   88]\n",
            " [  10   54   17   28    7   69   16   12  750   11]\n",
            " [   7   10    3   58  262   12    0  157   39  461]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '3' ... '5' '6' '5']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 3 ... 5 6 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [11 13 17 19 30 58 19 22 33 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.361 s \n",
            "\n",
            "Accuracy rate for 74.160000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       980\n",
            "           1       0.78      0.98      0.87      1135\n",
            "           2       0.74      0.63      0.68      1032\n",
            "           3       0.70      0.54      0.61      1010\n",
            "           4       0.70      0.85      0.77       982\n",
            "           5       0.67      0.68      0.68       892\n",
            "           6       0.87      0.81      0.84       958\n",
            "           7       0.76      0.79      0.77      1028\n",
            "           8       0.65      0.80      0.72       974\n",
            "           9       0.71      0.41      0.52      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 893    0   20    0    1   53    9    1    3    0]\n",
            " [   0 1115    2    4    0    5    3    0    4    2]\n",
            " [  53  143  646    7   22   14   59    8   71    9]\n",
            " [  32   62   48  549    4  113   12   18  166    6]\n",
            " [   3   10   21   23  831    4    4   39    8   39]\n",
            " [  42   10   15   78   12  609   13    2  100   11]\n",
            " [  37    6   52    2   39   34  777    0   11    0]\n",
            " [   4   21   50    9   22    6    0  809   12   95]\n",
            " [   8   50   10   37   10   55   14    8  775    7]\n",
            " [  15   12    7   77  249   10    1  185   41  412]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '3' ... '5' '6' '5']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 3 ... 5 6 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [13 18 23 25 33 61 25 26 38 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.786 s \n",
            "\n",
            "Accuracy rate for 77.570000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.72      0.67      0.69      1032\n",
            "           3       0.75      0.68      0.71      1010\n",
            "           4       0.73      0.87      0.80       982\n",
            "           5       0.69      0.72      0.71       892\n",
            "           6       0.84      0.81      0.82       958\n",
            "           7       0.84      0.79      0.81      1028\n",
            "           8       0.67      0.80      0.73       974\n",
            "           9       0.79      0.52      0.63      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.77      0.77     10000\n",
            "weighted avg       0.78      0.78      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    0   12    1    2   62    9    1    3    1]\n",
            " [   0 1106    5    1    0    4    5    0   13    1]\n",
            " [  47   95  689    5   18   18   65    8   79    8]\n",
            " [  30   22   35  686    0   93   23    8  112    1]\n",
            " [   1    2   32   16  853    4    2   15   13   44]\n",
            " [  30    6   16   79   11  643   23    3   78    3]\n",
            " [  18    4   89    1   26   30  775    1   14    0]\n",
            " [  10   10   54   16   20   13    0  809   19   77]\n",
            " [   8   29   10   54   11   52   20    6  778    6]\n",
            " [  10    9   11   56  220    9    1  113   51  529]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '3' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 3 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [13 21 28 34 35 77 27 27 45 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.233 s \n",
            "\n",
            "Accuracy rate for 78.940000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       980\n",
            "           1       0.87      0.96      0.92      1135\n",
            "           2       0.77      0.73      0.75      1032\n",
            "           3       0.79      0.72      0.76      1010\n",
            "           4       0.76      0.87      0.82       982\n",
            "           5       0.67      0.74      0.70       892\n",
            "           6       0.89      0.80      0.84       958\n",
            "           7       0.86      0.78      0.82      1028\n",
            "           8       0.65      0.80      0.72       974\n",
            "           9       0.77      0.59      0.67      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 851    0   15    2    2   90   11    0    5    4]\n",
            " [   0 1095    2    1    0    7    4    0   25    1]\n",
            " [  24   65  758   14   15   23   34    6   85    8]\n",
            " [  20   20   27  729    0   93   13    6  100    2]\n",
            " [   1    6   24   12  857    4    1   10   14   53]\n",
            " [  27   14   12   50    7  660   19    4   97    2]\n",
            " [  22    5   91    1   27   34  767    1   10    0]\n",
            " [   6   13   43   12   16   10    0  801   27  100]\n",
            " [   4   28   12   50   11   57   15    5  784    8]\n",
            " [   6   10    6   50  186    7    0  102   50  592]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '3' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 3 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [13 24 34 35 42 81 28 36 56 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.938 s \n",
            "\n",
            "Accuracy rate for 80.390000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       980\n",
            "           1       0.85      0.98      0.91      1135\n",
            "           2       0.80      0.73      0.77      1032\n",
            "           3       0.82      0.74      0.78      1010\n",
            "           4       0.73      0.92      0.81       982\n",
            "           5       0.66      0.78      0.72       892\n",
            "           6       0.85      0.83      0.84       958\n",
            "           7       0.88      0.83      0.85      1028\n",
            "           8       0.79      0.75      0.77       974\n",
            "           9       0.79      0.58      0.67      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    0   12    2    2   85    9    1    3    4]\n",
            " [   0 1109    3    2    0    8    4    0    8    1]\n",
            " [  30   82  758   12   15   18   65    8   40    4]\n",
            " [  21   22   29  751    1  110   14   13   45    4]\n",
            " [   1    2   13    0  900    2    2    7    5   50]\n",
            " [  23   15   11   47    6  693   16    5   69    7]\n",
            " [  22    5   71    0   31   35  793    0    1    0]\n",
            " [   2   17   32   15   22    5    0  854    1   80]\n",
            " [   7   47   14   42    6   84   31    9  731    3]\n",
            " [   7    8    4   49  245    5    0   76   27  588]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 5 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [19 25 42 39 48 90 29 41 61 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.196 s \n",
            "\n",
            "Accuracy rate for 78.410000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       980\n",
            "           1       0.85      0.96      0.90      1135\n",
            "           2       0.74      0.70      0.72      1032\n",
            "           3       0.79      0.75      0.77      1010\n",
            "           4       0.76      0.91      0.83       982\n",
            "           5       0.65      0.71      0.68       892\n",
            "           6       0.88      0.81      0.84       958\n",
            "           7       0.87      0.82      0.84      1028\n",
            "           8       0.74      0.75      0.75       974\n",
            "           9       0.82      0.59      0.69      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 790    0   34    4    1  134   12    0    1    4]\n",
            " [   0 1092    2    3    0   12    4    0   21    1]\n",
            " [  72   84  724    9   11   14   47    6   60    5]\n",
            " [  37   25   24  758    1   75    8   10   68    4]\n",
            " [   2    2   23    1  892    2    2    5    3   50]\n",
            " [  63   11   11   64    7  632   15    7   76    6]\n",
            " [  22    2  100    1   27   27  775    0    4    0]\n",
            " [   2   16   44   33   13    8    0  846    6   60]\n",
            " [  52   41    9   43    7   62   17    8  733    2]\n",
            " [   9    9    8   49  218    4    0   96   17  599]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [26 29 47 46 50 99 31 45 67 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 38.249 s \n",
            "\n",
            "Accuracy rate for 80.450000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.78      0.75      0.77      1032\n",
            "           3       0.79      0.75      0.77      1010\n",
            "           4       0.78      0.91      0.84       982\n",
            "           5       0.68      0.72      0.70       892\n",
            "           6       0.90      0.83      0.86       958\n",
            "           7       0.86      0.84      0.85      1028\n",
            "           8       0.76      0.77      0.77       974\n",
            "           9       0.82      0.65      0.73      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 824    1   25    2    1  103   14    1    1    8]\n",
            " [   0 1096    3    3    0    6    3    0   23    1]\n",
            " [  39   86  773   16    9    8   34   10   54    3]\n",
            " [  59   20   15  754    2   93    4   12   49    2]\n",
            " [   3    1   21    1  893    6    1    7    3   46]\n",
            " [  53   11    7   63    6  644   11   12   73   12]\n",
            " [  12    2   94    1   28   25  794    0    2    0]\n",
            " [   2   11   35   25   14    6    0  860    6   69]\n",
            " [  29   44    8   50    8   55   18    8  749    5]\n",
            " [   6    7    7   34  184    6    0   87   20  658]]\n",
            "--------------------------------\n",
            "final active learning accuracies [62.849999999999994, 66.17, 68.55, 73.15, 74.16, 77.57, 78.94, 80.39, 78.41, 80.45]\n",
            "saved Active-learning-experiment-13.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 14, using model = SvmModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 2 1 3 4 0 3 3 3 4] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.232 s \n",
            "\n",
            "Accuracy rate for 52.190000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.62      0.70       980\n",
            "           1       0.74      0.93      0.83      1135\n",
            "           2       0.90      0.15      0.26      1032\n",
            "           3       0.59      0.59      0.59      1010\n",
            "           4       0.47      0.64      0.54       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.81      0.68      0.74       958\n",
            "           7       0.40      0.63      0.49      1028\n",
            "           8       0.26      0.33      0.29       974\n",
            "           9       0.34      0.56      0.42      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.53      0.51      0.49     10000\n",
            "weighted avg       0.54      0.52      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 603    1    0    8   51    0   37  136  110   34]\n",
            " [   0 1054    0    1    0    0    3   23   43   11]\n",
            " [  22  143  154   57  150    0   58   89  269   90]\n",
            " [  33   30    2  593   36    0   23   51  190   52]\n",
            " [   0    8    0    0  630    0    4   69    4  267]\n",
            " [  45   36    0  112  133    0   26  133  258  149]\n",
            " [   3   23   14    1  116    0  654   17   31   99]\n",
            " [   0   52    0    6   46    0    0  647    3  274]\n",
            " [  22   50    2  220   41    0    4  186  317  132]\n",
            " [   6   19    0   10  147    0    0  257    3  567]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59975, 9) \n",
            " [7 0 4 ... 8 5 7]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 5  2  2  7  4 14  3  3  6  4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.205 s \n",
            "\n",
            "Accuracy rate for 66.830000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       980\n",
            "           1       0.79      0.94      0.86      1135\n",
            "           2       0.76      0.41      0.54      1032\n",
            "           3       0.70      0.73      0.72      1010\n",
            "           4       0.54      0.66      0.59       982\n",
            "           5       0.77      0.49      0.60       892\n",
            "           6       0.93      0.66      0.77       958\n",
            "           7       0.61      0.63      0.62      1028\n",
            "           8       0.62      0.68      0.64       974\n",
            "           9       0.39      0.56      0.46      1009\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.70      0.66      0.67     10000\n",
            "weighted avg       0.70      0.67      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 863    0   36   10   26   11   15    3    4   12]\n",
            " [   0 1070    0   32    5    1    1    6   15    5]\n",
            " [  44  111  428   55   89    3   14   38  203   47]\n",
            " [  18    7    5  740   12   65    4   22   93   44]\n",
            " [   0    8    3    1  648    1    3   55    4  259]\n",
            " [  48   40   17   93  105  435    9   32   44   69]\n",
            " [  17   22   43    7  100   13  628    3   25  100]\n",
            " [   6   49    1    4   51    2    0  648   11  256]\n",
            " [  15   23   20   72   21   23    2   59  658   81]\n",
            " [   6   18   11   45  149   10    0  195   10  565]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 9 ... 5 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 5  2  2  9  5 20  8 11  7  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.242 s \n",
            "\n",
            "Accuracy rate for 68.820000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       980\n",
            "           1       0.83      0.90      0.86      1135\n",
            "           2       0.73      0.40      0.52      1032\n",
            "           3       0.62      0.75      0.68      1010\n",
            "           4       0.56      0.69      0.62       982\n",
            "           5       0.70      0.52      0.60       892\n",
            "           6       0.88      0.63      0.73       958\n",
            "           7       0.68      0.82      0.74      1028\n",
            "           8       0.60      0.73      0.66       974\n",
            "           9       0.52      0.52      0.52      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.70      0.68      0.68     10000\n",
            "weighted avg       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 849    0   38    3   22   18   25   16    4    5]\n",
            " [   0 1025    0   82    6    0    2    2   18    0]\n",
            " [  48   86  413   67   83   10   10   32  242   41]\n",
            " [   8    4    3  758    7   83    1   44   91   11]\n",
            " [   0    7    2   11  681    3   19   49    8  202]\n",
            " [  19   34   14  137   79  466   18   48   48   29]\n",
            " [  11   14   61   15   79   12  606   30   31   99]\n",
            " [   2   43    2   33   39    3    0  844   13   49]\n",
            " [   9   16   19   53   25   40    8   49  715   40]\n",
            " [   6   11   13   64  205   33    2  125   25  525]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '4' ... '5' '6' '6']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 5  5  3  9  5 31 10 16  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.456 s \n",
            "\n",
            "Accuracy rate for 72.300000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.85       980\n",
            "           1       0.87      0.89      0.88      1135\n",
            "           2       0.81      0.50      0.62      1032\n",
            "           3       0.67      0.71      0.69      1010\n",
            "           4       0.65      0.73      0.69       982\n",
            "           5       0.60      0.74      0.66       892\n",
            "           6       0.90      0.76      0.82       958\n",
            "           7       0.73      0.83      0.77      1028\n",
            "           8       0.60      0.74      0.66       974\n",
            "           9       0.59      0.53      0.56      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.72      0.72     10000\n",
            "weighted avg       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 793    0    6    4    6   91   31   42    5    2]\n",
            " [   0 1006    1   94    0   28    1    0    5    0]\n",
            " [  42   58  514   25   30   28   15   75  205   40]\n",
            " [   9    2    4  716    5   83    4   33  136   18]\n",
            " [   1    7    7    9  716   31   15   20    6  170]\n",
            " [   5    6    6   82   20  656   10   22   68   17]\n",
            " [   8    4   61    9   56   28  731   25   27    9]\n",
            " [   3   42   12   21   24   16    0  850    1   59]\n",
            " [   4   22   19   33   10   73    9   32  716   56]\n",
            " [  11    4    7   79  231   57    0   67   21  532]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 9 ... 5 4 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 5  6 15  9  6 33 19 16  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.453 s \n",
            "\n",
            "Accuracy rate for 71.360000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85       980\n",
            "           1       0.90      0.91      0.91      1135\n",
            "           2       0.65      0.60      0.63      1032\n",
            "           3       0.72      0.69      0.71      1010\n",
            "           4       0.61      0.72      0.66       982\n",
            "           5       0.59      0.73      0.65       892\n",
            "           6       0.82      0.64      0.72       958\n",
            "           7       0.76      0.81      0.78      1028\n",
            "           8       0.64      0.73      0.68       974\n",
            "           9       0.57      0.51      0.54      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.72      0.71      0.71     10000\n",
            "weighted avg       0.72      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 752    0   50    1    4  114   24   29    6    0]\n",
            " [   0 1036    1   68    0   21    4    0    5    0]\n",
            " [  12   48  624   14   36   31   30   53  159   25]\n",
            " [   7    2   21  696    6   92   12   31  128   15]\n",
            " [   0    4    8    5  708   24   20   14    2  197]\n",
            " [   8    8   10   73   18  647   29   23   61   15]\n",
            " [   1    2  209    4   57   19  609   27   15   15]\n",
            " [   3   27   18   17   42   20    1  833    2   65]\n",
            " [   3   23   10   29   17   74   14   33  714   57]\n",
            " [  12    3    5   54  279   59    1   60   19  517]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 5  6 16 13  6 39 19 17 20  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.583 s \n",
            "\n",
            "Accuracy rate for 71.930000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.76      0.85       980\n",
            "           1       0.93      0.89      0.91      1135\n",
            "           2       0.65      0.62      0.63      1032\n",
            "           3       0.77      0.65      0.70      1010\n",
            "           4       0.65      0.65      0.65       982\n",
            "           5       0.57      0.82      0.67       892\n",
            "           6       0.85      0.63      0.72       958\n",
            "           7       0.74      0.83      0.78      1028\n",
            "           8       0.65      0.78      0.71       974\n",
            "           9       0.56      0.55      0.56      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.72      0.72     10000\n",
            "weighted avg       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 747    0   57    4    4  124   18   17    9    0]\n",
            " [   0 1006    1   45    0   19    5    5   54    0]\n",
            " [  11   50  642   27   30   35   28   73  122   14]\n",
            " [   5    0   23  657    2  170    9   40   91   13]\n",
            " [   0    3   10    4  642   29   16   17   10  251]\n",
            " [   6    2   12   42    6  727   18   22   36   21]\n",
            " [   2    2  216    1   57   30  603   12   21   14]\n",
            " [   2   15   17    9   29   12    1  852   13   78]\n",
            " [   3    2    9   21    5   75   12   45  762   40]\n",
            " [   9    2    6   48  209   54    0   67   59  555]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [ 9  7 22 13  6 41 28 17 23  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.806 s \n",
            "\n",
            "Accuracy rate for 72.020000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.78      0.83       980\n",
            "           1       0.93      0.85      0.89      1135\n",
            "           2       0.70      0.65      0.67      1032\n",
            "           3       0.79      0.59      0.68      1010\n",
            "           4       0.69      0.66      0.67       982\n",
            "           5       0.52      0.81      0.64       892\n",
            "           6       0.87      0.72      0.79       958\n",
            "           7       0.79      0.82      0.80      1028\n",
            "           8       0.60      0.78      0.68       974\n",
            "           9       0.58      0.54      0.56      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.72     10000\n",
            "weighted avg       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[760   0  27   2   0 152  28   5   6   0]\n",
            " [  0 970   9  19   0  20   4   2 111   0]\n",
            " [ 19  38 674  26  22  42  19  51 130  11]\n",
            " [  9   1  17 599   2 239  18  35  79  11]\n",
            " [  2   2  18   4 645  31  13  15  14 238]\n",
            " [ 16   4  13  35   7 723  17  17  45  15]\n",
            " [  8   1 167   0  23  27 691   0  40   1]\n",
            " [  7  19  33   6  24  10   0 839   9  81]\n",
            " [ 11   3   4  23   4  83   6  40 758  42]\n",
            " [ 10   2   6  45 214  56   1  63  69 543]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [14 10 24 15  8 45 30 17 25 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.407 s \n",
            "\n",
            "Accuracy rate for 73.660000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       980\n",
            "           1       0.93      0.88      0.90      1135\n",
            "           2       0.81      0.73      0.77      1032\n",
            "           3       0.84      0.57      0.68      1010\n",
            "           4       0.77      0.56      0.65       982\n",
            "           5       0.50      0.82      0.62       892\n",
            "           6       0.89      0.87      0.88       958\n",
            "           7       0.79      0.66      0.72      1028\n",
            "           8       0.67      0.72      0.69       974\n",
            "           9       0.55      0.76      0.64      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.77      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[782   0   9   0   0 165  20   3   1   0]\n",
            " [  0 994   8  21   0  16   1   1  94   0]\n",
            " [ 12  29 757   6  24  72  10  34  81   7]\n",
            " [ 25   6  33 575   1 234  18  33  75  10]\n",
            " [  2   2  12   5 551  34  13   5  14 344]\n",
            " [ 22   4  14  31   5 732  30  16  22  16]\n",
            " [  5   1  57   0  22  29 834   0  10   0]\n",
            " [ 20  23  35   8  28   7   0 674   2 231]\n",
            " [ 22   9   6  29   7 122  13  42 704  20]\n",
            " [ 15   3   2  10  82  42   1  42  49 763]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 9 ... 5 6 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [16 10 26 16 17 46 32 17 30 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.012 s \n",
            "\n",
            "Accuracy rate for 73.110000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.76      0.75       980\n",
            "           1       0.92      0.88      0.90      1135\n",
            "           2       0.86      0.76      0.80      1032\n",
            "           3       0.83      0.59      0.69      1010\n",
            "           4       0.80      0.51      0.62       982\n",
            "           5       0.53      0.82      0.64       892\n",
            "           6       0.88      0.90      0.89       958\n",
            "           7       0.81      0.64      0.71      1028\n",
            "           8       0.68      0.71      0.69       974\n",
            "           9       0.51      0.75      0.61      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.76      0.73      0.73     10000\n",
            "weighted avg       0.76      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[744   0   4   0   0 196  25   8   3   0]\n",
            " [  0 995   9  22   0   8   1   1  98   1]\n",
            " [ 30  32 780   8  21  56  16  29  43  17]\n",
            " [ 67  11  33 594   1 209  17  30  36  12]\n",
            " [  3   2   4   4 497  16  19   0  23 414]\n",
            " [ 32   5  14  31   7 732  29  14  19   9]\n",
            " [  7   3  28   0  23  23 865   0   9   0]\n",
            " [ 26  20  29  18  25  12   0 654   7 237]\n",
            " [ 64  10   8  28   4  95   9  35 690  31]\n",
            " [ 25   3   2  13  40  35   1  38  92 760]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['3' '5' '4' ... '5' '6' '5']\n",
            "probabilities: (59775, 10) \n",
            " [3 5 4 ... 5 6 5]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 16 34 18 19 49 33 17 32 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.929 s \n",
            "\n",
            "Accuracy rate for 74.540000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.76       980\n",
            "           1       0.89      0.93      0.91      1135\n",
            "           2       0.81      0.78      0.80      1032\n",
            "           3       0.84      0.61      0.71      1010\n",
            "           4       0.80      0.60      0.69       982\n",
            "           5       0.53      0.80      0.64       892\n",
            "           6       0.87      0.90      0.88       958\n",
            "           7       0.84      0.66      0.74      1028\n",
            "           8       0.68      0.69      0.68       974\n",
            "           9       0.58      0.70      0.64      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 741    0    3    0    0  190   39    4    3    0]\n",
            " [   0 1060   11    4    0    8    1    0   50    1]\n",
            " [  19   43  809   13   11   31   19   13   58   16]\n",
            " [  46   16   39  617    2  208   12   31   31    8]\n",
            " [   4    0    9    4  593   29   26    2   20  295]\n",
            " [  33   18   14   33    4  717   28   10   26    9]\n",
            " [   6    3   32    2   21   23  859    0   12    0]\n",
            " [  22   27   53   13   40   12    0  678   14  169]\n",
            " [  65   16   23   32    8  108    6   30  672   14]\n",
            " [  27    8    6   17   62   34    3   41  103  708]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '5' '4' ... '5' '6' '5']\n",
            "probabilities: (59750, 10) \n",
            " [3 5 4 ... 5 6 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [17 21 38 19 19 50 33 22 37 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.198 s \n",
            "\n",
            "Accuracy rate for 76.140000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.81      0.77       980\n",
            "           1       0.90      0.95      0.92      1135\n",
            "           2       0.81      0.76      0.78      1032\n",
            "           3       0.87      0.58      0.70      1010\n",
            "           4       0.88      0.63      0.73       982\n",
            "           5       0.56      0.79      0.65       892\n",
            "           6       0.87      0.88      0.87       958\n",
            "           7       0.81      0.74      0.77      1028\n",
            "           8       0.70      0.75      0.72       974\n",
            "           9       0.62      0.72      0.67      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.78      0.76      0.76     10000\n",
            "weighted avg       0.78      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 792    0    2    0    1  142   38    4    1    0]\n",
            " [   0 1073   15    2    1   10    1    0   33    0]\n",
            " [  29   32  782   16    7   32   22   20   80   12]\n",
            " [  82   12   30  586    1  208   13   26   45    7]\n",
            " [   4    1   14    2  615   33   20    8   25  260]\n",
            " [  43   15   18   28    1  706   27   13   29   12]\n",
            " [   7    2   52    2   20   23  843    0    9    0]\n",
            " [  10   26   38    4   14    8    0  760   16  152]\n",
            " [  73   24   15   20    7   82    7   11  728    7]\n",
            " [  26   10    1   15   32   27    1   95   73  729]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59725, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [18 25 38 25 23 56 35 22 37 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.094 s \n",
            "\n",
            "Accuracy rate for 74.750000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.80      0.75       980\n",
            "           1       0.90      0.93      0.92      1135\n",
            "           2       0.82      0.75      0.79      1032\n",
            "           3       0.81      0.53      0.64      1010\n",
            "           4       0.82      0.67      0.73       982\n",
            "           5       0.55      0.76      0.64       892\n",
            "           6       0.88      0.88      0.88       958\n",
            "           7       0.82      0.73      0.77      1028\n",
            "           8       0.67      0.76      0.71       974\n",
            "           9       0.60      0.65      0.62      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 785    0    2    1    0  151   38    3    0    0]\n",
            " [   0 1055   17    3    0   11    1    0   47    1]\n",
            " [  33   31  777    8   16   36   18   20   89    4]\n",
            " [ 134    7   24  539    1  198   11   26   64    6]\n",
            " [   3    0    9    3  654   16   15    1   23  258]\n",
            " [  60   13   12   45    5  680   24   15   30    8]\n",
            " [   7    2   44    4   23   27  842    0    9    0]\n",
            " [   7   28   40    6   15    9    0  747   14  162]\n",
            " [  65   25   18   24    5   74    6   12  739    6]\n",
            " [  27    8    3   36   79   24    1   88   86  657]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59700, 10) \n",
            " [5 5 4 ... 5 6 5]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [19 26 40 27 27 58 36 25 41 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.007 s \n",
            "\n",
            "Accuracy rate for 74.410000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.79      0.71       980\n",
            "           1       0.88      0.92      0.90      1135\n",
            "           2       0.80      0.76      0.78      1032\n",
            "           3       0.79      0.51      0.62      1010\n",
            "           4       0.86      0.69      0.76       982\n",
            "           5       0.56      0.71      0.63       892\n",
            "           6       0.89      0.87      0.88       958\n",
            "           7       0.81      0.75      0.78      1028\n",
            "           8       0.69      0.72      0.70       974\n",
            "           9       0.61      0.69      0.65      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.76      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 774    0    9    2    3  150   38    4    0    0]\n",
            " [   1 1046   18    2    0   13    1    0   52    2]\n",
            " [  42   54  787    6   12   30   15   19   63    4]\n",
            " [ 165   10   27  515    0  184    9   32   60    8]\n",
            " [   2    1   10    3  675   11    9    5   26  240]\n",
            " [  77   17   14   45    8  637   22   19   42   11]\n",
            " [   4    1   65    4   17   26  833    0    8    0]\n",
            " [   8   22   34    4    7    4    0  772    3  174]\n",
            " [  98   24   18   32    5   57    9   17  703   11]\n",
            " [  15    8    6   40   62   23    0   91   65  699]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59675, 10) \n",
            " [5 5 4 ... 5 6 5]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [20 26 43 32 30 64 37 25 46 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.688 s \n",
            "\n",
            "Accuracy rate for 74.850000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.78      0.72       980\n",
            "           1       0.89      0.93      0.91      1135\n",
            "           2       0.77      0.75      0.76      1032\n",
            "           3       0.72      0.58      0.64      1010\n",
            "           4       0.85      0.75      0.79       982\n",
            "           5       0.58      0.73      0.65       892\n",
            "           6       0.89      0.84      0.86       958\n",
            "           7       0.82      0.76      0.79      1028\n",
            "           8       0.70      0.70      0.70       974\n",
            "           9       0.62      0.64      0.63      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 762    0    8    3    5  163   32    4    1    2]\n",
            " [   0 1060   31    6    0    9    1    0   27    1]\n",
            " [  38   55  779   26   12   21   18   17   61    5]\n",
            " [ 148    4   18  586    1  165    8   27   46    7]\n",
            " [   2    1   12    5  732    5    9    3   17  196]\n",
            " [  68   11   13   47    9  648   19   15   51   11]\n",
            " [   7    1   92    5   14   29  805    0    5    0]\n",
            " [   6   21   31   12   10    3    0  785    4  156]\n",
            " [ 100   27   21   54    5   53   12    8  684   10]\n",
            " [  16    8    4   68   72   19    0   99   79  644]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '5' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 5 4 ... 5 6 5]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [22 26 46 34 33 66 37 30 51 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.293 s \n",
            "\n",
            "Accuracy rate for 75.210000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.76      0.70       980\n",
            "           1       0.92      0.93      0.92      1135\n",
            "           2       0.78      0.73      0.75      1032\n",
            "           3       0.72      0.60      0.66      1010\n",
            "           4       0.83      0.78      0.80       982\n",
            "           5       0.59      0.74      0.65       892\n",
            "           6       0.88      0.83      0.86       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.68      0.71      0.70       974\n",
            "           9       0.67      0.62      0.64      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 748    0   12    3    2  176   33    3    0    3]\n",
            " [   3 1053   18    6    0    7    2    1   44    1]\n",
            " [  43   50  755   25   11   18   17   19   91    3]\n",
            " [ 149    2   15  609    1  153    7   28   42    4]\n",
            " [   4    0   22    5  762    4   11    8   21  145]\n",
            " [  67   10   10   50    8  659   21   23   35    9]\n",
            " [  13    1   96    5   13   26  797    0    7    0]\n",
            " [   1    9   31   16    7    7    0  820    5  132]\n",
            " [ 103   17    8   60    4   50   13   17  692   10]\n",
            " [  11    6    5   70  113   21    0   77   80  626]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [23 30 49 44 34 66 41 31 52 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.383 s \n",
            "\n",
            "Accuracy rate for 76.050000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.72       980\n",
            "           1       0.92      0.95      0.93      1135\n",
            "           2       0.78      0.73      0.75      1032\n",
            "           3       0.76      0.63      0.69      1010\n",
            "           4       0.83      0.79      0.81       982\n",
            "           5       0.59      0.73      0.65       892\n",
            "           6       0.90      0.83      0.86       958\n",
            "           7       0.81      0.81      0.81      1028\n",
            "           8       0.67      0.72      0.70       974\n",
            "           9       0.68      0.64      0.66      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 751    0   20    2    4  173   25    3    0    2]\n",
            " [   0 1073    6    5    0    5    3    0   42    1]\n",
            " [  45   42  750   11    9   15   24   21  112    3]\n",
            " [ 103    4   16  635    0  158    5   34   51    4]\n",
            " [   4    0   20    5  776    5    7    9   12  144]\n",
            " [  68   13    9   60    8  648   17   24   36    9]\n",
            " [  12    2  101    2    8   32  794    0    7    0]\n",
            " [   2   16   26    5    5    7    0  832    6  129]\n",
            " [ 102   19    7   54    6   45   12   16  703   10]\n",
            " [  12    2    6   57  118   16    0   82   73  643]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [24 32 52 46 40 71 41 32 57 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 33.421 s \n",
            "\n",
            "Accuracy rate for 76.090000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.72      0.70       980\n",
            "           1       0.93      0.94      0.94      1135\n",
            "           2       0.79      0.75      0.77      1032\n",
            "           3       0.78      0.63      0.70      1010\n",
            "           4       0.81      0.84      0.82       982\n",
            "           5       0.57      0.74      0.64       892\n",
            "           6       0.90      0.83      0.86       958\n",
            "           7       0.80      0.81      0.80      1028\n",
            "           8       0.68      0.72      0.70       974\n",
            "           9       0.70      0.61      0.65      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 709    0   20    1    2  215   28    3    0    2]\n",
            " [   3 1066    7    3    0    3    3    1   47    2]\n",
            " [  40   31  777   13   11   14   22   19  102    3]\n",
            " [ 110    3   18  635    0  142    5   34   59    4]\n",
            " [   5    0   14    5  820    7    6    7    3  115]\n",
            " [  66    9    9   54    6  660   17   26   37    8]\n",
            " [  13    3   94    3    8   34  797    0    6    0]\n",
            " [   2   15   32    4   11    9    0  829    5  121]\n",
            " [  95   15    9   50    9   55   11   17  702   11]\n",
            " [   9    2    7   48  144   20    0  100   65  614]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59575, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [24 35 54 48 44 74 41 32 63 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.760 s \n",
            "\n",
            "Accuracy rate for 75.620000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.70      0.69       980\n",
            "           1       0.94      0.92      0.93      1135\n",
            "           2       0.81      0.74      0.77      1032\n",
            "           3       0.77      0.61      0.69      1010\n",
            "           4       0.84      0.80      0.82       982\n",
            "           5       0.56      0.74      0.64       892\n",
            "           6       0.92      0.83      0.87       958\n",
            "           7       0.82      0.77      0.80      1028\n",
            "           8       0.64      0.75      0.69       974\n",
            "           9       0.67      0.68      0.67      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 688    0   12    1    3  253   18    3    0    2]\n",
            " [   0 1040    4    9    0    3    2    0   76    1]\n",
            " [  38   27  760   11   12   16   22   16  125    5]\n",
            " [ 118    4   16  621    0  128    2   33   84    4]\n",
            " [   5    0   14    4  782    5    7    7    6  152]\n",
            " [  62    8    7   59    8  660   13   26   42    7]\n",
            " [  14    1   90    2   12   37  796    0    6    0]\n",
            " [   2   14   23    7    9    5    0  796   11  161]\n",
            " [  80    9    6   44    6   64    9   15  733    8]\n",
            " [  11    5    6   44   96   15    0   75   71  686]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59550, 10) \n",
            " [5 5 4 ... 5 6 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [24 37 61 49 45 77 42 34 67 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.872 s \n",
            "\n",
            "Accuracy rate for 75.000000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.70      0.69       980\n",
            "           1       0.95      0.89      0.91      1135\n",
            "           2       0.80      0.77      0.78      1032\n",
            "           3       0.78      0.59      0.67      1010\n",
            "           4       0.86      0.77      0.81       982\n",
            "           5       0.56      0.75      0.64       892\n",
            "           6       0.92      0.86      0.89       958\n",
            "           7       0.80      0.71      0.75      1028\n",
            "           8       0.63      0.73      0.68       974\n",
            "           9       0.63      0.72      0.67      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 682    0   27    1    3  245   19    2    0    1]\n",
            " [   0 1005    6    7    0    5    1    0  110    1]\n",
            " [  26    9  795    6   15   25   19   15  115    7]\n",
            " [ 119    3   27  597    0  145    3   33   79    4]\n",
            " [   4    2   11    5  761    6    6   12    4  171]\n",
            " [  59    6   13   61    9  669   14   13   40    8]\n",
            " [  10    3   73    2   12   30  820    0    8    0]\n",
            " [   3   16   24    2   11    4    0  734   10  224]\n",
            " [  91   13   14   48    4   56    8   21  708   11]\n",
            " [  12    5    4   36   73   12    0   91   47  729]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59525, 10) \n",
            " [5 5 4 ... 5 6 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [26 39 67 51 49 79 42 37 71 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 40.364 s \n",
            "\n",
            "Accuracy rate for 75.070000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70       980\n",
            "           1       0.95      0.88      0.91      1135\n",
            "           2       0.79      0.77      0.78      1032\n",
            "           3       0.77      0.58      0.66      1010\n",
            "           4       0.85      0.77      0.81       982\n",
            "           5       0.56      0.77      0.65       892\n",
            "           6       0.92      0.86      0.89       958\n",
            "           7       0.82      0.72      0.77      1028\n",
            "           8       0.62      0.75      0.68       974\n",
            "           9       0.63      0.71      0.67      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.77      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 680    0   33    1    3  243   17    2    0    1]\n",
            " [   0 1001    6    9    0    2    1    0  115    1]\n",
            " [  25   13  797    5   11   22   18   13  121    7]\n",
            " [ 115    2   31  587    0  145    2   25   99    4]\n",
            " [   3    1   11    9  753    9    6   12    5  173]\n",
            " [  50    8   11   53    6  685   15   11   42   11]\n",
            " [   6    3   70    2   12   36  821    0    8    0]\n",
            " [   3   16   27    7   11    5    0  742    5  212]\n",
            " [  71   10   13   45    3   64    9   20  728   11]\n",
            " [   9    5    5   47   86   15    0   78   51  713]]\n",
            "--------------------------------\n",
            "final active learning accuracies [52.190000000000005, 66.83, 68.82000000000001, 72.3, 71.36, 71.93, 72.02, 73.66, 73.11, 74.53999999999999, 76.14, 74.75, 74.41, 74.85000000000001, 75.21, 76.05, 76.09, 75.62, 75.0, 75.07000000000001]\n",
            "saved Active-learning-experiment-14.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 15, using model = SvmModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [3 0 0 0 1 1 3 0 1 1] [0 4 5 6 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.953 s \n",
            "\n",
            "Accuracy rate for 23.460000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.81      0.26       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.78      0.18      0.29       982\n",
            "           5       0.23      0.06      0.09       892\n",
            "           6       0.40      0.75      0.52       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.23      0.57      0.32       974\n",
            "           9       0.19      0.05      0.08      1009\n",
            "\n",
            "    accuracy                           0.23     10000\n",
            "   macro avg       0.20      0.24      0.16     10000\n",
            "weighted avg       0.19      0.23      0.15     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[789   0   0   0   1  18  42   0 123   7]\n",
            " [946   0   0   0   0  50  30   0 109   0]\n",
            " [535   0   0   0   7  11 331   0  45 103]\n",
            " [701   0   0   0   1   5  22   0 263  18]\n",
            " [325   0   0   0 175   8 247   0 191  36]\n",
            " [480   0   0   0   2  52  43   0 297  18]\n",
            " [223   0   0   0   2   6 721   0   1   5]\n",
            " [460   0   0   0   1  29  42   0 487   9]\n",
            " [271   0   0   0   6  15 111   0 560  11]\n",
            " [274   0   0   0  29  28 232   0 397  49]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['8' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59990, 6) \n",
            " [3 1 0 ... 0 3 0]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [6 0 0 0 1 7 3 0 2 1] [0 4 5 6 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.667 s \n",
            "\n",
            "Accuracy rate for 26.520000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.68      0.56       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.76      0.20      0.32       982\n",
            "           5       0.11      0.40      0.17       892\n",
            "           6       0.41      0.77      0.54       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.20      0.64      0.31       974\n",
            "           9       0.21      0.07      0.10      1009\n",
            "\n",
            "    accuracy                           0.27     10000\n",
            "   macro avg       0.22      0.28      0.20     10000\n",
            "weighted avg       0.21      0.27      0.19     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[671   0   0   0   0  94  60   0 147   8]\n",
            " [  2   0   0   0   0 916   8   0 209   0]\n",
            " [135   0   0   0  11 310 365   0 108 103]\n",
            " [ 72   0   0   0   0 465  42   0 395  36]\n",
            " [126   0   0   0 199 208 198   0 210  41]\n",
            " [135   0   0   0   1 357  54   0 322  23]\n",
            " [ 60   0   0   0   2 143 739   0   7   7]\n",
            " [ 76   0   0   0   0 295  45   0 608   4]\n",
            " [ 63   0   0   0   1 177  93   0 620  20]\n",
            " [ 74   0   0   0  48 224 181   0 416  66]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['8' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59980, 6) \n",
            " [2 0 2 ... 2 2 2]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [12  0  0  0  1 11  3  0  2  1] [0 4 5 6 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.438 s \n",
            "\n",
            "Accuracy rate for 27.750000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.79       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.80      0.28      0.42       982\n",
            "           5       0.12      0.97      0.21       892\n",
            "           6       0.67      0.69      0.68       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.59      0.17      0.26       974\n",
            "           9       0.29      0.06      0.10      1009\n",
            "\n",
            "    accuracy                           0.28     10000\n",
            "   macro avg       0.33      0.29      0.25     10000\n",
            "weighted avg       0.32      0.28      0.24     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 748    0    0    0    0  224    4    0    1    3]\n",
            " [   0    0    0    0    0 1103    3    0   28    1]\n",
            " [  98    0    0    0    7  644  201    0   22   60]\n",
            " [   2    0    0    0    0  982    1    0   10   15]\n",
            " [   6    0    0    0  276  576   72    0    8   44]\n",
            " [   3    0    0    0    1  863    4    0   12    9]\n",
            " [  19    0    0    0    8  269  659    0    1    2]\n",
            " [  11    0    0    0    2  987   10    0   13    5]\n",
            " [   3    0    0    0    0  782    6    0  166   17]\n",
            " [  25    0    0    0   52  833   18    0   18   63]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59970, 6) \n",
            " [2 0 2 ... 2 2 2]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [12  0  0  0  1 11 13  0  2  1] [0 4 5 6 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.769 s \n",
            "\n",
            "Accuracy rate for 28.320000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.80      0.28      0.41       982\n",
            "           5       0.12      0.96      0.22       892\n",
            "           6       0.56      0.76      0.64       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.61      0.17      0.26       974\n",
            "           9       0.29      0.06      0.10      1009\n",
            "\n",
            "    accuracy                           0.28     10000\n",
            "   macro avg       0.32      0.30      0.24     10000\n",
            "weighted avg       0.31      0.28      0.24     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[ 747    0    0    0    0  213   16    0    1    3]\n",
            " [   0    0    0    0    0 1105    3    0   26    1]\n",
            " [  76    0    0    0    8  540  333    0   18   57]\n",
            " [   2    0    0    0    0  981    3    0    9   15]\n",
            " [   5    0    0    0  274  517  136    0    6   44]\n",
            " [   2    0    0    0    1  858   10    0   12    9]\n",
            " [  10    0    0    0    7  210  728    0    1    2]\n",
            " [  12    0    0    0    2  983   13    0   13    5]\n",
            " [   3    0    0    0    0  776   15    0  163   17]\n",
            " [  26    0    0    0   52  805   47    0   17   62]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59960, 6) \n",
            " [2 0 2 ... 2 2 2]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [12  0 10  0  1 11 13  0  2  1] [0 2 4 5 6 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.639 s \n",
            "\n",
            "Accuracy rate for 32.580000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.76      0.82       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.82      0.42      0.55      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.82      0.29      0.43       982\n",
            "           5       0.12      0.97      0.22       892\n",
            "           6       0.70      0.76      0.73       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.64      0.16      0.26       974\n",
            "           9       0.78      0.05      0.09      1009\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.48      0.34      0.31     10000\n",
            "weighted avg       0.47      0.33      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 747    0    2    0    0  211   16    0    1    3]\n",
            " [   0    0    0    0    0 1103    3    0   29    0]\n",
            " [  38    0  432    0    0  479   77    0    6    0]\n",
            " [   1    0   10    0    0  990    2    0    7    0]\n",
            " [   3    0   23    0  285  527  133    0    6    5]\n",
            " [   2    0    3    0    0  864   10    0   12    1]\n",
            " [  11    0    4    0    5  206  728    0    1    3]\n",
            " [  11    0   19    0    2  975   12    0    8    1]\n",
            " [   5    0   18    0    0  782   13    0  156    0]\n",
            " [  23    0   15    0   54  808   47    0   16   46]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59950, 7) \n",
            " [3 0 3 ... 3 3 3]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [15  0 10  0  1 11 14  0  3  6] [0 2 4 5 6 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.251 s \n",
            "\n",
            "Accuracy rate for 34.420000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.96      0.36      0.52      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.98      0.18      0.31       982\n",
            "           5       0.14      0.94      0.25       892\n",
            "           6       0.62      0.70      0.66       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.66      0.20      0.31       974\n",
            "           9       0.30      0.35      0.32      1009\n",
            "\n",
            "    accuracy                           0.34     10000\n",
            "   macro avg       0.44      0.36      0.32     10000\n",
            "weighted avg       0.44      0.34      0.31     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 839    0    0    0    0  104   25    0    0   12]\n",
            " [   0    0    1    0    0 1088    5    0   41    0]\n",
            " [  93    0  368    0    0  367  140    0   18   46]\n",
            " [  31    0    3    0    0  952    7    0    9    8]\n",
            " [   2    0    1    0  178  419   98    0    6  278]\n",
            " [   7    0    0    0    0  837   25    0   11   12]\n",
            " [  48    0    0    0    2  204  672    0    1   31]\n",
            " [  14    0    7    0    0  592   11    0   11  393]\n",
            " [  35    0    1    0    0  640   70    0  198   30]\n",
            " [  17    0    1    0    2  601   33    0    5  350]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59940, 7) \n",
            " [3 0 3 ... 3 3 3]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [15  1 11  0  1 11 14  0 11  6] [0 1 2 4 5 6 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.002 s \n",
            "\n",
            "Accuracy rate for 37.730000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       980\n",
            "           1       0.40      0.00      0.00      1135\n",
            "           2       0.86      0.47      0.61      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.98      0.18      0.31       982\n",
            "           5       0.15      0.92      0.26       892\n",
            "           6       0.71      0.69      0.70       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.51      0.45      0.48       974\n",
            "           9       0.32      0.34      0.33      1009\n",
            "\n",
            "    accuracy                           0.38     10000\n",
            "   macro avg       0.47      0.39      0.35     10000\n",
            "weighted avg       0.47      0.38      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[840   0   1   0   0 101  25   0   1  12]\n",
            " [  0   2   1   0   0 999   5   0 128   0]\n",
            " [ 62   0 484   0   0 273  44   0 146  23]\n",
            " [ 23   0   7   0   0 915   6   0  52   7]\n",
            " [  2   0  14   0 178 414  95   0  11 268]\n",
            " [ 10   0   3   0   0 823  23   0  21  12]\n",
            " [ 43   0   9   0   2 195 665   0  12  32]\n",
            " [ 10   0  40   0   0 578  10   0  40 350]\n",
            " [ 18   3   4   0   0 469  29   0 439  12]\n",
            " [ 15   0   3   0   2 599  31   0  17 342]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59930, 8) \n",
            " [4 0 4 ... 4 4 6]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [15  1 12  0  2 11 22  0 11  6] [0 1 2 4 5 6 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.634 s \n",
            "\n",
            "Accuracy rate for 37.890000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       980\n",
            "           1       0.40      0.00      0.00      1135\n",
            "           2       0.67      0.36      0.47      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.81      0.33      0.47       982\n",
            "           5       0.16      0.89      0.27       892\n",
            "           6       0.51      0.86      0.64       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.55      0.43      0.48       974\n",
            "           9       0.34      0.26      0.30      1009\n",
            "\n",
            "    accuracy                           0.38     10000\n",
            "   macro avg       0.43      0.39      0.35     10000\n",
            "weighted avg       0.43      0.38      0.34     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[787   0   1   0   0 101  84   0   1   6]\n",
            " [  0   2   1   0   0 997  10   0 125   0]\n",
            " [ 48   0 369   0   1 171 331   0  94  18]\n",
            " [ 30   0  10   0   0 900  19   0  45   6]\n",
            " [  0   0  19   0 326 308 161   0  11 157]\n",
            " [ 11   0   6   0   2 794  54   0  17   8]\n",
            " [ 12   0   3   0   1 111 828   0   3   0]\n",
            " [ 10   0  80   0   8 544  34   0  34 318]\n",
            " [ 19   3  27   0   1 435  64   0 417   8]\n",
            " [ 12   0  38   0  64 557  54   0  18 266]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59920, 8) \n",
            " [4 0 2 ... 4 5 6]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [15  1 12  0 12 11 22  0 11  6] [0 1 2 4 5 6 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.375 s \n",
            "\n",
            "Accuracy rate for 38.500000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.83       980\n",
            "           1       0.40      0.00      0.00      1135\n",
            "           2       0.69      0.36      0.47      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.63      0.47      0.54       982\n",
            "           5       0.16      0.89      0.28       892\n",
            "           6       0.53      0.86      0.65       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.55      0.43      0.48       974\n",
            "           9       0.30      0.20      0.24      1009\n",
            "\n",
            "    accuracy                           0.38     10000\n",
            "   macro avg       0.41      0.40      0.35     10000\n",
            "weighted avg       0.41      0.39      0.34     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[786   0   1   0   0 102  84   0   1   6]\n",
            " [  0   2   1   0   0 997  10   0 125   0]\n",
            " [ 47   0 368   0  10 168 329   0  94  16]\n",
            " [ 30   0  10   0   0 901  19   0  45   5]\n",
            " [  0   0  15   0 461 271 117   0  10 108]\n",
            " [ 11   0   6   0   6 792  53   0  17   7]\n",
            " [ 11   0   3   0   3 110 827   0   3   1]\n",
            " [  8   0  77   0  40 516  31   0  33 323]\n",
            " [ 19   3  25   0   7 433  64   0 415   8]\n",
            " [ 12   0  29   0 207 511  34   0  17 199]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59910, 8) \n",
            " [4 0 3 ... 4 5 6]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [15  1 12  0 13 11 23  3 14  8] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.215 s \n",
            "\n",
            "Accuracy rate for 40.430000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83       980\n",
            "           1       0.40      0.00      0.00      1135\n",
            "           2       0.81      0.38      0.52      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.61      0.40      0.48       982\n",
            "           5       0.18      0.86      0.30       892\n",
            "           6       0.49      0.88      0.63       958\n",
            "           7       0.96      0.09      0.16      1028\n",
            "           8       0.41      0.52      0.46       974\n",
            "           9       0.37      0.28      0.32      1009\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.51      0.42      0.37     10000\n",
            "weighted avg       0.51      0.40      0.36     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[775   0   2   0   0  81 114   0   1   7]\n",
            " [  0   2   0   0   0 759  12   0 362   0]\n",
            " [ 46   0 390   0   7 168 284   2 118  17]\n",
            " [ 22   0   7   0   0 874  37   0  66   4]\n",
            " [  0   0  21   0 391 237 124   0  32 177]\n",
            " [  7   0   2   0   5 764  88   0  20   6]\n",
            " [  9   0   2   0   2  92 844   0   5   4]\n",
            " [  2   0  37   0  64 471  34  88  71 261]\n",
            " [ 12   3   3   0   7 304 128   1 510   6]\n",
            " [  5   0  18   0 162 431  58   1  55 279]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59900, 9) \n",
            " [4 0 3 ... 4 5 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [16  1 12  0 13 11 23 11 14  9] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.196 s \n",
            "\n",
            "Accuracy rate for 46.910000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.82      0.85       980\n",
            "           1       0.33      0.00      0.00      1135\n",
            "           2       0.86      0.38      0.52      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.68      0.39      0.49       982\n",
            "           5       0.20      0.86      0.33       892\n",
            "           6       0.51      0.87      0.65       958\n",
            "           7       0.94      0.66      0.78      1028\n",
            "           8       0.42      0.52      0.46       974\n",
            "           9       0.44      0.32      0.37      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.53      0.48      0.45     10000\n",
            "weighted avg       0.53      0.47      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[807   0   1   0   0  59 102   1   2   8]\n",
            " [  0   2   0   0   0 756  12   0 365   0]\n",
            " [ 53   0 387   0   3 163 264  14 117  31]\n",
            " [ 22   1   5   0   0 866  38   8  66   4]\n",
            " [  0   0  17   0 380 223 115   1  30 216]\n",
            " [  7   0   1   0   5 768  79   0  18  14]\n",
            " [ 11   0   2   0   3  91 838   0   5   8]\n",
            " [  5   0  25   0  12 122  18 679  55 112]\n",
            " [  7   3   4   0   6 304 130   3 511   6]\n",
            " [  7   0  10   0 149 410  44  14  56 319]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59890, 9) \n",
            " [4 0 3 ... 4 5 7]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [18  2 14  0 13 12 24 11 16 10] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.267 s \n",
            "\n",
            "Accuracy rate for 44.560000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       980\n",
            "           1       0.27      0.02      0.04      1135\n",
            "           2       0.78      0.42      0.54      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.63      0.30      0.41       982\n",
            "           5       0.18      0.86      0.30       892\n",
            "           6       0.52      0.88      0.65       958\n",
            "           7       0.96      0.58      0.73      1028\n",
            "           8       0.46      0.48      0.47       974\n",
            "           9       0.51      0.20      0.29      1009\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.52      0.46      0.43     10000\n",
            "weighted avg       0.52      0.45      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[828   7   0   0   0  34 103   0   1   7]\n",
            " [  0  24   1   0   0 991   4   0 115   0]\n",
            " [ 48   0 431   0   2 194 236   7 102  12]\n",
            " [ 17   3  11   0   0 906  31   7  32   3]\n",
            " [  3   6  37   0 293 256 164   0 114 109]\n",
            " [ 13   1   6   0   5 767  78   0  14   8]\n",
            " [ 14   4   1   0   2  85 844   0   4   4]\n",
            " [  8   1  43   0   6 228  26 599  73  44]\n",
            " [ 10  41   4   0   4 358  84   1 470   2]\n",
            " [  8   1  19   0 150 463  58   7 103 200]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59880, 9) \n",
            " [4 0 3 ... 4 5 4]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [18  2 14  0 13 12 24 18 16 13] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.004 s \n",
            "\n",
            "Accuracy rate for 44.750000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86       980\n",
            "           1       0.28      0.02      0.04      1135\n",
            "           2       0.80      0.41      0.55      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.72      0.24      0.36       982\n",
            "           5       0.19      0.86      0.31       892\n",
            "           6       0.54      0.88      0.67       958\n",
            "           7       0.74      0.65      0.69      1028\n",
            "           8       0.47      0.48      0.48       974\n",
            "           9       0.41      0.22      0.29      1009\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.50      0.46      0.42     10000\n",
            "weighted avg       0.50      0.45      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[824   7   0   0   0  33 100   3   1  12]\n",
            " [  0  24   1   0   0 991   4   0 115   0]\n",
            " [ 46   0 428   0   1 193 230   8 101  25]\n",
            " [ 17   3  11   0   0 901  31  13  31   3]\n",
            " [  2   5  27   0 240 228 141  46  90 203]\n",
            " [ 15   1   5   0   3 763  77   5  12  11]\n",
            " [ 14   4   1   0   2  86 841   0   4   6]\n",
            " [  3   0  40   0   2 171  19 664  71  58]\n",
            " [ 10  40   5   0   4 356  84   5 470   0]\n",
            " [  8   1  17   0  83 389  34 159  97 221]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59870, 9) \n",
            " [4 0 3 ... 4 5 4]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [18  2 14  0 19 13 24 19 16 15] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.941 s \n",
            "\n",
            "Accuracy rate for 49.140000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       980\n",
            "           1       0.28      0.02      0.04      1135\n",
            "           2       0.85      0.42      0.56      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.69      0.55      0.61       982\n",
            "           5       0.20      0.86      0.32       892\n",
            "           6       0.58      0.88      0.70       958\n",
            "           7       0.82      0.67      0.74      1028\n",
            "           8       0.54      0.47      0.50       974\n",
            "           9       0.55      0.33      0.41      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.54      0.50      0.47     10000\n",
            "weighted avg       0.54      0.49      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 827    6    0    0    1   33  100    1    2   10]\n",
            " [   0   24    1    0    0 1008    3    0   98    1]\n",
            " [  49    0  430    0    5  170  236    9  105   28]\n",
            " [  31    3   10    0    2  880   38    9   31    6]\n",
            " [   1    5   17    0  543  147   68   19   34  148]\n",
            " [  15    1    5    0   10  767   74    1   10    9]\n",
            " [  15    4    1    0    6   79  841    0    4    8]\n",
            " [   1    1   32    0    7  156   13  692   64   62]\n",
            " [   9   42    3    0    7  372   71    8  457    5]\n",
            " [   3    0    5    0  203  306    5  110   44  333]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59860, 9) \n",
            " [4 0 3 ... 4 5 4]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [19  2 17  1 19 16 25 20 16 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.633 s \n",
            "\n",
            "Accuracy rate for 49.200000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       980\n",
            "           1       0.21      0.01      0.02      1135\n",
            "           2       0.84      0.50      0.63      1032\n",
            "           3       1.00      0.00      0.00      1010\n",
            "           4       0.69      0.50      0.58       982\n",
            "           5       0.19      0.86      0.31       892\n",
            "           6       0.61      0.87      0.72       958\n",
            "           7       0.78      0.75      0.77      1028\n",
            "           8       0.59      0.41      0.49       974\n",
            "           9       0.60      0.28      0.39      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.64      0.50      0.47     10000\n",
            "weighted avg       0.64      0.49      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 839    5    0    0    0   35   89    3    2    7]\n",
            " [   0   13    3    0    0 1097    4    0   18    0]\n",
            " [  33    0  519    0    3  201  170   10   79   17]\n",
            " [  55    4   26    1    1  828   38   15   40    2]\n",
            " [   2    3   19    0  488  205   90   31   23  121]\n",
            " [  23    1    7    0    5  768   67    2   16    3]\n",
            " [   9    2    0    0    5  101  830    1    4    6]\n",
            " [   3    0   27    0    4  129    9  773   46   37]\n",
            " [  12   33   15    0    5  451   44   11  402    1]\n",
            " [   5    0    4    0  193  318   11  142   49  287]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [19  2 18  5 23 16 25 20 16 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.434 s \n",
            "\n",
            "Accuracy rate for 51.440000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86       980\n",
            "           1       0.23      0.01      0.02      1135\n",
            "           2       0.80      0.55      0.65      1032\n",
            "           3       0.93      0.04      0.07      1010\n",
            "           4       0.65      0.65      0.65       982\n",
            "           5       0.19      0.86      0.32       892\n",
            "           6       0.64      0.86      0.73       958\n",
            "           7       0.83      0.74      0.78      1028\n",
            "           8       0.67      0.40      0.50       974\n",
            "           9       0.60      0.30      0.40      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.64      0.53      0.50     10000\n",
            "weighted avg       0.64      0.51      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 840    5    0    0    0   35   89    3    0    8]\n",
            " [   0   13    4    0    0 1096    4    0   18    0]\n",
            " [  28    0  563    2    6  194  153    9   64   13]\n",
            " [  49    2   52   38    1  785   36   15   26    6]\n",
            " [   2    1    8    0  640  152   61   18   14   86]\n",
            " [  24    1    8    0   11  763   66    2   15    2]\n",
            " [   9    2    1    0   12   95  828    1    4    6]\n",
            " [   2    1   28    0   13  112    9  758   29   76]\n",
            " [  12   32   33    1   10  434   43   10  394    5]\n",
            " [   5    0    8    0  285  271    9   96   28  307]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59840, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [20  2 20  5 23 17 25 20 17 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.535 s \n",
            "\n",
            "Accuracy rate for 51.900000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       980\n",
            "           1       0.32      0.02      0.03      1135\n",
            "           2       0.78      0.56      0.65      1032\n",
            "           3       0.89      0.03      0.06      1010\n",
            "           4       0.68      0.65      0.66       982\n",
            "           5       0.20      0.88      0.32       892\n",
            "           6       0.65      0.87      0.74       958\n",
            "           7       0.83      0.73      0.77      1028\n",
            "           8       0.70      0.37      0.48       974\n",
            "           9       0.58      0.35      0.44      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.65      0.53      0.50     10000\n",
            "weighted avg       0.65      0.52      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    1    1    0    0   27   81    2    0   13]\n",
            " [   0   18    3    0    0 1103    3    0    8    0]\n",
            " [  26    1  576    2    7  200  149    9   51   11]\n",
            " [  49    1   61   31    2  740   44   14   35   33]\n",
            " [   2    2   10    1  636  151   61   20   14   85]\n",
            " [  24    1   11    0    3  782   52    2   16    1]\n",
            " [   7    2    2    0   15   91  834    1    4    2]\n",
            " [   2    1   33    0   14  123    7  746   14   88]\n",
            " [   9   30   32    1    9  456   43    9  357   28]\n",
            " [   5    0   11    0  255  265    8   97   13  355]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59830, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [20  2 25  7 23 18 26 20 18 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.052 s \n",
            "\n",
            "Accuracy rate for 51.190000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89       980\n",
            "           1       0.31      0.01      0.03      1135\n",
            "           2       0.78      0.49      0.61      1032\n",
            "           3       0.70      0.06      0.10      1010\n",
            "           4       0.68      0.64      0.66       982\n",
            "           5       0.19      0.87      0.32       892\n",
            "           6       0.65      0.88      0.75       958\n",
            "           7       0.83      0.72      0.77      1028\n",
            "           8       0.66      0.36      0.46       974\n",
            "           9       0.58      0.34      0.43      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.63      0.52      0.50     10000\n",
            "weighted avg       0.63      0.51      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 857    2    3    0    0   32   78    1    0    7]\n",
            " [   0   16    1    0    0 1104    2    0   12    0]\n",
            " [  21    0  509    3    6  236  162    9   76   10]\n",
            " [  35    1   23   57    1  785   26   15   38   29]\n",
            " [   1    1   10    1  632  159   57   17   19   85]\n",
            " [  15    1   14   14    4  779   52    1   11    1]\n",
            " [   5    0   11    2   10   83  843    1    2    1]\n",
            " [   2    0   34    4   13  135    5  736   13   86]\n",
            " [   9   30   27    0    8  456   62   10  348   24]\n",
            " [   4    0   18    1  257  271    7  101    8  342]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59820, 10) \n",
            " [5 0 4 ... 5 6 9]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [21  2 25  8 24 19 26 21 21 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.781 s \n",
            "\n",
            "Accuracy rate for 52.790000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88       980\n",
            "           1       0.28      0.01      0.02      1135\n",
            "           2       0.80      0.50      0.61      1032\n",
            "           3       0.71      0.10      0.17      1010\n",
            "           4       0.69      0.72      0.70       982\n",
            "           5       0.21      0.88      0.33       892\n",
            "           6       0.66      0.88      0.76       958\n",
            "           7       0.83      0.73      0.78      1028\n",
            "           8       0.60      0.37      0.46       974\n",
            "           9       0.56      0.37      0.45      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.63      0.54      0.52     10000\n",
            "weighted avg       0.63      0.53      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 833    2    2    0    0   36  101    1    0    5]\n",
            " [   0   13    1    2    0 1101    2    0   15    1]\n",
            " [  18    0  512    7    6  218  165   12   80   14]\n",
            " [  20    1   16   99    0  766   16   11   41   40]\n",
            " [   1    0   15    0  708   93   44   14   55   52]\n",
            " [  12    1   11   19    9  781   42    1   13    3]\n",
            " [   7    0   10    4   17   70  844    2    4    0]\n",
            " [   1    0   27    5    9   83    4  754   10  135]\n",
            " [   9   30   23    1   15  434   50    7  357   48]\n",
            " [   3    0   21    2  265  217    5  101   17  378]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59810, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [27  2 27 10 24 19 26 21 21 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.922 s \n",
            "\n",
            "Accuracy rate for 52.670000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.88       980\n",
            "           1       0.31      0.01      0.02      1135\n",
            "           2       0.79      0.47      0.59      1032\n",
            "           3       0.60      0.10      0.17      1010\n",
            "           4       0.69      0.72      0.70       982\n",
            "           5       0.20      0.85      0.33       892\n",
            "           6       0.67      0.86      0.76       958\n",
            "           7       0.84      0.73      0.78      1028\n",
            "           8       0.60      0.37      0.46       974\n",
            "           9       0.56      0.37      0.45      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.61      0.54      0.51     10000\n",
            "weighted avg       0.61      0.53      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    0    2    1    0   21   66    0    0    7]\n",
            " [   0   13    2    3    0 1099    2    0   15    1]\n",
            " [  21    0  481   16    5  217  182   12   85   13]\n",
            " [  53    1    9  103    0  736   13   11   43   41]\n",
            " [   0    0   20    1  709   92   44   13   54   49]\n",
            " [  30    0   13   19   11  761   41    1   13    3]\n",
            " [  26    0    9    3   18   69  828    2    3    0]\n",
            " [   3    0   29   14    8   78    4  753    9  130]\n",
            " [  12   28   19    3   15  430   48    7  363   49]\n",
            " [   6    0   26   10  265  215    3   94   17  373]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59800, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [28  2 27 10 25 19 26 24 22 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.385 s \n",
            "\n",
            "Accuracy rate for 55.180000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       980\n",
            "           1       0.39      0.01      0.02      1135\n",
            "           2       0.82      0.47      0.60      1032\n",
            "           3       0.62      0.08      0.15      1010\n",
            "           4       0.73      0.74      0.74       982\n",
            "           5       0.22      0.84      0.35       892\n",
            "           6       0.71      0.86      0.78       958\n",
            "           7       0.72      0.78      0.75      1028\n",
            "           8       0.59      0.45      0.51       974\n",
            "           9       0.58      0.52      0.55      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.63      0.56      0.53     10000\n",
            "weighted avg       0.63      0.55      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    0    2    1    0   29   65    0    0    6]\n",
            " [   0   11    3    3    0 1057    2   23   35    1]\n",
            " [  18    0  486   11   16  186  162   20  112   21]\n",
            " [  44    0    6   84    2  715    8   24   72   55]\n",
            " [   0    0   17    0  724   47   33   48   45   68]\n",
            " [  20    0   11   18   20  747   40    1   22   13]\n",
            " [  15    0    9    5   24   68  824    4    8    1]\n",
            " [   2    0   24    6   10   34    2  805    3  142]\n",
            " [   8   17   20    2   13  359   27   15  436   77]\n",
            " [   5    0   17    5  177   88    2  182    9  524]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59790, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [28  2 32 13 25 21 26 24 22 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.179 s \n",
            "\n",
            "Accuracy rate for 56.210000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       980\n",
            "           1       0.49      0.02      0.04      1135\n",
            "           2       0.74      0.60      0.66      1032\n",
            "           3       0.66      0.14      0.23      1010\n",
            "           4       0.75      0.74      0.75       982\n",
            "           5       0.21      0.77      0.33       892\n",
            "           6       0.77      0.85      0.81       958\n",
            "           7       0.76      0.78      0.77      1028\n",
            "           8       0.56      0.44      0.49       974\n",
            "           9       0.58      0.51      0.54      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.64      0.57      0.55     10000\n",
            "weighted avg       0.64      0.56      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    0    2    2    0   28   67    0    0    6]\n",
            " [   0   22    6    5    0 1053    1    0   47    1]\n",
            " [  15    0  615   18   11  158   74   16  112   13]\n",
            " [  39    1   23  141    3  654    4   20   81   44]\n",
            " [   0    1   30    0  728   52   20   43   41   67]\n",
            " [  22    0   32   18   19  685   47    3   37   29]\n",
            " [  16    0   24    5   20   66  813    2   11    1]\n",
            " [   2    0   37   11    8   36    0  798    1  135]\n",
            " [   8   21   37    6   13  336   23   17  431   82]\n",
            " [   5    0   24    8  165  141    1  145    7  513]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59780, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [28  2 32 13 25 25 27 24 26 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.045 s \n",
            "\n",
            "Accuracy rate for 56.890000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89       980\n",
            "           1       0.54      0.02      0.04      1135\n",
            "           2       0.76      0.55      0.64      1032\n",
            "           3       0.64      0.12      0.20      1010\n",
            "           4       0.77      0.72      0.74       982\n",
            "           5       0.24      0.77      0.37       892\n",
            "           6       0.75      0.89      0.81       958\n",
            "           7       0.79      0.77      0.78      1028\n",
            "           8       0.45      0.57      0.50       974\n",
            "           9       0.57      0.50      0.53      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.64      0.58      0.55     10000\n",
            "weighted avg       0.64      0.57      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[878   0   2   1   0  31  61   0   0   7]\n",
            " [  0  21  10   4   0 886   2   0 211   1]\n",
            " [ 19   0 572  15  11 104 107  14 174  16]\n",
            " [ 37   0  18 123   0 643   6  14 127  42]\n",
            " [  0   1  26   0 707  45  30  33  78  62]\n",
            " [ 21   0  29  19  19 691  43   0  45  25]\n",
            " [ 16   0  17   3   4  54 850   2  12   0]\n",
            " [  2   0  31  11   9  35   2 794   5 139]\n",
            " [  8  17  24   6  10 239  26  10 551  83]\n",
            " [  5   0  25  11 156 137   2 143  28 502]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59770, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [28  2 35 14 27 25 28 24 27 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.142 s \n",
            "\n",
            "Accuracy rate for 58.020000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89       980\n",
            "           1       0.65      0.02      0.03      1135\n",
            "           2       0.75      0.57      0.64      1032\n",
            "           3       0.58      0.15      0.23      1010\n",
            "           4       0.73      0.75      0.74       982\n",
            "           5       0.25      0.74      0.37       892\n",
            "           6       0.75      0.89      0.82       958\n",
            "           7       0.83      0.79      0.81      1028\n",
            "           8       0.46      0.66      0.54       974\n",
            "           9       0.60      0.47      0.52      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.65      0.59      0.56     10000\n",
            "weighted avg       0.65      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[867   0   5   0   0  29  72   0   0   7]\n",
            " [  0  20  20  15   0 854   2   0 224   0]\n",
            " [ 19   0 584  29  11  95  97  12 172  13]\n",
            " [ 36   0  22 148   0 594   8  10 149  43]\n",
            " [  0   0  27   2 740  33  30  25  72  53]\n",
            " [ 20   0  21  18  25 660  44   0  67  37]\n",
            " [ 12   0  22   5   3  50 856   1   9   0]\n",
            " [  2   0  30  14  11  33   1 812  12 113]\n",
            " [  9  11  22   7  10 185  27   5 645  53]\n",
            " [  4   0  30  19 208 105   3 114  56 470]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59760, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [29  2 38 14 30 27 28 24 28 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.677 s \n",
            "\n",
            "Accuracy rate for 57.940000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       980\n",
            "           1       0.60      0.02      0.03      1135\n",
            "           2       0.73      0.58      0.65      1032\n",
            "           3       0.64      0.14      0.23      1010\n",
            "           4       0.70      0.80      0.75       982\n",
            "           5       0.25      0.76      0.38       892\n",
            "           6       0.76      0.87      0.81       958\n",
            "           7       0.83      0.79      0.81      1028\n",
            "           8       0.48      0.66      0.56       974\n",
            "           9       0.59      0.45      0.51      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.65      0.59      0.56     10000\n",
            "weighted avg       0.65      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[827   0   8   1   7  40  87   0   1   9]\n",
            " [  0  18  20   7   0 861   0   0 229   0]\n",
            " [ 19   0 602  25  24  71  94  11 173  13]\n",
            " [ 39   0  26 143   1 606   4  11 134  46]\n",
            " [  6   0  26   0 786  32  18  22  33  59]\n",
            " [ 26   0  21  14  24 680  34   1  64  28]\n",
            " [ 16   0  16   2  27  56 832   1   8   0]\n",
            " [  2   0  39  11  11  35   0 808  13 109]\n",
            " [  8  12  31   6  11 179  28   6 642  51]\n",
            " [  5   0  34  13 230 122   2 112  35 456]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59750, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [29  2 38 15 34 28 28 24 30 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.483 s \n",
            "\n",
            "Accuracy rate for 58.010000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       980\n",
            "           1       0.61      0.01      0.03      1135\n",
            "           2       0.75      0.59      0.66      1032\n",
            "           3       0.68      0.17      0.27      1010\n",
            "           4       0.65      0.85      0.73       982\n",
            "           5       0.27      0.70      0.39       892\n",
            "           6       0.77      0.86      0.81       958\n",
            "           7       0.86      0.75      0.80      1028\n",
            "           8       0.45      0.69      0.54       974\n",
            "           9       0.50      0.44      0.47      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.64      0.59      0.56     10000\n",
            "weighted avg       0.64      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[838   0   9   0   4  33  88   0   0   8]\n",
            " [  0  17  19   8   0 752   2   0 322  15]\n",
            " [ 17   0 610  29  26  55 100  10 167  18]\n",
            " [ 44   0  26 167   4 558   5  10 145  51]\n",
            " [  6   0  22   0 834  11  10  10  17  72]\n",
            " [ 30   0  22  12  42 623  33   0  95  35]\n",
            " [ 17   0  18   6  31  46 827   1  12   0]\n",
            " [  2   0  36  11  14  17   0 774   5 169]\n",
            " [ 13  11  21   7  18 148  14   3 668  71]\n",
            " [  6   0  32   5 317  56   1  92  57 443]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59740, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [34  2 38 15 34 28 28 27 31 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.086 s \n",
            "\n",
            "Accuracy rate for 58.800000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       980\n",
            "           1       0.61      0.02      0.03      1135\n",
            "           2       0.77      0.59      0.67      1032\n",
            "           3       0.69      0.17      0.27      1010\n",
            "           4       0.66      0.84      0.74       982\n",
            "           5       0.27      0.71      0.40       892\n",
            "           6       0.78      0.87      0.83       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.47      0.68      0.55       974\n",
            "           9       0.51      0.45      0.48      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.64      0.60      0.56     10000\n",
            "weighted avg       0.65      0.59      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[864   0   8   0   0  34  64   1   1   8]\n",
            " [  0  19  23   9   1 755   2   1 306  19]\n",
            " [ 18   0 613  30  24  60  95  15 160  17]\n",
            " [ 44   0  26 167   2 568   6  15 127  55]\n",
            " [  6   0  19   0 820  12  11  11  20  83]\n",
            " [ 32   0  22  12  39 636  33   1  80  37]\n",
            " [ 23   0  18   5  20  46 836   1   9   0]\n",
            " [  2   0  32   9  11  16   0 810   5 143]\n",
            " [ 13  12  21   5  17 154  17   7 658  70]\n",
            " [  5   0  18   4 300  46   1 136  42 457]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59730, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [34  2 42 17 35 29 30 27 31 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.986 s \n",
            "\n",
            "Accuracy rate for 59.670000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87       980\n",
            "           1       0.62      0.02      0.03      1135\n",
            "           2       0.74      0.63      0.68      1032\n",
            "           3       0.72      0.26      0.38      1010\n",
            "           4       0.66      0.83      0.74       982\n",
            "           5       0.29      0.70      0.41       892\n",
            "           6       0.79      0.85      0.82       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.46      0.68      0.55       974\n",
            "           9       0.51      0.46      0.48      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.65      0.61      0.58     10000\n",
            "weighted avg       0.65      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[849   0  10   0   0  33  79   1   0   8]\n",
            " [  0  18  48   9   0 705   0   2 338  15]\n",
            " [ 16   0 655  21  22  57  75  14 155  17]\n",
            " [ 36   0  35 263   0 493   5  16 105  57]\n",
            " [  4   0  25   1 812  13  11  10  21  85]\n",
            " [ 25   0  16  21  45 621  31   1  84  48]\n",
            " [ 15   0  23  22  37  37 811   1  12   0]\n",
            " [  2   0  34  10   8   9   0 814   5 146]\n",
            " [ 14  11  14  10  19 148  15   7 658  78]\n",
            " [  6   0  21   7 283  45   1 136  44 466]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59720, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [35  2 42 18 36 31 30 29 32 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.233 s \n",
            "\n",
            "Accuracy rate for 60.790000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.88       980\n",
            "           1       0.66      0.02      0.03      1135\n",
            "           2       0.75      0.63      0.69      1032\n",
            "           3       0.69      0.34      0.46      1010\n",
            "           4       0.65      0.84      0.73       982\n",
            "           5       0.31      0.70      0.43       892\n",
            "           6       0.81      0.83      0.82       958\n",
            "           7       0.83      0.79      0.81      1028\n",
            "           8       0.48      0.70      0.57       974\n",
            "           9       0.48      0.45      0.47      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.65      0.62      0.59     10000\n",
            "weighted avg       0.66      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[858   0  13   0   0  30  66   1   3   9]\n",
            " [  0  19  50  52   0 653   0   2 331  28]\n",
            " [ 14   0 654  34  20  47  71  14 159  19]\n",
            " [ 28   0  31 348   3 410   3  13  91  83]\n",
            " [  4   0  20   3 824  12  12  11  14  82]\n",
            " [ 29   0  15  22  30 628  24   2  85  57]\n",
            " [ 14   0  21  20  30  61 796   1  15   0]\n",
            " [  2   0  39   9   6  10   0 816   3 143]\n",
            " [ 12  10   8  11  16 155   9   7 679  67]\n",
            " [  5   0  18   6 335  33   1 115  39 457]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59710, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [36  4 42 18 38 33 30 30 33 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.549 s \n",
            "\n",
            "Accuracy rate for 69.840000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       980\n",
            "           1       0.83      0.86      0.84      1135\n",
            "           2       0.80      0.61      0.69      1032\n",
            "           3       0.74      0.35      0.47      1010\n",
            "           4       0.67      0.82      0.74       982\n",
            "           5       0.42      0.71      0.53       892\n",
            "           6       0.83      0.82      0.83       958\n",
            "           7       0.84      0.82      0.83      1028\n",
            "           8       0.61      0.66      0.63       974\n",
            "           9       0.52      0.46      0.49      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.72      0.70      0.69     10000\n",
            "weighted avg       0.72      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[857   0  11   0   0  39  60   2   3   8]\n",
            " [  0 971   4  17   0 106   0   0  30   7]\n",
            " [ 15  59 634  24  22  36  64  11 152  15]\n",
            " [ 28   5  28 350   0 429   2  12  76  80]\n",
            " [  5   4  24   2 809   8   9  11  13  97]\n",
            " [ 28  19  13  23  20 636  18   6  79  50]\n",
            " [ 14  23  17  15  39  57 788   0   4   1]\n",
            " [  1  15  37   6   4   9   0 838   1 117]\n",
            " [  9  67   9  12  12 158   8   7 638  54]\n",
            " [  6   7  19  21 296  43   1 109  44 463]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59700, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [36 14 42 18 38 33 30 30 33 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.003 s \n",
            "\n",
            "Accuracy rate for 69.940000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       980\n",
            "           1       0.83      0.87      0.85      1135\n",
            "           2       0.80      0.61      0.69      1032\n",
            "           3       0.75      0.35      0.47      1010\n",
            "           4       0.67      0.82      0.74       982\n",
            "           5       0.42      0.71      0.53       892\n",
            "           6       0.83      0.82      0.83       958\n",
            "           7       0.84      0.82      0.83      1028\n",
            "           8       0.61      0.66      0.63       974\n",
            "           9       0.52      0.46      0.49      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.72      0.70      0.69     10000\n",
            "weighted avg       0.72      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[857   0  11   0   0  39  60   2   3   8]\n",
            " [  0 982   3  17   0  96   0   0  31   6]\n",
            " [ 15  59 632  24  22  37  63  11 154  15]\n",
            " [ 28   5  28 350   0 429   2  12  76  80]\n",
            " [  5   5  24   2 808   8   9  11  13  97]\n",
            " [ 28  18  13  23  20 637  18   6  79  50]\n",
            " [ 14  23  17  15  39  56 789   1   4   0]\n",
            " [  1  21  37   5   4   6   0 838   1 115]\n",
            " [  9  69   8  12  12 157   8   7 638  54]\n",
            " [  6   7  19  21 296  43   1 109  44 463]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59690, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [36 14 44 20 38 34 34 30 34 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.621 s \n",
            "\n",
            "Accuracy rate for 71.210000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       980\n",
            "           1       0.89      0.85      0.87      1135\n",
            "           2       0.79      0.66      0.72      1032\n",
            "           3       0.72      0.36      0.48      1010\n",
            "           4       0.70      0.82      0.75       982\n",
            "           5       0.44      0.72      0.55       892\n",
            "           6       0.83      0.89      0.86       958\n",
            "           7       0.85      0.81      0.83      1028\n",
            "           8       0.60      0.67      0.63       974\n",
            "           9       0.53      0.45      0.49      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.72      0.71      0.71     10000\n",
            "weighted avg       0.73      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[868   0  13   0   0  44  43   2   2   8]\n",
            " [  0 961   6  32   0 100   1   0  28   7]\n",
            " [ 17  27 680  17  21  32  77  11 137  13]\n",
            " [ 31   0  37 367   0 396   6  12  89  72]\n",
            " [  6   5  24   4 803   9   5  10  22  94]\n",
            " [ 29  10  11  25  20 645  22   4  86  40]\n",
            " [ 13   4  20   2  19  41 852   0   7   0]\n",
            " [  2  17  39  10   4   8   0 833   3 112]\n",
            " [  9  52  10  16  10 140  21   5 655  56]\n",
            " [  7   9  16  36 274  35   1 104  70 457]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59680, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [37 15 44 20 40 34 34 32 36 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.963 s \n",
            "\n",
            "Accuracy rate for 71.020000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       980\n",
            "           1       0.86      0.86      0.86      1135\n",
            "           2       0.77      0.64      0.70      1032\n",
            "           3       0.74      0.35      0.48      1010\n",
            "           4       0.68      0.81      0.74       982\n",
            "           5       0.45      0.70      0.55       892\n",
            "           6       0.82      0.89      0.85       958\n",
            "           7       0.82      0.81      0.81      1028\n",
            "           8       0.61      0.69      0.65       974\n",
            "           9       0.56      0.47      0.51      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.72      0.71      0.70     10000\n",
            "weighted avg       0.73      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[854   0  15   1   0  47  50   1   2  10]\n",
            " [  0 977   5  30   6  59   1   0  57   0]\n",
            " [ 18  51 663  19  24  32  79  14 128   4]\n",
            " [ 30   4  35 354   0 405   6  14  86  76]\n",
            " [  5   5  40   1 798   9   5  24  18  77]\n",
            " [ 27  11   9  24  22 626  24   7  85  57]\n",
            " [ 13   4  22   2  12  46 849   1   8   1]\n",
            " [  2  24  41   6   5   7   0 833   4 106]\n",
            " [  6  51   8  16   8 138  22  10 670  45]\n",
            " [  7   4  21  23 299  25   1 118  33 478]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59670, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [37 18 44 22 40 34 34 33 38 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.604 s \n",
            "\n",
            "Accuracy rate for 71.880000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       980\n",
            "           1       0.88      0.91      0.90      1135\n",
            "           2       0.79      0.63      0.70      1032\n",
            "           3       0.76      0.37      0.50      1010\n",
            "           4       0.69      0.82      0.75       982\n",
            "           5       0.48      0.72      0.58       892\n",
            "           6       0.83      0.89      0.86       958\n",
            "           7       0.80      0.81      0.81      1028\n",
            "           8       0.63      0.69      0.66       974\n",
            "           9       0.52      0.47      0.49      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.72      0.71     10000\n",
            "weighted avg       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 851    0   15    1    0   49   52    2    1    9]\n",
            " [   0 1036    3    9    2   31    1    1   49    3]\n",
            " [  15   37  654   31   22   27   75   14  151    6]\n",
            " [  34   11   33  372    0  381    6   12   68   93]\n",
            " [   5    4   40    0  805    8    5   28   19   68]\n",
            " [  29   13   11   24   20  639   21    4   67   64]\n",
            " [  13    7   21    3   12   41  851    1    9    0]\n",
            " [   2   15   28    9    5    8    0  835    3  123]\n",
            " [   6   51    5   19    9  116   17   12  671   68]\n",
            " [   7    1   21   20  297   20    1  133   35  474]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59660, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [38 18 47 22 41 34 37 34 39 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.167 s \n",
            "\n",
            "Accuracy rate for 72.240000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       980\n",
            "           1       0.90      0.91      0.90      1135\n",
            "           2       0.79      0.62      0.69      1032\n",
            "           3       0.78      0.37      0.50      1010\n",
            "           4       0.71      0.82      0.76       982\n",
            "           5       0.50      0.71      0.58       892\n",
            "           6       0.79      0.91      0.84       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.62      0.67      0.64       974\n",
            "           9       0.54      0.52      0.53      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.72      0.71     10000\n",
            "weighted avg       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    0   16    0    0   48   43    1    1   10]\n",
            " [   0 1032    3    6    3   32    2    1   53    3]\n",
            " [  15   28  640   25   27   18  107   12  153    7]\n",
            " [  39    8   30  374    0  372    9   11   72   95]\n",
            " [   6    3   30    1  803    6    3   28   30   72]\n",
            " [  29   16   13   23   22  634   28    2   56   69]\n",
            " [  13    5   23    4    7   24  874    2    6    0]\n",
            " [   1   14   30    9    5    7    0  825    4  133]\n",
            " [   8   43    5   19    9  117   44   10  654   65]\n",
            " [   5    1   20   21  263   21    1  118   32  527]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59650, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [38 20 47 22 44 35 38 34 42 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.176 s \n",
            "\n",
            "Accuracy rate for 72.640000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       980\n",
            "           1       0.90      0.91      0.91      1135\n",
            "           2       0.80      0.61      0.69      1032\n",
            "           3       0.79      0.36      0.49      1010\n",
            "           4       0.73      0.85      0.78       982\n",
            "           5       0.49      0.71      0.58       892\n",
            "           6       0.81      0.91      0.86       958\n",
            "           7       0.81      0.80      0.80      1028\n",
            "           8       0.59      0.69      0.63       974\n",
            "           9       0.56      0.54      0.55      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 876    0   13    0    0   52   30    1    1    7]\n",
            " [   0 1036    4    1    4    3    2    1   81    3]\n",
            " [  14   16  629   25   29   21  103   11  176    8]\n",
            " [  40   14   28  364    0  390    6   10   74   84]\n",
            " [   4    2   28    1  832    6    2   27   22   58]\n",
            " [  29   13    9   20   17  629   30    2   70   73]\n",
            " [  13    4   24    3   14   23  868    1    8    0]\n",
            " [   1   17   28   10    8    5    0  821    4  134]\n",
            " [   8   43    5   20    6  122   30   10  669   61]\n",
            " [   6    1   20   17  234   23    1  129   38  540]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59640, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [39 21 49 24 44 37 39 35 42 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.168 s \n",
            "\n",
            "Accuracy rate for 73.580000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       980\n",
            "           1       0.90      0.92      0.91      1135\n",
            "           2       0.78      0.61      0.69      1032\n",
            "           3       0.80      0.42      0.55      1010\n",
            "           4       0.72      0.85      0.78       982\n",
            "           5       0.52      0.71      0.60       892\n",
            "           6       0.82      0.91      0.86       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.60      0.70      0.65       974\n",
            "           9       0.58      0.53      0.55      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    0   24    0    1   43   28    1    1    5]\n",
            " [   0 1048    7    2    2    6    1    0   68    1]\n",
            " [  12   22  634   23   29   19  105   12  167    9]\n",
            " [  36   17   32  424    0  341    8   13   72   67]\n",
            " [   6    2   27    0  830    8    3   26   22   58]\n",
            " [  37   13    5   28   13  633   20    4   74   65]\n",
            " [  15    4   25    1   12   21  870    1    9    0]\n",
            " [   3   16   30   13    9    5    0  821    4  127]\n",
            " [   8   39    4   19    8  113   28    9  683   63]\n",
            " [   8    1   20   23  248   20    1  116   34  538]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59630, 10) \n",
            " [2 0 4 ... 5 6 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [40 22 50 26 44 40 39 35 43 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.239 s \n",
            "\n",
            "Accuracy rate for 73.700000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88       980\n",
            "           1       0.89      0.93      0.91      1135\n",
            "           2       0.80      0.61      0.69      1032\n",
            "           3       0.79      0.46      0.58      1010\n",
            "           4       0.74      0.85      0.79       982\n",
            "           5       0.52      0.71      0.60       892\n",
            "           6       0.82      0.91      0.86       958\n",
            "           7       0.81      0.77      0.79      1028\n",
            "           8       0.61      0.66      0.63       974\n",
            "           9       0.58      0.56      0.57      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    1   24    0    0   41   24    2    3    5]\n",
            " [   0 1056    3    1    2   15    1    0   56    1]\n",
            " [  17   35  625   32   26   14  108   12  155    8]\n",
            " [  33   14   22  469    0  332    7   12   58   63]\n",
            " [   4    1   26    2  836    7    3   31   25   47]\n",
            " [  40    9    6   28   12  633   18    2   82   62]\n",
            " [  17    4   24    2   12   19  871    1    8    0]\n",
            " [   3   18   27   10    8    8    0  796    3  155]\n",
            " [  15   47    3   24    7  133   26    4  642   73]\n",
            " [   8    1   17   26  226   20    1  119   29  562]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59620, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [40 22 51 27 45 41 40 37 44 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.045 s \n",
            "\n",
            "Accuracy rate for 75.270000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       980\n",
            "           1       0.90      0.93      0.91      1135\n",
            "           2       0.81      0.62      0.70      1032\n",
            "           3       0.83      0.54      0.66      1010\n",
            "           4       0.77      0.85      0.81       982\n",
            "           5       0.56      0.70      0.62       892\n",
            "           6       0.82      0.91      0.86       958\n",
            "           7       0.83      0.75      0.79      1028\n",
            "           8       0.61      0.69      0.65       974\n",
            "           9       0.59      0.62      0.61      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 881    1   22    1    0   36   29    2    3    5]\n",
            " [   0 1057    6    1    1   11    1    1   54    3]\n",
            " [  16   33  637   29   23   14  104   14  155    7]\n",
            " [  33   10   20  547    0  266    9   13   63   49]\n",
            " [   6    0   24    3  836    5    3   15   25   65]\n",
            " [  46    9    5   27   12  624   21    2   81   65]\n",
            " [  15    6   28    2   10   15  872    1    9    0]\n",
            " [   3   18   29   11    6    4    0  775    4  178]\n",
            " [  16   41    2   20    8  124   28    8  670   57]\n",
            " [   7    1   14   15  186   18    1  106   33  628]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59610, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [40 26 51 28 45 45 40 37 44 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.768 s \n",
            "\n",
            "Accuracy rate for 75.280000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       980\n",
            "           1       0.86      0.96      0.91      1135\n",
            "           2       0.81      0.62      0.70      1032\n",
            "           3       0.84      0.53      0.65      1010\n",
            "           4       0.77      0.85      0.81       982\n",
            "           5       0.56      0.70      0.62       892\n",
            "           6       0.82      0.91      0.86       958\n",
            "           7       0.83      0.74      0.78      1028\n",
            "           8       0.65      0.68      0.66       974\n",
            "           9       0.58      0.63      0.61      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 872    1   21    1    1   43   31    2    2    6]\n",
            " [   0 1088    6    0    1    2    1    1   34    2]\n",
            " [  16   59  641   25   24   13  107   14  125    8]\n",
            " [  30   19   21  538    1  279    7    9   54   52]\n",
            " [   6    0   25    3  834    6    2   17   26   63]\n",
            " [  45   15    3   25   12  624   18    1   74   75]\n",
            " [  13    6   26    1   11   18  874    1    8    0]\n",
            " [   3   17   30   15    6    2    0  761    5  189]\n",
            " [  15   59    5   20    7  118   26    7  661   56]\n",
            " [   8    1   13   14  191   15    1  105   26  635]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['2' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [40 30 54 29 45 46 41 37 44 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 30.523 s \n",
            "\n",
            "Accuracy rate for 75.780000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       980\n",
            "           1       0.87      0.97      0.91      1135\n",
            "           2       0.81      0.65      0.72      1032\n",
            "           3       0.80      0.57      0.66      1010\n",
            "           4       0.77      0.85      0.81       982\n",
            "           5       0.57      0.69      0.62       892\n",
            "           6       0.83      0.92      0.87       958\n",
            "           7       0.83      0.74      0.78      1028\n",
            "           8       0.66      0.65      0.66       974\n",
            "           9       0.59      0.63      0.61      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.75     10000\n",
            "weighted avg       0.76      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    1   22    1    1   39   30    2    3    6]\n",
            " [   0 1097    4    2    0    1    3    1   25    2]\n",
            " [  17   34  674   39   25   13   97   13  114    6]\n",
            " [  27   24   26  572    0  252    6   10   43   50]\n",
            " [   6    1   23    2  839    6    0   16   27   62]\n",
            " [  46   15    3   33    9  616   19    1   76   74]\n",
            " [  16    5   29    2    9   15  877    1    4    0]\n",
            " [   3   19   32   13    6    1    0  761    5  188]\n",
            " [  12   69    6   35    6  128   27    7  632   52]\n",
            " [   8    2   15   15  189   14    1  104   26  635]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59590, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [40 32 54 31 46 46 41 39 46 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.050 s \n",
            "\n",
            "Accuracy rate for 75.670000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.81      0.65      0.72      1032\n",
            "           3       0.81      0.56      0.66      1010\n",
            "           4       0.75      0.86      0.80       982\n",
            "           5       0.57      0.69      0.62       892\n",
            "           6       0.82      0.92      0.87       958\n",
            "           7       0.85      0.75      0.80      1028\n",
            "           8       0.66      0.64      0.65       974\n",
            "           9       0.59      0.62      0.60      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    1   22    1    0   39   29    2    3    6]\n",
            " [   0 1104    3    2    1    3    3    0   17    2]\n",
            " [  17   29  669   31   25   15  100   13  128    5]\n",
            " [  29   32   25  568    1  245    6    5   44   55]\n",
            " [   6    1   26    1  847    3    0   22   22   54]\n",
            " [  45   16    2   33   13  612   18    0   73   80]\n",
            " [  16    4   26    0    9   18  880    1    4    0]\n",
            " [   3   15   35   14    7    1    0  768    4  181]\n",
            " [  15   83    5   35    6  122   35    6  620   47]\n",
            " [   8    2   15   15  223   14    1   82   27  622]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['3' '0' '3' ... '5' '6' '9']\n",
            "probabilities: (59580, 10) \n",
            " [3 0 3 ... 5 6 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [40 32 56 32 49 48 41 40 47 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 31.660 s \n",
            "\n",
            "Accuracy rate for 76.340000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.79      0.64      0.71      1032\n",
            "           3       0.79      0.61      0.69      1010\n",
            "           4       0.77      0.88      0.82       982\n",
            "           5       0.59      0.69      0.64       892\n",
            "           6       0.81      0.92      0.86       958\n",
            "           7       0.86      0.73      0.79      1028\n",
            "           8       0.68      0.63      0.65       974\n",
            "           9       0.61      0.64      0.62      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 876    1   23    1    0   38   30    2    3    6]\n",
            " [   0 1106    2    3    1    4    4    0   14    1]\n",
            " [  15   34  659   21   23   17  119   11  125    8]\n",
            " [  31   21   32  620    0  203    7    5   48   43]\n",
            " [   6    1   23    6  864    4    0   17   16   45]\n",
            " [  46   18    5   48    5  619   17    1   61   72]\n",
            " [  14    4   29    0    7   19  881    1    3    0]\n",
            " [   3   15   35   17    6    1    0  753    4  194]\n",
            " [  16   83    6   39    6  126   31    4  614   49]\n",
            " [   8    2   16   25  206   12    1   78   19  642]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['3' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59570, 10) \n",
            " [3 0 1 ... 5 6 5]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [40 34 56 34 51 49 41 40 50 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 32.794 s \n",
            "\n",
            "Accuracy rate for 76.420000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.79      0.65      0.71      1032\n",
            "           3       0.78      0.65      0.71      1010\n",
            "           4       0.78      0.88      0.83       982\n",
            "           5       0.59      0.66      0.62       892\n",
            "           6       0.81      0.91      0.86       958\n",
            "           7       0.86      0.72      0.79      1028\n",
            "           8       0.68      0.64      0.66       974\n",
            "           9       0.61      0.65      0.63      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 874    0   23    2    1   39   30    2    3    6]\n",
            " [   0 1097    2    5    0    3    5    1   22    0]\n",
            " [  14   35  667   25   23   15  119   11  116    7]\n",
            " [  28   20   28  655    0  192    8    5   29   45]\n",
            " [   3    2   23    5  863    6    0   18   14   48]\n",
            " [  45   21    9   47    8  587   17    1   81   76]\n",
            " [  13    5   30    0   11   18  876    1    4    0]\n",
            " [   3   16   33   29    7    1    0  743    2  194]\n",
            " [  14   76    7   42    5  119   30    4  628   49]\n",
            " [   7    3   17   31  184   11    1   77   26  652]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['3' '0' '1' ... '5' '6' '5']\n",
            "probabilities: (59560, 10) \n",
            " [3 0 1 ... 5 6 5]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [41 37 58 35 52 49 41 40 52 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 33.418 s \n",
            "\n",
            "Accuracy rate for 76.630000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       980\n",
            "           1       0.86      0.97      0.92      1135\n",
            "           2       0.80      0.66      0.73      1032\n",
            "           3       0.79      0.64      0.70      1010\n",
            "           4       0.78      0.87      0.83       982\n",
            "           5       0.59      0.64      0.61       892\n",
            "           6       0.83      0.91      0.87       958\n",
            "           7       0.86      0.72      0.79      1028\n",
            "           8       0.66      0.66      0.66       974\n",
            "           9       0.60      0.65      0.62      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    0   12    3    1   38   27    1    3    6]\n",
            " [   0 1105    3    5    0    2    5    0   15    0]\n",
            " [  14   21  685   23   18   13  103   11  139    5]\n",
            " [  31   18   27  643    0  189    6    6   38   52]\n",
            " [   3    1   30    5  858    5    0   18   13   49]\n",
            " [  42   30    8   51   10  568   19    1   86   77]\n",
            " [  15    5   30    1   10   18  872    1    6    0]\n",
            " [   4   15   31   27    7    1    0  744    3  196]\n",
            " [  12   79    7   36    6  116   19    4  646   49]\n",
            " [   7    4   20   21  188   13    1   76   26  653]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '1' ... '5' '6' '5']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 1 ... 5 6 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [42 37 59 37 54 51 41 41 53 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 34.202 s \n",
            "\n",
            "Accuracy rate for 77.470000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       980\n",
            "           1       0.86      0.98      0.92      1135\n",
            "           2       0.82      0.67      0.74      1032\n",
            "           3       0.77      0.67      0.72      1010\n",
            "           4       0.81      0.88      0.84       982\n",
            "           5       0.62      0.63      0.62       892\n",
            "           6       0.84      0.91      0.87       958\n",
            "           7       0.85      0.73      0.78      1028\n",
            "           8       0.66      0.67      0.67       974\n",
            "           9       0.62      0.67      0.64      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.77      0.77     10000\n",
            "weighted avg       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    0    7    2    1   39   24    1    3    6]\n",
            " [   0 1108    3    4    1    2    5    0   12    0]\n",
            " [  13   21  693   28   16    9  101   12  133    6]\n",
            " [  29   21   18  681    0  156    4   11   38   52]\n",
            " [   1    1   29    5  861    2    1   18   16   48]\n",
            " [  37   28    8   68    8  559   19    2   99   64]\n",
            " [  16    5   28    1   10   19  872    1    6    0]\n",
            " [   5   14   32   30    5    0    0  747    2  193]\n",
            " [  11   81    8   45    5   98   17    4  657   48]\n",
            " [   8    4   21   26  155   13    0   81   29  672]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['3' '0' '1' ... '5' '6' '5']\n",
            "probabilities: (59540, 10) \n",
            " [3 0 1 ... 5 6 5]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [43 37 60 38 55 55 41 42 54 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.188 s \n",
            "\n",
            "Accuracy rate for 77.320000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       980\n",
            "           1       0.86      0.98      0.92      1135\n",
            "           2       0.81      0.68      0.74      1032\n",
            "           3       0.76      0.63      0.69      1010\n",
            "           4       0.82      0.87      0.84       982\n",
            "           5       0.61      0.66      0.63       892\n",
            "           6       0.84      0.91      0.87       958\n",
            "           7       0.85      0.73      0.79      1028\n",
            "           8       0.67      0.67      0.67       974\n",
            "           9       0.63      0.66      0.65      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.77      0.77     10000\n",
            "weighted avg       0.77      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    0    7    2    1   39   23    1    3    6]\n",
            " [   0 1108    4    3    1    3    4    0   12    0]\n",
            " [  13   16  705   25   18   15   90   12  132    6]\n",
            " [  51   22   29  635    0  183    4    8   37   41]\n",
            " [   5    2   27    5  854    5    0   21   15   48]\n",
            " [  39   28    6   54    7  586   23    1   89   59]\n",
            " [  17    6   26    1   12   16  872    1    7    0]\n",
            " [   4   17   32   33    4    1    0  753    4  180]\n",
            " [  15   79    9   42    3  101   22    5  654   44]\n",
            " [  10    4   21   34  140   15    0   88   30  667]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['3' '0' '1' ... '5' '6' '5']\n",
            "probabilities: (59530, 10) \n",
            " [3 0 1 ... 5 6 5]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [43 38 62 40 55 57 41 43 55 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 35.835 s \n",
            "\n",
            "Accuracy rate for 77.950000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       980\n",
            "           1       0.88      0.98      0.92      1135\n",
            "           2       0.83      0.66      0.74      1032\n",
            "           3       0.76      0.64      0.69      1010\n",
            "           4       0.82      0.88      0.85       982\n",
            "           5       0.63      0.67      0.65       892\n",
            "           6       0.84      0.91      0.87       958\n",
            "           7       0.84      0.76      0.80      1028\n",
            "           8       0.66      0.70      0.68       974\n",
            "           9       0.66      0.67      0.66      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.77     10000\n",
            "weighted avg       0.78      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 901    0    8    2    1   37   22    1    3    5]\n",
            " [   0 1109    2    3    0    2    5    1   13    0]\n",
            " [  14   11  680   25   20   14   95   12  155    6]\n",
            " [  49   22   21  643    1  172    5   11   52   34]\n",
            " [   6    2   21    7  866    4    0   19   13   44]\n",
            " [  42   30    2   53    9  594   20    2   86   54]\n",
            " [  19    5   24    0   14   19  869    1    7    0]\n",
            " [   3   16   32   30    3    0    0  784    2  158]\n",
            " [  15   64    4   47    4   88   19   12  678   43]\n",
            " [  10    4   22   31  138   14    0   95   24  671]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['3' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59520, 10) \n",
            " [3 0 1 ... 5 2 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [44 38 63 42 57 58 42 45 55 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 36.475 s \n",
            "\n",
            "Accuracy rate for 78.520000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       980\n",
            "           1       0.88      0.98      0.92      1135\n",
            "           2       0.84      0.66      0.74      1032\n",
            "           3       0.77      0.66      0.71      1010\n",
            "           4       0.81      0.90      0.85       982\n",
            "           5       0.64      0.66      0.65       892\n",
            "           6       0.84      0.91      0.87       958\n",
            "           7       0.85      0.78      0.82      1028\n",
            "           8       0.66      0.69      0.67       974\n",
            "           9       0.68      0.67      0.68      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.79      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    0    8    3    1   32   28    1    2    5]\n",
            " [   0 1109    2    3    0    3    3    2   13    0]\n",
            " [  15   10  679   31   21   15   87   13  155    6]\n",
            " [  47   22   15  670    1  155    6   10   50   34]\n",
            " [   5    2   22    3  882    4    0   17   10   37]\n",
            " [  42   30    2   59    9  587   19    3   87   54]\n",
            " [  16    5   25    3   14   19  868    1    7    0]\n",
            " [   3   18   27   28    3    1    0  805    3  140]\n",
            " [  19   64    3   44    7   88   19   13  674   43]\n",
            " [   7    4   24   26  149   15    1   80   25  678]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['3' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59510, 10) \n",
            " [3 0 1 ... 5 6 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [47 38 65 42 57 60 42 45 55 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 37.099 s \n",
            "\n",
            "Accuracy rate for 78.440000 \n",
            "Classification report for classifier SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.87       980\n",
            "           1       0.87      0.98      0.92      1135\n",
            "           2       0.85      0.66      0.74      1032\n",
            "           3       0.78      0.66      0.72      1010\n",
            "           4       0.81      0.88      0.84       982\n",
            "           5       0.64      0.65      0.65       892\n",
            "           6       0.84      0.90      0.87       958\n",
            "           7       0.86      0.77      0.81      1028\n",
            "           8       0.66      0.70      0.68       974\n",
            "           9       0.68      0.70      0.69      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    0   11    3    1   45   29    1    2    5]\n",
            " [   0 1110    2    3    0    1    3    2   13    1]\n",
            " [  21   12  684   31   20   11   85   15  150    3]\n",
            " [  50   24   17  668    0  147    5   10   54   35]\n",
            " [   5    2   20    5  868    3    0   17   10   52]\n",
            " [  48   28    5   55    9  584   18    3   85   57]\n",
            " [  16    6   22    1   15   24  866    1    7    0]\n",
            " [   3   17   31   25    5    2    0  792    2  151]\n",
            " [  20   70    3   43    7   82   18   13  682   36]\n",
            " [  13    5   12   24  148   14    1   64   21  707]]\n",
            "--------------------------------\n",
            "final active learning accuracies [23.46, 26.52, 27.750000000000004, 28.32, 32.58, 34.42, 37.730000000000004, 37.89, 38.5, 40.43, 46.910000000000004, 44.56, 44.75, 49.14, 49.2, 51.44, 51.9, 51.190000000000005, 52.790000000000006, 52.669999999999995, 55.17999999999999, 56.21000000000001, 56.88999999999999, 58.02, 57.940000000000005, 58.01, 58.8, 59.67, 60.79, 69.84, 69.94, 71.21, 71.02000000000001, 71.88, 72.24000000000001, 72.64, 73.58, 73.7, 75.27000000000001, 75.28, 75.78, 75.67, 76.34, 76.42, 76.63, 77.47, 77.32, 77.95, 78.52, 78.44]\n",
            "saved Active-learning-experiment-15.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 16, using model = RfModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [25 24 25 24 29 27 22 27 21 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.853 s \n",
            "\n",
            "Accuracy rate for 84.990000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.92       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.87      0.80      0.83      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.78      0.89      0.83       982\n",
            "           5       0.77      0.77      0.77       892\n",
            "           6       0.88      0.86      0.87       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.93      0.71      0.80       974\n",
            "           9       0.82      0.79      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    1    0    1   16   19    1    5    0]\n",
            " [   0 1101   12    1    1    2    2    3   13    0]\n",
            " [  11   36  822   43   32    9   37   29    9    4]\n",
            " [   9   12   29  869    1   47    4   19   12    8]\n",
            " [   2    5    2    0  877    7   16    2    4   67]\n",
            " [  30   21    7   87   14  689   18   10    5   11]\n",
            " [  40    8   11    1   39   34  823    2    0    0]\n",
            " [   4   29   38    7   19    1    0  899    4   27]\n",
            " [   6   42   19   42   23   70   19    7  689   57]\n",
            " [   7   16    6    5  122   20    2   35    3  793]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [52 56 52 54 52 44 41 49 47 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.780 s \n",
            "\n",
            "Accuracy rate for 87.140000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       980\n",
            "           1       0.92      0.97      0.94      1135\n",
            "           2       0.87      0.86      0.86      1032\n",
            "           3       0.79      0.89      0.84      1010\n",
            "           4       0.83      0.88      0.85       982\n",
            "           5       0.88      0.75      0.81       892\n",
            "           6       0.94      0.88      0.91       958\n",
            "           7       0.91      0.88      0.90      1028\n",
            "           8       0.89      0.77      0.83       974\n",
            "           9       0.82      0.84      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    2    1    1    5    7    1    3    1]\n",
            " [   0 1098   11    3    0    1    2    1   19    0]\n",
            " [  25   23  885   25   20    2    7   25   19    1]\n",
            " [  11    3   24  902    1   28    1   18   12   10]\n",
            " [   2    6   13    1  861    1   11    4    8   75]\n",
            " [  27   13   10  114   15  667   10   11   10   15]\n",
            " [  36    6   23    1   19   27  842    3    1    0]\n",
            " [   3   26   29    3   15    0    1  904   14   33]\n",
            " [   6   14   14   87   13   16   14    6  753   51]\n",
            " [   9   10   10   12   89    7    1   19    9  843]]\n",
            "--------------------------------\n",
            "final active learning accuracies [84.99, 87.14]\n",
            "saved Active-learning-experiment-16.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 17, using model = RfModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [16 11 12  8  9  8 20 12 13 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.803 s \n",
            "\n",
            "Accuracy rate for 71.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.75      0.99      0.85      1135\n",
            "           2       0.81      0.59      0.68      1032\n",
            "           3       0.86      0.44      0.58      1010\n",
            "           4       0.92      0.49      0.64       982\n",
            "           5       0.87      0.38      0.53       892\n",
            "           6       0.60      0.94      0.73       958\n",
            "           7       0.92      0.66      0.77      1028\n",
            "           8       0.61      0.76      0.68       974\n",
            "           9       0.51      0.92      0.66      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.77      0.71      0.70     10000\n",
            "weighted avg       0.77      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    1    9    0    1    1   68    2    4    2]\n",
            " [   0 1121    0    0    0    0    6    0    5    3]\n",
            " [  35  133  609    5    7    1  187   16   18   21]\n",
            " [  24   42   70  440    3   31   53   10  266   71]\n",
            " [   1   12    1    0  484    0   93    5   16  370]\n",
            " [  41   49    0   51   10  341  144    8  136  112]\n",
            " [  11   20    1    0    2    3  903    1   13    4]\n",
            " [   4   63   34    0    6    0    5  676    2  238]\n",
            " [  25   44   19   16    2   14   48    7  741   58]\n",
            " [  16   14    8    1   13    0    6    6   16  929]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '9' '6' '9']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 9 6 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [37 28 25 14 22 21 25 24 29 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.241 s \n",
            "\n",
            "Accuracy rate for 83.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89       980\n",
            "           1       0.81      0.99      0.89      1135\n",
            "           2       0.90      0.77      0.83      1032\n",
            "           3       0.93      0.65      0.77      1010\n",
            "           4       0.83      0.88      0.85       982\n",
            "           5       0.83      0.68      0.75       892\n",
            "           6       0.88      0.88      0.88       958\n",
            "           7       0.85      0.82      0.84      1028\n",
            "           8       0.75      0.82      0.79       974\n",
            "           9       0.78      0.82      0.80      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    0    1    0    0    2    4    3    2    0]\n",
            " [   0 1123    2    1    0    2    1    0    5    1]\n",
            " [  39   73  796    5   20    1   23   27   38   10]\n",
            " [  33   29   41  656   10   63   11   30  110   27]\n",
            " [   6    9    3    0  861    0   26   10    9   58]\n",
            " [  54   34    1   26   30  605   31   22   53   36]\n",
            " [  33   24    1    0   15   30  844    2    6    3]\n",
            " [   6   52   27    0   15    0    1  841   17   69]\n",
            " [  32   28   11   16    8   20   15   15  803   26]\n",
            " [  19   12    3    1   82    2    2   35   28  825]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [48 40 39 22 39 32 41 34 39 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.279 s \n",
            "\n",
            "Accuracy rate for 86.610000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92       980\n",
            "           1       0.88      0.99      0.93      1135\n",
            "           2       0.89      0.84      0.87      1032\n",
            "           3       0.92      0.74      0.82      1010\n",
            "           4       0.86      0.91      0.88       982\n",
            "           5       0.89      0.71      0.79       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.92      0.85      0.88      1028\n",
            "           8       0.78      0.83      0.80       974\n",
            "           9       0.81      0.88      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 966    0    5    1    0    0    4    2    1    1]\n",
            " [   0 1118    5    0    0    1    1    3    7    0]\n",
            " [  36   27  872    4   14    1   18   22   33    5]\n",
            " [  20   24   43  746    5   33    8   18  100   13]\n",
            " [   3    5    1    0  893    1   12    1    9   57]\n",
            " [  33   25    6   40   32  635   40   13   48   20]\n",
            " [  26   16   13    0   20   16  861    1    5    0]\n",
            " [   4   38   25    0   11    1    1  872    8   68]\n",
            " [  24   17    9   19    9   25   14    7  811   39]\n",
            " [  15    7    2    4   58    1    0   13   22  887]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [61 54 56 34 48 48 59 44 50 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.808 s \n",
            "\n",
            "Accuracy rate for 88.810000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92       980\n",
            "           1       0.92      0.99      0.95      1135\n",
            "           2       0.91      0.87      0.89      1032\n",
            "           3       0.92      0.81      0.86      1010\n",
            "           4       0.88      0.89      0.88       982\n",
            "           5       0.88      0.80      0.84       892\n",
            "           6       0.89      0.93      0.91       958\n",
            "           7       0.91      0.88      0.89      1028\n",
            "           8       0.88      0.83      0.86       974\n",
            "           9       0.83      0.88      0.85      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    0    1    0    0    2    5    3    1    0]\n",
            " [   0 1126    2    1    0    3    1    0    1    1]\n",
            " [  27   15  898    7   13    3   22   23   18    6]\n",
            " [  17   10   36  814    2   47    3   21   41   19]\n",
            " [   2    4    4    0  873    2   27    1    7   62]\n",
            " [  27   11    1   39   27  715   27   11   13   21]\n",
            " [  32    8    2    0   14   12  887    1    2    0]\n",
            " [   6   27   31    0    6    2    1  903    7   45]\n",
            " [  27   18    7   19   10   26   18   10  813   26]\n",
            " [  15    7    5    6   51    2    1   19   19  884]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.36, 83.22, 86.61, 88.81]\n",
            "saved Active-learning-experiment-17.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 18, using model = RfModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [5 7 4 5 7 2 6 7 2 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.463 s \n",
            "\n",
            "Accuracy rate for 58.600000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.90      0.82       980\n",
            "           1       0.59      0.96      0.73      1135\n",
            "           2       0.84      0.43      0.57      1032\n",
            "           3       0.52      0.72      0.60      1010\n",
            "           4       0.39      0.89      0.54       982\n",
            "           5       0.71      0.10      0.18       892\n",
            "           6       0.80      0.74      0.77       958\n",
            "           7       0.60      0.82      0.69      1028\n",
            "           8       0.65      0.08      0.15       974\n",
            "           9       0.47      0.12      0.19      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.63      0.58      0.52     10000\n",
            "weighted avg       0.63      0.59      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    3    5    2    4    1   13   73    0    1]\n",
            " [   0 1088    0   34    5    0    2    6    0    0]\n",
            " [  24  144  447  186   88    0   87   35   11   10]\n",
            " [  26   77   21  726   39   29    4   56   14   18]\n",
            " [   0   34    0    3  876    1   19   11    1   37]\n",
            " [ 132  108   11  130  157   91   24  203    5   31]\n",
            " [  26   45    7   10  133    1  712   18    3    3]\n",
            " [   3   84    3    2   71    0    0  843    3   19]\n",
            " [  51  232   38  282  231    6   21   19   81   13]\n",
            " [  32   32    2   22  654    0    8  134    7  118]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['7' '0' '9' ... '7' '6' '9']\n",
            "probabilities: (59950, 10) \n",
            " [7 0 9 ... 7 6 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [15 10  6 12 14  8 11 10  5  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.462 s \n",
            "\n",
            "Accuracy rate for 66.180000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.96      0.84       980\n",
            "           1       0.73      0.91      0.81      1135\n",
            "           2       0.92      0.35      0.51      1032\n",
            "           3       0.52      0.79      0.63      1010\n",
            "           4       0.49      0.91      0.64       982\n",
            "           5       0.68      0.37      0.48       892\n",
            "           6       0.71      0.76      0.74       958\n",
            "           7       0.76      0.80      0.78      1028\n",
            "           8       0.85      0.30      0.44       974\n",
            "           9       0.69      0.40      0.51      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.71      0.66      0.64     10000\n",
            "weighted avg       0.71      0.66      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    3    0    6    2   20    4    0    1]\n",
            " [   0 1032    0   93    3    1    4    2    0    0]\n",
            " [  50  120  363  217   59    2  158   26   14   23]\n",
            " [  38    7    5  800    8   91   13   19   14   15]\n",
            " [   0   14    0    0  896    0   33    0    0   39]\n",
            " [  99   54    1   87  124  333   34   96   12   52]\n",
            " [  62   13    2    2  137    9  732    1    0    0]\n",
            " [  11   56    3   24   78    1    0  820    7   28]\n",
            " [  39   98   15  300   98   47   32   25  291   29]\n",
            " [  26   21    1   25  431    1    1   90    5  408]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '4' ... '7' '6' '9']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 4 ... 7 6 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [24 14  8 17 21 13 13 17  9 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.040 s \n",
            "\n",
            "Accuracy rate for 75.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.99      0.86       980\n",
            "           1       0.81      0.97      0.88      1135\n",
            "           2       0.97      0.46      0.62      1032\n",
            "           3       0.64      0.83      0.72      1010\n",
            "           4       0.55      0.96      0.70       982\n",
            "           5       0.80      0.68      0.74       892\n",
            "           6       0.83      0.76      0.79       958\n",
            "           7       0.80      0.87      0.83      1028\n",
            "           8       0.91      0.48      0.63       974\n",
            "           9       0.88      0.53      0.66      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.80      0.75      0.75     10000\n",
            "weighted avg       0.80      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    1    0    0    3    2    5    1    0    0]\n",
            " [   0 1103    1   22    1    1    4    3    0    0]\n",
            " [  68   90  472  147   94    6   86   34   32    3]\n",
            " [  32    3    0  839   12   77    2   22    7   16]\n",
            " [   3    6    0    3  943    0    8    4    0   15]\n",
            " [  52   29    0   59   78  607   20   30    1   16]\n",
            " [  77    6    1    1  124   14  732    2    1    0]\n",
            " [   8   45    8    7   53    2    1  892    2   10]\n",
            " [  31   64    4  206   82   45   26   35  471   10]\n",
            " [  26   16    0   22  317    5    0   86    1  536]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '0' '0']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 0 0]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [31 19  8 24 23 17 18 25 14 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.701 s \n",
            "\n",
            "Accuracy rate for 79.120000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.98      0.87       980\n",
            "           1       0.82      0.96      0.88      1135\n",
            "           2       0.98      0.44      0.61      1032\n",
            "           3       0.62      0.89      0.73      1010\n",
            "           4       0.77      0.87      0.82       982\n",
            "           5       0.83      0.66      0.74       892\n",
            "           6       0.82      0.83      0.83       958\n",
            "           7       0.79      0.90      0.84      1028\n",
            "           8       0.92      0.58      0.71       974\n",
            "           9       0.81      0.76      0.78      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.81      0.79      0.78     10000\n",
            "weighted avg       0.81      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    1    0    1    3    5   12    1    0    0]\n",
            " [   0 1085    0   44    0    0    4    2    0    0]\n",
            " [  52   87  456  169   54    5  101   55   39   14]\n",
            " [  31    2    0  899    1   41    7   16    3   10]\n",
            " [   3   12    0   11  858    0   10    7    0   81]\n",
            " [  55   40    0   81   36  593   25   33    2   27]\n",
            " [  60    6    2    5   65   14  798    6    2    0]\n",
            " [  10   38    5    9   11    0    1  928    1   25]\n",
            " [  25   47    1  197   16   43   18   32  569   26]\n",
            " [  20   13    0   25   75   10    0   95    2  769]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 0 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [35 23 13 29 27 19 24 30 24 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.287 s \n",
            "\n",
            "Accuracy rate for 82.320000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87       980\n",
            "           1       0.85      0.98      0.91      1135\n",
            "           2       0.97      0.52      0.68      1032\n",
            "           3       0.72      0.89      0.79      1010\n",
            "           4       0.81      0.89      0.85       982\n",
            "           5       0.91      0.63      0.74       892\n",
            "           6       0.83      0.87      0.85       958\n",
            "           7       0.83      0.91      0.86      1028\n",
            "           8       0.84      0.77      0.80       974\n",
            "           9       0.82      0.78      0.80      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.84      0.82      0.82     10000\n",
            "weighted avg       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    1    2    3    4   14    1    2    0]\n",
            " [   0 1108    0   12    1    1    5    2    6    0]\n",
            " [  55   98  535   98   21    2   77   54   76   16]\n",
            " [  26    0    3  899    1   25    4   20   15   17]\n",
            " [   2    6    1   11  875    0   18    6    2   61]\n",
            " [  64   27    0   90   30  561   33   32   20   35]\n",
            " [  55    4    1    3   50    5  834    2    4    0]\n",
            " [  13   31    6   11   11    0    1  931    3   21]\n",
            " [  15   25    2  104   15   14   17   15  748   19]\n",
            " [  22   10    1   26   78    3    1   64   15  789]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [39 31 17 35 36 23 28 32 26 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.278 s \n",
            "\n",
            "Accuracy rate for 83.250000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.97      0.90       980\n",
            "           1       0.82      0.99      0.90      1135\n",
            "           2       0.95      0.63      0.76      1032\n",
            "           3       0.73      0.90      0.81      1010\n",
            "           4       0.75      0.91      0.82       982\n",
            "           5       0.91      0.66      0.76       892\n",
            "           6       0.85      0.86      0.86       958\n",
            "           7       0.86      0.88      0.87      1028\n",
            "           8       0.90      0.73      0.81       974\n",
            "           9       0.85      0.76      0.80      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    1    5    4    2   10    1    4    0]\n",
            " [   0 1120    0    5    0    0    4    1    5    0]\n",
            " [  45   95  655   71   36    1   51   39   34    5]\n",
            " [  18    7    5  909    2   31    8   15    6    9]\n",
            " [   2    9    0    9  893    0   11    5    2   51]\n",
            " [  47   38    0   92   35  586   32   20   11   31]\n",
            " [  43    7    5    2   66    7  825    1    2    0]\n",
            " [  10   36   18   11   19    0    1  903    2   28]\n",
            " [  14   36    7  118   21    9   24   17  713   15]\n",
            " [  16   16    2   23  118   10    0   43   12  769]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '0' '0']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 0 0]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [41 38 19 40 46 28 34 36 34 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.118 s \n",
            "\n",
            "Accuracy rate for 84.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90       980\n",
            "           1       0.86      0.98      0.91      1135\n",
            "           2       0.96      0.59      0.73      1032\n",
            "           3       0.79      0.87      0.83      1010\n",
            "           4       0.73      0.93      0.82       982\n",
            "           5       0.89      0.76      0.82       892\n",
            "           6       0.84      0.89      0.87       958\n",
            "           7       0.88      0.88      0.88      1028\n",
            "           8       0.85      0.79      0.82       974\n",
            "           9       0.88      0.75      0.81      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    1    1    3    4    4   14    1    3    0]\n",
            " [   0 1113    0    5    1    1    3    1   11    0]\n",
            " [  42   81  611   69   39    2   63   44   80    1]\n",
            " [  20    6    5  877    4   47   10   15   16   10]\n",
            " [   2    6    1    8  918    0   11    3    2   31]\n",
            " [  38   22    0   38   38  681   36   12    8   19]\n",
            " [  33    5    2    2   55    7  853    1    0    0]\n",
            " [   8   35   15   10   23    0    2  907    3   25]\n",
            " [  13   18    1   80   21   18   21   15  772   15]\n",
            " [  19   14    1   17  152    8    0   30   13  755]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [51 49 23 45 48 31 37 41 38 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.738 s \n",
            "\n",
            "Accuracy rate for 84.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.98      0.91       980\n",
            "           1       0.83      0.98      0.90      1135\n",
            "           2       0.94      0.61      0.74      1032\n",
            "           3       0.79      0.90      0.84      1010\n",
            "           4       0.77      0.93      0.84       982\n",
            "           5       0.92      0.70      0.79       892\n",
            "           6       0.85      0.89      0.87       958\n",
            "           7       0.88      0.87      0.88      1028\n",
            "           8       0.86      0.79      0.82       974\n",
            "           9       0.87      0.78      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    1    2    1    2    1    9    1    4    0]\n",
            " [   0 1115    0    5    0    1    4    1    9    0]\n",
            " [  34  108  627   52   30    1   64   40   72    4]\n",
            " [  24    5    8  909    3   26    7   11   13    4]\n",
            " [   2    7    2    5  913    0   14    3    5   31]\n",
            " [  46   26    2   68   40  622   31   12   14   31]\n",
            " [  38    5    5    1   47    6  855    1    0    0]\n",
            " [   9   41   19   10   19    0    2  896    1   31]\n",
            " [  10   19    3   78   25    9   22   17  773   18]\n",
            " [  17   17    2   21  110   10    0   37   10  785]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [56 55 26 49 52 41 40 45 43 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.015 s \n",
            "\n",
            "Accuracy rate for 85.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91       980\n",
            "           1       0.84      0.98      0.90      1135\n",
            "           2       0.94      0.63      0.75      1032\n",
            "           3       0.82      0.87      0.85      1010\n",
            "           4       0.81      0.92      0.86       982\n",
            "           5       0.85      0.79      0.82       892\n",
            "           6       0.86      0.89      0.87       958\n",
            "           7       0.91      0.86      0.88      1028\n",
            "           8       0.86      0.79      0.83       974\n",
            "           9       0.87      0.83      0.85      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    1    3    2    1    4    6    1    1    0]\n",
            " [   0 1110    0    6    1    1    4    1   12    0]\n",
            " [  37   99  648   46   23    3   64   35   71    6]\n",
            " [  24    9    9  881    2   46    7   13   11    8]\n",
            " [   2    6    1    6  905    1   13    2    4   42]\n",
            " [  42   17    0   44   30  703   24    5    8   19]\n",
            " [  38    5    3    2   49    9  852    0    0    0]\n",
            " [   8   44   22    9   18    0    2  885    4   36]\n",
            " [   8   21    5   62   16   41   20   12  773   16]\n",
            " [  12   16    2   15   74   21    1   19   12  837]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [61 60 32 52 56 47 45 51 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.516 s \n",
            "\n",
            "Accuracy rate for 86.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.93      0.68      0.79      1032\n",
            "           3       0.83      0.88      0.86      1010\n",
            "           4       0.83      0.92      0.87       982\n",
            "           5       0.88      0.80      0.84       892\n",
            "           6       0.87      0.91      0.89       958\n",
            "           7       0.89      0.88      0.89      1028\n",
            "           8       0.87      0.82      0.84       974\n",
            "           9       0.88      0.83      0.85      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    2    2    2    3    8    1    3    0]\n",
            " [   0 1103    8    5    0    1    5    1   12    0]\n",
            " [  37   74  706   33   27    2   57   36   58    2]\n",
            " [  22    4   11  893    2   40    4   15   13    6]\n",
            " [   2    5    1    6  906    1   12    4    4   41]\n",
            " [  39   14    1   44   24  711   22    7    8   22]\n",
            " [  29    3    2    2   37    8  874    0    3    0]\n",
            " [   6   37   18    7   13    0    1  908    5   33]\n",
            " [  10   12    6   62   15   27   17   15  794   16]\n",
            " [  12   11    2   16   70   13    1   30   14  840]]\n",
            "--------------------------------\n",
            "final active learning accuracies [58.599999999999994, 66.18, 75.63, 79.12, 82.32000000000001, 83.25, 84.36, 84.54, 85.55, 86.94]\n",
            "saved Active-learning-experiment-18.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 19, using model = RfModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 2 2 4 5 1 1 5 0 3] [0 1 2 3 4 5 6 7 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.933 s \n",
            "\n",
            "Accuracy rate for 40.470000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.58      0.70       980\n",
            "           1       0.63      0.91      0.75      1135\n",
            "           2       0.39      0.28      0.33      1032\n",
            "           3       0.37      0.63      0.46      1010\n",
            "           4       0.28      0.49      0.36       982\n",
            "           5       0.26      0.01      0.02       892\n",
            "           6       0.37      0.04      0.07       958\n",
            "           7       0.29      0.71      0.41      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.30      0.25      0.27      1009\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.37      0.39      0.34     10000\n",
            "weighted avg       0.38      0.40      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 573    0  159   71   54    5   16   49    0   53]\n",
            " [   0 1038   14   60    0    0    0   23    0    0]\n",
            " [  15  123  291  238  225    0    9   59    0   72]\n",
            " [   8  105   57  637    8    9    3  176    0    7]\n",
            " [   2   18    2    1  478    0    0  354    0  127]\n",
            " [  34   80   73  276   73   10    7  339    0    0]\n",
            " [  14   63  131    9  560    3   38  125    0   15]\n",
            " [   1   65    1   29   45    0    0  730    0  157]\n",
            " [  14  127   15  398   64   11   29  167    0  149]\n",
            " [   6   27    2   15  194    1    0  512    0  252]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '0' '7' ... '7' '4' '7']\n",
            "probabilities: (59975, 9) \n",
            " [3 0 7 ... 7 4 7]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 5  4  3 10  8  4  3  7  1  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.465 s \n",
            "\n",
            "Accuracy rate for 51.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.74      0.72       980\n",
            "           1       0.72      0.96      0.82      1135\n",
            "           2       0.76      0.15      0.25      1032\n",
            "           3       0.34      0.95      0.51      1010\n",
            "           4       0.43      0.68      0.52       982\n",
            "           5       0.62      0.08      0.14       892\n",
            "           6       0.82      0.34      0.48       958\n",
            "           7       0.42      0.77      0.55      1028\n",
            "           8       0.91      0.04      0.08       974\n",
            "           9       0.58      0.29      0.38      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.63      0.50      0.45     10000\n",
            "weighted avg       0.63      0.51      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 723    0   14   90   59   31   16   25    1   21]\n",
            " [   0 1090    1   33    0    0    0   11    0    0]\n",
            " [  99  149  154  372  178    0   30   46    1    3]\n",
            " [   6    2   11  958    4    7    0   21    0    1]\n",
            " [   1   18    0   31  663    0    5  226    0   38]\n",
            " [  48   43    6  497   66   72    8  142    2    8]\n",
            " [  42   23   12   89  350    1  322  118    0    1]\n",
            " [   3   75    1   74   24    0    0  788    0   63]\n",
            " [ 106   82    3  581   11    5   13   54   43   76]\n",
            " [   7   27    1   59  195    1    1  430    0  288]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '7' '4' '7']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 7 4 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 8  6  6 14  9  9  4  8  2  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.551 s \n",
            "\n",
            "Accuracy rate for 64.700000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.85      0.80       980\n",
            "           1       0.77      0.98      0.86      1135\n",
            "           2       0.80      0.57      0.67      1032\n",
            "           3       0.52      0.91      0.66      1010\n",
            "           4       0.50      0.70      0.58       982\n",
            "           5       0.70      0.59      0.64       892\n",
            "           6       0.88      0.37      0.52       958\n",
            "           7       0.70      0.71      0.70      1028\n",
            "           8       0.78      0.10      0.18       974\n",
            "           9       0.50      0.61      0.55      1009\n",
            "\n",
            "    accuracy                           0.65     10000\n",
            "   macro avg       0.69      0.64      0.62     10000\n",
            "weighted avg       0.69      0.65      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 836    0   13   22   32   26   19    4    0   28]\n",
            " [   0 1108    5   10    0    2    0    1    0    9]\n",
            " [ 100   61  589  117  108    8   16   19    2   12]\n",
            " [  11    6   18  924    3   28    0   11    1    8]\n",
            " [   0   24    0   14  692    6    2   53    0  191]\n",
            " [  11   29    6  198   42  522    6   27    3   48]\n",
            " [  35   19   68   19  303   64  350   39    0   61]\n",
            " [   5   96   22   38   30    1    0  728   17   91]\n",
            " [  96   63   16  401   10   79    4   22  102  181]\n",
            " [   7   30    1   30  170    5    0  142    5  619]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 8  7  9 17 14 10  5  9 10 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.623 s \n",
            "\n",
            "Accuracy rate for 72.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       980\n",
            "           1       0.89      0.93      0.91      1135\n",
            "           2       0.81      0.72      0.76      1032\n",
            "           3       0.56      0.93      0.70      1010\n",
            "           4       0.52      0.91      0.66       982\n",
            "           5       0.85      0.44      0.58       892\n",
            "           6       0.90      0.51      0.65       958\n",
            "           7       0.91      0.65      0.76      1028\n",
            "           8       0.81      0.63      0.71       974\n",
            "           9       0.67      0.66      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.77      0.72      0.72     10000\n",
            "weighted avg       0.78      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 810    0   15   45   21   15   36    0   10   28]\n",
            " [   0 1055   13   35    3    0    2    0   19    8]\n",
            " [  39   35  740  106   49    3    5    7   36   12]\n",
            " [   5    1   22  944    7    6    0    4    8   13]\n",
            " [   2    9    5    6  893    0    6    1    3   57]\n",
            " [   9   13   19  314   88  395    5    9   17   23]\n",
            " [  34   14   55   42  265   20  486    0   21   21]\n",
            " [   6   47   32   33  119    3    0  673   22   93]\n",
            " [  45    8    6  145   49   23    1    4  616   77]\n",
            " [   7    4    6   30  236    0    1   45   12  668]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [10  9 15 19 15 12  8 10 15 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.675 s \n",
            "\n",
            "Accuracy rate for 76.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.80      0.84       980\n",
            "           1       0.90      0.91      0.91      1135\n",
            "           2       0.67      0.79      0.73      1032\n",
            "           3       0.66      0.93      0.77      1010\n",
            "           4       0.62      0.90      0.73       982\n",
            "           5       0.91      0.53      0.67       892\n",
            "           6       0.93      0.52      0.67       958\n",
            "           7       0.89      0.75      0.81      1028\n",
            "           8       0.69      0.76      0.72       974\n",
            "           9       0.77      0.67      0.72      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.79      0.76      0.76     10000\n",
            "weighted avg       0.79      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 787    0   57   39   12   14   31    1   20   19]\n",
            " [   0 1035   13    9    1    0    0    1   69    7]\n",
            " [  28   22  820   39   36    0    2    5   74    6]\n",
            " [   2    3   28  939    5    3    0    6   17    7]\n",
            " [   2   10    8    4  884    0    3    5    9   57]\n",
            " [   9   11   44  253   52  474    4   10   25   10]\n",
            " [  18    9  166   17  159    9  500    0   70   10]\n",
            " [   4   41   64   15   59    2    0  773   25   45]\n",
            " [  31    8   19   74   36   15    0    7  736   48]\n",
            " [   6    7   10   27  188    3    0   64   23  681]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [11 16 19 24 17 13  8 12 18 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.574 s \n",
            "\n",
            "Accuracy rate for 75.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.78      0.83       980\n",
            "           1       0.87      0.96      0.91      1135\n",
            "           2       0.68      0.81      0.74      1032\n",
            "           3       0.64      0.93      0.76      1010\n",
            "           4       0.61      0.91      0.73       982\n",
            "           5       0.92      0.52      0.66       892\n",
            "           6       0.93      0.50      0.65       958\n",
            "           7       0.87      0.76      0.81      1028\n",
            "           8       0.71      0.75      0.73       974\n",
            "           9       0.80      0.61      0.69      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.79      0.75      0.75     10000\n",
            "weighted avg       0.79      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 760    0   71   29   10   13   26    7   53   11]\n",
            " [   0 1092    2   25    2    0    0    1    9    4]\n",
            " [  18   41  841   48   25    0    2    8   45    4]\n",
            " [   2    3   27  941    4    4    0    5   20    4]\n",
            " [   2   13   11    4  894    0    5    1   15   37]\n",
            " [   8   21   31  257   50  464    2    8   46    5]\n",
            " [  21   14  168    9  173   14  475    1   81    2]\n",
            " [   2   52   61   27   46    0    0  782   11   47]\n",
            " [  35    9   17   83   44   10    0    5  735   36]\n",
            " [   8   10   11   52  207    1    0   81   26  613]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [13 17 23 28 20 13 12 15 19 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.899 s \n",
            "\n",
            "Accuracy rate for 78.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.78      0.83       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.71      0.82      0.76      1032\n",
            "           3       0.63      0.96      0.76      1010\n",
            "           4       0.67      0.89      0.76       982\n",
            "           5       0.94      0.50      0.65       892\n",
            "           6       0.88      0.63      0.74       958\n",
            "           7       0.85      0.82      0.84      1028\n",
            "           8       0.80      0.72      0.76       974\n",
            "           9       0.81      0.67      0.74      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.81      0.78      0.78     10000\n",
            "weighted avg       0.81      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 760    0   74   29    7    6   44   13   38    9]\n",
            " [   0 1100    3   20    1    0    2    1    8    0]\n",
            " [  25   34  848   43   23    0    5   17   31    6]\n",
            " [   0    1   18  968    4    1    1    6    8    3]\n",
            " [   2   11   13    1  874    2   17    3   11   48]\n",
            " [   5   12   27  298   51  446    8   11   20   14]\n",
            " [  13   12  129   16  132    8  608    0   39    1]\n",
            " [   3   38   49   19   33    0    0  847    6   33]\n",
            " [  33    7   26  101   34   12    3   11  705   42]\n",
            " [   8   11   11   47  150    1    0   89   14  678]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15 18 28 29 22 13 18 18 21 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.531 s \n",
            "\n",
            "Accuracy rate for 79.210000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.73      0.82       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.69      0.86      0.77      1032\n",
            "           3       0.65      0.94      0.77      1010\n",
            "           4       0.72      0.89      0.79       982\n",
            "           5       0.95      0.44      0.60       892\n",
            "           6       0.80      0.75      0.78       958\n",
            "           7       0.88      0.82      0.85      1028\n",
            "           8       0.80      0.74      0.77       974\n",
            "           9       0.81      0.71      0.76      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.81      0.79      0.78     10000\n",
            "weighted avg       0.81      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 714    1   78   16    3    5  123    8   28    4]\n",
            " [   0 1096    4   21    2    0    3    1    7    1]\n",
            " [  12   26  889   24   19    0    8   18   33    3]\n",
            " [   0    1   27  949    4    0    0    4   14   11]\n",
            " [   0    9   18    1  874    0   16    3    7   54]\n",
            " [   7   14   45  302   47  392   15    9   40   21]\n",
            " [   6   12  120    7   53    8  721    0   31    0]\n",
            " [   0   35   59   19   36    0    0  843    7   29]\n",
            " [  27    8   30   83   27    6   11   13  723   46]\n",
            " [   6    5   19   37  154    1    2   55   10  720]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [17 19 33 32 22 17 21 20 25 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.478 s \n",
            "\n",
            "Accuracy rate for 81.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.79      0.85       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.74      0.87      0.80      1032\n",
            "           3       0.71      0.91      0.80      1010\n",
            "           4       0.75      0.86      0.80       982\n",
            "           5       0.94      0.54      0.68       892\n",
            "           6       0.82      0.82      0.82       958\n",
            "           7       0.88      0.85      0.86      1028\n",
            "           8       0.81      0.77      0.79       974\n",
            "           9       0.81      0.73      0.77      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.81      0.81     10000\n",
            "weighted avg       0.83      0.82      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 776    0   62    7    2    3   95    7   28    0]\n",
            " [   0 1106    5    4    1    0    3    1   13    2]\n",
            " [  18   18  897   26   20    1   10   14   26    2]\n",
            " [   3    2   35  919    2    8    0    8   26    7]\n",
            " [   0    8    9    4  843    0   29    4    9   76]\n",
            " [   8   21   28  232   35  480   13   16   41   18]\n",
            " [   9    8   85    3   30   14  784    0   25    0]\n",
            " [   0   36   50   12   22    0    1  876    7   24]\n",
            " [  24   11   26   55   34    4   21    9  752   38]\n",
            " [   7   11   13   39  128    3    2   65    7  734]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59775, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 23 35 33 25 18 24 22 27 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.930 s \n",
            "\n",
            "Accuracy rate for 81.620000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86       980\n",
            "           1       0.90      0.96      0.93      1135\n",
            "           2       0.77      0.86      0.81      1032\n",
            "           3       0.69      0.92      0.79      1010\n",
            "           4       0.79      0.84      0.81       982\n",
            "           5       0.94      0.49      0.64       892\n",
            "           6       0.80      0.86      0.83       958\n",
            "           7       0.89      0.83      0.86      1028\n",
            "           8       0.79      0.75      0.77       974\n",
            "           9       0.79      0.78      0.79      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.81      0.81     10000\n",
            "weighted avg       0.83      0.82      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 791    0   42    7    2    1  112    4   21    0]\n",
            " [   0 1094    9    3    1    0    4    1   23    0]\n",
            " [  21   22  890   26   15    2   11   11   30    4]\n",
            " [   2    3   28  929    2    6    3    7   21    9]\n",
            " [   0   10   11    2  823    0   32    5   13   86]\n",
            " [   7   19   40  266   30  438   16   21   39   16]\n",
            " [  10    7   49    3   24   16  824    2   23    0]\n",
            " [   1   36   55   12   23    0    1  850    9   41]\n",
            " [  29   12   29   61   28    4   17    5  733   56]\n",
            " [   8   10    9   29   97    1    8   44   13  790]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [26 28 35 35 27 18 27 25 31 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.392 s \n",
            "\n",
            "Accuracy rate for 82.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.82      0.84      0.83      1032\n",
            "           3       0.73      0.92      0.81      1010\n",
            "           4       0.77      0.87      0.82       982\n",
            "           5       0.95      0.50      0.66       892\n",
            "           6       0.82      0.86      0.84       958\n",
            "           7       0.89      0.84      0.86      1028\n",
            "           8       0.77      0.81      0.79       974\n",
            "           9       0.84      0.75      0.79      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.82      0.82     10000\n",
            "weighted avg       0.84      0.83      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 860    0   19    3    1    1   76    3   17    0]\n",
            " [   0 1100    2    3    1    0    5    1   23    0]\n",
            " [  31   31  865   18   22    0   19   13   28    5]\n",
            " [   5    4   22  926    2    5    7    6   28    5]\n",
            " [   0    8    8    1  850    1   28    3   16   67]\n",
            " [  12   27   25  243   36  450   20   18   48   13]\n",
            " [  19    7   38    1   22   12  826    1   32    0]\n",
            " [   1   41   52    5   21    0    1  862   24   21]\n",
            " [  19    7   17   45   26    5   24   11  788   32]\n",
            " [  11   11   11   25  118    1    7   55   15  755]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59725, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [27 30 41 37 30 20 31 27 32 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.938 s \n",
            "\n",
            "Accuracy rate for 83.030000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89       980\n",
            "           1       0.90      0.97      0.93      1135\n",
            "           2       0.81      0.86      0.83      1032\n",
            "           3       0.70      0.92      0.80      1010\n",
            "           4       0.76      0.88      0.82       982\n",
            "           5       0.91      0.52      0.66       892\n",
            "           6       0.84      0.87      0.85       958\n",
            "           7       0.90      0.83      0.86      1028\n",
            "           8       0.82      0.80      0.81       974\n",
            "           9       0.84      0.74      0.79      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.82     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 849    0   29    8    2    2   76    3   11    0]\n",
            " [   0 1103    6    2    1    0    3    1   19    0]\n",
            " [  27   23  892   28   20    2    8    8   21    3]\n",
            " [   0    7   31  926    3    9    1    5   20    8]\n",
            " [   0    7   11    2  861    1   23    4   12   61]\n",
            " [   7   20   24  259   38  461   21   13   33   16]\n",
            " [  15    7   36    3   21   21  830    0   25    0]\n",
            " [   2   40   50   11   22    1    1  851   20   30]\n",
            " [  21   12   16   51   26    7   22   10  782   27]\n",
            " [   9    9   11   28  132    1    7   50   14  748]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [31 34 42 38 31 23 34 31 34 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.425 s \n",
            "\n",
            "Accuracy rate for 84.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.90       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.85      0.86      0.86      1032\n",
            "           3       0.75      0.90      0.82      1010\n",
            "           4       0.80      0.90      0.84       982\n",
            "           5       0.92      0.55      0.69       892\n",
            "           6       0.83      0.90      0.86       958\n",
            "           7       0.88      0.86      0.87      1028\n",
            "           8       0.82      0.79      0.81       974\n",
            "           9       0.87      0.77      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    0   19    2    0    3   48    6    5    1]\n",
            " [   0 1101    3    3    1    0    4    0   23    0]\n",
            " [  33   25  885   18   16    2   17   16   16    4]\n",
            " [   3    8   21  910    2   11    7    8   34    6]\n",
            " [   1    8    7    1  882    0   30    2   12   39]\n",
            " [  16   26   14  212   34  493   27   18   35   17]\n",
            " [  19    5   18    1   20   23  861    0   11    0]\n",
            " [   1   41   50    2   17    0    2  880   15   20]\n",
            " [  19   12   15   45   30    5   33   13  773   29]\n",
            " [  13   13    6   22  105    0    8   55   15  772]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59675, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [33 36 45 39 35 26 35 35 37 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.727 s \n",
            "\n",
            "Accuracy rate for 85.190000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.85      0.86      0.86      1032\n",
            "           3       0.78      0.90      0.84      1010\n",
            "           4       0.79      0.90      0.84       982\n",
            "           5       0.90      0.60      0.72       892\n",
            "           6       0.87      0.87      0.87       958\n",
            "           7       0.87      0.86      0.87      1028\n",
            "           8       0.83      0.82      0.82       974\n",
            "           9       0.86      0.76      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    3    3    0    3   42    3    9    0]\n",
            " [   0 1106    3    3    1    1    3    0   18    0]\n",
            " [  30   20  890   20   19    3    8   19   20    3]\n",
            " [   4   12   28  908    3   14    3    8   23    7]\n",
            " [   1   10    7    0  885    0   24    4    7   44]\n",
            " [  14   18    9  172   42  533   20   19   42   23]\n",
            " [  20    5   33    1   21   27  830    0   20    1]\n",
            " [   2   43   43    3   12    1    1  885   16   22]\n",
            " [  16   14   21   28   28    8   20   15  795   29]\n",
            " [   9   14    4   23  110    0    7   59   13  770]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [36 39 46 42 38 29 38 36 39 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.699 s \n",
            "\n",
            "Accuracy rate for 85.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       980\n",
            "           1       0.89      0.98      0.93      1135\n",
            "           2       0.88      0.83      0.86      1032\n",
            "           3       0.79      0.89      0.84      1010\n",
            "           4       0.77      0.90      0.83       982\n",
            "           5       0.91      0.60      0.72       892\n",
            "           6       0.87      0.88      0.87       958\n",
            "           7       0.89      0.86      0.88      1028\n",
            "           8       0.82      0.82      0.82       974\n",
            "           9       0.85      0.79      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    2    2    5    2   29    3    9    0]\n",
            " [   0 1109    3    3    1    1    3    0   15    0]\n",
            " [  34   23  860   23   25    1   14   19   28    5]\n",
            " [   6   14   20  903    3   14    9    8   21   12]\n",
            " [   1    9    6    0  883    0   20    2    9   52]\n",
            " [  14   18   11  162   49  536   17   20   40   25]\n",
            " [  21    5   18    1   27   27  839    1   19    0]\n",
            " [   3   38   40    3   12    0    2  889   17   24]\n",
            " [  16   17   12   27   29    7   30   14  796   26]\n",
            " [   9   15    4   17  109    0    5   42   12  796]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [38 40 49 42 39 30 39 41 47 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.569 s \n",
            "\n",
            "Accuracy rate for 85.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.90      0.97      0.94      1135\n",
            "           2       0.87      0.87      0.87      1032\n",
            "           3       0.80      0.89      0.84      1010\n",
            "           4       0.80      0.87      0.83       982\n",
            "           5       0.91      0.58      0.71       892\n",
            "           6       0.87      0.87      0.87       958\n",
            "           7       0.89      0.86      0.87      1028\n",
            "           8       0.80      0.86      0.83       974\n",
            "           9       0.83      0.81      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    0    3    1    2    2   33    4    9    0]\n",
            " [   0 1105    3    3    1    1    3    0   19    0]\n",
            " [  29   17  894   18   19    1   12   23   16    3]\n",
            " [   5   10   22  894    2   18    5   10   34   10]\n",
            " [   0    9    8    0  854    0   23    4   14   70]\n",
            " [  11   19   14  153   43  515   20   17   61   39]\n",
            " [  21    6   21    1   31   24  834    1   19    0]\n",
            " [   3   37   43    3   11    1    2  886   22   20]\n",
            " [   7   12   13   22   21    6   25   14  834   20]\n",
            " [   9    7    4   17   90    0    5   42   18  817]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [41 43 51 45 41 34 42 44 49 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.934 s \n",
            "\n",
            "Accuracy rate for 86.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.90      0.97      0.94      1135\n",
            "           2       0.88      0.86      0.87      1032\n",
            "           3       0.82      0.89      0.85      1010\n",
            "           4       0.80      0.90      0.85       982\n",
            "           5       0.90      0.66      0.76       892\n",
            "           6       0.86      0.88      0.87       958\n",
            "           7       0.89      0.88      0.88      1028\n",
            "           8       0.83      0.85      0.84       974\n",
            "           9       0.87      0.80      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    0    2    0    4    3   38    3    7    0]\n",
            " [   0 1105    5    3    1    1    3    0   17    0]\n",
            " [  28   17  886   17   21    1   14   23   23    2]\n",
            " [   4   12   20  895    2   17    7   12   32    9]\n",
            " [   0    8    8    0  882    0   23    3   13   45]\n",
            " [  12   18   13  139   38  585   19   13   28   27]\n",
            " [  19    5   12    1   34   32  847    1    7    0]\n",
            " [   1   30   44    1   16    0    1  901   20   14]\n",
            " [   5   16   14   19   19    8   27   12  828   26]\n",
            " [   9   11    4   17   85    0    7   47   18  811]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59575, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [43 49 54 47 46 36 44 44 51 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.929 s \n",
            "\n",
            "Accuracy rate for 86.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       980\n",
            "           1       0.90      0.97      0.94      1135\n",
            "           2       0.87      0.86      0.87      1032\n",
            "           3       0.80      0.89      0.85      1010\n",
            "           4       0.80      0.90      0.84       982\n",
            "           5       0.92      0.64      0.75       892\n",
            "           6       0.88      0.89      0.89       958\n",
            "           7       0.88      0.87      0.88      1028\n",
            "           8       0.82      0.85      0.84       974\n",
            "           9       0.88      0.79      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    2    0    6    2   30    3    9    0]\n",
            " [   0 1105    5    3    1    1    3    1   16    0]\n",
            " [  28   21  887   15   21    2    9   22   26    1]\n",
            " [   5   10   23  900    1   10    2   12   38    9]\n",
            " [   1   10    7    1  879    0   21    5   16   42]\n",
            " [   8   15   15  151   34  569   19   15   35   31]\n",
            " [  19    5   14    1   36   25  852    0    6    0]\n",
            " [   3   34   44    2   14    0    1  899   18   13]\n",
            " [   6   12   15   27   21    6   22   17  832   16]\n",
            " [   8    9    4   19   92    1    6   50   18  802]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [46 50 58 49 50 39 45 46 53 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.267 s \n",
            "\n",
            "Accuracy rate for 87.070000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.88      0.87      0.88      1032\n",
            "           3       0.82      0.88      0.85      1010\n",
            "           4       0.78      0.91      0.84       982\n",
            "           5       0.91      0.68      0.78       892\n",
            "           6       0.90      0.88      0.89       958\n",
            "           7       0.90      0.88      0.89      1028\n",
            "           8       0.83      0.85      0.84       974\n",
            "           9       0.88      0.79      0.84      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    3    0    5    3   18    4    7    0]\n",
            " [   0 1104    3    3    1    0    4    0   20    0]\n",
            " [  29   18  899   15   18    1    7   22   22    1]\n",
            " [   9   15   24  886    3   16    3   13   33    8]\n",
            " [   0    9    6    1  896    2   17    2   14   35]\n",
            " [  15   13   10  124   38  611   17    9   29   26]\n",
            " [  20    6   10    1   42   28  843    1    7    0]\n",
            " [   3   34   43    3   16    0    1  900   18   10]\n",
            " [   5    9   12   27   26   10   23    7  828   27]\n",
            " [   7   11    6   17  101    0    5   45   17  800]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59525, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [50 50 61 51 53 42 45 50 55 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.460 s \n",
            "\n",
            "Accuracy rate for 87.000000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94       980\n",
            "           1       0.91      0.97      0.94      1135\n",
            "           2       0.89      0.88      0.88      1032\n",
            "           3       0.81      0.88      0.85      1010\n",
            "           4       0.80      0.91      0.85       982\n",
            "           5       0.90      0.67      0.77       892\n",
            "           6       0.90      0.87      0.88       958\n",
            "           7       0.89      0.86      0.87      1028\n",
            "           8       0.83      0.86      0.84       974\n",
            "           9       0.88      0.81      0.84      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    3    0    5    4   22    3    7    1]\n",
            " [   0 1105    4    2    1    1    3    1   18    0]\n",
            " [  23   19  905   16   17    1    6   22   21    2]\n",
            " [   7   11   19  892    2   17    3   15   36    8]\n",
            " [   2    8    5    2  892    3   18    2   14   36]\n",
            " [  16   14    6  131   36  595   17   16   31   30]\n",
            " [  19    5   17    1   51   25  834    0    6    0]\n",
            " [   2   33   43    2   17    1    1  887   25   17]\n",
            " [   5   13    8   30   18   12   17   11  839   21]\n",
            " [   9    8    7   20   82    0    6   43   18  816]]\n",
            "--------------------------------\n",
            "final active learning accuracies [40.47, 51.01, 64.7, 72.8, 76.29, 75.97, 78.34, 79.21000000000001, 81.67, 81.62, 82.82000000000001, 83.03, 84.53, 85.19, 85.39, 85.59, 86.63, 86.53, 87.07000000000001, 87.0]\n",
            "saved Active-learning-experiment-19.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 20, using model = RfModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [1 1 1 1 0 1 0 1 0 4] [0 1 2 3 5 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.353 s \n",
            "\n",
            "Accuracy rate for 31.420000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.47      0.53       980\n",
            "           1       0.60      0.92      0.73      1135\n",
            "           2       0.71      0.40      0.51      1032\n",
            "           3       0.37      0.11      0.17      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.18      0.04      0.06       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.85      0.12      0.21      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.15      0.96      0.26      1009\n",
            "\n",
            "    accuracy                           0.31     10000\n",
            "   macro avg       0.35      0.30      0.25     10000\n",
            "weighted avg       0.36      0.31      0.26     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 456   52    1  120    0   68    0    9    0  274]\n",
            " [   0 1039    2    0    0    0    0    0    0   94]\n",
            " [  35  156  411   24    0   13    0    1    0  392]\n",
            " [  16   35   18  112    0    1    0    0    0  828]\n",
            " [   1   26    1    0    0   14    0    2    0  938]\n",
            " [  25  142    5   17    0   34    0    2    0  667]\n",
            " [ 160   69   82    0    0   54    0    0    0  593]\n",
            " [   0   54    6    0    0    1    0  121    0  846]\n",
            " [  30  130   49   25    0    6    0    4    0  730]\n",
            " [   2   26    1    7    0    0    0    4    0  969]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['9' '1' '9' ... '9' '9' '1']\n",
            "probabilities: (59990, 7) \n",
            " [6 1 6 ... 6 6 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [3 1 3 1 0 2 1 5 0 4] [0 1 2 3 5 6 7 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.380 s \n",
            "\n",
            "Accuracy rate for 37.040000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "           4       0.69      0.38      0.49       982\n",
            "           5       0.65      0.42      0.51       892\n",
            "           6       0.95      0.32      0.48       958\n",
            "           7       0.75      0.88      0.81      1028\n",
            "           8       0.53      0.82      0.65       974\n",
            "           9       0.44      0.74      0.56      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.72      0.67      0.66     10000\n",
            "weighted avg       0.73      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 911    1    0    0    0   17    0   25   22    4]\n",
            " [   0 1118    0    2    0    2    0    2   11    0]\n",
            " [  44  111  659   16   18    7    2   54   90   31]\n",
            " [  46   54    9  565    2   56    0   60  195   23]\n",
            " [   5   20    1    0  369   13   12   24   38  500]\n",
            " [  77   28    7   82    8  377    0   33  158  122]\n",
            " [ 190   27   36    0   55   55  310   28  105  152]\n",
            " [   3   35   12    0    4    3    0  908   13   50]\n",
            " [  21   49    2    8    4   15    1   14  803   57]\n",
            " [  13   11    0    0   71   31    0   62   72  749]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['3' '0' '7' ... '5' '0' '8']\n",
            "probabilities: (59930, 10) \n",
            " [3 0 7 ... 5 0 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [10  6  8  8  6  7  4 10 10 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.072 s \n",
            "\n",
            "Accuracy rate for 70.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.95      0.82       980\n",
            "           1       0.80      0.98      0.88      1135\n",
            "           2       0.83      0.69      0.75      1032\n",
            "           3       0.75      0.77      0.76      1010\n",
            "           4       0.65      0.41      0.51       982\n",
            "           5       0.69      0.52      0.59       892\n",
            "           6       0.94      0.25      0.40       958\n",
            "           7       0.81      0.86      0.83      1028\n",
            "           8       0.66      0.73      0.70       974\n",
            "           9       0.45      0.76      0.57      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.73      0.69      0.68     10000\n",
            "weighted avg       0.73      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    2    0    2    0   14    2    7   15   11]\n",
            " [   0 1110    1    5    0    2    0    1   16    0]\n",
            " [  49   91  712   19    8   12    2   44   63   32]\n",
            " [  31   21   11  781    1   17    0   37   79   32]\n",
            " [   6   19    6    0  407   19   10   15   21  479]\n",
            " [  57   28    6  166    4  467    1   17   42  104]\n",
            " [ 175   24  108    4  106   99  241   16   70  115]\n",
            " [   1   34   15    1    8    5    0  882   11   71]\n",
            " [  28   42    1   62   11   24    0   14  712   80]\n",
            " [  17   12    0    7   82   19    0   62   45  765]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['3' '0' '7' ... '5' '5' '8']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 7 ... 5 5 8]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [10  9 10  8  7  8  6 10 10 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.741 s \n",
            "\n",
            "Accuracy rate for 71.910000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.93      0.83       980\n",
            "           1       0.78      0.97      0.87      1135\n",
            "           2       0.75      0.70      0.73      1032\n",
            "           3       0.77      0.75      0.76      1010\n",
            "           4       0.68      0.43      0.53       982\n",
            "           5       0.81      0.56      0.67       892\n",
            "           6       0.85      0.43      0.57       958\n",
            "           7       0.84      0.81      0.82      1028\n",
            "           8       0.72      0.71      0.71       974\n",
            "           9       0.48      0.82      0.61      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.71      0.71     10000\n",
            "weighted avg       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    1    2    0    8   23    8   12   10]\n",
            " [   0 1105   11    5    0    4    0    1    9    0]\n",
            " [  45   96  723   20    5   10   14   37   67   15]\n",
            " [  30   44   15  754    0   19    0   35   71   42]\n",
            " [   4   18   20    1  425    5   25   11   15  458]\n",
            " [  53   32    7  142    5  503    6   19   20  105]\n",
            " [ 128   17  135    0   87   44  413   18   33   83]\n",
            " [   1   44   27    2   12    2    0  834   13   93]\n",
            " [  37   47   14   54   10   19    3   12  688   90]\n",
            " [  18   14    6    4   80    4    2   22   29  830]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['3' '0' '7' ... '5' '6' '8']\n",
            "probabilities: (59910, 10) \n",
            " [3 0 7 ... 5 6 8]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [10  9 11 10  9  9  6 12 11 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.115 s \n",
            "\n",
            "Accuracy rate for 73.610000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.93      0.84       980\n",
            "           1       0.79      0.97      0.87      1135\n",
            "           2       0.72      0.71      0.72      1032\n",
            "           3       0.78      0.78      0.78      1010\n",
            "           4       0.73      0.50      0.60       982\n",
            "           5       0.86      0.54      0.66       892\n",
            "           6       0.91      0.43      0.59       958\n",
            "           7       0.80      0.85      0.83      1028\n",
            "           8       0.71      0.76      0.74       974\n",
            "           9       0.53      0.80      0.64      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.72     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    4    3    0    6   15   13   11   12]\n",
            " [   0 1104   15    3    0    4    0    0    9    0]\n",
            " [  38   89  736   17    0    5   10   41   80   16]\n",
            " [  23   39   20  792    0   32    0   36   44   24]\n",
            " [   5   22   21    0  495    0   13   15   12  399]\n",
            " [  51   33   11  139    8  480    2   28   50   90]\n",
            " [ 132   21  167    2   62   26  416   22   49   61]\n",
            " [   1   39   25    2   24    0    0  873    8   56]\n",
            " [  31   41   19   48    9    5    0   14  738   69]\n",
            " [  16   15    6    4   77    3    0   44   33  811]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '9' ... '5' '0' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 9 ... 5 0 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [10 10 13 10 10 10  6 14 12 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.876 s \n",
            "\n",
            "Accuracy rate for 73.450000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       980\n",
            "           1       0.78      0.96      0.86      1135\n",
            "           2       0.67      0.72      0.70      1032\n",
            "           3       0.84      0.76      0.79      1010\n",
            "           4       0.78      0.51      0.62       982\n",
            "           5       0.84      0.58      0.69       892\n",
            "           6       0.92      0.39      0.55       958\n",
            "           7       0.82      0.84      0.83      1028\n",
            "           8       0.72      0.74      0.73       974\n",
            "           9       0.50      0.85      0.63      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.77      0.73      0.73     10000\n",
            "weighted avg       0.77      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    0    5    2    0    7   16   12   14   15]\n",
            " [   0 1089   23    3    0    2    0    4   14    0]\n",
            " [  29   87  744   14    1   10    7   38   83   19]\n",
            " [  27   48   25  764    0   21    0   31   46   48]\n",
            " [   3   15   24    1  504    3    7   14    4  407]\n",
            " [  57   27   19   83    3  520    1   24   49  109]\n",
            " [  98   23  199    0   67   39  376   15   42   99]\n",
            " [   1   41   27    3    8    0    0  866    6   76]\n",
            " [  25   44   25   41    5   11    1   14  717   91]\n",
            " [  14   15   13    2   55    3    0   33   18  856]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59890, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [14 11 13 13 11 10  7 14 12 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.174 s \n",
            "\n",
            "Accuracy rate for 75.730000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.96      0.84       980\n",
            "           1       0.82      0.96      0.88      1135\n",
            "           2       0.73      0.69      0.71      1032\n",
            "           3       0.75      0.82      0.78      1010\n",
            "           4       0.81      0.53      0.64       982\n",
            "           5       0.85      0.57      0.68       892\n",
            "           6       0.93      0.59      0.72       958\n",
            "           7       0.81      0.86      0.84      1028\n",
            "           8       0.72      0.73      0.72       974\n",
            "           9       0.58      0.81      0.68      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.78      0.75      0.75     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    2    0    0    6   10    5   11    4]\n",
            " [   0 1088   18    6    0    2    0    3   18    0]\n",
            " [  45   72  713   15    1    6   11   39  116   14]\n",
            " [  32   20   19  824    2   18    1   28   44   22]\n",
            " [   6   23   29    3  524    3   12   21    4  357]\n",
            " [  65   24   14  169    2  505    4   27   45   37]\n",
            " [ 119   18  119    1   33   37  561   18   23   29]\n",
            " [   1   36   25    2    8    1    0  886    9   60]\n",
            " [  38   36   26   65    6   11    4   16  711   61]\n",
            " [  20   16    7   15   67    2    0   50   13  819]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59880, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [15 12 15 14 12 10  8 15 13 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.303 s \n",
            "\n",
            "Accuracy rate for 76.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.96      0.86       980\n",
            "           1       0.80      0.97      0.88      1135\n",
            "           2       0.72      0.70      0.71      1032\n",
            "           3       0.73      0.84      0.78      1010\n",
            "           4       0.86      0.58      0.69       982\n",
            "           5       0.89      0.45      0.60       892\n",
            "           6       0.93      0.63      0.75       958\n",
            "           7       0.81      0.86      0.84      1028\n",
            "           8       0.75      0.72      0.74       974\n",
            "           9       0.59      0.85      0.69      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.79      0.76      0.75     10000\n",
            "weighted avg       0.78      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    4    1    0    6    8    7   12    5]\n",
            " [   0 1100   19    4    0    2    0    4    6    0]\n",
            " [  33   86  718   15    1    3   13   49  105    9]\n",
            " [  30   24   20  852    1    8    0   28   27   20]\n",
            " [   4   17   29    4  570    1   18   19    2  318]\n",
            " [  58   34   15  228    7  402    3   25   39   81]\n",
            " [  93   20  113    4   27   24  604   14   23   36]\n",
            " [   1   39   24    3   11    0    0  888    5   57]\n",
            " [  35   35   49   46    6    4    4   17  702   76]\n",
            " [  16   14   13   15   42    1    1   40   11  856]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59870, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [16 13 15 14 14 14  9 16 13 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.789 s \n",
            "\n",
            "Accuracy rate for 78.660000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.95      0.86       980\n",
            "           1       0.84      0.97      0.90      1135\n",
            "           2       0.71      0.69      0.70      1032\n",
            "           3       0.79      0.79      0.79      1010\n",
            "           4       0.83      0.68      0.75       982\n",
            "           5       0.75      0.69      0.72       892\n",
            "           6       0.90      0.70      0.78       958\n",
            "           7       0.82      0.87      0.84      1028\n",
            "           8       0.79      0.69      0.74       974\n",
            "           9       0.68      0.80      0.73      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.78      0.78     10000\n",
            "weighted avg       0.79      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    4    1    1   14   15    4    8    2]\n",
            " [   0 1098   19    3    0    5    0    3    7    0]\n",
            " [  33   75  717   16    1    8   18   54  101    9]\n",
            " [  38   13   19  799    1   62    1   34   25   18]\n",
            " [   2   18   36    3  671    7   19   20    1  205]\n",
            " [  61   17   20  113    7  619    8   17   11   19]\n",
            " [  59    9  104    1   27   69  666    8    6    9]\n",
            " [   1   29   29    2   11    2    0  890    7   57]\n",
            " [  35   29   50   58   12   31   11   13  671   64]\n",
            " [  13   14   15   12   79   12    3   48    9  804]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59860, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [16 15 18 14 14 15  9 17 15 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.171 s \n",
            "\n",
            "Accuracy rate for 79.880000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       980\n",
            "           1       0.82      0.97      0.89      1135\n",
            "           2       0.72      0.77      0.74      1032\n",
            "           3       0.85      0.77      0.81      1010\n",
            "           4       0.86      0.68      0.76       982\n",
            "           5       0.77      0.72      0.75       892\n",
            "           6       0.91      0.69      0.78       958\n",
            "           7       0.83      0.86      0.85      1028\n",
            "           8       0.82      0.74      0.78       974\n",
            "           9       0.67      0.82      0.74      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0    6    0    0    7   13    6   19    7]\n",
            " [   0 1100   21    3    0    3    0    3    5    0]\n",
            " [  31   84  790    9    0    7   18   38   49    6]\n",
            " [  39   17   28  775    0   63    3   34   28   23]\n",
            " [   4   17   25    1  667    7   19   15    3  224]\n",
            " [  54   19   15   82    6  645    6   17   24   24]\n",
            " [  64   15  100    1   29   57  660    7   10   15]\n",
            " [   1   43   35    1    6    0    1  887    3   51]\n",
            " [  20   25   52   35   14   29    7   16  717   59]\n",
            " [  13   17   18    6   53   18    2   45   12  825]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '2' '2']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 2 2]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [18 17 19 15 15 16  9 18 15 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.379 s \n",
            "\n",
            "Accuracy rate for 79.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       980\n",
            "           1       0.80      0.97      0.88      1135\n",
            "           2       0.72      0.76      0.74      1032\n",
            "           3       0.84      0.77      0.80      1010\n",
            "           4       0.84      0.73      0.78       982\n",
            "           5       0.73      0.74      0.73       892\n",
            "           6       0.90      0.65      0.76       958\n",
            "           7       0.82      0.86      0.84      1028\n",
            "           8       0.86      0.68      0.76       974\n",
            "           9       0.69      0.82      0.75      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.79      0.79     10000\n",
            "weighted avg       0.80      0.80      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    1    6    1    0   14   19    2   10    4]\n",
            " [   0 1103   21    2    0    2    0    3    4    0]\n",
            " [  25   99  786    8    1   11   16   45   36    5]\n",
            " [  32   21   22  773    0   77    2   38   25   20]\n",
            " [   2   19   30    1  712    9   19   16    1  173]\n",
            " [  51   19   16   85    5  659    4   15   13   25]\n",
            " [  55   16  118    1   54   70  627    6    8    3]\n",
            " [   1   37   28    2   12    1    0  881    3   63]\n",
            " [  24   39   56   37   12   38   11   18  666   73]\n",
            " [   9   21   14    7   51   21    1   47    9  829]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['5' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59840, 10) \n",
            " [5 0 4 ... 5 0 5]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [19 17 20 16 15 19  9 19 17 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.815 s \n",
            "\n",
            "Accuracy rate for 79.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       980\n",
            "           1       0.82      0.97      0.89      1135\n",
            "           2       0.70      0.74      0.72      1032\n",
            "           3       0.89      0.74      0.81      1010\n",
            "           4       0.85      0.66      0.74       982\n",
            "           5       0.73      0.82      0.77       892\n",
            "           6       0.93      0.64      0.76       958\n",
            "           7       0.83      0.87      0.85      1028\n",
            "           8       0.83      0.75      0.79       974\n",
            "           9       0.68      0.83      0.74      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.80     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 921    1    4    1    0   20   10    2   16    5]\n",
            " [   0 1104   19    2    0    4    0    2    4    0]\n",
            " [  24   92  766   10    1   14   13   50   55    7]\n",
            " [  28   17   24  748    0   98    1   38   35   21]\n",
            " [   3   16   33    1  649   11   16   17    3  233]\n",
            " [  35   17   21   38    3  732    0   14   17   15]\n",
            " [  55   17  137    0   51   66  611   11    6    4]\n",
            " [   1   34   27    2    6    4    0  896    3   55]\n",
            " [  25   30   40   29    7   36    8   10  728   61]\n",
            " [   8   15   16    5   49   22    1   45   13  835]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59830, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [20 18 20 17 17 20 10 20 19 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.134 s \n",
            "\n",
            "Accuracy rate for 81.110000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       980\n",
            "           1       0.83      0.97      0.90      1135\n",
            "           2       0.74      0.74      0.74      1032\n",
            "           3       0.88      0.79      0.83      1010\n",
            "           4       0.80      0.77      0.79       982\n",
            "           5       0.75      0.79      0.77       892\n",
            "           6       0.91      0.64      0.75       958\n",
            "           7       0.85      0.87      0.86      1028\n",
            "           8       0.79      0.77      0.78       974\n",
            "           9       0.75      0.80      0.77      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.81     10000\n",
            "weighted avg       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    5    1    0   18   16    2   20    2]\n",
            " [   0 1104   18    2    0    5    0    2    4    0]\n",
            " [  23   86  759   10    6   15   14   44   72    3]\n",
            " [  17   19   24  794    0   70    1   24   41   20]\n",
            " [   2   18   25    1  758    9   14   16    3  136]\n",
            " [  28   17   18   63    6  709    4    8   27   12]\n",
            " [  66   13   94    1   89   65  615    3   12    0]\n",
            " [   1   34   29    1    9    4    0  896    4   50]\n",
            " [  19   25   40   25   16   33    6   12  754   44]\n",
            " [  10   15   15    9   64   23    3   49   15  806]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59820, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [20 18 21 20 19 21 10 22 20 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.016 s \n",
            "\n",
            "Accuracy rate for 81.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.89       980\n",
            "           1       0.85      0.97      0.90      1135\n",
            "           2       0.74      0.72      0.73      1032\n",
            "           3       0.84      0.83      0.83      1010\n",
            "           4       0.77      0.82      0.80       982\n",
            "           5       0.78      0.77      0.77       892\n",
            "           6       0.94      0.64      0.76       958\n",
            "           7       0.83      0.89      0.86      1028\n",
            "           8       0.78      0.78      0.78       974\n",
            "           9       0.79      0.75      0.77      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 918    0    5    2    0   19   10    3   18    5]\n",
            " [   0 1101   17    6    0    3    0    4    4    0]\n",
            " [  26   73  740   14    7   12   10   53   91    6]\n",
            " [  18   10   17  838    1   49    1   28   33   15]\n",
            " [   2   15   25    4  807    8    8   13    4   96]\n",
            " [  29   17   18   82   14  684    5   12   23    8]\n",
            " [  49   12  114    6   82   57  617    4   17    0]\n",
            " [   1   27   22    2   11    1    0  919   10   35]\n",
            " [  21   27   31   39   17   24    5   15  763   32]\n",
            " [   8   17   11    8  106   25    2   61   18  753]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59810, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [22 19 22 21 19 21 11 22 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.071 s \n",
            "\n",
            "Accuracy rate for 81.710000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       980\n",
            "           1       0.85      0.97      0.91      1135\n",
            "           2       0.73      0.75      0.74      1032\n",
            "           3       0.84      0.82      0.83      1010\n",
            "           4       0.80      0.79      0.79       982\n",
            "           5       0.78      0.76      0.77       892\n",
            "           6       0.94      0.67      0.78       958\n",
            "           7       0.84      0.89      0.86      1028\n",
            "           8       0.79      0.82      0.81       974\n",
            "           9       0.77      0.74      0.76      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    6    1    0   18   12    4   20    2]\n",
            " [   0 1102   20    4    0    2    0    4    3    0]\n",
            " [  23   69  772   17    9   11   10   43   73    5]\n",
            " [  17   10   24  825    0   55    0   23   40   16]\n",
            " [   3   17   27    3  776    9    9   13    6  119]\n",
            " [  36   16   18   80    9  681    3   11   25   13]\n",
            " [  54   13  118    3   60   54  639    6   11    0]\n",
            " [   1   28   23    1   10    4    0  910    9   42]\n",
            " [  19   25   40   29    7   14    6   10  801   23]\n",
            " [   8   15   12   17  101   25    2   53   28  748]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [23 20 22 22 21 21 11 23 26 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.889 s \n",
            "\n",
            "Accuracy rate for 81.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.75      0.70      0.73      1032\n",
            "           3       0.84      0.83      0.83      1010\n",
            "           4       0.76      0.86      0.80       982\n",
            "           5       0.83      0.72      0.77       892\n",
            "           6       0.94      0.63      0.75       958\n",
            "           7       0.83      0.89      0.86      1028\n",
            "           8       0.74      0.84      0.79       974\n",
            "           9       0.81      0.73      0.77      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.82      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0    5    1    0    9   11    4   26    2]\n",
            " [   0 1103   18    1    0    4    0    4    5    0]\n",
            " [  27   73  726   15   10    8   12   54   99    8]\n",
            " [  19    5   20  837    1   30    1   26   59   12]\n",
            " [   2   11   15    3  842    4    8   15    5   77]\n",
            " [  40   16   19   97   15  644    5   12   29   15]\n",
            " [  52   15  109    3  101   46  606    7   19    0]\n",
            " [   1   26   19    1   15    2    0  915   13   36]\n",
            " [  25   17   29   30    9   12    4    8  821   19]\n",
            " [   8   14    7   12  118   19    1   61   30  739]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59790, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [23 20 24 23 22 23 13 24 26 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.726 s \n",
            "\n",
            "Accuracy rate for 82.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90       980\n",
            "           1       0.87      0.96      0.91      1135\n",
            "           2       0.77      0.74      0.75      1032\n",
            "           3       0.83      0.83      0.83      1010\n",
            "           4       0.81      0.82      0.82       982\n",
            "           5       0.79      0.74      0.76       892\n",
            "           6       0.93      0.74      0.83       958\n",
            "           7       0.85      0.88      0.87      1028\n",
            "           8       0.75      0.84      0.79       974\n",
            "           9       0.80      0.74      0.77      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.82      0.82     10000\n",
            "weighted avg       0.83      0.83      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 911    0    6    1    0   14   12    2   33    1]\n",
            " [   0 1085   24    3    0    4    0    3   16    0]\n",
            " [  19   64  766   11   12   12   15   50   80    3]\n",
            " [  16   11   22  840    2   35    0   22   49   13]\n",
            " [   2   11   18    3  808    7   13   10   13   97]\n",
            " [  33   14   18  106   11  658    6    8   29    9]\n",
            " [  46   10   86    2   24   55  711    5   19    0]\n",
            " [   1   20   23    0   17    3    0  908   15   41]\n",
            " [  19   21   29   36    8   12    4    7  817   21]\n",
            " [   6   14    7   10  114   30    4   49   25  750]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59780, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [23 22 25 24 22 24 13 27 27 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.426 s \n",
            "\n",
            "Accuracy rate for 82.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       980\n",
            "           1       0.88      0.96      0.92      1135\n",
            "           2       0.75      0.72      0.74      1032\n",
            "           3       0.85      0.82      0.83      1010\n",
            "           4       0.83      0.81      0.82       982\n",
            "           5       0.78      0.73      0.76       892\n",
            "           6       0.93      0.72      0.82       958\n",
            "           7       0.83      0.90      0.87      1028\n",
            "           8       0.73      0.86      0.79       974\n",
            "           9       0.80      0.76      0.78      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.82      0.82     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    0    4    2    0   15    9    4   38    1]\n",
            " [   0 1086   28    2    0    2    0    5   12    0]\n",
            " [  24   57  743   11   10   17   12   57   97    4]\n",
            " [  17    6   24  831    1   35    0   23   60   13]\n",
            " [   2   12   23    1  797    5   11   13   10  108]\n",
            " [  33   13   20  104    9  652    7   10   31   13]\n",
            " [  47   12   87    1   24   62  693    7   25    0]\n",
            " [   1   21   26    0   10    3    0  926   11   30]\n",
            " [  17   18   21   24    8   18    6    8  833   21]\n",
            " [   7   13   10    5   99   23    4   56   24  768]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59770, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [25 23 25 24 22 24 17 29 27 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.461 s \n",
            "\n",
            "Accuracy rate for 82.410000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88       980\n",
            "           1       0.85      0.96      0.90      1135\n",
            "           2       0.78      0.72      0.75      1032\n",
            "           3       0.85      0.83      0.84      1010\n",
            "           4       0.83      0.77      0.80       982\n",
            "           5       0.82      0.73      0.77       892\n",
            "           6       0.91      0.79      0.85       958\n",
            "           7       0.83      0.89      0.86      1028\n",
            "           8       0.76      0.83      0.79       974\n",
            "           9       0.77      0.77      0.77      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    0    5    2    0    9   14    4   37    0]\n",
            " [   0 1089   30    3    0    2    0    3    8    0]\n",
            " [  31   72  746    8    8   11   14   52   85    5]\n",
            " [  19   16   19  834    2   34    1   27   45   13]\n",
            " [   2   13   23    0  756    5   23   15    5  140]\n",
            " [  35   17   19  100    9  647   12   11   26   16]\n",
            " [  48   14   51    1   20   42  760    7   14    1]\n",
            " [   1   26   28    0   12    1    0  915   12   33]\n",
            " [  21   20   30   28    5   14    8   13  805   30]\n",
            " [  10   14    9    5   94   22    6   53   16  780]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59760, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [25 25 26 26 22 26 17 30 28 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.476 s \n",
            "\n",
            "Accuracy rate for 82.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       980\n",
            "           1       0.86      0.97      0.91      1135\n",
            "           2       0.78      0.74      0.76      1032\n",
            "           3       0.84      0.85      0.85      1010\n",
            "           4       0.83      0.78      0.80       982\n",
            "           5       0.80      0.74      0.77       892\n",
            "           6       0.91      0.78      0.84       958\n",
            "           7       0.84      0.90      0.87      1028\n",
            "           8       0.77      0.82      0.80       974\n",
            "           9       0.79      0.75      0.77      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    1    7    1    0   10   16    3   36    0]\n",
            " [   0 1098   24    3    0    3    0    3    4    0]\n",
            " [  23   67  763   12    6   10   12   50   85    4]\n",
            " [  16    9   20  854    2   27    0   19   48   15]\n",
            " [   3   11   23    0  768    9   17   17    5  129]\n",
            " [  30   14   19  101    9  660   10    9   26   14]\n",
            " [  46   11   45    3   23   61  752    7   10    0]\n",
            " [   1   23   31    0   11    0    0  929    9   24]\n",
            " [  19   22   31   32    6   23   12    8  803   18]\n",
            " [   8   14   11    5  102   26    4   66   16  757]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [25 26 28 27 22 26 18 33 29 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.562 s \n",
            "\n",
            "Accuracy rate for 83.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90       980\n",
            "           1       0.87      0.97      0.91      1135\n",
            "           2       0.77      0.75      0.76      1032\n",
            "           3       0.84      0.84      0.84      1010\n",
            "           4       0.85      0.75      0.80       982\n",
            "           5       0.85      0.72      0.78       892\n",
            "           6       0.91      0.80      0.85       958\n",
            "           7       0.86      0.90      0.88      1028\n",
            "           8       0.76      0.83      0.80       974\n",
            "           9       0.75      0.80      0.78      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    0    6    1    0   11   19    2   34    0]\n",
            " [   0 1096   24    4    0    2    0    3    6    0]\n",
            " [  22   60  779   11    8    6   16   45   81    4]\n",
            " [  12   13   20  850    1   21    0   21   56   16]\n",
            " [   2   13   24    0  737    3   18   11    5  169]\n",
            " [  27   22   22  103    9  643    7   10   32   17]\n",
            " [  45    8   63    0   19   41  765    5   11    1]\n",
            " [   1   23   27    4    9    0    0  923    9   32]\n",
            " [  15   18   33   32    2   16   10   13  811   24]\n",
            " [   6   14   10    8   86   10    3   45   18  809]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59740, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [25 26 28 29 22 27 23 34 29 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.414 s \n",
            "\n",
            "Accuracy rate for 84.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.87      0.97      0.92      1135\n",
            "           2       0.82      0.76      0.79      1032\n",
            "           3       0.83      0.84      0.84      1010\n",
            "           4       0.86      0.78      0.82       982\n",
            "           5       0.86      0.75      0.80       892\n",
            "           6       0.88      0.87      0.87       958\n",
            "           7       0.87      0.89      0.88      1028\n",
            "           8       0.79      0.81      0.80       974\n",
            "           9       0.77      0.82      0.79      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    1    7    4    0    5   31    2   30    0]\n",
            " [   0 1103   20    3    0    2    0    2    5    0]\n",
            " [  22   57  782   14    7    9   19   44   73    5]\n",
            " [  12   10   20  852    1   28    3   19   52   13]\n",
            " [   2   12   17    1  765    3   24   10    5  143]\n",
            " [  17   21   14   98   10  668   18    7   24   15]\n",
            " [  29   11   30    1   22   24  831    4    3    3]\n",
            " [   1   25   27    3    8    1    0  918    8   37]\n",
            " [  16   19   28   44    3   21   17    9  790   27]\n",
            " [   6   14    7    7   78   15    4   41   12  825]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59730, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [26 27 30 29 23 27 25 35 30 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.120 s \n",
            "\n",
            "Accuracy rate for 84.520000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       980\n",
            "           1       0.88      0.96      0.92      1135\n",
            "           2       0.83      0.76      0.80      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.87      0.77      0.82       982\n",
            "           5       0.87      0.74      0.80       892\n",
            "           6       0.86      0.89      0.87       958\n",
            "           7       0.85      0.90      0.87      1028\n",
            "           8       0.81      0.81      0.81       974\n",
            "           9       0.77      0.82      0.79      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    1    4    2    0    8   36    6   27    0]\n",
            " [   0 1092   29    3    0    3    0    3    5    0]\n",
            " [  24   51  789   18    5    8   27   43   61    6]\n",
            " [  10    9   17  865    1   26    3   21   44   14]\n",
            " [   1   13   14    1  758    2   30   12    5  146]\n",
            " [  19   18   14  108    7  664   21    9   20   12]\n",
            " [  22    9   20    3   18   22  852    9    2    1]\n",
            " [   1   22   26    1    7    2    1  924    9   35]\n",
            " [  16   20   28   43    4   15   19   12  788   29]\n",
            " [   5   11    8    7   67   16    7   47   17  824]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59720, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [27 27 32 30 23 28 27 37 31 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.147 s \n",
            "\n",
            "Accuracy rate for 85.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.88      0.96      0.92      1135\n",
            "           2       0.85      0.76      0.81      1032\n",
            "           3       0.82      0.86      0.84      1010\n",
            "           4       0.88      0.78      0.83       982\n",
            "           5       0.89      0.74      0.81       892\n",
            "           6       0.85      0.90      0.88       958\n",
            "           7       0.86      0.90      0.88      1028\n",
            "           8       0.80      0.83      0.82       974\n",
            "           9       0.79      0.82      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    0    3    2    0    2   31    5   37    0]\n",
            " [   0 1089   31    4    0    3    0    3    5    0]\n",
            " [  23   54  789   22    7    7   26   41   60    3]\n",
            " [  12    5   19  873    0   23    5   18   42   13]\n",
            " [   2   10   12    2  765    1   33   12    6  139]\n",
            " [  23   21    7   97    9  662   26    8   26   13]\n",
            " [  19   10   11    5   14   24  864    7    4    0]\n",
            " [   1   24   30    1    8    0    1  923    8   32]\n",
            " [  16   17   18   47    3   10   18   11  813   21]\n",
            " [   3   11    7   10   64   10    9   49   20  826]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59710, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [27 29 32 30 25 28 27 39 33 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.251 s \n",
            "\n",
            "Accuracy rate for 85.460000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91       980\n",
            "           1       0.88      0.96      0.92      1135\n",
            "           2       0.83      0.77      0.80      1032\n",
            "           3       0.83      0.85      0.84      1010\n",
            "           4       0.88      0.80      0.84       982\n",
            "           5       0.88      0.75      0.81       892\n",
            "           6       0.87      0.88      0.88       958\n",
            "           7       0.86      0.90      0.88      1028\n",
            "           8       0.80      0.83      0.82       974\n",
            "           9       0.81      0.86      0.83      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    0    3    2    0    5   25    5   34    0]\n",
            " [   0 1094   30    2    0    1    1    3    4    0]\n",
            " [  22   54  798   13    6    6   23   44   64    2]\n",
            " [  14    7   19  855    1   29    3   19   46   17]\n",
            " [   3   11   16    1  782    2   28   10    5  124]\n",
            " [  25   18   14   91   11  667   20   13   22   11]\n",
            " [  20   10   15    3   31   24  845    6    3    1]\n",
            " [   1   22   26    4    6    0    0  930    7   32]\n",
            " [  16   15   28   43    5   10   18   11  806   22]\n",
            " [   4   13   10   10   43   11    4   39   12  863]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [29 30 33 30 25 29 28 41 34 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.065 s \n",
            "\n",
            "Accuracy rate for 84.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.92       980\n",
            "           1       0.87      0.96      0.91      1135\n",
            "           2       0.83      0.77      0.80      1032\n",
            "           3       0.84      0.83      0.84      1010\n",
            "           4       0.91      0.76      0.83       982\n",
            "           5       0.85      0.77      0.81       892\n",
            "           6       0.85      0.89      0.87       958\n",
            "           7       0.86      0.89      0.87      1028\n",
            "           8       0.81      0.83      0.82       974\n",
            "           9       0.77      0.85      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    1    6    3    0    4   27    5   30    0]\n",
            " [   0 1087   33    2    0    2    0    3    8    0]\n",
            " [  24   60  790   13    5    9   27   39   61    4]\n",
            " [  10   12   23  841    1   33    5   20   44   21]\n",
            " [   1   13   14    0  750    2   38   13    5  146]\n",
            " [  17   16   11   89    7  684   23   12   13   20]\n",
            " [  17   12   13    3   17   34  853    6    1    2]\n",
            " [   1   21   33    2    6    1    1  920    8   35]\n",
            " [  11   17   21   39    4   23   21    9  804   25]\n",
            " [   5   11    8    7   34   11    6   48   18  861]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['5' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59690, 10) \n",
            " [5 0 4 ... 5 6 2]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [31 31 35 30 25 31 30 41 34 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.388 s \n",
            "\n",
            "Accuracy rate for 85.690000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       980\n",
            "           1       0.87      0.96      0.91      1135\n",
            "           2       0.83      0.79      0.81      1032\n",
            "           3       0.89      0.81      0.85      1010\n",
            "           4       0.90      0.76      0.83       982\n",
            "           5       0.84      0.80      0.82       892\n",
            "           6       0.88      0.89      0.88       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.82      0.83      0.83       974\n",
            "           9       0.77      0.87      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 921    1    5    1    0    4   23    3   21    1]\n",
            " [   0 1094   29    2    0    3    0    0    7    0]\n",
            " [  26   56  817    9    4    7   20   36   54    3]\n",
            " [  12   13   25  815    1   59    3   18   44   20]\n",
            " [   2   13   17    0  747    1   26   11    8  157]\n",
            " [  20   23   12   51    8  716   18   15   14   15]\n",
            " [  18   12   13    1   21   34  850    6    1    2]\n",
            " [   1   19   32    1    4    0    1  923    9   38]\n",
            " [  14   21   22   32    3   18   19    8  810   27]\n",
            " [   7   11    8    4   38   12    4   33   16  876]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59680, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [31 32 36 31 25 32 30 42 37 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.754 s \n",
            "\n",
            "Accuracy rate for 85.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.91       980\n",
            "           1       0.88      0.96      0.92      1135\n",
            "           2       0.84      0.78      0.81      1032\n",
            "           3       0.86      0.84      0.85      1010\n",
            "           4       0.93      0.72      0.81       982\n",
            "           5       0.86      0.80      0.83       892\n",
            "           6       0.86      0.89      0.87       958\n",
            "           7       0.89      0.89      0.89      1028\n",
            "           8       0.81      0.83      0.82       974\n",
            "           9       0.75      0.89      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    1    7    1    0    3   29    4   28    0]\n",
            " [   0 1092   31    3    0    3    1    0    5    0]\n",
            " [  24   60  805   11    3    9   25   32   56    7]\n",
            " [  11    6   27  845    1   39    4   15   43   19]\n",
            " [   0   10   19    0  709    1   37   10   10  186]\n",
            " [  25   13   10   65    5  711   19    9   19   16]\n",
            " [  15   11   17    1   15   31  852    5    6    5]\n",
            " [   1   23   27    3    5    0    1  912   10   46]\n",
            " [  16   15   16   44    2   19   18    7  811   26]\n",
            " [   6   11    4    7   20    7    8   36   14  896]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59670, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [32 32 38 33 26 33 30 43 39 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.763 s \n",
            "\n",
            "Accuracy rate for 85.620000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91       980\n",
            "           1       0.89      0.96      0.92      1135\n",
            "           2       0.83      0.80      0.81      1032\n",
            "           3       0.90      0.81      0.85      1010\n",
            "           4       0.91      0.74      0.81       982\n",
            "           5       0.84      0.82      0.83       892\n",
            "           6       0.87      0.86      0.87       958\n",
            "           7       0.87      0.91      0.89      1028\n",
            "           8       0.81      0.85      0.83       974\n",
            "           9       0.76      0.88      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    1    9    2    0   10   26    4   29    0]\n",
            " [   0 1091   29    2    0    3    1    2    7    0]\n",
            " [  18   53  821   10    3    9   17   41   54    6]\n",
            " [  13    6   35  819    1   57    3   17   42   17]\n",
            " [   1    9   16    0  722    2   31   13    9  179]\n",
            " [  18   18   11   40    3  734   19    9   22   18]\n",
            " [  20   12   14    2   43   30  827    5    5    0]\n",
            " [   1   15   32    1    3    1    1  933   11   30]\n",
            " [  11   13   14   32    3   20   18   10  830   23]\n",
            " [   5   12    5    6   16   10    7   44   18  886]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59660, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [34 34 38 33 27 35 31 43 39 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.131 s \n",
            "\n",
            "Accuracy rate for 85.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91       980\n",
            "           1       0.89      0.96      0.92      1135\n",
            "           2       0.85      0.78      0.82      1032\n",
            "           3       0.88      0.82      0.85      1010\n",
            "           4       0.90      0.74      0.81       982\n",
            "           5       0.83      0.81      0.82       892\n",
            "           6       0.88      0.87      0.87       958\n",
            "           7       0.89      0.90      0.89      1028\n",
            "           8       0.81      0.85      0.83       974\n",
            "           9       0.75      0.89      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    0    4    2    0   13   30    3   30    0]\n",
            " [   0 1091   29    2    0    4    0    3    6    0]\n",
            " [  20   56  810   10    5   10   17   41   54    9]\n",
            " [  13    8   24  831    1   59    3   17   37   17]\n",
            " [   1   12   17    0  724    1   26    8    9  184]\n",
            " [  23   13   11   52    7  724   15    6   17   24]\n",
            " [  19   10   15    1   37   33  833    4    5    1]\n",
            " [   1   15   22    1    6    1    1  925   17   39]\n",
            " [  12   13   16   35    3   21   16    8  825   25]\n",
            " [   4   10    7    9   18    9    7   25   17  903]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [34 34 40 34 28 35 33 45 40 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.975 s \n",
            "\n",
            "Accuracy rate for 85.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       980\n",
            "           1       0.90      0.96      0.93      1135\n",
            "           2       0.84      0.81      0.83      1032\n",
            "           3       0.87      0.82      0.85      1010\n",
            "           4       0.94      0.73      0.82       982\n",
            "           5       0.84      0.82      0.83       892\n",
            "           6       0.86      0.90      0.88       958\n",
            "           7       0.89      0.89      0.89      1028\n",
            "           8       0.81      0.84      0.82       974\n",
            "           9       0.75      0.89      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    1    5    1    0   12   33    2   27    0]\n",
            " [   0 1091   29    3    0    3    1    1    7    0]\n",
            " [  18   48  835    8    3   13   18   33   48    8]\n",
            " [  13    5   30  826    0   47    4   20   44   21]\n",
            " [   1   11   14    0  721    2   37   14    6  176]\n",
            " [  15   13    7   59    4  728   20    8   19   19]\n",
            " [  14    9   11    1   18   32  863    3    6    1]\n",
            " [   1   15   27    0    3    1    1  920   14   46]\n",
            " [   9   13   26   39    3   17   18   11  816   22]\n",
            " [   3   11    7    8   19    8    8   26   21  898]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59640, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [34 35 41 34 29 37 34 45 41 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.594 s \n",
            "\n",
            "Accuracy rate for 86.130000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       980\n",
            "           1       0.90      0.96      0.93      1135\n",
            "           2       0.83      0.81      0.82      1032\n",
            "           3       0.90      0.82      0.86      1010\n",
            "           4       0.93      0.73      0.82       982\n",
            "           5       0.84      0.83      0.84       892\n",
            "           6       0.87      0.90      0.89       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.83      0.83      0.83       974\n",
            "           9       0.75      0.90      0.82      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    0    7    1    0   16   24    2   31    0]\n",
            " [   0 1085   32    3    0    3    1    4    7    0]\n",
            " [  17   46  832    7    5   12   19   41   46    7]\n",
            " [  12    6   29  828    1   49    4   20   37   24]\n",
            " [   2    8   17    0  715    1   39   12    5  183]\n",
            " [  14   12    7   44    7  744   18    8   16   22]\n",
            " [  16    9   15    1   15   27  864    4    7    0]\n",
            " [   1   14   30    0    5    1    1  928    7   41]\n",
            " [  11   15   23   34    2   22   19    8  808   32]\n",
            " [   5   10    6    5   20    6    5   29   13  910]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59630, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [36 36 41 35 29 37 35 45 43 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.195 s \n",
            "\n",
            "Accuracy rate for 86.140000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.90      0.96      0.93      1135\n",
            "           2       0.86      0.79      0.82      1032\n",
            "           3       0.91      0.82      0.86      1010\n",
            "           4       0.93      0.71      0.81       982\n",
            "           5       0.83      0.84      0.83       892\n",
            "           6       0.87      0.89      0.88       958\n",
            "           7       0.88      0.90      0.89      1028\n",
            "           8       0.82      0.84      0.83       974\n",
            "           9       0.73      0.91      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 920    1    2    1    0   14   19    2   20    1]\n",
            " [   0 1090   31    2    0    4    0    2    6    0]\n",
            " [  21   49  816    7    4   13   20   45   47   10]\n",
            " [  11    3   23  830    1   56    3   18   45   20]\n",
            " [   1    8   12    0  700    1   39   10    8  203]\n",
            " [  16   13    4   31    8  746   18    8   22   26]\n",
            " [  17    9   13    0   21   32  856    5    5    0]\n",
            " [   1   11   27    1    4    1    1  923   11   48]\n",
            " [   7   13   20   32    2   27   20    9  817   27]\n",
            " [   4   10    5    7    9    6    5   28   19  916]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59620, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [36 36 42 37 29 41 37 46 43 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.133 s \n",
            "\n",
            "Accuracy rate for 86.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       980\n",
            "           1       0.90      0.96      0.93      1135\n",
            "           2       0.84      0.81      0.82      1032\n",
            "           3       0.88      0.84      0.86      1010\n",
            "           4       0.94      0.71      0.81       982\n",
            "           5       0.84      0.85      0.84       892\n",
            "           6       0.87      0.90      0.89       958\n",
            "           7       0.89      0.90      0.89      1028\n",
            "           8       0.84      0.82      0.83       974\n",
            "           9       0.74      0.90      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    5    1    0   12   28    1   19    0]\n",
            " [   0 1085   32    2    0    6    1    2    7    0]\n",
            " [  20   49  835    9    3    8   18   35   50    5]\n",
            " [   9    4   25  847    0   54    2   17   33   19]\n",
            " [   1    7   15    1  701    1   35    8    5  208]\n",
            " [  12   11    7   46    7  756   19    8   10   16]\n",
            " [  15    8   15    3   17   30  866    3    1    0]\n",
            " [   1   13   29    2    5    0    0  924   10   44]\n",
            " [  12   15   22   40    3   25   20   11  797   29]\n",
            " [   4   11    8    9   11    7    7   28   15  909]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59610, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [36 36 43 39 30 42 39 47 44 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.305 s \n",
            "\n",
            "Accuracy rate for 86.310000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.91      0.96      0.93      1135\n",
            "           2       0.85      0.80      0.83      1032\n",
            "           3       0.90      0.82      0.86      1010\n",
            "           4       0.95      0.67      0.79       982\n",
            "           5       0.84      0.87      0.86       892\n",
            "           6       0.88      0.89      0.88       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.83      0.84      0.83       974\n",
            "           9       0.71      0.91      0.80      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    0    5    2    0   12   17    1   19    1]\n",
            " [   0 1086   30    1    0    6    1    2    9    0]\n",
            " [  22   35  829    9    2   13   18   42   49   13]\n",
            " [  12    7   25  829    0   61    2   14   38   22]\n",
            " [   1    7   11    1  662    1   37    9    7  246]\n",
            " [  14   11    7   23    1  780   20    5   13   18]\n",
            " [  18    8   14    1   20   33  855    4    4    1]\n",
            " [   1   13   24    1    1    1    0  928   12   47]\n",
            " [   8   12   20   43    2   15   20    9  816   29]\n",
            " [   6   11    5    7    8    8    5   19   17  923]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [37 38 44 40 30 45 40 48 44 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.143 s \n",
            "\n",
            "Accuracy rate for 86.950000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.92      0.96      0.94      1135\n",
            "           2       0.86      0.82      0.84      1032\n",
            "           3       0.89      0.82      0.86      1010\n",
            "           4       0.93      0.71      0.81       982\n",
            "           5       0.84      0.88      0.86       892\n",
            "           6       0.88      0.92      0.90       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.84      0.82      0.83       974\n",
            "           9       0.75      0.90      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    2    1    0   10   20    1   22    0]\n",
            " [   0 1085   31    4    0    2    2    2    9    0]\n",
            " [  21   33  850    9    5   14   14   38   41    7]\n",
            " [  11    2   23  831    1   68    2   19   38   15]\n",
            " [   1    7   12    1  700    1   42    7    7  204]\n",
            " [  15   11    4   21    6  782   20    6   12   15]\n",
            " [  15    4   11    2   20   21  880    1    4    0]\n",
            " [   1   12   31    4    5    0    1  932    5   37]\n",
            " [  10   12   21   50    3   20   18   10  800   30]\n",
            " [   4   10    6    7   11    8    6   28   18  911]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59590, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [37 39 45 42 32 45 40 48 46 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.152 s \n",
            "\n",
            "Accuracy rate for 86.850000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94       980\n",
            "           1       0.92      0.95      0.94      1135\n",
            "           2       0.85      0.82      0.84      1032\n",
            "           3       0.90      0.84      0.87      1010\n",
            "           4       0.94      0.68      0.79       982\n",
            "           5       0.86      0.88      0.87       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.89      0.90      0.90      1028\n",
            "           8       0.84      0.84      0.84       974\n",
            "           9       0.72      0.91      0.80      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    1    1    0    0   11   26    3   25    0]\n",
            " [   0 1081   37    4    0    3    0    2    8    0]\n",
            " [  14   33  851    8    2   15   18   38   43   10]\n",
            " [   9    4   24  850    1   48    2   19   35   18]\n",
            " [   1    8   13    1  668    2   35    7    7  240]\n",
            " [   9   10    6   20    6  787   17    5   12   20]\n",
            " [  15    7   10    2   22   23  872    4    2    1]\n",
            " [   1   13   36    1    1    1    1  925    7   42]\n",
            " [   5   10   18   49    2   16   20    8  817   29]\n",
            " [   4   10    6    6    7    9    5   25   16  921]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59580, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [39 39 46 43 35 46 41 49 46 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.410 s \n",
            "\n",
            "Accuracy rate for 87.030000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       980\n",
            "           1       0.92      0.95      0.93      1135\n",
            "           2       0.85      0.82      0.84      1032\n",
            "           3       0.90      0.82      0.86      1010\n",
            "           4       0.94      0.73      0.82       982\n",
            "           5       0.82      0.89      0.85       892\n",
            "           6       0.90      0.90      0.90       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.84      0.83      0.84       974\n",
            "           9       0.74      0.90      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 921    0    2    1    0   18   18    1   19    0]\n",
            " [   0 1078   37    5    0    4    0    1   10    0]\n",
            " [  17   34  851    7    2   17   14   35   44   11]\n",
            " [   8    5   24  829    2   73    2   14   34   19]\n",
            " [   1    7   16    1  721    3   26    6    8  193]\n",
            " [  11   10    6   16    5  792   15    6   12   19]\n",
            " [  16    6   10    1   21   31  866    2    3    2]\n",
            " [   1   12   31    3    4    1    0  922    8   46]\n",
            " [   5   11   23   48    2   22   18    9  811   25]\n",
            " [   5   11    6    6   10    8    4   28   19  912]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59570, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [39 40 48 44 36 48 43 50 46 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.895 s \n",
            "\n",
            "Accuracy rate for 87.380000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94       980\n",
            "           1       0.91      0.95      0.93      1135\n",
            "           2       0.86      0.83      0.85      1032\n",
            "           3       0.87      0.84      0.86      1010\n",
            "           4       0.93      0.75      0.83       982\n",
            "           5       0.85      0.88      0.86       892\n",
            "           6       0.89      0.91      0.90       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.85      0.83      0.84       974\n",
            "           9       0.77      0.90      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    1    3    0   15   18    1   18    0]\n",
            " [   0 1076   37    5    0    3    0    3   11    0]\n",
            " [  20   36  859    7    3   15   13   35   36    8]\n",
            " [  10    4   27  850    1   56    1   15   32   14]\n",
            " [   1    8   12    2  739    2   33    7    8  170]\n",
            " [  11    9    3   31    7  781   17    7   10   16]\n",
            " [  13    9    7    2   25   23  875    3    1    0]\n",
            " [   2   14   32    6    4    1    1  922    8   38]\n",
            " [   5   13   16   61    3   11   22   11  804   28]\n",
            " [   6   11    7    5   14   10    7   22   19  908]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59560, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [40 40 49 45 37 50 45 50 48 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.072 s \n",
            "\n",
            "Accuracy rate for 87.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.94       980\n",
            "           1       0.92      0.95      0.93      1135\n",
            "           2       0.86      0.83      0.84      1032\n",
            "           3       0.89      0.83      0.86      1010\n",
            "           4       0.94      0.75      0.83       982\n",
            "           5       0.82      0.90      0.86       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.85      0.82      0.84       974\n",
            "           9       0.77      0.91      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    0    1    2    0   24   22    1   15    0]\n",
            " [   0 1076   36    6    0    2    2    2   11    0]\n",
            " [  17   34  857    8    5   15   13   31   42   10]\n",
            " [   9    3   24  842    1   65    1   14   34   17]\n",
            " [   1    9   13    1  737    4   36    9    4  168]\n",
            " [  10    8    2   20    6  803   17    3    8   15]\n",
            " [  14    6    6    1   21   33  871    3    3    0]\n",
            " [   1   12   33    4    5    2    0  921    8   42]\n",
            " [   4   10   21   59    3   24   19    7  803   24]\n",
            " [   4   10    5    5    9   12    8   24   18  914]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [41 40 49 47 38 51 46 51 50 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.897 s \n",
            "\n",
            "Accuracy rate for 87.460000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.95      0.93      1135\n",
            "           2       0.85      0.82      0.84      1032\n",
            "           3       0.89      0.84      0.86      1010\n",
            "           4       0.93      0.76      0.84       982\n",
            "           5       0.84      0.89      0.86       892\n",
            "           6       0.89      0.90      0.89       958\n",
            "           7       0.90      0.90      0.90      1028\n",
            "           8       0.85      0.82      0.84       974\n",
            "           9       0.77      0.91      0.84      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    3    1    0   13   16    1   11    0]\n",
            " [   0 1077   39    4    0    4    0    3    8    0]\n",
            " [  21   31  846   12    3   14   16   35   47    7]\n",
            " [   9    3   23  845    1   55    2   14   42   16]\n",
            " [   1    8   16    2  746    3   29    8    6  163]\n",
            " [   8   11    3   25    7  792   15    6    8   17]\n",
            " [  15    8    6    1   27   33  863    3    2    0]\n",
            " [   1   13   36    3    2    1    0  921    7   44]\n",
            " [   8   13   14   53    2   22   24   11  803   24]\n",
            " [   5   11    5    6   12    9    8   22   13  918]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59540, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [42 40 49 47 41 51 47 52 52 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.160 s \n",
            "\n",
            "Accuracy rate for 87.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.95      0.93      1135\n",
            "           2       0.86      0.82      0.84      1032\n",
            "           3       0.89      0.84      0.87      1010\n",
            "           4       0.93      0.75      0.83       982\n",
            "           5       0.83      0.89      0.86       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.91      0.89      0.90      1028\n",
            "           8       0.85      0.83      0.84       974\n",
            "           9       0.76      0.91      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    0    2    0    0   15   18    1   12    0]\n",
            " [   0 1078   33    4    0    3    1    4   12    0]\n",
            " [  18   34  851   15    2   14   15   34   43    6]\n",
            " [   9    4   20  852    1   61    1   14   33   15]\n",
            " [   1    9   13    2  740    2   29    6    7  173]\n",
            " [  11   10    4   21    5  795   11    4    9   22]\n",
            " [  13    5    5    1   27   33  868    2    4    0]\n",
            " [   3   11   33    5    4    1    0  920    9   42]\n",
            " [   5   13   16   48    2   19   22    8  811   30]\n",
            " [   6   10    8    7   11   10    4   21   15  917]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59530, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [45 40 49 48 42 54 47 52 53 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.358 s \n",
            "\n",
            "Accuracy rate for 87.680000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.94      0.93      1135\n",
            "           2       0.86      0.83      0.84      1032\n",
            "           3       0.90      0.83      0.86      1010\n",
            "           4       0.93      0.76      0.83       982\n",
            "           5       0.83      0.90      0.86       892\n",
            "           6       0.90      0.91      0.91       958\n",
            "           7       0.90      0.89      0.90      1028\n",
            "           8       0.85      0.84      0.84       974\n",
            "           9       0.77      0.91      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    1    2    1    0   15   16    1   11    0]\n",
            " [   0 1069   37    5    0    3    0    4   17    0]\n",
            " [  21   31  856   11    5   13    8   37   41    9]\n",
            " [   9    2   22  838    2   64    2   15   41   15]\n",
            " [   1    8   13    1  745    1   27    7    8  171]\n",
            " [   9    9    3   20    7  802   13    6    6   17]\n",
            " [  12    7    8    1   25   29  870    2    4    0]\n",
            " [   2   12   34    2    5    1    0  919   11   42]\n",
            " [   6   10   17   43    3   24   21    8  815   27]\n",
            " [   6   10    7    7   13   12    5   19    9  921]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59520, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [45 42 51 49 43 54 47 54 55 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.135 s \n",
            "\n",
            "Accuracy rate for 87.650000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.95      0.94      1135\n",
            "           2       0.85      0.83      0.84      1032\n",
            "           3       0.89      0.83      0.86      1010\n",
            "           4       0.92      0.76      0.84       982\n",
            "           5       0.84      0.87      0.85       892\n",
            "           6       0.90      0.91      0.90       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.86      0.85      0.85       974\n",
            "           9       0.77      0.90      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    0    3    2    0   15   16    1   14    0]\n",
            " [   0 1080   35    3    0    5    1    1   10    0]\n",
            " [  16   34  861   11    6   17   12   31   36    8]\n",
            " [   8    4   27  842    1   58    1   16   33   20]\n",
            " [   1    7   14    1  750    3   26    7    9  164]\n",
            " [  11    9    3   33    9  777   15    5    8   22]\n",
            " [  14    6    9    3   26   25  868    3    4    0]\n",
            " [   2   12   36    2    3    1    1  921    7   43]\n",
            " [   7   12   17   46    3   19   16    9  824   21]\n",
            " [   6   11    7    6   15   10    7   23   11  913]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59510, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [46 42 52 51 43 56 49 55 56 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.775 s \n",
            "\n",
            "Accuracy rate for 88.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       980\n",
            "           1       0.92      0.95      0.94      1135\n",
            "           2       0.86      0.83      0.85      1032\n",
            "           3       0.88      0.85      0.86      1010\n",
            "           4       0.93      0.78      0.85       982\n",
            "           5       0.85      0.88      0.86       892\n",
            "           6       0.90      0.93      0.91       958\n",
            "           7       0.90      0.89      0.90      1028\n",
            "           8       0.85      0.83      0.84       974\n",
            "           9       0.79      0.90      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    1    1    1    0   15   18    2   11    0]\n",
            " [   0 1081   31    5    0    3    2    1   12    0]\n",
            " [  20   34  860   12    5   13   11   33   34   10]\n",
            " [   9    2   25  857    1   53    1   16   34   12]\n",
            " [   1    6   12    3  765    0   28    8   11  148]\n",
            " [  11   10    2   32    7  784   15    7    6   18]\n",
            " [  13    7    3    1   17   22  890    3    2    0]\n",
            " [   2   12   39    4    5    0    0  914   12   40]\n",
            " [   5   14   18   50    4   24   20    9  810   20]\n",
            " [   6   10    7    7   16    7    7   20   20  909]]\n",
            "--------------------------------\n",
            "final active learning accuracies [31.419999999999998, 37.04, 42.42, 58.76, 64.44, 65.27, 67.69, 70.04, 71.91, 73.61, 73.45, 75.73, 76.29, 78.66, 79.88, 79.59, 79.9, 81.11, 81.39999999999999, 81.71000000000001, 81.55, 82.54, 82.36, 82.41000000000001, 82.89999999999999, 83.2, 84.34, 84.52, 85.04, 85.46000000000001, 84.94, 85.69, 85.39999999999999, 85.61999999999999, 85.64, 85.97, 86.13, 86.14, 86.33999999999999, 86.31, 86.95, 86.85000000000001, 87.03, 87.38, 87.39, 87.46000000000001, 87.64, 87.68, 87.64999999999999, 88.01]\n",
            "saved Active-learning-experiment-20.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 21, using model = RfModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [18 34 22 28 27 29 21 19 30 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.189 s \n",
            "\n",
            "Accuracy rate for 83.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       980\n",
            "           1       0.80      0.95      0.86      1135\n",
            "           2       0.89      0.66      0.76      1032\n",
            "           3       0.84      0.86      0.85      1010\n",
            "           4       0.77      0.87      0.82       982\n",
            "           5       0.83      0.83      0.83       892\n",
            "           6       0.86      0.85      0.86       958\n",
            "           7       0.93      0.82      0.87      1028\n",
            "           8       0.73      0.78      0.75       974\n",
            "           9       0.81      0.78      0.80      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 882    0    5    7    0   32   23    1   30    0]\n",
            " [   0 1073    6    3    1    1    3    0   48    0]\n",
            " [  15   98  686   19   25    8   52   24  104    1]\n",
            " [   4   22   18  866    3   27    4    9   41   16]\n",
            " [   7   13    6    0  853    2   10    1   16   74]\n",
            " [  10   19    3   67   16  739   17    2   16    3]\n",
            " [  63    4    5    0   46   18  812    0   10    0]\n",
            " [   1   58   27    2   22    1    0  847   12   58]\n",
            " [  11   45    5   44   12   41   18    7  763   28]\n",
            " [  12   16    6   19  125   20    1   17    8  785]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [40 41 51 63 51 57 38 38 61 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.381 s \n",
            "\n",
            "Accuracy rate for 90.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.93      0.88      0.90      1032\n",
            "           3       0.89      0.92      0.91      1010\n",
            "           4       0.89      0.94      0.91       982\n",
            "           5       0.84      0.86      0.85       892\n",
            "           6       0.96      0.86      0.91       958\n",
            "           7       0.96      0.83      0.89      1028\n",
            "           8       0.89      0.87      0.88       974\n",
            "           9       0.83      0.91      0.87      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.91      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    1    0    1   13    5    0    3    1]\n",
            " [   0 1109    2    5    0    3    3    0   13    0]\n",
            " [  10   22  909   16   12   11    9   14   22    7]\n",
            " [   9    1   19  927    2   23    0    7   13    9]\n",
            " [   1    3    1    0  919    3    8    1    4   42]\n",
            " [  16   12    1   47    6  768   10    4   13   15]\n",
            " [  24    3    8    3   31   48  827    0   14    0]\n",
            " [   4   25   34    8   12    2    0  858    9   76]\n",
            " [   3   13    5   17   14   33    2    4  845   38]\n",
            " [   5    8    0   13   30   12    1    6   16  918]]\n",
            "--------------------------------\n",
            "final active learning accuracies [83.06, 90.36]\n",
            "saved Active-learning-experiment-21.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 22, using model = RfModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [13 12  9  7 12 15 10 12 21 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.904 s \n",
            "\n",
            "Accuracy rate for 71.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86       980\n",
            "           1       0.83      0.90      0.86      1135\n",
            "           2       0.96      0.62      0.75      1032\n",
            "           3       0.80      0.30      0.43      1010\n",
            "           4       0.67      0.61      0.64       982\n",
            "           5       0.52      0.79      0.63       892\n",
            "           6       0.85      0.83      0.84       958\n",
            "           7       0.89      0.74      0.81      1028\n",
            "           8       0.52      0.91      0.66       974\n",
            "           9       0.62      0.63      0.63      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.75      0.72      0.71     10000\n",
            "weighted avg       0.76      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 835    0    1    0    0   82   33    0   21    8]\n",
            " [   0 1022    3   29   18    6    2    0   55    0]\n",
            " [  56   96  643    9   15   17   46    6  137    7]\n",
            " [  12    8   18  301   17  423    6    7  206   12]\n",
            " [   2    7    0    0  598    0   27    3   71  274]\n",
            " [   8   16    1    1   30  706   13   10   87   20]\n",
            " [  23   25    2    0   13   66  791    0   36    2]\n",
            " [   3   46    4   29   34    1    0  761   97   53]\n",
            " [  17    9    0    3    4   39    2    3  886   11]\n",
            " [   9    6    1    5  166   13    6   61  105  637]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 19 18 29 38 29 14 28 27 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.401 s \n",
            "\n",
            "Accuracy rate for 83.470000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       980\n",
            "           1       0.86      0.99      0.92      1135\n",
            "           2       0.97      0.69      0.81      1032\n",
            "           3       0.80      0.83      0.81      1010\n",
            "           4       0.69      0.95      0.80       982\n",
            "           5       0.71      0.79      0.75       892\n",
            "           6       0.95      0.76      0.84       958\n",
            "           7       0.88      0.92      0.90      1028\n",
            "           8       0.86      0.76      0.81       974\n",
            "           9       0.90      0.69      0.78      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.85      0.83      0.83     10000\n",
            "weighted avg       0.85      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    0    2    0   27    5    1    1    0]\n",
            " [   0 1118    1    2    0    5    2    1    6    0]\n",
            " [  49   69  715   50   44   15   14   43   30    3]\n",
            " [  17    4    8  834    7   89    4   22   22    3]\n",
            " [   4    6    0    0  935    1    4    6    3   23]\n",
            " [  27   11    0   78   29  701    7    3   24   12]\n",
            " [  44   11    1    0   74   96  724    0    7    1]\n",
            " [   1   28   10    5   19    1    0  941   13   10]\n",
            " [  11   41    2   68   28   41    2   12  743   26]\n",
            " [  11   10    1    7  221   12    0   44   10  693]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [27 22 33 47 49 44 30 33 46 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.568 s \n",
            "\n",
            "Accuracy rate for 89.210000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.94       980\n",
            "           1       0.93      0.99      0.96      1135\n",
            "           2       0.96      0.86      0.91      1032\n",
            "           3       0.87      0.88      0.87      1010\n",
            "           4       0.77      0.95      0.85       982\n",
            "           5       0.83      0.86      0.85       892\n",
            "           6       0.93      0.88      0.90       958\n",
            "           7       0.94      0.88      0.91      1028\n",
            "           8       0.88      0.83      0.86       974\n",
            "           9       0.91      0.82      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.90      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    2    1    4   17    9    1    3    0]\n",
            " [   0 1118    2    4    1    1    5    0    4    0]\n",
            " [  26    7  886   33   27    1   14   18   19    1]\n",
            " [  12    0   10  887    3   65    1   13   12    7]\n",
            " [   1    2    1    0  933    0    8    1    7   29]\n",
            " [  14   12    0   32   20  771   17    1   19    6]\n",
            " [  19    4    3    1   47   32  844    0    8    0]\n",
            " [   1   31   17    7   24    2    0  902   26   18]\n",
            " [  10   17    4   45   19   30   11    6  812   20]\n",
            " [   6    8    1   10  126   10    2   13    8  825]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [33 26 50 64 56 59 43 46 60 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.686 s \n",
            "\n",
            "Accuracy rate for 91.490000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95       980\n",
            "           1       0.94      0.99      0.97      1135\n",
            "           2       0.95      0.88      0.91      1032\n",
            "           3       0.91      0.87      0.89      1010\n",
            "           4       0.91      0.88      0.90       982\n",
            "           5       0.87      0.88      0.87       892\n",
            "           6       0.95      0.94      0.94       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.92      0.89      0.90       974\n",
            "           9       0.85      0.90      0.87      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.92      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    0    1    0    0    4    3    1    3    0]\n",
            " [   0 1121    2    3    1    1    4    0    3    0]\n",
            " [  19   10  910   19   13    1   13   17   27    3]\n",
            " [  14    1   12  877    0   66    2   14   13   11]\n",
            " [   2    0    6    0  864    1   10    4    7   88]\n",
            " [  24   10    0   39    5  782   13    2    9    8]\n",
            " [  22    2    2    1    5   17  904    0    5    0]\n",
            " [   3   17   21    1    6    1    0  951    5   23]\n",
            " [   5   19    4   17    9   16    4    9  865   26]\n",
            " [   6    7    3   10   42    7    3   22    2  907]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.8, 83.47, 89.21, 91.49000000000001]\n",
            "saved Active-learning-experiment-22.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 23, using model = RfModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [6 8 2 4 7 3 7 2 7 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.420 s \n",
            "\n",
            "Accuracy rate for 54.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.95      0.82       980\n",
            "           1       0.46      0.99      0.63      1135\n",
            "           2       0.74      0.08      0.15      1032\n",
            "           3       0.77      0.45      0.57      1010\n",
            "           4       0.46      0.86      0.60       982\n",
            "           5       0.77      0.20      0.32       892\n",
            "           6       0.74      0.81      0.78       958\n",
            "           7       0.83      0.19      0.31      1028\n",
            "           8       0.42      0.73      0.53       974\n",
            "           9       0.19      0.09      0.12      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.61      0.54      0.48     10000\n",
            "weighted avg       0.61      0.54      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    4    1    1    0   18   20    0    4    0]\n",
            " [   0 1127    0    1    0    0    2    0    5    0]\n",
            " [  72  411   86   30  166    1   96    0  154   16]\n",
            " [  79  179    1  451   13    5   27    3  248    4]\n",
            " [   2   52    3    0  848    3   28    2   26   18]\n",
            " [ 126  149    3   56   53  179   61    4  256    5]\n",
            " [  26   94    9    8   21    4  780    0   10    6]\n",
            " [  41  215    8    0   65    5    8  197  143  346]\n",
            " [  13  164    5   28   15   15   18    2  714    0]\n",
            " [  16   59    0   10  645    2    8   29  148   92]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['8' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [8 0 4 ... 8 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  8 10 13  9 10  9 12 10 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.470 s \n",
            "\n",
            "Accuracy rate for 71.720000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89       980\n",
            "           1       0.73      0.99      0.84      1135\n",
            "           2       0.86      0.57      0.68      1032\n",
            "           3       0.58      0.82      0.68      1010\n",
            "           4       0.61      0.58      0.60       982\n",
            "           5       0.70      0.47      0.56       892\n",
            "           6       0.94      0.78      0.85       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.71      0.67      0.69       974\n",
            "           9       0.49      0.57      0.53      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.71      0.71     10000\n",
            "weighted avg       0.73      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 858    2   11   13    0   66   11   11    5    3]\n",
            " [   0 1118    0    8    0    1    1    0    6    1]\n",
            " [  26  159  586  117   28    9   10   34   48   15]\n",
            " [  10   27   10  828    4   29    0   10   80   12]\n",
            " [   0   11   14   15  574    4    5   17    5  337]\n",
            " [  22   62    3  244   12  416   16   23   72   22]\n",
            " [  11   31   18   59   17   36  745    1    8   32]\n",
            " [   1   44   30    4   16    6    0  818    8  101]\n",
            " [   3   71    4  123    8   21    5   15  651   73]\n",
            " [   9   10    7   15  288    6    1   63   32  578]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '9' ... '9' '6' '9']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 9 ... 9 6 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [12  9 15 21 12 16 13 20 17 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.572 s \n",
            "\n",
            "Accuracy rate for 78.440000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       980\n",
            "           1       0.85      0.97      0.90      1135\n",
            "           2       0.95      0.68      0.79      1032\n",
            "           3       0.62      0.90      0.73      1010\n",
            "           4       0.62      0.68      0.65       982\n",
            "           5       0.85      0.65      0.74       892\n",
            "           6       0.93      0.85      0.89       958\n",
            "           7       0.75      0.93      0.83      1028\n",
            "           8       0.85      0.70      0.77       974\n",
            "           9       0.67      0.50      0.57      1009\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.80      0.78      0.78     10000\n",
            "weighted avg       0.80      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    0    4    7    0   16   18    6    2    0]\n",
            " [   0 1097    1   12    0    1    2   15    6    1]\n",
            " [  28   57  701  110   36    5   16   51   26    2]\n",
            " [   3   15    9  912    1   18    2   26   22    2]\n",
            " [   1    7    2   15  665    2    7   64   15  204]\n",
            " [   8   27    1  209   14  580   13   21   15    4]\n",
            " [  19   21    3   28   18   30  818    9    7    5]\n",
            " [   1   22   13    7   10    0    0  955    6   14]\n",
            " [   7   32    2  152    5   26    6   38  685   21]\n",
            " [  12   12    0   29  331    2    2   96   21  504]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [16 11 23 23 19 25 15 21 19 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.117 s \n",
            "\n",
            "Accuracy rate for 83.620000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93       980\n",
            "           1       0.88      0.98      0.93      1135\n",
            "           2       0.91      0.78      0.84      1032\n",
            "           3       0.80      0.85      0.82      1010\n",
            "           4       0.80      0.70      0.74       982\n",
            "           5       0.78      0.82      0.80       892\n",
            "           6       0.96      0.85      0.90       958\n",
            "           7       0.86      0.90      0.88      1028\n",
            "           8       0.91      0.68      0.78       974\n",
            "           9       0.65      0.82      0.72      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    1    0    0   16    3    3    2    9]\n",
            " [   0 1116    1    2    0    3    1    8    4    0]\n",
            " [  35   34  804   46   35    9    6   41   17    5]\n",
            " [   5   13   20  855    2   63    3   13   19   17]\n",
            " [   3    6    4    2  686    0    1   16    5  259]\n",
            " [  14   24    6   44    8  735    6   15    9   31]\n",
            " [  35   10    9    3   22   38  810    4    2   25]\n",
            " [   0   22   19    5   10    2    0  921    2   47]\n",
            " [  15   28   16  108    5   57   12   13  663   57]\n",
            " [   7   16    1    7   94   15    1   35    7  826]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 13 33 30 22 33 21 22 29 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.383 s \n",
            "\n",
            "Accuracy rate for 86.510000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94       980\n",
            "           1       0.90      0.98      0.94      1135\n",
            "           2       0.86      0.84      0.85      1032\n",
            "           3       0.87      0.83      0.85      1010\n",
            "           4       0.87      0.74      0.80       982\n",
            "           5       0.79      0.88      0.83       892\n",
            "           6       0.95      0.90      0.92       958\n",
            "           7       0.91      0.86      0.89      1028\n",
            "           8       0.88      0.81      0.84       974\n",
            "           9       0.71      0.85      0.77      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 920    0    5    1    0   34    7    2    6    5]\n",
            " [   0 1113    3    3    0    1    3    0   12    0]\n",
            " [   7   41  866   28   12    8   11   26   30    3]\n",
            " [   4    6   21  840    1   85    4   13   29    7]\n",
            " [   0    4   14    2  730    1    4    9    5  213]\n",
            " [   8   14   12   31    3  783    8    6   14   13]\n",
            " [  20    3   22    2    8   29  866    0    4    4]\n",
            " [   0   25   30   14    7    4    1  887    4   56]\n",
            " [   8   13   23   38    4   33   11    8  789   47]\n",
            " [   3   12    7   11   77   16    1   22    3  857]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '9' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 9 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [17 14 36 40 33 38 25 29 33 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.265 s \n",
            "\n",
            "Accuracy rate for 88.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       980\n",
            "           1       0.93      0.98      0.95      1135\n",
            "           2       0.89      0.78      0.83      1032\n",
            "           3       0.81      0.89      0.85      1010\n",
            "           4       0.83      0.92      0.87       982\n",
            "           5       0.85      0.87      0.86       892\n",
            "           6       0.94      0.93      0.94       958\n",
            "           7       0.89      0.90      0.90      1028\n",
            "           8       0.91      0.81      0.86       974\n",
            "           9       0.85      0.82      0.84      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    0    6    2    1   16   10    2    4    9]\n",
            " [   0 1107    2    6    2    0    4    2   11    1]\n",
            " [   6   31  808   88   17    5   12   44   18    3]\n",
            " [   1    1   15  898    2   52    4   15   18    4]\n",
            " [   0    2   11    1  904    1    4   10    2   47]\n",
            " [   7   10   11   39    9  779   10    3   12   12]\n",
            " [  12    3   10    1   20   15  892    0    4    1]\n",
            " [   0   20   24    5    8    1    0  928    4   38]\n",
            " [   5    5   18   59   19   26    9   14  792   27]\n",
            " [   3    9    6   10  105   17    2   27    5  825]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [20 16 43 45 38 42 28 31 49 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.361 s \n",
            "\n",
            "Accuracy rate for 89.850000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       980\n",
            "           1       0.94      0.97      0.96      1135\n",
            "           2       0.92      0.86      0.89      1032\n",
            "           3       0.90      0.87      0.89      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.84      0.86      0.85       892\n",
            "           6       0.94      0.91      0.93       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.84      0.93      0.88       974\n",
            "           9       0.87      0.82      0.84      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    5    1    2   27    7    2    6    2]\n",
            " [   0 1105    2    3    0    1    5    1   18    0]\n",
            " [   3   29  892   20   11    6   10   32   26    3]\n",
            " [   3    1   15  880    2   68    2   13   22    4]\n",
            " [   1    2    6    0  889    1    5    5   13   60]\n",
            " [   6   10    6   40    9  767   13    2   30    9]\n",
            " [  14    4    2    2   31   18  871    0   15    1]\n",
            " [   0   15   29    5    7    5    0  922   10   35]\n",
            " [   5    2    5   15   13    6    7    7  902   12]\n",
            " [   3    9    7    8   84   12    2   27   28  829]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [23 16 45 51 42 49 32 38 53 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.150 s \n",
            "\n",
            "Accuracy rate for 91.100000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.95      0.87      0.90      1032\n",
            "           3       0.89      0.88      0.89      1010\n",
            "           4       0.91      0.89      0.90       982\n",
            "           5       0.85      0.90      0.87       892\n",
            "           6       0.94      0.92      0.93       958\n",
            "           7       0.92      0.91      0.91      1028\n",
            "           8       0.90      0.88      0.89       974\n",
            "           9       0.84      0.91      0.87      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    3    1    0   19    6    1    5    2]\n",
            " [   0 1108    2    2    1    0    4    1   17    0]\n",
            " [   6   16  895   39   13    7   16   27   12    1]\n",
            " [   4    0   11  890    2   62    1   13   21    6]\n",
            " [   1    0    3    1  875    0    8    7    4   83]\n",
            " [   9    3    4   20    7  807   11    4   17   10]\n",
            " [  12    3    0    1   24   28  882    0    8    0]\n",
            " [   1   10   24    3    7    3    0  937    2   41]\n",
            " [   6    1    3   36   10   15    6    9  853   35]\n",
            " [   3    8    1    6   23   12    1   24   11  920]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [26 16 46 61 51 53 34 47 59 57] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.694 s \n",
            "\n",
            "Accuracy rate for 91.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.98      0.85      0.91      1032\n",
            "           3       0.84      0.94      0.89      1010\n",
            "           4       0.89      0.93      0.91       982\n",
            "           5       0.91      0.84      0.88       892\n",
            "           6       0.95      0.91      0.93       958\n",
            "           7       0.90      0.95      0.92      1028\n",
            "           8       0.89      0.89      0.89       974\n",
            "           9       0.88      0.89      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.91      0.91     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    0    3    1    9    3    2    4    1]\n",
            " [   0 1094    2    5    1    1    5    2   25    0]\n",
            " [   9   11  882   43   16    6   11   37   14    3]\n",
            " [   3    0    3  950    0   15    3   10   21    5]\n",
            " [   2    0    2    1  915    0    6    8    6   42]\n",
            " [  10    1    4   74    9  751    9    8   18    8]\n",
            " [  16    3    1    4   28   20  872    1   12    1]\n",
            " [   0    4    9    8    6    0    0  973    1   27]\n",
            " [   4    2    0   33   11   14    4   11  865   30]\n",
            " [   4    6    0   11   38    7    1   32   10  900]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [29 17 49 64 57 65 38 51 70 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.481 s \n",
            "\n",
            "Accuracy rate for 91.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.97      0.96      0.97      1135\n",
            "           2       0.96      0.86      0.91      1032\n",
            "           3       0.91      0.90      0.91      1010\n",
            "           4       0.89      0.93      0.91       982\n",
            "           5       0.89      0.88      0.89       892\n",
            "           6       0.96      0.90      0.93       958\n",
            "           7       0.90      0.95      0.92      1028\n",
            "           8       0.84      0.93      0.88       974\n",
            "           9       0.90      0.89      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    0    0    1    0   15    1    3    9    1]\n",
            " [   0 1089    0    6    1    1    4    3   31    0]\n",
            " [   8   14  883   28   13    6   13   28   35    4]\n",
            " [   5    0    8  911    1   31    2   14   33    5]\n",
            " [   2    0    5    0  914    0    3   15    9   34]\n",
            " [  10    2    2   41   10  788   10    6   15    8]\n",
            " [  13    3    1    1   32   24  863    0   21    0]\n",
            " [   1    5   15    1    3    1    0  974    6   22]\n",
            " [   5    1    1    3   11   13    4    9  905   22]\n",
            " [   3    6    1    7   41    6    1   26   17  901]]\n",
            "--------------------------------\n",
            "final active learning accuracies [54.059999999999995, 71.72, 78.44, 83.62, 86.50999999999999, 88.63, 89.85, 91.10000000000001, 91.59, 91.78]\n",
            "saved Active-learning-experiment-23.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 24, using model = RfModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 3 2 1 4 2 4 3 1 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.653 s \n",
            "\n",
            "Accuracy rate for 51.750000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.67      0.72       980\n",
            "           1       0.40      0.99      0.57      1135\n",
            "           2       0.56      0.29      0.38      1032\n",
            "           3       0.72      0.16      0.27      1010\n",
            "           4       0.46      0.88      0.61       982\n",
            "           5       0.36      0.31      0.33       892\n",
            "           6       0.62      0.79      0.70       958\n",
            "           7       0.81      0.60      0.69      1028\n",
            "           8       0.59      0.14      0.22       974\n",
            "           9       0.40      0.28      0.33      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.57      0.51      0.48     10000\n",
            "weighted avg       0.57      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 654   24   12    3    9   62  192   13    8    3]\n",
            " [   0 1125    4    0    1    0    2    1    0    2]\n",
            " [  64  353  298   36   91    2   48   33    2  105]\n",
            " [  44  265  152  166   14  270   23   12   18   46]\n",
            " [   0   70    1    0  867    0   22    0    1   21]\n",
            " [  62  265   12   11   90  276   73   19   48   36]\n",
            " [   7   99    5    1   83    0  756    0    7    0]\n",
            " [   0  200    1    0  100    0    4  617    0  106]\n",
            " [  11  349   45   15   54  155   78   24  135  108]\n",
            " [   2   81    3    0  569    6   15   44    8  281]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['1' '0' '4' ... '5' '6' '6']\n",
            "probabilities: (59975, 10) \n",
            " [1 0 4 ... 5 6 6]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 3 3 5 4 6 7 6 5 7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.772 s \n",
            "\n",
            "Accuracy rate for 66.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.68      0.78       980\n",
            "           1       0.75      0.97      0.85      1135\n",
            "           2       0.87      0.38      0.53      1032\n",
            "           3       0.54      0.58      0.56      1010\n",
            "           4       0.81      0.57      0.67       982\n",
            "           5       0.55      0.62      0.58       892\n",
            "           6       0.56      0.92      0.70       958\n",
            "           7       0.73      0.72      0.73      1028\n",
            "           8       0.84      0.46      0.59       974\n",
            "           9       0.46      0.69      0.55      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.71      0.66      0.65     10000\n",
            "weighted avg       0.71      0.66      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 668    4    1   23    0   29  234   17    0    4]\n",
            " [   0 1098    8    6    0    5    6    0    0   12]\n",
            " [  11  104  393  238   14    3  100    7   23  139]\n",
            " [   9   19   34  587    1  207   21   14   47   71]\n",
            " [   0   27    0   12  556   43  103   39    5  197]\n",
            " [  21   60    2   68    9  554  104   52    2   20]\n",
            " [   9   22    4   15   20    3  882    0    0    3]\n",
            " [   0   56    0    9    1    5    4  743    2  208]\n",
            " [   3   59   11  112    4   95   91   12  444  143]\n",
            " [   2    7    0   11   82   60   19  131    5  692]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '5' ... '5' '6' '5']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 5 ... 5 6 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 4  4  8  8 11 10  7  8  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.471 s \n",
            "\n",
            "Accuracy rate for 70.770000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.67      0.78       980\n",
            "           1       0.83      0.96      0.89      1135\n",
            "           2       0.72      0.75      0.73      1032\n",
            "           3       0.72      0.58      0.64      1010\n",
            "           4       0.57      0.92      0.70       982\n",
            "           5       0.53      0.78      0.63       892\n",
            "           6       0.70      0.67      0.68       958\n",
            "           7       0.82      0.72      0.77      1028\n",
            "           8       0.94      0.53      0.68       974\n",
            "           9       0.57      0.48      0.52      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.73      0.70      0.70     10000\n",
            "weighted avg       0.74      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 661    1   13   11    4   85  194    8    0    3]\n",
            " [   0 1089   16    9    1   14    1    5    0    0]\n",
            " [  10   60  772   51   44   10   10   16    5   54]\n",
            " [  11    7   88  583    5  251    3   11   13   38]\n",
            " [   0    6    2    1  899   21    9    5    2   37]\n",
            " [  13   23   13   53   57  693   21   11    5    3]\n",
            " [  11   13   65    6  159   63  638    1    0    2]\n",
            " [   0   47   10   20   37   27    0  745    1  141]\n",
            " [   2   51   89   72   23   94   40    9  512   82]\n",
            " [   4    8    3    8  346   56    0   95    4  485]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59925, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6  5 12 11 13 13 10  8  9 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.447 s \n",
            "\n",
            "Accuracy rate for 77.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85       980\n",
            "           1       0.85      0.96      0.90      1135\n",
            "           2       0.73      0.81      0.76      1032\n",
            "           3       0.74      0.78      0.76      1010\n",
            "           4       0.70      0.90      0.79       982\n",
            "           5       0.63      0.80      0.71       892\n",
            "           6       0.84      0.76      0.80       958\n",
            "           7       0.91      0.66      0.77      1028\n",
            "           8       0.95      0.52      0.67       974\n",
            "           9       0.65      0.72      0.68      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.79      0.77      0.77     10000\n",
            "weighted avg       0.79      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 767    1   17   16   12   95   59    9    1    3]\n",
            " [   0 1089   18   24    0    3    1    0    0    0]\n",
            " [  14   57  833   46   29    8    6   12    4   23]\n",
            " [   9   12   56  789    3   89    1    5   13   33]\n",
            " [   0    4    7    1  888   21   16    2    1   42]\n",
            " [  14   16   20   52   33  716   26    3    5    7]\n",
            " [  10   17   55    4   99   42  730    0    0    1]\n",
            " [   0   38   34   32   26   21    0  680    0  197]\n",
            " [   3   42   95   89   14   98   30    5  507   91]\n",
            " [   6    8   11   11  168   43    1   30    1  730]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '4' '5']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 5 4 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [10  5 12 15 15 15 11 11 17 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.828 s \n",
            "\n",
            "Accuracy rate for 81.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       980\n",
            "           1       0.89      0.96      0.92      1135\n",
            "           2       0.88      0.68      0.77      1032\n",
            "           3       0.76      0.79      0.78      1010\n",
            "           4       0.68      0.94      0.79       982\n",
            "           5       0.77      0.79      0.78       892\n",
            "           6       0.88      0.79      0.83       958\n",
            "           7       0.91      0.79      0.85      1028\n",
            "           8       0.73      0.80      0.76       974\n",
            "           9       0.80      0.66      0.73      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 888    0    2    1    3   18   43    1   24    0]\n",
            " [   0 1087    9   23    1    2    2    0   11    0]\n",
            " [  36   46  700   53   40    6   16   15  102   18]\n",
            " [   3    8   23  802    5   80    0    8   73    8]\n",
            " [   2    0    3    1  919    9   13    3    8   24]\n",
            " [  12   15   11   51   32  705   17    4   37    8]\n",
            " [  38    7   13    3  110   13  759    0   14    1]\n",
            " [   4   37   19   34   26   11    0  817   11   69]\n",
            " [   2    9   15   73   11   30   11   10  777   36]\n",
            " [  10    8    2   15  210   41    0   41   13  669]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [11  7 15 16 17 19 13 13 18 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.581 s \n",
            "\n",
            "Accuracy rate for 82.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       980\n",
            "           1       0.88      0.99      0.93      1135\n",
            "           2       0.87      0.75      0.81      1032\n",
            "           3       0.87      0.74      0.80      1010\n",
            "           4       0.80      0.90      0.85       982\n",
            "           5       0.74      0.85      0.79       892\n",
            "           6       0.90      0.84      0.87       958\n",
            "           7       0.94      0.66      0.78      1028\n",
            "           8       0.85      0.76      0.80       974\n",
            "           9       0.64      0.86      0.73      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 912    1    1    1    1   25   24    2   11    2]\n",
            " [   0 1120    1    7    0    2    2    0    0    3]\n",
            " [  13   54  779   32   34    9   10    9   60   32]\n",
            " [   4    3   23  747    4  157    0    3   18   51]\n",
            " [   1    5    4    0  887    2   18    0    7   58]\n",
            " [   7   15   12   16   21  755   14   10   18   24]\n",
            " [  32   10   20    2   49   28  808    0    7    2]\n",
            " [   1   34   20    8   13    5    0  683   10  254]\n",
            " [   1   31   28   43   12   33   16    5  742   63]\n",
            " [   9    7    3    5   92    9    3   12    4  865]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [13  8 17 19 17 23 16 16 22 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.180 s \n",
            "\n",
            "Accuracy rate for 86.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94       980\n",
            "           1       0.90      0.99      0.94      1135\n",
            "           2       0.89      0.77      0.82      1032\n",
            "           3       0.87      0.80      0.83      1010\n",
            "           4       0.86      0.87      0.86       982\n",
            "           5       0.75      0.87      0.81       892\n",
            "           6       0.91      0.89      0.90       958\n",
            "           7       0.94      0.80      0.86      1028\n",
            "           8       0.81      0.80      0.81       974\n",
            "           9       0.75      0.89      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    1    1    0    0   27   24    5    5    2]\n",
            " [   0 1122    0    6    0    4    2    0    1    0]\n",
            " [  12   48  790   24   24   19   13   18   58   26]\n",
            " [   6    4   17  803    1  115    0    7   20   37]\n",
            " [   1    6    4    3  851    0   17    0   19   81]\n",
            " [   6   10    8   17   18  775   13    8   19   18]\n",
            " [  12    4   12    0   30   39  852    3    6    0]\n",
            " [   2   26   22   13    7    2    0  819   37  100]\n",
            " [   0   22   23   47    7   42   11    3  783   36]\n",
            " [  10    5    7    5   54    9    1    7   13  898]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [14  8 24 22 20 25 16 22 23 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.201 s \n",
            "\n",
            "Accuracy rate for 88.090000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       980\n",
            "           1       0.94      0.95      0.95      1135\n",
            "           2       0.82      0.89      0.85      1032\n",
            "           3       0.87      0.85      0.86      1010\n",
            "           4       0.89      0.86      0.87       982\n",
            "           5       0.82      0.84      0.83       892\n",
            "           6       0.95      0.87      0.91       958\n",
            "           7       0.87      0.91      0.89      1028\n",
            "           8       0.89      0.81      0.85       974\n",
            "           9       0.82      0.87      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    1    7    0    0   22    8    6    4    0]\n",
            " [   0 1083    1    7    1    3    2   38    0    0]\n",
            " [   5   22  918   17    9    6    4   27   19    5]\n",
            " [   4    2   27  856    0   67    0    9   21   24]\n",
            " [   0    2   29    0  840    0    9    5   16   81]\n",
            " [   8    5   12   50    9  749   10   13   17   19]\n",
            " [  19    3   39    3   25   33  830    3    3    0]\n",
            " [   0   13   38    2    5    0    0  936    8   26]\n",
            " [   0   18   22   42   15   31    9    8  792   37]\n",
            " [   5    4   25   10   44    6    2   30   10  873]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [16  8 27 24 24 27 16 25 32 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.974 s \n",
            "\n",
            "Accuracy rate for 88.420000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       980\n",
            "           1       0.97      0.96      0.96      1135\n",
            "           2       0.87      0.89      0.88      1032\n",
            "           3       0.88      0.86      0.87      1010\n",
            "           4       0.81      0.91      0.86       982\n",
            "           5       0.85      0.80      0.82       892\n",
            "           6       0.95      0.82      0.88       958\n",
            "           7       0.88      0.93      0.90      1028\n",
            "           8       0.81      0.89      0.85       974\n",
            "           9       0.87      0.80      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    6    0    1   11   12    5    3    0]\n",
            " [   0 1085    5    6    1    2    2   26    8    0]\n",
            " [   7    3  920    8   13   13    4   30   31    3]\n",
            " [   4    0   27  872    1   39    0   13   34   20]\n",
            " [   0    1    7    0  894    2    7    3   19   49]\n",
            " [  10    5   10   70   13  712    7   10   44   11]\n",
            " [  27    4   31    0   43   28  786    3   36    0]\n",
            " [   1   10   19    1    9    3    0  951   12   22]\n",
            " [   1    2   16   24    9   19    7    7  871   18]\n",
            " [   6    4   14    5  114    9    0   34   14  809]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59775, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [17 10 28 25 26 29 19 28 35 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.814 s \n",
            "\n",
            "Accuracy rate for 88.950000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95       980\n",
            "           1       0.95      0.98      0.97      1135\n",
            "           2       0.91      0.84      0.87      1032\n",
            "           3       0.90      0.84      0.87      1010\n",
            "           4       0.85      0.90      0.87       982\n",
            "           5       0.88      0.80      0.83       892\n",
            "           6       0.94      0.87      0.91       958\n",
            "           7       0.90      0.91      0.91      1028\n",
            "           8       0.79      0.90      0.84       974\n",
            "           9       0.84      0.88      0.86      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    3    0    3    8   24    3   14    1]\n",
            " [   0 1114    2    5    0    2    0    0   12    0]\n",
            " [  10   22  872    6   21    6    6   33   48    8]\n",
            " [   4    1   33  847    2   53    0   13   37   20]\n",
            " [   0    2    3    1  888    2    5    3   21   57]\n",
            " [   9   10    7   52   23  710   10   10   49   12]\n",
            " [  19    3   12    1   45   11  837    2   28    0]\n",
            " [   0   15   15    1    8    0    0  939   12   38]\n",
            " [   3    1   10   16    4   12    7   10  880   31]\n",
            " [   3    4    5   11   55    6    0   26   15  884]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [19 10 30 29 29 32 23 30 35 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.611 s \n",
            "\n",
            "Accuracy rate for 89.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95       980\n",
            "           1       0.94      0.98      0.96      1135\n",
            "           2       0.91      0.85      0.88      1032\n",
            "           3       0.88      0.84      0.86      1010\n",
            "           4       0.89      0.88      0.88       982\n",
            "           5       0.81      0.80      0.81       892\n",
            "           6       0.95      0.92      0.93       958\n",
            "           7       0.91      0.91      0.91      1028\n",
            "           8       0.86      0.86      0.86       974\n",
            "           9       0.80      0.91      0.85      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    0    4    0    3   26   19    2    3    0]\n",
            " [   0 1107    2    5    0    4    3    0   14    0]\n",
            " [  10   30  876    9   15    9    6   37   33    7]\n",
            " [   6    2   25  849    1   79    1    7   23   17]\n",
            " [   1    2    5    0  863    0    4    3   12   92]\n",
            " [  11   11    8   69   11  716   11    8   27   20]\n",
            " [  10    4    8    1   28   16  877    0   10    4]\n",
            " [   0   13   21    2    8    0    0  934    8   42]\n",
            " [   4    3   10   16    6   23    4   16  842   50]\n",
            " [   4    5    6   10   38    7    0   20    5  914]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59725, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [22 10 30 32 30 40 29 32 37 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.970 s \n",
            "\n",
            "Accuracy rate for 89.880000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       980\n",
            "           1       0.95      0.96      0.96      1135\n",
            "           2       0.92      0.85      0.88      1032\n",
            "           3       0.92      0.86      0.88      1010\n",
            "           4       0.91      0.87      0.89       982\n",
            "           5       0.81      0.89      0.85       892\n",
            "           6       0.94      0.93      0.93       958\n",
            "           7       0.89      0.91      0.90      1028\n",
            "           8       0.85      0.86      0.85       974\n",
            "           9       0.84      0.88      0.86      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    3    0    2   14   14    1    2    0]\n",
            " [   0 1093    1    5    0    3    3    4   26    0]\n",
            " [   8   23  876    8   13   16    7   33   44    4]\n",
            " [   6    0   22  865    1   76    1    8   25    6]\n",
            " [   1    2    4    0  859    3    6    8   13   86]\n",
            " [  10    6    6   29    4  791    9    6   22    9]\n",
            " [  11    3    5    1   11   31  888    0    8    0]\n",
            " [   2   14   19    3    7    1    0  940    6   36]\n",
            " [   6    4    8   17    7   35   12   15  840   30]\n",
            " [   4    4    4   17   38    6    2   36    6  892]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [24 10 34 36 32 40 35 34 39 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.069 s \n",
            "\n",
            "Accuracy rate for 90.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.97      0.97      0.97      1135\n",
            "           2       0.91      0.88      0.90      1032\n",
            "           3       0.91      0.88      0.89      1010\n",
            "           4       0.92      0.87      0.90       982\n",
            "           5       0.88      0.88      0.88       892\n",
            "           6       0.91      0.96      0.94       958\n",
            "           7       0.90      0.92      0.91      1028\n",
            "           8       0.89      0.85      0.87       974\n",
            "           9       0.84      0.90      0.86      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    2    0    1   14   13    1    2    0]\n",
            " [   0 1096    3   11    0    0    6    3   15    1]\n",
            " [   7   13  910   10   10   10   18   28   22    4]\n",
            " [   5    0   27  888    1   50    4    9   24    2]\n",
            " [   1    1    3    0  859    1   10    9    7   91]\n",
            " [  10    3    9   37    5  785   13    6   16    8]\n",
            " [  16    3    2    0    6    5  921    0    5    0]\n",
            " [   3    8   26    5    6    0    1  942    6   31]\n",
            " [   4    1   11   15    9   27   20   16  830   41]\n",
            " [   5    1    6   15   33    2    2   35    6  904]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59675, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [26 14 37 37 36 42 35 36 42 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.508 s \n",
            "\n",
            "Accuracy rate for 91.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.94      0.88      0.91      1032\n",
            "           3       0.91      0.88      0.89      1010\n",
            "           4       0.91      0.91      0.91       982\n",
            "           5       0.88      0.88      0.88       892\n",
            "           6       0.94      0.95      0.94       958\n",
            "           7       0.91      0.91      0.91      1028\n",
            "           8       0.90      0.87      0.88       974\n",
            "           9       0.84      0.89      0.86      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    0    2    0    1    5    7    1    1    0]\n",
            " [   0 1112    3    5    0    2    4    1    8    0]\n",
            " [  10   10  906   13   18   10   14   21   25    5]\n",
            " [   8    0   22  888    1   54    2    7   22    6]\n",
            " [   1    2    2    0  891    1    6    6    3   70]\n",
            " [  14   12    2   28    6  784   12    7   20    7]\n",
            " [  17    3    2    0   10   11  910    0    5    0]\n",
            " [   3   11   14    8   10    1    0  931    5   45]\n",
            " [   8    1    7   18    9   23   10   17  846   35]\n",
            " [   6    6    3   15   38    2    3   35    4  897]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [27 14 40 37 42 44 39 38 46 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.675 s \n",
            "\n",
            "Accuracy rate for 91.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.94      0.88      0.91      1032\n",
            "           3       0.92      0.86      0.89      1010\n",
            "           4       0.91      0.91      0.91       982\n",
            "           5       0.88      0.88      0.88       892\n",
            "           6       0.91      0.96      0.94       958\n",
            "           7       0.92      0.91      0.91      1028\n",
            "           8       0.91      0.85      0.88       974\n",
            "           9       0.83      0.91      0.87      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    0    1    0    1    4   11    0    1    1]\n",
            " [   0 1113    4    4    1    0    6    0    6    1]\n",
            " [   8   15  911    5   19    4   16   25   21    8]\n",
            " [   8    0   31  871    1   60    3    6   21    9]\n",
            " [   1    2    0    0  898    0   10    3    2   66]\n",
            " [  10    4    2   32    7  782   22    9   15    9]\n",
            " [  10    3    2    1    7   10  922    0    3    0]\n",
            " [   2   17   11    5   10    0    0  935    5   43]\n",
            " [   8    2    4   19    9   24   18   13  832   45]\n",
            " [   5    7    1    8   36    5    3   25    4  915]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [28 15 41 39 44 46 41 40 55 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.429 s \n",
            "\n",
            "Accuracy rate for 92.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.95      0.88      0.91      1032\n",
            "           3       0.95      0.87      0.90      1010\n",
            "           4       0.92      0.91      0.91       982\n",
            "           5       0.90      0.89      0.89       892\n",
            "           6       0.93      0.97      0.95       958\n",
            "           7       0.93      0.91      0.92      1028\n",
            "           8       0.88      0.90      0.89       974\n",
            "           9       0.85      0.92      0.88      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    0    0    1    8   10    1    1    0]\n",
            " [   0 1108    3    4    1    2    5    2   10    0]\n",
            " [  12    7  909    2   16    4   17   18   39    8]\n",
            " [   8    0   24  874    1   53    4    9   27   10]\n",
            " [   1    2    2    0  894    1   10    3    4   65]\n",
            " [   9    8    1   23    4  793   14    3   30    7]\n",
            " [  12    3    2    0    6    6  925    0    4    0]\n",
            " [   1   19   13    2   11    0    0  933    4   45]\n",
            " [   7    2    2   10    3   14   11   14  878   33]\n",
            " [   7    7    1    8   36    2    2   15    3  928]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [29 15 49 43 46 50 42 41 58 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.336 s \n",
            "\n",
            "Accuracy rate for 92.370000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.97      0.96      0.96      1135\n",
            "           2       0.94      0.91      0.92      1032\n",
            "           3       0.94      0.88      0.91      1010\n",
            "           4       0.94      0.92      0.93       982\n",
            "           5       0.89      0.89      0.89       892\n",
            "           6       0.95      0.95      0.95       958\n",
            "           7       0.94      0.91      0.93      1028\n",
            "           8       0.86      0.92      0.89       974\n",
            "           9       0.87      0.92      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    0    2    0    0   11    9    1    2    0]\n",
            " [   0 1088    5    4    0    3    5    2   28    0]\n",
            " [  10    3  937    6    9    7   12   19   25    4]\n",
            " [   5    0   23  886    1   50    1    6   28   10]\n",
            " [   1    1    1    0  900    1    8    3    7   60]\n",
            " [   6    4    4   25    3  796   11    3   31    9]\n",
            " [  15    3    4    1    5   12  912    1    5    0]\n",
            " [   2   16   16    2   10    2    0  938    6   36]\n",
            " [   6    1    6   13    5   14    6   10  893   20]\n",
            " [   5    4    3   10   26    3    1   15   10  932]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59575, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [30 18 49 46 47 53 44 42 65 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.910 s \n",
            "\n",
            "Accuracy rate for 91.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.95      0.89      0.92      1032\n",
            "           3       0.94      0.83      0.88      1010\n",
            "           4       0.94      0.89      0.91       982\n",
            "           5       0.86      0.90      0.88       892\n",
            "           6       0.94      0.96      0.95       958\n",
            "           7       0.96      0.90      0.93      1028\n",
            "           8       0.87      0.92      0.89       974\n",
            "           9       0.84      0.93      0.88      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    0    1    0    0    7    6    0    2    1]\n",
            " [   0 1109    5    4    1    1    5    0   10    0]\n",
            " [  12    7  922    7    7   10   13   18   27    9]\n",
            " [   8    0   21  835    1   88    1    5   40   11]\n",
            " [   1    2    1    0  875    1   11    1    8   82]\n",
            " [   8    5    2   22    2  806   14    1   26    6]\n",
            " [  11    3    2    0   12    5  918    0    7    0]\n",
            " [   3   21   14    2    9    0    0  925    9   45]\n",
            " [   5    0    1   14    6   14    5    5  897   27]\n",
            " [   9    5    1    9   22    1    2   10   10  940]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [30 21 51 52 54 55 45 43 67 57] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.821 s \n",
            "\n",
            "Accuracy rate for 92.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.96      0.98      0.97      1135\n",
            "           2       0.94      0.92      0.93      1032\n",
            "           3       0.93      0.89      0.91      1010\n",
            "           4       0.90      0.93      0.92       982\n",
            "           5       0.90      0.89      0.90       892\n",
            "           6       0.95      0.95      0.95       958\n",
            "           7       0.95      0.90      0.93      1028\n",
            "           8       0.88      0.92      0.90       974\n",
            "           9       0.89      0.90      0.90      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    0    0    1   12    6    0    4    1]\n",
            " [   0 1114    4    4    1    2    4    0    6    0]\n",
            " [  11    6  949    3   13    4    9   16   18    3]\n",
            " [   7    0   22  896    1   44    2    9   24    5]\n",
            " [   1    1    2    0  918    2    7    0   15   36]\n",
            " [   8    7    4   27    5  798   10    2   25    6]\n",
            " [   9    3    2    1   15   11  912    0    5    0]\n",
            " [   1   18   17    2   12    0    0  926    8   44]\n",
            " [   4    3    5   16    7   11    7    8  900   13]\n",
            " [   6    6    1   10   48    3    1   11   12  911]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59525, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [30 21 52 55 60 59 46 47 70 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.516 s \n",
            "\n",
            "Accuracy rate for 93.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.97      0.98      0.97      1135\n",
            "           2       0.96      0.91      0.93      1032\n",
            "           3       0.92      0.91      0.92      1010\n",
            "           4       0.89      0.95      0.92       982\n",
            "           5       0.92      0.90      0.91       892\n",
            "           6       0.95      0.95      0.95       958\n",
            "           7       0.95      0.91      0.93      1028\n",
            "           8       0.90      0.92      0.91       974\n",
            "           9       0.90      0.91      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    1    0    3    8    7    1    4    0]\n",
            " [   0 1116    4    5    1    2    3    0    4    0]\n",
            " [  10    2  939   12   17    4   11   19   16    2]\n",
            " [   8    0   14  920    1   27    1    7   27    5]\n",
            " [   1    1    0    0  928    3    8    0    5   36]\n",
            " [   7    4    2   32    6  801   12    2   22    4]\n",
            " [  10    3    2    1   19   10  910    0    3    0]\n",
            " [   1   21   16    4   12    0    0  935    5   34]\n",
            " [   4    3    2   14    6   12    8    8  899   18]\n",
            " [   5    6    2    9   48    0    1    8   12  918]]\n",
            "--------------------------------\n",
            "final active learning accuracies [51.74999999999999, 66.17, 70.77, 77.29, 81.23, 82.98, 86.08, 88.09, 88.42, 88.94999999999999, 89.01, 89.88000000000001, 90.82000000000001, 91.28, 91.4, 92.01, 92.36999999999999, 91.9, 92.80000000000001, 93.22]\n",
            "saved Active-learning-experiment-24.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 25, using model = RfModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [0 0 0 1 1 1 2 0 3 2] [3 4 5 6 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.263 s \n",
            "\n",
            "Accuracy rate for 24.610000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.84      0.24      0.37      1010\n",
            "           4       0.27      0.37      0.31       982\n",
            "           5       0.69      0.05      0.09       892\n",
            "           6       0.33      0.81      0.47       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.24      0.70      0.36       974\n",
            "           9       0.11      0.35      0.17      1009\n",
            "\n",
            "    accuracy                           0.25     10000\n",
            "   macro avg       0.25      0.25      0.18     10000\n",
            "weighted avg       0.24      0.25      0.17     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   0   7  98  14 471   0 348  42]\n",
            " [  0   0   0   0  86   0  41   0  69 939]\n",
            " [  0   0   0   9  54   0 431   0 284 254]\n",
            " [  0   0   0 239  97   0 196   0 344 134]\n",
            " [  0   0   0   0 366   0 111   0 223 282]\n",
            " [  0   0   0  25  55  41 226   0 355 190]\n",
            " [  0   0   0   0  96   0 779   0  72  11]\n",
            " [  0   0   0   0 273   4  11   0  88 652]\n",
            " [  0   0   0   3  19   0  61   0 686 205]\n",
            " [  0   0   0   1 224   0  59   0 375 350]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['6' '6' '4' ... '9' '6' '9']\n",
            "probabilities: (59990, 6) \n",
            " [3 3 1 ... 5 3 5]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [0 1 3 5 1 2 2 0 3 3] [1 2 3 4 5 6 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.664 s \n",
            "\n",
            "Accuracy rate for 39.070000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.82      0.31      0.45      1135\n",
            "           2       0.38      0.58      0.46      1032\n",
            "           3       0.33      0.88      0.48      1010\n",
            "           4       0.56      0.14      0.22       982\n",
            "           5       0.36      0.17      0.23       892\n",
            "           6       0.70      0.57      0.63       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.63      0.34      0.45       974\n",
            "           9       0.27      0.89      0.41      1009\n",
            "\n",
            "    accuracy                           0.39     10000\n",
            "   macro avg       0.41      0.39      0.33     10000\n",
            "weighted avg       0.41      0.39      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0  82 515  12 227 121   0  12  11]\n",
            " [  0 351 327 184   0  12   1   0   0 260]\n",
            " [  0  21 599 264   6   3  54   0  21  64]\n",
            " [  0   2  25 890   0   0   3   0  14  76]\n",
            " [  0   5  26   9 137   0  26   0  21 758]\n",
            " [  0   5  28 407   4 149  18   0  60 221]\n",
            " [  0   7 162  95  43   8 548   0  24  71]\n",
            " [  0   9 144  63  25   8   0   0  13 766]\n",
            " [  0  27 131 209   4   6  10   0 335 252]\n",
            " [  0   1  40  26  15   1   0   0  28 898]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['3' '5' '9' ... '9' '6' '9']\n",
            "probabilities: (59980, 8) \n",
            " [2 4 7 ... 7 5 7]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [1 2 3 6 3 3 3 0 5 4] [0 1 2 3 4 5 6 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.639 s \n",
            "\n",
            "Accuracy rate for 52.590000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.12      0.21       980\n",
            "           1       0.79      0.94      0.86      1135\n",
            "           2       0.78      0.34      0.47      1032\n",
            "           3       0.42      0.87      0.57      1010\n",
            "           4       0.49      0.36      0.42       982\n",
            "           5       0.38      0.34      0.36       892\n",
            "           6       0.66      0.80      0.72       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.64      0.64      0.64       974\n",
            "           9       0.34      0.78      0.47      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.54      0.52      0.47     10000\n",
            "weighted avg       0.54      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 118    4    9  270   12  396  151    0   14    6]\n",
            " [   0 1065    5   31    0    1    3    0    3   27]\n",
            " [   2   84  348  316   30    2  123    0   50   77]\n",
            " [   0    9   11  879    6    4    4    0   20   77]\n",
            " [   0   11    1    5  357    9   65    0   76  458]\n",
            " [   2   58   11  322   27  307   27    0   58   80]\n",
            " [  10   18    7   32   31    9  767    0   53   31]\n",
            " [   0   36   37   17  139   56    4    0   33  706]\n",
            " [   0   53   14  184    3    9    6    0  626   79]\n",
            " [   2    4    3   17  123   15   14    0   39  792]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['3' '5' '4' ... '9' '6' '9']\n",
            "probabilities: (59970, 9) \n",
            " [3 5 4 ... 8 6 8]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [4 2 4 7 5 4 4 0 5 5] [0 1 2 3 4 5 6 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.634 s \n",
            "\n",
            "Accuracy rate for 60.880000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       980\n",
            "           1       0.86      0.91      0.89      1135\n",
            "           2       0.82      0.42      0.55      1032\n",
            "           3       0.46      0.90      0.61      1010\n",
            "           4       0.48      0.71      0.58       982\n",
            "           5       0.73      0.36      0.48       892\n",
            "           6       0.69      0.77      0.73       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.84      0.51      0.64       974\n",
            "           9       0.37      0.65      0.48      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.61      0.61      0.58     10000\n",
            "weighted avg       0.61      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 817    1    2   56    5   61   35    0    1    2]\n",
            " [   0 1029    3   64    5    6    4    0    0   24]\n",
            " [  31   63  431  253   72    1  133    0   36   12]\n",
            " [   8    1    4  904    6    6    5    0    7   69]\n",
            " [   2    4    1    7  699    1   75    0    4  189]\n",
            " [  17   11    3  398   53  318   35    0   27   30]\n",
            " [  91    6    2    9   87   14  737    0   10    2]\n",
            " [  31   21   49    3  219   14    6    0    6  679]\n",
            " [   6   50   26  242   20   15   28    0  497   90]\n",
            " [  19    4    4   26  280    2   16    0    2  656]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['3' '0' '4' ... '9' '5' '8']\n",
            "probabilities: (59960, 9) \n",
            " [3 0 4 ... 8 5 7]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [5 2 6 9 6 7 4 1 5 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.216 s \n",
            "\n",
            "Accuracy rate for 61.240000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       980\n",
            "           1       0.93      0.80      0.86      1135\n",
            "           2       0.59      0.65      0.62      1032\n",
            "           3       0.50      0.92      0.65      1010\n",
            "           4       0.46      0.80      0.59       982\n",
            "           5       0.50      0.47      0.49       892\n",
            "           6       0.86      0.72      0.78       958\n",
            "           7       0.50      0.00      0.01      1028\n",
            "           8       0.91      0.41      0.57       974\n",
            "           9       0.41      0.49      0.45      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.65      0.61      0.58     10000\n",
            "weighted avg       0.65      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[807   0   2  22   2 141   5   0   1   0]\n",
            " [  0 909  77  85   0  59   3   0   0   2]\n",
            " [ 38  24 673 161  54  17  51   1   9   4]\n",
            " [ 11   0  24 932   4  22   1   1   2  13]\n",
            " [  1   5  14   4 789   8  26   0   1 134]\n",
            " [ 30   8   8 350  40 423  15   1  14   3]\n",
            " [ 43   3  36  13 125  39 690   0   8   1]\n",
            " [ 54   5 141  15 237  69   0   4   0 503]\n",
            " [  6  20 146 258  27  58  11   1 401  46]\n",
            " [ 16   3  12  28 435  12   4   0   3 496]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 5 5 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [6 2 6 9 6 8 7 4 7 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.245 s \n",
            "\n",
            "Accuracy rate for 67.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       980\n",
            "           1       0.95      0.79      0.86      1135\n",
            "           2       0.71      0.55      0.62      1032\n",
            "           3       0.52      0.91      0.66      1010\n",
            "           4       0.50      0.77      0.61       982\n",
            "           5       0.62      0.50      0.55       892\n",
            "           6       0.77      0.89      0.83       958\n",
            "           7       0.80      0.32      0.45      1028\n",
            "           8       0.87      0.63      0.73       974\n",
            "           9       0.51      0.54      0.52      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.71      0.68      0.67     10000\n",
            "weighted avg       0.72      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[854   0   5  12   0  86  21   1   1   0]\n",
            " [  0 896  55 111   0  18   9  44   1   1]\n",
            " [ 30   9 569 161  67   7 139  11  33   6]\n",
            " [  9   0  13 915   6  37   4   9   7  10]\n",
            " [  0   4  11   6 761   7  21   3   8 161]\n",
            " [ 21   7   4 320  40 445  28   0  26   1]\n",
            " [ 13   3   8  14  33  36 849   0   2   0]\n",
            " [ 20   4  85   9 213  44   4 326   8 315]\n",
            " [  5  14  42 192  18  28  20   6 617  32]\n",
            " [ 16   3   9  27 382  12   2   6   8 544]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59940, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [6 2 7 9 7 9 8 8 9 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.223 s \n",
            "\n",
            "Accuracy rate for 72.240000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89       980\n",
            "           1       0.96      0.73      0.83      1135\n",
            "           2       0.82      0.58      0.68      1032\n",
            "           3       0.59      0.86      0.70      1010\n",
            "           4       0.54      0.80      0.65       982\n",
            "           5       0.75      0.47      0.58       892\n",
            "           6       0.73      0.89      0.80       958\n",
            "           7       0.66      0.85      0.74      1028\n",
            "           8       0.81      0.69      0.75       974\n",
            "           9       0.74      0.43      0.54      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.75      0.72      0.72     10000\n",
            "weighted avg       0.75      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[888   0   3   4   2  46  33   2   2   0]\n",
            " [  0 833  41  75   0   2   8 154  20   2]\n",
            " [ 31   5 596  71  84   4 136  71  32   2]\n",
            " [ 16   1  20 867  10  43   7  27  15   4]\n",
            " [  1   2   2   9 783   3  25  34  21 102]\n",
            " [ 17   6   1 284  47 420  59  21  32   5]\n",
            " [ 18   2   3   3  64  10 852   3   3   0]\n",
            " [ 18   4  18   2  66  12   2 876  21   9]\n",
            " [  4  10  38 126  16  14  36  27 675  28]\n",
            " [ 17   3   4  39 370   6   3 122  11 434]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59930, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 6  3  8 11  7 10  8  8 11  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.926 s \n",
            "\n",
            "Accuracy rate for 74.920000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       980\n",
            "           1       0.94      0.77      0.85      1135\n",
            "           2       0.81      0.55      0.65      1032\n",
            "           3       0.62      0.89      0.73      1010\n",
            "           4       0.66      0.67      0.67       982\n",
            "           5       0.72      0.51      0.60       892\n",
            "           6       0.78      0.87      0.82       958\n",
            "           7       0.78      0.81      0.79      1028\n",
            "           8       0.72      0.76      0.74       974\n",
            "           9       0.67      0.75      0.71      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[868   0   2   4   6  65  26   1   8   0]\n",
            " [  0 875  62  43   0   5   5  82  59   4]\n",
            " [ 27  22 565  67  73   8 126  51  80  13]\n",
            " [ 12   0  10 897   3  42   2  15  19  10]\n",
            " [  0   8   0   6 658   2  25  20  34 229]\n",
            " [ 19   1   1 296  30 457  34  10  32  12]\n",
            " [ 21   2   3   4  51  29 838   1   9   0]\n",
            " [ 19   6  21   4  44   8   0 835  29  62]\n",
            " [  4  11  29  99   4  12  21  15 739  40]\n",
            " [ 20   2   2  24 121   9   4  47  20 760]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['3' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 4 ... 9 6 8]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 6  5 12 11  9 10  8  9 11  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.850 s \n",
            "\n",
            "Accuracy rate for 78.810000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.87       980\n",
            "           1       0.89      0.93      0.91      1135\n",
            "           2       0.82      0.82      0.82      1032\n",
            "           3       0.67      0.83      0.74      1010\n",
            "           4       0.72      0.76      0.74       982\n",
            "           5       0.70      0.52      0.60       892\n",
            "           6       0.87      0.84      0.85       958\n",
            "           7       0.80      0.80      0.80      1028\n",
            "           8       0.80      0.71      0.75       974\n",
            "           9       0.71      0.77      0.74      1009\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.78      0.78     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 836    0   17    1    3   89   25    2    6    1]\n",
            " [   0 1051   17    2    0    2    3   28   30    2]\n",
            " [  15   18  843   12   20    9   31   54   18   12]\n",
            " [  10   19   53  841    2   34    1   23   16   11]\n",
            " [   0   10    2    1  751    2   23   26   24  143]\n",
            " [  11   17    5  292   39  460   21    9   32    6]\n",
            " [  25    9   18    1   66   28  800    0   11    0]\n",
            " [  13   11   27    2   37   10    0  826   22   80]\n",
            " [   3   33   49   82   13   15    9   16  692   62]\n",
            " [  21   12    3   23  105    4    2   48   10  781]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59910, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  6 13 11 10 11  8 10 12 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.566 s \n",
            "\n",
            "Accuracy rate for 79.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90       980\n",
            "           1       0.89      0.95      0.92      1135\n",
            "           2       0.83      0.81      0.82      1032\n",
            "           3       0.73      0.79      0.76      1010\n",
            "           4       0.73      0.75      0.74       982\n",
            "           5       0.73      0.61      0.66       892\n",
            "           6       0.92      0.75      0.83       958\n",
            "           7       0.83      0.80      0.81      1028\n",
            "           8       0.81      0.72      0.76       974\n",
            "           9       0.68      0.84      0.75      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.80     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    8    0    2   34   14    1    6    1]\n",
            " [   0 1082   11    1    0    3    3   19   15    1]\n",
            " [  31   24  835   19   22    6   17   42   15   21]\n",
            " [  11   21   43  795    3   81    0   23   20   13]\n",
            " [   4    8    3    0  740    0   11   18   17  181]\n",
            " [   7   15    4  186   41  541   16   12   43   27]\n",
            " [  26    7   25    1  115   44  719    0   17    4]\n",
            " [  29   16   33    0   30   12    0  819   18   71]\n",
            " [   7   34   41   73   10   16    4    4  700   85]\n",
            " [  22   12    5   13   45    5    1   47    8  851]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [5 0 4 ... 9 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 7  7 16 13 11 11 10 10 13 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.864 s \n",
            "\n",
            "Accuracy rate for 81.240000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.80      0.85      0.83      1032\n",
            "           3       0.67      0.85      0.75      1010\n",
            "           4       0.76      0.78      0.77       982\n",
            "           5       0.79      0.48      0.60       892\n",
            "           6       0.89      0.88      0.89       958\n",
            "           7       0.87      0.78      0.82      1028\n",
            "           8       0.86      0.73      0.79       974\n",
            "           9       0.72      0.83      0.77      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.82      0.81      0.81     10000\n",
            "weighted avg       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    0   14    3    2   26   20    2    5    0]\n",
            " [   0 1096   17    2    0    2    2    2   12    2]\n",
            " [  19   19  880   23   17    2   18   29   14   11]\n",
            " [   8   24   42  854    4   41    1   20    6   10]\n",
            " [   0   10   14    1  765    0   12   11   13  156]\n",
            " [   9   17   10  266   47  427   30   17   50   19]\n",
            " [  17    8   12    3   49   23  841    0    2    3]\n",
            " [  18   15   56    5   45    7    0  806   11   65]\n",
            " [   5   25   44   92   12    9   14    2  713   58]\n",
            " [  20   11   12   20   63    2    2   41    4  834]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['3' '0' '4' ... '7' '6' '8']\n",
            "probabilities: (59890, 10) \n",
            " [3 0 4 ... 7 6 8]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 7  7 17 15 12 13 10 10 15 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.807 s \n",
            "\n",
            "Accuracy rate for 82.330000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       980\n",
            "           1       0.91      0.96      0.93      1135\n",
            "           2       0.77      0.88      0.82      1032\n",
            "           3       0.73      0.84      0.78      1010\n",
            "           4       0.78      0.77      0.78       982\n",
            "           5       0.76      0.66      0.71       892\n",
            "           6       0.92      0.84      0.88       958\n",
            "           7       0.90      0.74      0.81      1028\n",
            "           8       0.89      0.73      0.80       974\n",
            "           9       0.72      0.87      0.79      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.83      0.82      0.82     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    0   15    2    1   47   18    1    3    1]\n",
            " [   0 1084   33    3    0    4    3    1    6    1]\n",
            " [  20   10  907   17   11    0   15   20   17   15]\n",
            " [  10   14   54  851    1   48    0   14    9    9]\n",
            " [   1    9    7    3  760    3   17   11   14  157]\n",
            " [  11   12   11  174   37  587    8    4   26   22]\n",
            " [  23    7   26    2   50   43  804    0    1    2]\n",
            " [  14   16   63    3   56    7    0  761   11   97]\n",
            " [   5   24   56   96   13   25    8    1  711   35]\n",
            " [  10   11    8   20   42    6    1   33    2  876]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59880, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 8  7 18 15 13 17 10 11 16 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.836 s \n",
            "\n",
            "Accuracy rate for 83.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95       980\n",
            "           1       0.92      0.96      0.94      1135\n",
            "           2       0.79      0.88      0.84      1032\n",
            "           3       0.79      0.83      0.81      1010\n",
            "           4       0.77      0.77      0.77       982\n",
            "           5       0.70      0.76      0.73       892\n",
            "           6       0.96      0.78      0.86       958\n",
            "           7       0.91      0.77      0.84      1028\n",
            "           8       0.87      0.77      0.81       974\n",
            "           9       0.73      0.86      0.79      1009\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 921    0    3    0    0   46    3    1    4    2]\n",
            " [   0 1084   17    3    1    7    1    0   22    0]\n",
            " [   7   10  910   16   15    7    8   20   24   15]\n",
            " [   2    8   46  842    0   80    0   16    7    9]\n",
            " [   1    8    7    1  753    5   13    9   13  172]\n",
            " [   5   10   10  114   31  682    5    3   19   13]\n",
            " [  14    9   50    1   69   65  743    0    5    2]\n",
            " [   7   20   45    1   50   23    0  795   11   76]\n",
            " [   2   16   53   69    9   36    4    4  746   35]\n",
            " [   7   10    5   14   53   23    1   26    6  864]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59870, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 8  7 18 15 15 18 12 14 18 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.624 s \n",
            "\n",
            "Accuracy rate for 85.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93       980\n",
            "           1       0.95      0.96      0.96      1135\n",
            "           2       0.82      0.85      0.84      1032\n",
            "           3       0.82      0.83      0.83      1010\n",
            "           4       0.80      0.85      0.82       982\n",
            "           5       0.71      0.77      0.74       892\n",
            "           6       0.93      0.84      0.88       958\n",
            "           7       0.84      0.87      0.85      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.80      0.81      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    0    3    0    1   58   12    2    6    0]\n",
            " [   0 1090   15    3    1    5    4    4   13    0]\n",
            " [   9    6  874   19   16    9   18   34   31   16]\n",
            " [   5    5   32  839    2   78    0   20   22    7]\n",
            " [   0    6    7    1  831    3    7   25    7   95]\n",
            " [   4   12   11   78   30  691    8   16   26   16]\n",
            " [  15    2   29    0   36   64  802    3    6    1]\n",
            " [   2   14   42    4   30    4    0  890    2   40]\n",
            " [   3    7   43   61   17   35    5    4  776   23]\n",
            " [   8    5    5   12   72   22    2   56   14  813]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59860, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [10  7 21 15 15 20 12 15 19 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.767 s \n",
            "\n",
            "Accuracy rate for 84.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.91      0.93       980\n",
            "           1       0.96      0.94      0.95      1135\n",
            "           2       0.74      0.89      0.81      1032\n",
            "           3       0.86      0.76      0.80      1010\n",
            "           4       0.83      0.82      0.82       982\n",
            "           5       0.65      0.82      0.72       892\n",
            "           6       0.95      0.78      0.86       958\n",
            "           7       0.86      0.84      0.85      1028\n",
            "           8       0.87      0.81      0.84       974\n",
            "           9       0.80      0.83      0.82      1009\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.85      0.84      0.84     10000\n",
            "weighted avg       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    0    6    0    0   68    6    2    6    0]\n",
            " [   0 1064   48    1    0    3    4    3   12    0]\n",
            " [  11    5  921   12    9    8   12   19   26    9]\n",
            " [   2    3   49  763    3  142    0   18   23    7]\n",
            " [   2    4   25    0  802    4    6   24    7  108]\n",
            " [   1    7   16   63   21  727    4   14   25   14]\n",
            " [  20    2   62    0   30   92  747    2    2    1]\n",
            " [   2   12   57    1   35    6    0  867    7   41]\n",
            " [   1    5   54   43   12   38    4    5  787   25]\n",
            " [   7    5    9    8   53   29    0   52   10  836]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59850, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [11  7 21 17 18 20 15 15 19 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.985 s \n",
            "\n",
            "Accuracy rate for 85.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       980\n",
            "           1       0.95      0.95      0.95      1135\n",
            "           2       0.81      0.87      0.84      1032\n",
            "           3       0.82      0.81      0.82      1010\n",
            "           4       0.79      0.87      0.83       982\n",
            "           5       0.75      0.78      0.77       892\n",
            "           6       0.92      0.86      0.89       958\n",
            "           7       0.87      0.82      0.85      1028\n",
            "           8       0.86      0.80      0.83       974\n",
            "           9       0.80      0.80      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    0    4    0    0   29   10    3    6    0]\n",
            " [   0 1077   25    2    1    3    4    4   19    0]\n",
            " [   5    6  893   22   13    5   27   20   29   12]\n",
            " [   5    7   39  823    3   79    1   17   25   11]\n",
            " [   1    4   14    0  854    2    9   16    6   76]\n",
            " [   5   11   10   86   25  698    9   12   24   12]\n",
            " [  15    2   25    0   21   67  825    0    2    1]\n",
            " [   2   18   49    0   44    2    0  845    4   64]\n",
            " [   4    7   40   60   21   30    7    4  777   24]\n",
            " [   6    6    6    8  104   15    1   45    9  809]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59840, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [13  7 23 19 19 20 17 15 19 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.669 s \n",
            "\n",
            "Accuracy rate for 84.850000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95       980\n",
            "           1       0.95      0.94      0.94      1135\n",
            "           2       0.81      0.85      0.83      1032\n",
            "           3       0.78      0.81      0.79      1010\n",
            "           4       0.80      0.85      0.82       982\n",
            "           5       0.75      0.76      0.75       892\n",
            "           6       0.93      0.89      0.91       958\n",
            "           7       0.87      0.83      0.85      1028\n",
            "           8       0.87      0.76      0.81       974\n",
            "           9       0.79      0.81      0.80      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    2    0    1   21    8    2    4    0]\n",
            " [   0 1065   39    1    0    3    4    8   15    0]\n",
            " [  22   10  880   31   11    3   16   19   30   10]\n",
            " [   3    4   29  818    2  104    1   18   21   10]\n",
            " [   1    4   11    0  832    4   10   16    7   97]\n",
            " [  10    7   14   94   32  679   10   11   19   16]\n",
            " [  23    2   11    1   21   43  853    1    2    1]\n",
            " [   3   15   56    1   31    4    0  852    4   62]\n",
            " [   3    5   38   95   16   31    9    9  744   24]\n",
            " [   6    7    6   12   93   19    2   38    6  820]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59830, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [14  7 23 19 21 23 18 15 20 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.142 s \n",
            "\n",
            "Accuracy rate for 85.450000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       980\n",
            "           1       0.96      0.94      0.95      1135\n",
            "           2       0.84      0.84      0.84      1032\n",
            "           3       0.82      0.75      0.79      1010\n",
            "           4       0.79      0.90      0.84       982\n",
            "           5       0.72      0.83      0.77       892\n",
            "           6       0.93      0.88      0.90       958\n",
            "           7       0.89      0.83      0.86      1028\n",
            "           8       0.85      0.77      0.81       974\n",
            "           9       0.83      0.81      0.82      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    0    1    0    0   14    9    1    5    0]\n",
            " [   0 1072   17    0    1    3    6   14   20    2]\n",
            " [  31    7  871   25   17    4   15   18   37    7]\n",
            " [   8    5   29  762    2  147    1   15   33    8]\n",
            " [   1    4   11    0  886    5    8   12    4   51]\n",
            " [   7    7   10   57   27  738   12   12   11   11]\n",
            " [  13    2    9    0   30   55  842    1    5    1]\n",
            " [   2   11   53    1   40    1    0  858    4   58]\n",
            " [   4    7   31   72   28   36   11    6  746   33]\n",
            " [   7    6    7    7   92   28    3   31    8  820]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59820, 10) \n",
            " [5 0 4 ... 5 5 8]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [14  8 23 23 21 23 19 16 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.923 s \n",
            "\n",
            "Accuracy rate for 86.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       980\n",
            "           1       0.94      0.94      0.94      1135\n",
            "           2       0.85      0.84      0.85      1032\n",
            "           3       0.80      0.83      0.82      1010\n",
            "           4       0.83      0.88      0.86       982\n",
            "           5       0.80      0.79      0.80       892\n",
            "           6       0.94      0.90      0.92       958\n",
            "           7       0.89      0.80      0.85      1028\n",
            "           8       0.86      0.82      0.84       974\n",
            "           9       0.79      0.84      0.81      1009\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    0    3    1    0   11    8    2    6    0]\n",
            " [   0 1064   32    2    1    3    4    6   23    0]\n",
            " [  25    6  872   32    8    6   14   21   36   12]\n",
            " [   4   10   24  838    2   72    0   14   33   13]\n",
            " [   2    9   10    0  865    2   10   15    3   66]\n",
            " [   6    6    8  102   22  709    7    6   13   13]\n",
            " [  18    3    7    0   20   42  864    1    3    0]\n",
            " [   4   18   47    1   23    8    0  825    2  100]\n",
            " [   1   10   25   57   21   21    9    5  800   25]\n",
            " [   8   11    3   13   79   15    1   27    9  843]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['3' '0' '4' ... '5' '5' '8']\n",
            "probabilities: (59810, 10) \n",
            " [3 0 4 ... 5 5 8]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [14  9 25 26 21 23 20 17 23 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.113 s \n",
            "\n",
            "Accuracy rate for 86.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.93      0.94      0.93      1135\n",
            "           2       0.84      0.84      0.84      1032\n",
            "           3       0.78      0.89      0.83      1010\n",
            "           4       0.84      0.85      0.85       982\n",
            "           5       0.89      0.74      0.81       892\n",
            "           6       0.94      0.91      0.93       958\n",
            "           7       0.89      0.83      0.86      1028\n",
            "           8       0.86      0.82      0.84       974\n",
            "           9       0.78      0.86      0.82      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    0    5    2    0    6    8    3    7    0]\n",
            " [   0 1068   34    4    1    2    3    3   20    0]\n",
            " [  13   15  867   33    8    0   12   25   48   11]\n",
            " [   2   12   17  902    3   31    0   10   21   12]\n",
            " [   2    9   20    0  833    1    7   18    1   91]\n",
            " [   6    8   12  124   17  658   14   18   17   18]\n",
            " [  20    3    9    2   28   17  875    1    3    0]\n",
            " [   3   19   44    7   22    1    0  854    0   78]\n",
            " [   3    9   14   64   18   15    9    2  801   39]\n",
            " [   6   10    6   15   59    9    1   23    9  871]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [14  9 25 28 21 26 20 18 26 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.181 s \n",
            "\n",
            "Accuracy rate for 87.190000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       980\n",
            "           1       0.94      0.92      0.93      1135\n",
            "           2       0.84      0.85      0.85      1032\n",
            "           3       0.81      0.87      0.84      1010\n",
            "           4       0.89      0.81      0.85       982\n",
            "           5       0.85      0.79      0.82       892\n",
            "           6       0.93      0.92      0.93       958\n",
            "           7       0.89      0.87      0.88      1028\n",
            "           8       0.82      0.84      0.83       974\n",
            "           9       0.80      0.86      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    1    1    0   17    8    2    7    0]\n",
            " [   0 1048   51    2    0    1    6    2   25    0]\n",
            " [  12   10  879   30    8    1   12   22   43   15]\n",
            " [   3    6   16  881    2   49    0   11   37    5]\n",
            " [   2   10   19    1  798    2    9   17    8  116]\n",
            " [   7    8    7   86   17  706   14   10   29    8]\n",
            " [  13    3   13    3   16   24  883    0    3    0]\n",
            " [   3   17   42   11   13    1    0  894    4   43]\n",
            " [   4    6   13   59   10   21   11    8  817   25]\n",
            " [   6    9    5   19   31   11    2   38   19  869]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59790, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [14 10 28 28 25 27 20 18 27 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.912 s \n",
            "\n",
            "Accuracy rate for 87.110000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       980\n",
            "           1       0.93      0.97      0.95      1135\n",
            "           2       0.86      0.85      0.86      1032\n",
            "           3       0.84      0.84      0.84      1010\n",
            "           4       0.80      0.88      0.84       982\n",
            "           5       0.80      0.84      0.82       892\n",
            "           6       0.94      0.90      0.92       958\n",
            "           7       0.89      0.85      0.87      1028\n",
            "           8       0.82      0.85      0.84       974\n",
            "           9       0.84      0.76      0.80      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    3    2    0   23   11    2    2    0]\n",
            " [   0 1104    8    2    0    2    6    4    9    0]\n",
            " [   4   17  879   29    4    7   11   25   47    9]\n",
            " [   5    6   19  849    1   60    0   12   52    6]\n",
            " [   2    9   20    1  869    3   10   14    5   49]\n",
            " [   7   11   10   55   19  745    8    6   28    3]\n",
            " [  10    2   19    6   28   26  864    1    2    0]\n",
            " [   3   18   42    5   21    5    0  876    9   49]\n",
            " [   0   11    9   50   11   32    7    1  826   27]\n",
            " [   4   10    9    8  129   23    1   40   23  762]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59780, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [15 10 28 28 26 28 22 19 27 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.082 s \n",
            "\n",
            "Accuracy rate for 88.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       980\n",
            "           1       0.94      0.97      0.96      1135\n",
            "           2       0.86      0.87      0.87      1032\n",
            "           3       0.88      0.84      0.86      1010\n",
            "           4       0.85      0.86      0.85       982\n",
            "           5       0.84      0.85      0.84       892\n",
            "           6       0.93      0.92      0.93       958\n",
            "           7       0.92      0.83      0.87      1028\n",
            "           8       0.86      0.85      0.85       974\n",
            "           9       0.80      0.86      0.83      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    2    0    0   16   10    2    6    0]\n",
            " [   0 1102   12    1    0    2    6    2   10    0]\n",
            " [   3    9  898   28    5    3   11   22   42   11]\n",
            " [   3    8   18  853    1   69    0   15   38    5]\n",
            " [   2    7   24    0  845    1   10   10    2   81]\n",
            " [   3    9   14   30   23  755   18    7   20   13]\n",
            " [  19    3   12    2   22   14  883    1    2    0]\n",
            " [   3   16   42    4   25    3    0  855    1   79]\n",
            " [   1    7   10   39   16   27   12    1  827   34]\n",
            " [   4   10   11   10   58   13    1   19   17  866]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59770, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [15 10 29 29 26 29 22 22 29 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.855 s \n",
            "\n",
            "Accuracy rate for 88.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       980\n",
            "           1       0.95      0.97      0.96      1135\n",
            "           2       0.87      0.87      0.87      1032\n",
            "           3       0.85      0.84      0.85      1010\n",
            "           4       0.87      0.85      0.86       982\n",
            "           5       0.84      0.81      0.82       892\n",
            "           6       0.94      0.92      0.93       958\n",
            "           7       0.90      0.84      0.87      1028\n",
            "           8       0.85      0.85      0.85       974\n",
            "           9       0.78      0.87      0.82      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    2    0    0   15   11    1    9    0]\n",
            " [   0 1101   15    2    0    1    5    4    7    0]\n",
            " [   5   11  895   34    3    2    9   29   34   10]\n",
            " [   3    8   21  852    2   64    0   14   39    7]\n",
            " [   1    6   16    0  839    3    9   13    4   91]\n",
            " [   5    7    8   58   18  722   17    4   35   18]\n",
            " [  17    3   12    3   28   12  878    0    4    1]\n",
            " [   3   13   39    2   16    5    0  868    2   80]\n",
            " [   1    9   14   37   13   27    7    2  825   39]\n",
            " [   5    6    8   11   46   13    0   28   13  879]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59760, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [17 10 29 29 30 31 22 23 29 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.596 s \n",
            "\n",
            "Accuracy rate for 88.490000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.95      0.96      0.96      1135\n",
            "           2       0.87      0.87      0.87      1032\n",
            "           3       0.88      0.82      0.85      1010\n",
            "           4       0.82      0.90      0.86       982\n",
            "           5       0.80      0.87      0.83       892\n",
            "           6       0.96      0.89      0.92       958\n",
            "           7       0.91      0.86      0.88      1028\n",
            "           8       0.88      0.85      0.86       974\n",
            "           9       0.82      0.86      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.89      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    3    2    1   14    5    1    2    0]\n",
            " [   0 1090   25    2    0    3    3    2   10    0]\n",
            " [   4    8  900   26   10    5    7   25   36   11]\n",
            " [   3    7   21  830    2   90    0   19   29    9]\n",
            " [   1    5   14    0  882    3    6   10    2   59]\n",
            " [   4    6    4   33   25  772    9    5   20   14]\n",
            " [  20    2   15    2   43   20  855    0    1    0]\n",
            " [   3   13   36    1   24    9    0  881    2   59]\n",
            " [   2    7    7   41   13   35    9    4  824   32]\n",
            " [   8    7    7    5   73   20    1   16    9  863]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 2]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [17 10 30 30 32 32 23 23 31 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.838 s \n",
            "\n",
            "Accuracy rate for 88.300000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.96      0.96      1135\n",
            "           2       0.87      0.88      0.87      1032\n",
            "           3       0.87      0.85      0.86      1010\n",
            "           4       0.81      0.91      0.86       982\n",
            "           5       0.82      0.82      0.82       892\n",
            "           6       0.96      0.88      0.92       958\n",
            "           7       0.92      0.84      0.87      1028\n",
            "           8       0.88      0.85      0.86       974\n",
            "           9       0.82      0.86      0.84      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    2    2    0   21    5    1    2    0]\n",
            " [   0 1089   25    1    0    3    4    4    7    2]\n",
            " [   6    2  905   35    9    4    8   22   32    9]\n",
            " [   3    3   19  863    3   72    0   17   22    8]\n",
            " [   1    3   17    0  898    3    4    7    4   45]\n",
            " [   7    8    8   47   25  734    6    7   32   18]\n",
            " [  22    3   12    2   52   18  844    0    5    0]\n",
            " [   2   14   38    3   29    6    0  860    2   74]\n",
            " [   2    7   11   32   17   26    8    6  826   39]\n",
            " [   6    8    8   10   77   10    1   14   11  864]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59740, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [18 10 31 30 33 35 23 24 34 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.734 s \n",
            "\n",
            "Accuracy rate for 89.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.96      0.96      1135\n",
            "           2       0.86      0.90      0.88      1032\n",
            "           3       0.92      0.81      0.86      1010\n",
            "           4       0.82      0.93      0.87       982\n",
            "           5       0.81      0.88      0.84       892\n",
            "           6       0.96      0.89      0.92       958\n",
            "           7       0.92      0.85      0.89      1028\n",
            "           8       0.86      0.87      0.86       974\n",
            "           9       0.85      0.84      0.85      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    5    0    0   14    6    1    2    0]\n",
            " [   0 1090   24    2    0    2    4    4    9    0]\n",
            " [   7    3  930   20    8    2    5   17   36    4]\n",
            " [   4    8   22  815    3   91    1   14   46    6]\n",
            " [   2    4   15    0  916    0    2    7    5   31]\n",
            " [   5    6   14   17   21  784    9    5   23    8]\n",
            " [  19    3   15    2   50   17  848    0    4    0]\n",
            " [   4   12   40    0   15    8    0  876    3   70]\n",
            " [   1    6   14   27   20   33    4    0  843   26]\n",
            " [   8    6    6    5   84   17    0   26   10  847]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59730, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [18 11 34 30 33 35 25 24 35 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.245 s \n",
            "\n",
            "Accuracy rate for 89.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96       980\n",
            "           1       0.95      0.96      0.96      1135\n",
            "           2       0.88      0.90      0.89      1032\n",
            "           3       0.90      0.83      0.86      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.84      0.87      0.85       892\n",
            "           6       0.95      0.91      0.93       958\n",
            "           7       0.92      0.84      0.88      1028\n",
            "           8       0.87      0.86      0.86       974\n",
            "           9       0.81      0.88      0.84      1009\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    3    1    0   14   10    2    4    0]\n",
            " [   0 1093   17    1    0    3    3    5   13    0]\n",
            " [  10    5  930   19    8    1    4   17   28   10]\n",
            " [   2    7   24  840    1   73    0   14   41    8]\n",
            " [   1    4    9    0  890    0    9    9    2   58]\n",
            " [   4    6    7   30   20  773   14    4   23   11]\n",
            " [  16    3    6    3   41   18  869    0    2    0]\n",
            " [   2   14   34    2   19    5    0  867    1   84]\n",
            " [   2    8   18   30   16   22    6    1  836   35]\n",
            " [   3    6    3    7   56   14    1   23   11  885]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['3' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59720, 10) \n",
            " [3 0 4 ... 5 6 2]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [18 11 35 32 35 35 26 25 36 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.613 s \n",
            "\n",
            "Accuracy rate for 89.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       980\n",
            "           1       0.96      0.97      0.96      1135\n",
            "           2       0.88      0.89      0.89      1032\n",
            "           3       0.90      0.81      0.86      1010\n",
            "           4       0.85      0.91      0.88       982\n",
            "           5       0.80      0.88      0.84       892\n",
            "           6       0.95      0.90      0.93       958\n",
            "           7       0.93      0.86      0.89      1028\n",
            "           8       0.88      0.87      0.88       974\n",
            "           9       0.84      0.89      0.87      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    5    0    0   16    7    2    6    0]\n",
            " [   0 1100   15    2    0    3    3    3    9    0]\n",
            " [   6    4  923   26   12    4    8   15   25    9]\n",
            " [   2    4   24  822    4   94    0   13   38    9]\n",
            " [   1    5   10    0  896    1    6    7    2   54]\n",
            " [   2    6    5   27   19  782   13    4   19   15]\n",
            " [  16    3    7    2   40   26  861    0    3    0]\n",
            " [   3   13   37    2   23    4    0  885    5   56]\n",
            " [   2    6   19   24   14   26    5    0  851   27]\n",
            " [   6    7    4    5   40   16    0   21    7  903]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59710, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [20 11 35 33 35 38 27 25 38 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.983 s \n",
            "\n",
            "Accuracy rate for 90.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.95      0.97      0.96      1135\n",
            "           2       0.89      0.90      0.90      1032\n",
            "           3       0.91      0.82      0.87      1010\n",
            "           4       0.87      0.92      0.89       982\n",
            "           5       0.83      0.88      0.85       892\n",
            "           6       0.95      0.92      0.93       958\n",
            "           7       0.93      0.87      0.90      1028\n",
            "           8       0.88      0.88      0.88       974\n",
            "           9       0.86      0.88      0.87      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    1    3    0    0   15    9    1    4    1]\n",
            " [   0 1100   16    2    0    2    4    3    8    0]\n",
            " [   8    7  933   23   11    3    6   12   20    9]\n",
            " [   5    4   22  833    4   81    0   13   42    6]\n",
            " [   2    5    6    0  904    0    7    9    4   45]\n",
            " [   8    6    7   28   12  788   13    4   18    8]\n",
            " [  19    3    3    1   32   19  877    0    4    0]\n",
            " [   3   13   40    3   18    5    0  891    4   51]\n",
            " [   3    9   14   21   13   22    5    2  858   27]\n",
            " [   6    6    3    2   46   19    0   22   13  892]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [20 11 35 34 35 39 29 27 39 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.843 s \n",
            "\n",
            "Accuracy rate for 90.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.97      0.97      1135\n",
            "           2       0.90      0.90      0.90      1032\n",
            "           3       0.92      0.82      0.86      1010\n",
            "           4       0.87      0.87      0.87       982\n",
            "           5       0.83      0.90      0.86       892\n",
            "           6       0.94      0.93      0.93       958\n",
            "           7       0.95      0.87      0.91      1028\n",
            "           8       0.92      0.86      0.89       974\n",
            "           9       0.81      0.92      0.86      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    0    1    0   15   12    1    4    1]\n",
            " [   0 1103   16    1    0    3    4    3    5    0]\n",
            " [   9    4  928   23    9    0    9   12   26   12]\n",
            " [   5    5   20  825    2  101    0   14   22   16]\n",
            " [   1    4   11    0  855    0   13    5    1   92]\n",
            " [   5    4    3   22   16  807   17    4    9    5]\n",
            " [  16    3    6    1   26   10  892    0    4    0]\n",
            " [   2   13   32    2   19    4    0  895    0   61]\n",
            " [   3    9   18   20   14   25    4    3  842   36]\n",
            " [   5    5    2    5   37   13    0    8    7  927]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59690, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [21 11 35 37 36 39 30 28 40 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.402 s \n",
            "\n",
            "Accuracy rate for 90.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.96      0.97      0.96      1135\n",
            "           2       0.92      0.87      0.90      1032\n",
            "           3       0.87      0.88      0.87      1010\n",
            "           4       0.90      0.86      0.88       982\n",
            "           5       0.85      0.89      0.87       892\n",
            "           6       0.94      0.93      0.94       958\n",
            "           7       0.94      0.86      0.90      1028\n",
            "           8       0.91      0.85      0.88       974\n",
            "           9       0.79      0.93      0.86      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    2    2    0   12    5    1    1    1]\n",
            " [   0 1097   13    5    0    2    3    5   10    0]\n",
            " [  10    6  899   32   12    3    9   12   31   18]\n",
            " [   5    2   10  886    2   59    0   13   20   13]\n",
            " [   1    4    6    0  848    1   15    5    2  100]\n",
            " [   5    4    1   42    9  790   13    4    9   15]\n",
            " [  19    3    4    3   24   16  887    0    2    0]\n",
            " [   2   13   24    4   17    3    0  889    3   73]\n",
            " [   3    9   11   39   11   32    7    3  832   27]\n",
            " [   6    5    2    7   19   10    0   13    9  938]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59680, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [21 12 36 39 36 40 32 29 42 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.185 s \n",
            "\n",
            "Accuracy rate for 90.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.97      0.97      1135\n",
            "           2       0.93      0.86      0.89      1032\n",
            "           3       0.87      0.87      0.87      1010\n",
            "           4       0.92      0.87      0.89       982\n",
            "           5       0.83      0.89      0.86       892\n",
            "           6       0.93      0.94      0.93       958\n",
            "           7       0.93      0.89      0.91      1028\n",
            "           8       0.91      0.85      0.88       974\n",
            "           9       0.82      0.92      0.87      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.90      0.90     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    1    1    0   11   11    2    1    0]\n",
            " [   0 1106    9    5    0    1    6    3    5    0]\n",
            " [  11    4  884   36    7    5   16   17   38   14]\n",
            " [   5    1   11  881    1   79    0   11   14    7]\n",
            " [   1    4    7    0  856    1   12    6    2   93]\n",
            " [   7    5    4   40    9  794   16    2    7    8]\n",
            " [  12    3    2    0   18   16  902    1    4    0]\n",
            " [   3   10   24    1    9    5    0  920    3   53]\n",
            " [   3    9    9   41   10   33   10    5  828   26]\n",
            " [   5    5    0   11   22   12    0   19    5  930]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59670, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [21 12 39 41 37 41 32 30 43 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.678 s \n",
            "\n",
            "Accuracy rate for 91.070000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.96      0.97      0.97      1135\n",
            "           2       0.90      0.89      0.90      1032\n",
            "           3       0.87      0.89      0.88      1010\n",
            "           4       0.92      0.87      0.89       982\n",
            "           5       0.88      0.87      0.88       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.93      0.90      0.92      1028\n",
            "           8       0.90      0.87      0.88       974\n",
            "           9       0.84      0.92      0.88      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    1    2    0    0    8   10    1    3    0]\n",
            " [   0 1099   12    6    0    1    4    3   10    0]\n",
            " [  10    2  919   31    7    1   11   15   25   11]\n",
            " [   7    1   18  901    1   48    0   11   16    7]\n",
            " [   1    4   11    0  854    0   11    8    6   87]\n",
            " [   6    4    4   48   11  778   13    3   17    8]\n",
            " [  15    3    3    0   16   11  905    1    4    0]\n",
            " [   3   12   32    2    6    4    0  923    4   42]\n",
            " [   3   11   13   33    9   26    8    5  847   19]\n",
            " [   7    4    2   10   23    9    0   19    9  926]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59660, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [23 12 40 42 40 41 32 31 45 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.254 s \n",
            "\n",
            "Accuracy rate for 90.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.96      0.97      0.97      1135\n",
            "           2       0.91      0.89      0.90      1032\n",
            "           3       0.84      0.89      0.87      1010\n",
            "           4       0.89      0.90      0.90       982\n",
            "           5       0.87      0.86      0.86       892\n",
            "           6       0.95      0.94      0.94       958\n",
            "           7       0.93      0.89      0.91      1028\n",
            "           8       0.91      0.84      0.88       974\n",
            "           9       0.85      0.90      0.87      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 958    0    3    0    0    7    6    2    3    1]\n",
            " [   0 1097    6    9    0    2    5    4   12    0]\n",
            " [   8    5  917   32    9    0   10   15   25   11]\n",
            " [   6    0   16  901    1   58    0   12   11    5]\n",
            " [   1    3    9    0  888    1    7    7    1   65]\n",
            " [   7    3    6   63   12  763   13    7   10    8]\n",
            " [  16    2    4    1   20   10  901    0    3    1]\n",
            " [   4   13   32    4   10    6    0  915    4   40]\n",
            " [   4   11   16   51   13   20   11    5  819   24]\n",
            " [   8    4    2   12   41    9    0   20    8  905]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [25 12 41 43 42 41 32 32 47 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.462 s \n",
            "\n",
            "Accuracy rate for 90.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       980\n",
            "           1       0.96      0.97      0.97      1135\n",
            "           2       0.93      0.87      0.90      1032\n",
            "           3       0.83      0.91      0.87      1010\n",
            "           4       0.87      0.92      0.90       982\n",
            "           5       0.90      0.83      0.86       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.93      0.89      0.91      1028\n",
            "           8       0.90      0.88      0.89       974\n",
            "           9       0.87      0.89      0.88      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 958    1    2    0    1    5    9    2    2    0]\n",
            " [   0 1100    7    9    2    1    4    2   10    0]\n",
            " [   9    3  899   35   13    0   14   14   30   15]\n",
            " [   6    0   13  920    2   31    0   10   19    9]\n",
            " [   1    4    5    0  906    1   12    4    2   47]\n",
            " [   6    6    3   86   18  736   14    8   11    4]\n",
            " [  12    2    2    1   19   12  903    1    6    0]\n",
            " [   2   12   25    3   16    4    0  919    4   43]\n",
            " [   4   11    8   38   12   18    4    3  857   19]\n",
            " [   6    4    1   13   52    8    0   20    7  898]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59640, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [27 12 42 46 42 41 34 33 47 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.324 s \n",
            "\n",
            "Accuracy rate for 91.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.97      0.97      0.97      1135\n",
            "           2       0.92      0.90      0.91      1032\n",
            "           3       0.82      0.92      0.87      1010\n",
            "           4       0.89      0.91      0.90       982\n",
            "           5       0.92      0.80      0.86       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.93      0.90      0.92      1028\n",
            "           8       0.93      0.86      0.89       974\n",
            "           9       0.87      0.90      0.88      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    2    2    0    4   11    0    0    2]\n",
            " [   0 1099   14    9    2    0    3    2    6    0]\n",
            " [   7    2  933   23   12    0   11   12   22   10]\n",
            " [   6    0   14  930    2   30    0   11   10    7]\n",
            " [   1    4    5    0  898    0   10    6    2   56]\n",
            " [  12    3    5   98   15  716   15   11   10    7]\n",
            " [  15    2    4    3   21    5  902    1    5    0]\n",
            " [   3    9   30    3   15    2    0  929    2   35]\n",
            " [   3   12   10   50   10   13    7    6  841   22]\n",
            " [   7    3    1   16   37    6    0   21    8  910]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59630, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [27 12 44 46 43 41 34 33 52 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.390 s \n",
            "\n",
            "Accuracy rate for 91.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.97      0.97      0.97      1135\n",
            "           2       0.91      0.90      0.90      1032\n",
            "           3       0.84      0.91      0.87      1010\n",
            "           4       0.91      0.92      0.91       982\n",
            "           5       0.92      0.80      0.86       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.95      0.90      0.92      1028\n",
            "           8       0.89      0.90      0.89       974\n",
            "           9       0.88      0.92      0.90      1009\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.92      0.91      0.91     10000\n",
            "weighted avg       0.92      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    1    2    1    0    4    7    1    2    1]\n",
            " [   0 1097   10    5    0    1    4    2   16    0]\n",
            " [   7    3  924   26   11    0   12   12   32    5]\n",
            " [   5    0   16  922    1   36    0    9   13    8]\n",
            " [   1    2    9    0  900    0    6    3    5   56]\n",
            " [  10    4    9   87   16  715   17    9   17    8]\n",
            " [  18    2    6    3   16    8  901    0    4    0]\n",
            " [   2   11   29    2   12    1    0  924    3   44]\n",
            " [   3    9    5   42    7   14    7    4  873   10]\n",
            " [   7    1    1   15   28    1    0   10   15  931]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59620, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [27 12 46 46 45 44 35 33 54 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.418 s \n",
            "\n",
            "Accuracy rate for 91.650000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.97      0.95      0.96      1135\n",
            "           2       0.92      0.89      0.91      1032\n",
            "           3       0.88      0.89      0.88      1010\n",
            "           4       0.91      0.91      0.91       982\n",
            "           5       0.90      0.87      0.89       892\n",
            "           6       0.95      0.94      0.95       958\n",
            "           7       0.95      0.89      0.92      1028\n",
            "           8       0.86      0.91      0.88       974\n",
            "           9       0.87      0.92      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    1    1    0    6    9    1    4    1]\n",
            " [   0 1082    7    6    0    3    5    2   30    0]\n",
            " [   7    3  917   22   11    1   10   12   41    8]\n",
            " [   6    0   17  899    2   41    0   11   26    8]\n",
            " [   1    4    9    0  894    0    7    4    4   59]\n",
            " [   8    1    2   54   13  776   12    5   14    7]\n",
            " [  16    2    5    0   14   11  905    0    5    0]\n",
            " [   3   10   27    2   13    1    0  920    6   46]\n",
            " [   4    6    8   34    7   14    4    2  882   13]\n",
            " [   6    4    1    9   27    6    0   11   12  933]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59610, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [29 12 47 47 47 45 36 33 55 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.848 s \n",
            "\n",
            "Accuracy rate for 91.740000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.91      0.90      0.91      1032\n",
            "           3       0.89      0.90      0.89      1010\n",
            "           4       0.90      0.91      0.90       982\n",
            "           5       0.91      0.86      0.88       892\n",
            "           6       0.95      0.94      0.94       958\n",
            "           7       0.95      0.90      0.92      1028\n",
            "           8       0.87      0.91      0.89       974\n",
            "           9       0.88      0.91      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    4    1    0    4   12    1    4    0]\n",
            " [   0 1092   12    3    0    3    4    2   18    1]\n",
            " [   8    2  931   18    9    0   10   12   35    7]\n",
            " [   5    0   18  907    3   34    0   12   26    5]\n",
            " [   1    3    8    0  891    0    8    6    7   58]\n",
            " [   9    1    4   51   15  763   12    8   23    6]\n",
            " [  17    2    5    0   13   15  899    0    7    0]\n",
            " [   2   11   30    2   15    2    0  925    2   39]\n",
            " [   5    5    6   27    6   18    3    0  890   14]\n",
            " [   6    2    1   12   39    4    0    9   14  922]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [29 12 48 47 49 46 36 34 55 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.742 s \n",
            "\n",
            "Accuracy rate for 91.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.92      0.90      0.91      1032\n",
            "           3       0.90      0.89      0.90      1010\n",
            "           4       0.92      0.91      0.92       982\n",
            "           5       0.90      0.86      0.88       892\n",
            "           6       0.94      0.95      0.94       958\n",
            "           7       0.96      0.88      0.92      1028\n",
            "           8       0.88      0.92      0.90       974\n",
            "           9       0.84      0.93      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    3    0    1    5   10    1    5    1]\n",
            " [   0 1094    7    4    1    1    5    3   19    1]\n",
            " [   8    2  932   12   10    1   11   10   37    9]\n",
            " [   5    0   20  901    2   41    0    7   22   12]\n",
            " [   1    2    7    0  892    1    7    6    2   64]\n",
            " [   7    2    3   55   10  768   16    3   18   10]\n",
            " [  12    2    4    1   12   15  906    0    6    0]\n",
            " [   2   11   28    1    7    5    0  909    4   61]\n",
            " [   5    5    4   20    7   12    5    1  900   15]\n",
            " [   6    2    0    9   25    2    0   10   15  940]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59590, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [29 13 49 48 51 47 36 36 56 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.175 s \n",
            "\n",
            "Accuracy rate for 91.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       980\n",
            "           1       0.97      0.96      0.97      1135\n",
            "           2       0.91      0.90      0.91      1032\n",
            "           3       0.86      0.90      0.88      1010\n",
            "           4       0.92      0.91      0.92       982\n",
            "           5       0.90      0.84      0.87       892\n",
            "           6       0.95      0.95      0.95       958\n",
            "           7       0.94      0.90      0.92      1028\n",
            "           8       0.89      0.89      0.89       974\n",
            "           9       0.86      0.92      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    5    1    0    6   13    1    1    1]\n",
            " [   0 1088   11    7    1    2    4    4   18    0]\n",
            " [   9    2  930   17    6    0    8   19   32    9]\n",
            " [   4    1   18  913    0   36    0   14   14   10]\n",
            " [   1    2    7    0  892    0    6    4    3   67]\n",
            " [   5    2    6   74   13  753    9    6   19    5]\n",
            " [  10    3    5    2    8   13  908    1    7    1]\n",
            " [   1   10   25    2    8    2    0  928    5   47]\n",
            " [   4    9    8   39    8   19    5    3  866   13]\n",
            " [   6    2    2    9   30    8    0   10    9  933]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59580, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [30 13 50 48 51 50 36 39 57 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.940 s \n",
            "\n",
            "Accuracy rate for 91.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.92      0.90      0.91      1032\n",
            "           3       0.86      0.90      0.88      1010\n",
            "           4       0.92      0.91      0.91       982\n",
            "           5       0.90      0.84      0.87       892\n",
            "           6       0.95      0.95      0.95       958\n",
            "           7       0.93      0.92      0.92      1028\n",
            "           8       0.89      0.91      0.90       974\n",
            "           9       0.88      0.91      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    0    5    1    0    6   11    1    5    0]\n",
            " [   0 1089   10    6    0    1    4    3   21    1]\n",
            " [   7    1  928   17   14    1    6   19   30    9]\n",
            " [   5    1   20  911    0   36    0   16   16    5]\n",
            " [   1    1    7    0  896    0    7    6    2   62]\n",
            " [   9    2    5   79   11  749   10    5   17    5]\n",
            " [  15    2    3    1   12   10  910    0    5    0]\n",
            " [   2   10   25    1    4    5    1  943    4   33]\n",
            " [   6    4    7   28    6   14    4    4  890   11]\n",
            " [   5    3    1   10   34   10    1   18    8  919]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59570, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [30 13 51 50 53 52 36 39 58 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.989 s \n",
            "\n",
            "Accuracy rate for 91.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.98      0.97      0.97      1135\n",
            "           2       0.91      0.91      0.91      1032\n",
            "           3       0.89      0.89      0.89      1010\n",
            "           4       0.92      0.92      0.92       982\n",
            "           5       0.88      0.86      0.87       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.94      0.91      0.92      1028\n",
            "           8       0.90      0.90      0.90       974\n",
            "           9       0.86      0.92      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    0    7    1    2    8   11    1    1    1]\n",
            " [   0 1096   11    4    0    2    4    3   13    2]\n",
            " [   7    0  936   13   10    2    9   15   26   14]\n",
            " [   5    0   21  899    1   40    0   16   21    7]\n",
            " [   1    2    6    0  904    0    5    3    2   59]\n",
            " [  13    3   10   54   11  769    7    5   16    4]\n",
            " [  13    2    5    0   12   20  899    0    7    0]\n",
            " [   1    9   24    0    4    6    0  935    3   46]\n",
            " [   5    6   10   27    8   25    2    4  873   14]\n",
            " [   5    2    2    8   31    5    0   13   12  931]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59560, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [31 13 52 51 53 53 37 40 60 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.316 s \n",
            "\n",
            "Accuracy rate for 91.790000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.94      0.90      0.92      1032\n",
            "           3       0.86      0.90      0.88      1010\n",
            "           4       0.92      0.92      0.92       982\n",
            "           5       0.89      0.85      0.87       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.94      0.90      0.92      1028\n",
            "           8       0.89      0.91      0.90       974\n",
            "           9       0.85      0.92      0.88      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    0    2    1    2    7    8    1    3    1]\n",
            " [   0 1090    9    5    0    3    4    5   17    2]\n",
            " [   7    1  926   16    8    1    7   16   34   16]\n",
            " [   4    0   15  906    0   38    0   16   23    8]\n",
            " [   1    2    5    0  900    1    4    3    2   64]\n",
            " [   8    1    5   78   10  755   14    3   10    8]\n",
            " [  15    2    4    1   12   12  905    1    6    0]\n",
            " [   1    9   14    3    6    5    0  929    3   58]\n",
            " [   4    4    6   35    7   18    2    3  882   13]\n",
            " [   4    3    1   11   29   13    1   10    6  931]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [33 13 55 51 55 55 37 40 60 61] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.236 s \n",
            "\n",
            "Accuracy rate for 91.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.91      0.92      0.91      1032\n",
            "           3       0.88      0.89      0.88      1010\n",
            "           4       0.92      0.92      0.92       982\n",
            "           5       0.87      0.87      0.87       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.95      0.89      0.92      1028\n",
            "           8       0.90      0.89      0.90       974\n",
            "           9       0.85      0.92      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    1    7    0    1    9    9    1    1    1]\n",
            " [   0 1093   11    4    0    3    4    3   15    2]\n",
            " [   5    2  946   13    9    1    6   12   30    8]\n",
            " [   3    0   17  896    1   49    0   11   22   11]\n",
            " [   1    1    6    0  908    1    4    6    1   54]\n",
            " [   6    1    8   61    5  779   12    3    9    8]\n",
            " [  16    3    5    0   14   13  899    0    7    1]\n",
            " [   1   10   25    2    5    5    0  916    2   62]\n",
            " [   5    4    9   30   10   26    4    2  870   14]\n",
            " [   4    2    2    9   31   10    1   12    5  933]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59540, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [34 13 56 53 55 56 40 40 61 62] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.563 s \n",
            "\n",
            "Accuracy rate for 92.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       980\n",
            "           1       0.99      0.95      0.97      1135\n",
            "           2       0.91      0.93      0.92      1032\n",
            "           3       0.88      0.90      0.89      1010\n",
            "           4       0.94      0.91      0.92       982\n",
            "           5       0.88      0.87      0.87       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.94      0.91      0.92      1028\n",
            "           8       0.89      0.91      0.90       974\n",
            "           9       0.87      0.93      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    7    1    0    6    9    1    4    0]\n",
            " [   0 1082    7    6    1    2    4    5   27    1]\n",
            " [   6    0  957   12    6    0    4   14   25    8]\n",
            " [   4    0   17  909    1   38    0   14   23    4]\n",
            " [   1    2    9    0  895    1    5    3    5   61]\n",
            " [   7    1    9   64    4  775   10    4    7   11]\n",
            " [  12    2    5    0   13   19  899    0    8    0]\n",
            " [   1    7   32    2    3    5    0  931    3   44]\n",
            " [   6    2    5   31    7   22    2    2  888    9]\n",
            " [   4    2    1   10   26   13    1   13    4  935]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59530, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [35 14 56 54 56 57 40 44 61 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.960 s \n",
            "\n",
            "Accuracy rate for 92.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.91      0.92      0.91      1032\n",
            "           3       0.87      0.90      0.88      1010\n",
            "           4       0.92      0.92      0.92       982\n",
            "           5       0.88      0.85      0.87       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.93      0.92      0.93      1028\n",
            "           8       0.92      0.90      0.91       974\n",
            "           9       0.89      0.90      0.89      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    0    8    2    2    4   11    2    1    0]\n",
            " [   0 1095   12    5    0    2    4    4   12    1]\n",
            " [   7    4  951   16    5    1    7   14   21    6]\n",
            " [   4    0   18  906    1   39    0   17   18    7]\n",
            " [   1    0    6    0  906    1    4    4    4   56]\n",
            " [   9    3   10   77    5  761    6    3   10    8]\n",
            " [  11    2    4    1   12   17  904    0    7    0]\n",
            " [   1    8   29    0    5    5    0  949    2   29]\n",
            " [   5    4   10   28    7   22    7    5  875   11]\n",
            " [   4    3    1    8   44   12    1   20    5  911]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59520, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [36 14 56 55 56 60 40 45 64 64] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.504 s \n",
            "\n",
            "Accuracy rate for 92.410000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       980\n",
            "           1       0.98      0.97      0.97      1135\n",
            "           2       0.92      0.92      0.92      1032\n",
            "           3       0.88      0.89      0.89      1010\n",
            "           4       0.94      0.91      0.93       982\n",
            "           5       0.89      0.87      0.88       892\n",
            "           6       0.97      0.95      0.96       958\n",
            "           7       0.94      0.92      0.93      1028\n",
            "           8       0.90      0.90      0.90       974\n",
            "           9       0.87      0.92      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    5    1    0    5    7    1    3    1]\n",
            " [   0 1098   13    3    0    1    4    5   10    1]\n",
            " [   8    2  949   16    7    1    3   18   20    8]\n",
            " [   6    0   21  899    1   40    0   14   22    7]\n",
            " [   1    1   10    0  898    0    4    2    4   62]\n",
            " [   4    2    3   66    3  775    7    3   18   11]\n",
            " [  13    2    2    0   13   13  906    0    9    0]\n",
            " [   0    9   23    1    5    3    0  948    4   35]\n",
            " [   5    7    7   24    6   25    4    3  880   13]\n",
            " [   4    3    1    8   24   12    1   17    8  931]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59510, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [36 14 58 56 58 62 40 46 65 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.791 s \n",
            "\n",
            "Accuracy rate for 92.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       980\n",
            "           1       0.98      0.96      0.97      1135\n",
            "           2       0.91      0.93      0.92      1032\n",
            "           3       0.90      0.88      0.89      1010\n",
            "           4       0.93      0.93      0.93       982\n",
            "           5       0.85      0.91      0.88       892\n",
            "           6       0.96      0.94      0.95       958\n",
            "           7       0.94      0.93      0.93      1028\n",
            "           8       0.92      0.90      0.91       974\n",
            "           9       0.90      0.91      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    0    4    1    2   10   11    1    2    0]\n",
            " [   0 1093   18    2    0    4    4    3   10    1]\n",
            " [   8    1  957   16    7    1    4   13   17    8]\n",
            " [   6    0   21  890    0   49    0   18   19    7]\n",
            " [   1    2    6    0  909    3    4    6    2   49]\n",
            " [   8    1    4   43    4  811    6    2    7    6]\n",
            " [  13    3    2    1   12   19  902    0    6    0]\n",
            " [   2    7   34    1    3    2    0  951    5   23]\n",
            " [   5    6    9   25    3   36    5    4  873    8]\n",
            " [   5    3    1    9   33   15    1   17    6  919]]\n",
            "--------------------------------\n",
            "final active learning accuracies [24.610000000000003, 39.07, 52.59, 60.88, 61.24000000000001, 67.75999999999999, 72.24000000000001, 74.92, 78.81, 79.96, 81.24, 82.33, 83.39999999999999, 85.04, 84.06, 85.28999999999999, 84.85000000000001, 85.45, 86.29, 86.78, 87.19, 87.11, 88.28, 88.01, 88.49000000000001, 88.3, 89.01, 89.29, 89.67, 90.22, 90.2, 90.22, 90.53, 91.07, 90.64, 90.96, 91.17, 91.47999999999999, 91.64999999999999, 91.74, 91.96, 91.63, 91.86, 91.9, 91.79, 91.9, 92.23, 92.08, 92.41, 92.54]\n",
            "saved Active-learning-experiment-25.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.610000000000003,\n",
            "          39.07,\n",
            "          52.59,\n",
            "          60.88,\n",
            "          61.24000000000001,\n",
            "          67.75999999999999,\n",
            "          72.24000000000001,\n",
            "          74.92,\n",
            "          78.81,\n",
            "          79.96,\n",
            "          81.24,\n",
            "          82.33,\n",
            "          83.39999999999999,\n",
            "          85.04,\n",
            "          84.06,\n",
            "          85.28999999999999,\n",
            "          84.85000000000001,\n",
            "          85.45,\n",
            "          86.29,\n",
            "          86.78,\n",
            "          87.19,\n",
            "          87.11,\n",
            "          88.28,\n",
            "          88.01,\n",
            "          88.49000000000001,\n",
            "          88.3,\n",
            "          89.01,\n",
            "          89.29,\n",
            "          89.67,\n",
            "          90.22,\n",
            "          90.2,\n",
            "          90.22,\n",
            "          90.53,\n",
            "          91.07,\n",
            "          90.64,\n",
            "          90.96,\n",
            "          91.17,\n",
            "          91.47999999999999,\n",
            "          91.64999999999999,\n",
            "          91.74,\n",
            "          91.96,\n",
            "          91.63,\n",
            "          91.86,\n",
            "          91.9,\n",
            "          91.79,\n",
            "          91.9,\n",
            "          92.23,\n",
            "          92.08,\n",
            "          92.41,\n",
            "          92.54\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.8,\n",
            "          83.47,\n",
            "          89.21,\n",
            "          91.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.74999999999999,\n",
            "          66.17,\n",
            "          70.77,\n",
            "          77.29,\n",
            "          81.23,\n",
            "          82.98,\n",
            "          86.08,\n",
            "          88.09,\n",
            "          88.42,\n",
            "          88.94999999999999,\n",
            "          89.01,\n",
            "          89.88000000000001,\n",
            "          90.82000000000001,\n",
            "          91.28,\n",
            "          91.4,\n",
            "          92.01,\n",
            "          92.36999999999999,\n",
            "          91.9,\n",
            "          92.80000000000001,\n",
            "          93.22\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.06,\n",
            "          90.36\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          54.059999999999995,\n",
            "          71.72,\n",
            "          78.44,\n",
            "          83.62,\n",
            "          86.50999999999999,\n",
            "          88.63,\n",
            "          89.85,\n",
            "          91.10000000000001,\n",
            "          91.59,\n",
            "          91.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 26, using model = RfModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [24 43 21 23 21 11 24 23 31 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.893 s \n",
            "\n",
            "Accuracy rate for 80.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       980\n",
            "           1       0.76      0.99      0.86      1135\n",
            "           2       0.95      0.75      0.84      1032\n",
            "           3       0.79      0.79      0.79      1010\n",
            "           4       0.87      0.70      0.77       982\n",
            "           5       0.93      0.35      0.51       892\n",
            "           6       0.82      0.92      0.87       958\n",
            "           7       0.88      0.84      0.86      1028\n",
            "           8       0.73      0.85      0.78       974\n",
            "           9       0.69      0.89      0.78      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.83      0.80      0.80     10000\n",
            "weighted avg       0.83      0.81      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    3    0    0    0    1   36    1    9    0]\n",
            " [   0 1121    0    4    0    0    5    0    5    0]\n",
            " [  21   87  777   20   11    1   26   38   43    8]\n",
            " [  16   53   12  793    0   18    9   14   72   23]\n",
            " [   2   15    3    0  686    0   34   10   10  222]\n",
            " [  75   77    0  158   25  312   56   20  137   32]\n",
            " [  28   15    2    0   24    2  882    2    2    1]\n",
            " [  11   43   19    0   12    0    0  866    5   72]\n",
            " [   6   46    3   16    5    2   18   10  827   41]\n",
            " [  12   13    1    8   29    0    5   19   26  896]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '1']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 41 240  24  23  25  13  25  43  31  35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.758 s \n",
            "\n",
            "Accuracy rate for 81.050000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       980\n",
            "           1       0.67      1.00      0.80      1135\n",
            "           2       0.96      0.77      0.85      1032\n",
            "           3       0.80      0.73      0.77      1010\n",
            "           4       0.89      0.73      0.80       982\n",
            "           5       0.91      0.43      0.58       892\n",
            "           6       0.85      0.90      0.88       958\n",
            "           7       0.87      0.86      0.86      1028\n",
            "           8       0.80      0.78      0.79       974\n",
            "           9       0.71      0.89      0.79      1009\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.83      0.80      0.80     10000\n",
            "weighted avg       0.83      0.81      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    3    0    0    0    2   25    1    4    1]\n",
            " [   0 1130    1    1    0    0    1    1    1    0]\n",
            " [  27   90  793   12    5    0   23   45   25   12]\n",
            " [  14   99   16  740    1   28    5   17   63   27]\n",
            " [   2   34    3    0  718    0   25   13    2  185]\n",
            " [  66  126    0  144   24  382   44   14   72   20]\n",
            " [  31   25    2    0   21    4  864    7    3    1]\n",
            " [   6   61   10    0   11    0    1  883    1   55]\n",
            " [  11   91    4   12    8    4   20   10  755   59]\n",
            " [  14   26    1   11   17    0    5   26   13  896]]\n",
            "--------------------------------\n",
            "final active learning accuracies [80.9, 81.05]\n",
            "saved Active-learning-experiment-26.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 27, using model = RfModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [ 9 18 12 11 11 11 13 16 12 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.935 s \n",
            "\n",
            "Accuracy rate for 77.100000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.82      0.87       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.82      0.68      0.75      1032\n",
            "           3       0.70      0.69      0.69      1010\n",
            "           4       0.78      0.73      0.75       982\n",
            "           5       0.78      0.70      0.74       892\n",
            "           6       0.76      0.92      0.84       958\n",
            "           7       0.75      0.86      0.81      1028\n",
            "           8       0.73      0.67      0.70       974\n",
            "           9       0.75      0.64      0.69      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.77      0.77     10000\n",
            "weighted avg       0.77      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 803    0   18   21    0   81   36    1   19    1]\n",
            " [   0 1089   21    2    0    4    5    1   13    0]\n",
            " [  19   91  705   41   10    2   78   32   41   13]\n",
            " [   6   62   51  693    9   42   10   29   96   12]\n",
            " [   2   19    8    0  717    2   60   30   12  132]\n",
            " [   7   34    3  110   25  625   42    8   30    8]\n",
            " [  14   17    9    1   11   18  885    0    2    1]\n",
            " [   3   48   21    2   10    3    4  889    7   41]\n",
            " [   1   77   17  108   18   21   30   34  655   13]\n",
            " [  10   21    7   13  122    3   10  154   20  649]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 18 103  16  12  12  11  13  20  12  33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.958 s \n",
            "\n",
            "Accuracy rate for 73.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       980\n",
            "           1       0.59      0.99      0.74      1135\n",
            "           2       0.89      0.68      0.77      1032\n",
            "           3       0.76      0.62      0.68      1010\n",
            "           4       0.91      0.43      0.58       982\n",
            "           5       0.78      0.59      0.67       892\n",
            "           6       0.84      0.87      0.86       958\n",
            "           7       0.93      0.72      0.81      1028\n",
            "           8       0.80      0.57      0.67       974\n",
            "           9       0.49      0.91      0.64      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.79      0.73      0.73     10000\n",
            "weighted avg       0.78      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 844    1    9   10    0   65   23    3   20    5]\n",
            " [   0 1127    2    0    0    0    4    1    0    1]\n",
            " [  33  158  702   17    5    2   49   14   18   34]\n",
            " [   5  147   31  631    2   46    7   12   59   70]\n",
            " [   8   31    3    0  421    0   32    1    3  483]\n",
            " [  14   91    2  107    6  525   23    1   21  102]\n",
            " [  43   40    2    0    8   20  836    0    3    6]\n",
            " [   7   87   14    1    2    0    2  740    4  171]\n",
            " [   6  190   23   62    4   13   18   11  558   89]\n",
            " [  16   27    4    5   14    1    1   13   10  918]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [ 24 200  18  13  13  12  13  30  12  40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.996 s \n",
            "\n",
            "Accuracy rate for 73.330000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87       980\n",
            "           1       0.53      1.00      0.69      1135\n",
            "           2       0.90      0.67      0.77      1032\n",
            "           3       0.75      0.60      0.67      1010\n",
            "           4       0.91      0.49      0.64       982\n",
            "           5       0.80      0.58      0.67       892\n",
            "           6       0.86      0.86      0.86       958\n",
            "           7       0.91      0.79      0.85      1028\n",
            "           8       0.82      0.52      0.63       974\n",
            "           9       0.54      0.91      0.68      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.79      0.73      0.73     10000\n",
            "weighted avg       0.79      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 846    7   12   10    0   62   25    1   14    3]\n",
            " [   0 1132    1    0    0    0    1    0    0    1]\n",
            " [  25  204  693   20    5    1   32   16   13   23]\n",
            " [   2  196   26  607    2   30    4   19   54   70]\n",
            " [   9   34    4    0  486    0   29    4    0  416]\n",
            " [  14  128    2  105   11  518   20    2   16   76]\n",
            " [  47   55    2    1   11   16  821    0    3    2]\n",
            " [   6   98   13    1    4    1    0  809    3   93]\n",
            " [  12  246   11   56   12   16   16   14  505   86]\n",
            " [  14   27    5    6    6    2    3   20   10  916]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 29 286  20  13  13  12  13  51  12  51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.945 s \n",
            "\n",
            "Accuracy rate for 72.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85       980\n",
            "           1       0.56      1.00      0.71      1135\n",
            "           2       0.89      0.70      0.78      1032\n",
            "           3       0.75      0.59      0.66      1010\n",
            "           4       0.93      0.43      0.59       982\n",
            "           5       0.77      0.54      0.63       892\n",
            "           6       0.85      0.85      0.85       958\n",
            "           7       0.88      0.83      0.86      1028\n",
            "           8       0.82      0.51      0.63       974\n",
            "           9       0.51      0.92      0.65      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.78      0.72      0.72     10000\n",
            "weighted avg       0.78      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 811    3    6   16    0   77   39    9   14    5]\n",
            " [   0 1131    2    0    0    0    1    1    0    0]\n",
            " [  29  173  719   13    5    2   30   27   10   24]\n",
            " [   1  177   35  597    0   27    5   23   49   96]\n",
            " [  11   26    1    0  422    4   31    5    0  482]\n",
            " [   8  113    4  115    5  480   19   14   17  117]\n",
            " [  51   54    4    0   14   16  812    0    0    7]\n",
            " [   3   83    7    0    0    1    0  856    6   72]\n",
            " [   9  253   27   48    7   12   15   11  500   92]\n",
            " [  14   20    3    5    2    1    3   25   11  925]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.10000000000001, 73.02, 73.33, 72.53]\n",
            "saved Active-learning-experiment-27.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 28, using model = RfModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [ 4  3  3  6 11  3  5  6  2  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.739 s \n",
            "\n",
            "Accuracy rate for 58.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.92      0.81       980\n",
            "           1       0.73      0.90      0.81      1135\n",
            "           2       0.83      0.24      0.37      1032\n",
            "           3       0.46      0.63      0.53      1010\n",
            "           4       0.41      0.84      0.55       982\n",
            "           5       0.94      0.26      0.41       892\n",
            "           6       0.81      0.75      0.78       958\n",
            "           7       0.70      0.65      0.68      1028\n",
            "           8       0.82      0.13      0.22       974\n",
            "           9       0.36      0.51      0.42      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.68      0.58      0.56     10000\n",
            "weighted avg       0.68      0.59      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    1   10    1   26    1   34    0    0    9]\n",
            " [   0 1026    1    6   45    0    2    8    8   39]\n",
            " [  55  175  247   99  311    1   57   40   18   29]\n",
            " [ 108   24    9  634   12    0   10   25    1  187]\n",
            " [   0   15    1    4  826    0    4   28    0  104]\n",
            " [ 107   34    9  219   60  233   23    5    0  202]\n",
            " [  37   22    5    8  137    1  721    2    0   25]\n",
            " [  18   33    5   10   66    4    0  673    0  219]\n",
            " [  12   70    9  355  244    6   35   26  124   93]\n",
            " [   9    6    2   42  279    1    1  153    0  516]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '9' '0' '4']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 9 0 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 5  9  3  9 19  3  5 29  2 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.356 s \n",
            "\n",
            "Accuracy rate for 62.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.83      0.81       980\n",
            "           1       0.76      0.93      0.84      1135\n",
            "           2       0.80      0.25      0.38      1032\n",
            "           3       0.51      0.72      0.59      1010\n",
            "           4       0.46      0.90      0.61       982\n",
            "           5       0.94      0.18      0.31       892\n",
            "           6       0.74      0.60      0.66       958\n",
            "           7       0.57      0.92      0.70      1028\n",
            "           8       0.71      0.15      0.25       974\n",
            "           9       0.59      0.65      0.62      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.69      0.61      0.58     10000\n",
            "weighted avg       0.68      0.62      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 818    5   13    5   11    1   68   51    1    7]\n",
            " [   0 1051    1   16   24    0    2    6   29    6]\n",
            " [  40  120  254  119  285    0   58  116   26   14]\n",
            " [  46   31   12  723    7    0    4  133    4   50]\n",
            " [   1   11    0   12  883    0    2   29    0   44]\n",
            " [  63   61   13  176   85  165   22  124    1  182]\n",
            " [  36   26    8   32  265    1  572   12    0    6]\n",
            " [   1   22    3   19   28    2    0  943    0   10]\n",
            " [  23   44   11  307  196    5   40   55  147  146]\n",
            " [   3    7    2   17  133    2    2  184    0  659]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['7' '0' '4' ... '7' '6' '4']\n",
            "probabilities: (59900, 10) \n",
            " [7 0 4 ... 7 6 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 5 17  4  9 26  4  6 47  2 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.501 s \n",
            "\n",
            "Accuracy rate for 62.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       980\n",
            "           1       0.67      0.94      0.78      1135\n",
            "           2       0.86      0.26      0.39      1032\n",
            "           3       0.56      0.59      0.58      1010\n",
            "           4       0.53      0.85      0.65       982\n",
            "           5       0.86      0.20      0.32       892\n",
            "           6       0.71      0.66      0.68       958\n",
            "           7       0.65      0.92      0.76      1028\n",
            "           8       0.69      0.14      0.23       974\n",
            "           9       0.47      0.82      0.60      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.68      0.62      0.58     10000\n",
            "weighted avg       0.68      0.63      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 792    7    8    4   14   13   85   44    1   12]\n",
            " [   0 1064    1   13   23    0    2    3   25    4]\n",
            " [  39  169  264   80  202    0   84   90   33   71]\n",
            " [  42   78   12  597    8   11    8  130    3  121]\n",
            " [   2   14    0    2  835    0    2   12    0  115]\n",
            " [  41   86    9  108   67  177   30   92    0  282]\n",
            " [  38   44    5   18  201    2  631    7    0   12]\n",
            " [   1   28    3   10   12    0    0  942    0   32]\n",
            " [  21   81    2  221  151    4   42   36  137  279]\n",
            " [   4   12    2    9   66    0    1   87    0  828]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['9' '0' '4' ... '9' '0' '0']\n",
            "probabilities: (59850, 10) \n",
            " [9 0 4 ... 9 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 5 27  4  9 38  4  6 62  3 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.175 s \n",
            "\n",
            "Accuracy rate for 61.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.69      0.76       980\n",
            "           1       0.66      0.94      0.78      1135\n",
            "           2       0.88      0.22      0.36      1032\n",
            "           3       0.74      0.50      0.59      1010\n",
            "           4       0.50      0.87      0.63       982\n",
            "           5       0.91      0.17      0.28       892\n",
            "           6       0.60      0.64      0.62       958\n",
            "           7       0.62      0.91      0.74      1028\n",
            "           8       0.74      0.26      0.38       974\n",
            "           9       0.45      0.85      0.58      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.70      0.60      0.57     10000\n",
            "weighted avg       0.69      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 676    3    5    0   11    9  128  119    0   29]\n",
            " [   0 1072    0    1   22    0    1    3   35    1]\n",
            " [  13  174  230   37  209    0  162   79   36   92]\n",
            " [  29  107   14  500    8    5   16  152   10  169]\n",
            " [   0   13    0    1  850    0    2   11    0  105]\n",
            " [  30   78    6   62   94  149   37   97    3  336]\n",
            " [  25   36    3    4  251    0  609   13    1   16]\n",
            " [   0   36    1    3   19    0    1  933    1   34]\n",
            " [  15   94    1   64  193    1   50   22  252  282]\n",
            " [   0   13    2    6   54    0    2   74    1  857]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['9' '0' '4' ... '9' '6' '9']\n",
            "probabilities: (59800, 10) \n",
            " [9 0 4 ... 9 6 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 5 37  4 10 48  4  6 81  3 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.103 s \n",
            "\n",
            "Accuracy rate for 60.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79       980\n",
            "           1       0.65      0.94      0.77      1135\n",
            "           2       0.88      0.25      0.39      1032\n",
            "           3       0.66      0.39      0.49      1010\n",
            "           4       0.57      0.82      0.67       982\n",
            "           5       0.81      0.15      0.25       892\n",
            "           6       0.69      0.64      0.67       958\n",
            "           7       0.56      0.92      0.70      1028\n",
            "           8       0.69      0.26      0.37       974\n",
            "           9       0.41      0.87      0.56      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.68      0.60      0.56     10000\n",
            "weighted avg       0.68      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 711    3    4    0    5   14   74  121    1   47]\n",
            " [   0 1067    1    6   21    0    1    9   30    0]\n",
            " [  14  176  258   63  160    0  117   92   63   89]\n",
            " [  28  119   17  392    2   12   12  195   10  223]\n",
            " [   0   15    0    0  809    0    2   21    0  135]\n",
            " [  33   76    7   49   66  131   28  140    5  357]\n",
            " [  29   45    2    4  211    1  612   25    0   29]\n",
            " [   0   32    1    7   12    0    0  944    3   29]\n",
            " [  12   95    3   73  117    4   35   53  250  332]\n",
            " [   1   13    1    2   28    0    1   86    1  876]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['7' '0' '4' ... '7' '7' '9']\n",
            "probabilities: (59750, 10) \n",
            " [7 0 4 ... 7 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 5 49  4 11 53  4  6 98  3 67] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.690 s \n",
            "\n",
            "Accuracy rate for 59.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77       980\n",
            "           1       0.64      0.94      0.76      1135\n",
            "           2       0.90      0.22      0.36      1032\n",
            "           3       0.73      0.43      0.54      1010\n",
            "           4       0.53      0.81      0.64       982\n",
            "           5       0.90      0.13      0.23       892\n",
            "           6       0.67      0.59      0.63       958\n",
            "           7       0.60      0.90      0.72      1028\n",
            "           8       0.71      0.18      0.28       974\n",
            "           9       0.39      0.91      0.55      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.69      0.58      0.55     10000\n",
            "weighted avg       0.69      0.59      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 700    7    6    1   18    8   87  118    0   35]\n",
            " [   0 1070    0    2   33    0    1    8   20    1]\n",
            " [  25  188  232   34  194    0  116  100   38  105]\n",
            " [  38  106   12  431   16    3   15  177    6  206]\n",
            " [   0   10    0    0  797    0    1   13    0  161]\n",
            " [  32   90    5   44   71  120   28  105    1  396]\n",
            " [  31   61    2    6  234    2  565   12    0   45]\n",
            " [   0   30    1    5   13    0    0  924    3   52]\n",
            " [  16  104    0   69  108    1   31   42  172  431]\n",
            " [   1   12    1    1   24    0    1   50    1  918]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['7' '0' '4' ... '9' '7' '9']\n",
            "probabilities: (59700, 10) \n",
            " [7 0 4 ... 9 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [  5  65   4  13  59   4   6 117   3  74] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.174 s \n",
            "\n",
            "Accuracy rate for 60.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.71      0.77       980\n",
            "           1       0.66      0.95      0.78      1135\n",
            "           2       0.92      0.22      0.35      1032\n",
            "           3       0.74      0.53      0.62      1010\n",
            "           4       0.55      0.81      0.65       982\n",
            "           5       0.82      0.16      0.27       892\n",
            "           6       0.69      0.58      0.63       958\n",
            "           7       0.60      0.91      0.73      1028\n",
            "           8       0.76      0.16      0.26       974\n",
            "           9       0.39      0.93      0.55      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.70      0.59      0.56     10000\n",
            "weighted avg       0.70      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 694    2    2    1   17   14   75  116    0   59]\n",
            " [   0 1077    0    1   35    0    1    7   14    0]\n",
            " [  20  182  224   50  183    0   96  136   25  116]\n",
            " [  28   95    7  532    8   14   21  156    5  144]\n",
            " [   0    8    0    0  794    0    2   14    0  164]\n",
            " [  31   71    3   52   55  141   24   91    0  424]\n",
            " [  38   41    2    3  224    0  559   22    0   69]\n",
            " [   0   26    2    3   14    0    0  938    3   42]\n",
            " [  15  113    2   74  103    2   31   36  151  447]\n",
            " [   1   14    2    2   14    0    1   36    1  938]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['7' '0' '4' ... '9' '0' '9']\n",
            "probabilities: (59650, 10) \n",
            " [7 0 4 ... 9 0 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [  5  79   4  14  63   4   6 133   3  89] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.837 s \n",
            "\n",
            "Accuracy rate for 60.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.70      0.75       980\n",
            "           1       0.65      0.96      0.77      1135\n",
            "           2       0.92      0.20      0.33      1032\n",
            "           3       0.76      0.53      0.63      1010\n",
            "           4       0.58      0.78      0.67       982\n",
            "           5       0.90      0.12      0.20       892\n",
            "           6       0.75      0.59      0.66       958\n",
            "           7       0.60      0.91      0.72      1028\n",
            "           8       0.69      0.20      0.31       974\n",
            "           9       0.37      0.93      0.53      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.70      0.59      0.56     10000\n",
            "weighted avg       0.70      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 682    2    5    1    4    4   50  148    0   84]\n",
            " [   0 1088    0    3   14    0    1    4   25    0]\n",
            " [  19  204  211   49  176    1   80  118   44  130]\n",
            " [  35   85    8  538    5    5   12  161    7  154]\n",
            " [   0    9    0    0  769    0    1   10    0  193]\n",
            " [  50   76    2   38   54  103   25  101    6  437]\n",
            " [  30   46    0    5  200    1  563   23    0   90]\n",
            " [   0   29    1    3   13    0    0  931    2   49]\n",
            " [  15  129    2   66   69    1   20   30  193  449]\n",
            " [   1   16    1    1   12    0    1   37    1  939]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['7' '0' '4' ... '9' '9' '9']\n",
            "probabilities: (59600, 10) \n",
            " [7 0 4 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [  5  91   4  15  73   5   7 146   3 101] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.851 s \n",
            "\n",
            "Accuracy rate for 60.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.67      0.77       980\n",
            "           1       0.66      0.96      0.78      1135\n",
            "           2       0.92      0.14      0.24      1032\n",
            "           3       0.78      0.62      0.69      1010\n",
            "           4       0.51      0.81      0.62       982\n",
            "           5       0.90      0.18      0.31       892\n",
            "           6       0.65      0.62      0.64       958\n",
            "           7       0.58      0.91      0.71      1028\n",
            "           8       0.81      0.18      0.29       974\n",
            "           9       0.41      0.91      0.57      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.72      0.60      0.56     10000\n",
            "weighted avg       0.71      0.61      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 657    3    6    1   18    6   70  152    0   67]\n",
            " [   0 1084    0    1   36    0    1    5    8    0]\n",
            " [   9  191  141   44  223    0  153  152   24   95]\n",
            " [  14   64    2  623   11   10   29  138    5  114]\n",
            " [   0   11    0    0  794    0    1   11    0  165]\n",
            " [  14   68    2   61   66  165   35  108    1  372]\n",
            " [  16   40    0    3  252    0  595   10    0   42]\n",
            " [   0   29    0    3   13    0    0  935    1   47]\n",
            " [   5  126    1   59  129    1   31   46  172  404]\n",
            " [   1   19    1    1   20    1    1   44    1  920]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['7' '0' '4' ... '9' '4' '9']\n",
            "probabilities: (59550, 10) \n",
            " [7 0 4 ... 9 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [  5 107   4  16  78   6   7 164   4 109] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.658 s \n",
            "\n",
            "Accuracy rate for 59.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.77       980\n",
            "           1       0.63      0.97      0.76      1135\n",
            "           2       0.90      0.17      0.29      1032\n",
            "           3       0.79      0.51      0.62      1010\n",
            "           4       0.57      0.80      0.66       982\n",
            "           5       0.91      0.15      0.25       892\n",
            "           6       0.68      0.58      0.63       958\n",
            "           7       0.59      0.91      0.72      1028\n",
            "           8       0.76      0.15      0.25       974\n",
            "           9       0.37      0.93      0.53      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.71      0.59      0.55     10000\n",
            "weighted avg       0.71      0.60      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 662    3    7    0   10    7   56  158    0   77]\n",
            " [   0 1105    0    1   16    0    0    4    8    1]\n",
            " [  11  218  176   40  176    0  123  141   24  123]\n",
            " [  17   80    8  515   11    6   22  153   10  188]\n",
            " [   0   11    0    0  787    0    2   10    0  172]\n",
            " [  12   93    3   35   47  130   26   86    2  458]\n",
            " [  20   48    1    0  227    0  560   24    0   78]\n",
            " [   0   31    0    3   10    0    0  932    2   50]\n",
            " [  12  150    0   59   93    0   29   28  145  458]\n",
            " [   0   16    0    0   15    0    1   33    1  943]]\n",
            "--------------------------------\n",
            "final active learning accuracies [58.98, 62.150000000000006, 62.67, 61.28, 60.5, 59.29, 60.480000000000004, 60.17, 60.86, 59.550000000000004]\n",
            "saved Active-learning-experiment-28.pkl /content ['.config', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 29, using model = RfModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [1 3 1 5 1 0 4 5 2 3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.530 s \n",
            "\n",
            "Accuracy rate for 41.730000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.09      0.16       980\n",
            "           1       0.52      0.86      0.65      1135\n",
            "           2       0.95      0.15      0.25      1032\n",
            "           3       0.31      0.77      0.44      1010\n",
            "           4       0.81      0.03      0.06       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.43      0.83      0.56       958\n",
            "           7       0.37      0.81      0.51      1028\n",
            "           8       0.64      0.18      0.28       974\n",
            "           9       0.37      0.35      0.36      1009\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.52      0.41      0.33     10000\n",
            "weighted avg       0.52      0.42      0.34     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 90  51   3 589   0   0  33 148  31  35]\n",
            " [  0 972   0  23   0   0 139   0   0   1]\n",
            " [  1  93 150 344   0   0 364  43  28   9]\n",
            " [  2 133   0 774   0   0  13  51  12  25]\n",
            " [  0  71   1   0  29   0 176 397   2 306]\n",
            " [  6 198   0 364   0   0  63 115  17 129]\n",
            " [ 12  45   4  30   2   0 795  67   0   3]\n",
            " [  0 111   0  11   2   0  36 829   2  37]\n",
            " [  8 125   0 344   1   0 182  76 177  61]\n",
            " [  0  68   0  20   2   0  66 488   8 357]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '3' '1' ... '1' '6' '6']\n",
            "probabilities: (59975, 9) \n",
            " [3 3 1 ... 1 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 1  7  1  9  4  4  4  7  2 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.949 s \n",
            "\n",
            "Accuracy rate for 45.420000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.17      0.26       980\n",
            "           1       0.66      0.80      0.72      1135\n",
            "           2       0.93      0.20      0.33      1032\n",
            "           3       0.28      0.87      0.43      1010\n",
            "           4       0.89      0.09      0.17       982\n",
            "           5       0.47      0.12      0.19       892\n",
            "           6       0.51      0.71      0.59       958\n",
            "           7       0.47      0.81      0.60      1028\n",
            "           8       0.87      0.07      0.13       974\n",
            "           9       0.40      0.59      0.48      1009\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.60      0.44      0.39     10000\n",
            "weighted avg       0.61      0.45      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[171   9   3 662   0  14  28  67   3  23]\n",
            " [  0 904   0  11   0   0 186   0   0  34]\n",
            " [  6  78 208 454   0   2 238  34   3   9]\n",
            " [ 17  29   1 881   0  17   4  22   2  37]\n",
            " [ 12  53   1  12  90   0  78 351   0 385]\n",
            " [ 28  83   0 426   0 106  27  49   0 173]\n",
            " [ 61  57  10  86   0   0 682  57   0   5]\n",
            " [  0  79   0  14   2   4  19 834   1  75]\n",
            " [ 16  50   0 528   0  69  57  38  69 147]\n",
            " [  6  22   0  36   9  12  19 307   1 597]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '3' '1' ... '5' '1' '6']\n",
            "probabilities: (59950, 10) \n",
            " [3 3 1 ... 5 1 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 1 20  1  9  4  4  4 14  2 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.019 s \n",
            "\n",
            "Accuracy rate for 46.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.26      0.35       980\n",
            "           1       0.55      0.99      0.70      1135\n",
            "           2       0.91      0.26      0.40      1032\n",
            "           3       0.32      0.82      0.46      1010\n",
            "           4       0.95      0.02      0.04       982\n",
            "           5       0.66      0.09      0.15       892\n",
            "           6       0.74      0.59      0.65       958\n",
            "           7       0.46      0.87      0.60      1028\n",
            "           8       0.79      0.07      0.13       974\n",
            "           9       0.34      0.57      0.42      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.63      0.45      0.39     10000\n",
            "weighted avg       0.63      0.47      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 253   22    6  543    0    8   19   63    2   64]\n",
            " [   0 1121    0    5    0    0    8    0    0    1]\n",
            " [  13  254  266  296    0    1  111   57   11   23]\n",
            " [  20   85    1  825    0    7    2   28    3   39]\n",
            " [  18   67    2    3   19    0   32  374    0  467]\n",
            " [  22  105    1  395    0   77   11   38    0  243]\n",
            " [  94   71   12   94    1    0  562   82    0   42]\n",
            " [   1   84    2    0    0    0    1  895    1   44]\n",
            " [  21  217    1  378    0   23   12   41   69  212]\n",
            " [   5   26    0   23    0    1    3  378    1  572]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '3' '1' ... '5' '6' '9']\n",
            "probabilities: (59925, 10) \n",
            " [3 3 1 ... 5 6 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 1 26  1 10  7  7  4 20  3 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.037 s \n",
            "\n",
            "Accuracy rate for 49.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.22      0.32       980\n",
            "           1       0.61      0.99      0.75      1135\n",
            "           2       0.78      0.25      0.38      1032\n",
            "           3       0.32      0.83      0.46      1010\n",
            "           4       0.86      0.07      0.13       982\n",
            "           5       0.74      0.17      0.28       892\n",
            "           6       0.70      0.60      0.65       958\n",
            "           7       0.47      0.89      0.62      1028\n",
            "           8       0.88      0.12      0.22       974\n",
            "           9       0.40      0.65      0.50      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.64      0.48      0.43     10000\n",
            "weighted avg       0.63      0.49      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 214    7    4  559    0   25   26  113    0   32]\n",
            " [   0 1122    0    7    0    0    5    0    0    1]\n",
            " [  13  214  255  338    0    3  132   55    6   16]\n",
            " [  18   71    3  834    0    1    2   23    1   57]\n",
            " [  14   49    1    6   70    0   36  389    0  417]\n",
            " [  20   84    0  381    9  154   18   57    3  166]\n",
            " [  56   72   61   98    1    3  578   72    0   17]\n",
            " [   0   67    0    2    0    0    5  919    0   35]\n",
            " [  21  150    1  371    1   20   23   37  121  229]\n",
            " [   7   12    0   32    0    1    6  291    7  653]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '3' '1' ... '9' '9' '9']\n",
            "probabilities: (59900, 10) \n",
            " [3 3 1 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 1 30  1 12 10  8  4 33  4 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.166 s \n",
            "\n",
            "Accuracy rate for 50.440000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.22      0.31       980\n",
            "           1       0.65      0.99      0.78      1135\n",
            "           2       0.83      0.23      0.36      1032\n",
            "           3       0.34      0.83      0.48      1010\n",
            "           4       0.79      0.18      0.29       982\n",
            "           5       0.67      0.18      0.29       892\n",
            "           6       0.68      0.63      0.66       958\n",
            "           7       0.42      0.92      0.57      1028\n",
            "           8       0.86      0.17      0.28       974\n",
            "           9       0.45      0.58      0.51      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.62      0.49      0.45     10000\n",
            "weighted avg       0.62      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 215    4    8  475    0   36   25  193    0   24]\n",
            " [   0 1120    0    4    0    0    9    1    0    1]\n",
            " [  21  184  235  332    1    1  146   87   12   13]\n",
            " [  19   49    2  838    0    2    3   45    2   50]\n",
            " [  15   44    1    5  172    0   43  411    0  291]\n",
            " [  20   67    0  373   20  163   20   84    4  141]\n",
            " [  74   53   34   62    4    5  603  104    0   19]\n",
            " [   1   55    1    3    0    0    2  948    0   18]\n",
            " [  30  143    2  346    6   36   26   54  163  168]\n",
            " [   4   10    0   34   14    2    4  345    9  587]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '7' '7' ... '9' '7' '9']\n",
            "probabilities: (59875, 10) \n",
            " [3 7 7 ... 9 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 1 37  1 13 15  8  4 38  4 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.760 s \n",
            "\n",
            "Accuracy rate for 53.240000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.19      0.28       980\n",
            "           1       0.67      0.99      0.80      1135\n",
            "           2       0.77      0.24      0.37      1032\n",
            "           3       0.33      0.83      0.48      1010\n",
            "           4       0.76      0.39      0.52       982\n",
            "           5       0.75      0.16      0.27       892\n",
            "           6       0.76      0.60      0.67       958\n",
            "           7       0.52      0.91      0.66      1028\n",
            "           8       0.88      0.15      0.26       974\n",
            "           9       0.42      0.73      0.53      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.64      0.52      0.48     10000\n",
            "weighted avg       0.64      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 183    4    5  553    0   28   21  166    0   20]\n",
            " [   0 1123    0    5    0    0    4    1    0    2]\n",
            " [  11  194  249  332   23    2   98   87   12   24]\n",
            " [  25   48    1  841    0    0    2   28    1   64]\n",
            " [  11   22    1    1  386    0   28  201    0  332]\n",
            " [  21   51    0  360   36  146   13   61    5  199]\n",
            " [  40   48   67   63   28    6  577   95    0   34]\n",
            " [   0   54    0    5    0    0    2  935    0   32]\n",
            " [  18  124    1  330   12   10   13   21  150  295]\n",
            " [   4    8    0   29   24    2    2  203    3  734]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '3' '4' ... '9' '4' '9']\n",
            "probabilities: (59850, 10) \n",
            " [3 3 4 ... 9 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [ 1 45  1 15 17 11  4 43  6 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.436 s \n",
            "\n",
            "Accuracy rate for 57.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.27      0.35       980\n",
            "           1       0.68      0.99      0.80      1135\n",
            "           2       0.82      0.27      0.40      1032\n",
            "           3       0.36      0.84      0.51      1010\n",
            "           4       0.84      0.47      0.60       982\n",
            "           5       0.67      0.27      0.39       892\n",
            "           6       0.74      0.54      0.62       958\n",
            "           7       0.58      0.92      0.71      1028\n",
            "           8       0.87      0.27      0.41       974\n",
            "           9       0.47      0.78      0.59      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.66      0.56      0.54     10000\n",
            "weighted avg       0.65      0.57      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 264    5    8  444    0   83   13  148    3   12]\n",
            " [   0 1119    0    5    0    0    8    0    2    1]\n",
            " [  21  200  275  313    9    4   94   82   15   19]\n",
            " [  31   33    3  844    0    2    1   19    6   71]\n",
            " [  18   17    1    0  462    0   27  156    2  299]\n",
            " [  30   49    1  326   23  245   18   40    6  154]\n",
            " [ 114   49   44   84   30   11  515   65    1   45]\n",
            " [   0   56    0    3    0    0    2  941    0   26]\n",
            " [  29  110    4  273   11   16   13   19  261  238]\n",
            " [   7   10    0   29   17    2    1  157    4  782]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '4' '1' ... '5' '4' '9']\n",
            "probabilities: (59825, 10) \n",
            " [3 4 1 ... 5 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 1 50  1 17 19 12  4 52  7 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.649 s \n",
            "\n",
            "Accuracy rate for 57.880000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.23      0.33       980\n",
            "           1       0.70      0.98      0.82      1135\n",
            "           2       0.89      0.24      0.38      1032\n",
            "           3       0.40      0.84      0.54      1010\n",
            "           4       0.80      0.42      0.56       982\n",
            "           5       0.66      0.29      0.41       892\n",
            "           6       0.64      0.64      0.64       958\n",
            "           7       0.57      0.90      0.70      1028\n",
            "           8       0.82      0.34      0.48       974\n",
            "           9       0.47      0.79      0.59      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.65      0.57      0.54     10000\n",
            "weighted avg       0.65      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 226    2    8  402    1   98   41  184    6   12]\n",
            " [   0 1115    0    5    0    0   11    1    2    1]\n",
            " [  20  176  248  243   14    3  199   77   35   17]\n",
            " [  18   26    1  852    0    4    2   28    9   70]\n",
            " [   7   17    0    0  417    0   34  136    0  371]\n",
            " [  13   49    1  318   25  261   22   47   13  143]\n",
            " [  71   35   20   42   40   11  614   71    3   51]\n",
            " [   0   55    0    2    1    0    6  929    0   35]\n",
            " [  17  104    2  238   11   15   30   18  327  212]\n",
            " [   4    7    0   21   11    4    6  151    6  799]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['7' '4' '1' ... '5' '4' '9']\n",
            "probabilities: (59800, 10) \n",
            " [7 4 1 ... 5 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [ 1 54  2 18 21 13  4 60 10 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.661 s \n",
            "\n",
            "Accuracy rate for 60.470000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.19      0.29       980\n",
            "           1       0.70      0.99      0.82      1135\n",
            "           2       0.73      0.39      0.51      1032\n",
            "           3       0.40      0.84      0.54      1010\n",
            "           4       0.82      0.60      0.69       982\n",
            "           5       0.68      0.29      0.41       892\n",
            "           6       0.77      0.55      0.64       958\n",
            "           7       0.59      0.90      0.71      1028\n",
            "           8       0.81      0.39      0.52       974\n",
            "           9       0.51      0.80      0.62      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.66      0.59      0.58     10000\n",
            "weighted avg       0.66      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 189    4   15  463    0   84   18  187    4   16]\n",
            " [   0 1122    0    4    0    0    6    2    1    0]\n",
            " [   5  199  402  202   21    6   70   65   50   12]\n",
            " [  19   25    2  845    1    4    1   23    8   82]\n",
            " [   4   20    3    1  589    0   22   97    3  243]\n",
            " [  14   49    2  316   24  261   19   48    8  151]\n",
            " [  49   38  111   47   47    9  526   72    7   52]\n",
            " [   0   51    2    2    1    0    2  928    3   39]\n",
            " [  18   87   12  223   13   15   17   21  377  191]\n",
            " [   4   10    2   26   19    5    3  128    4  808]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59775, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 1 57  2 25 23 14  4 68 10 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.787 s \n",
            "\n",
            "Accuracy rate for 62.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.22      0.31       980\n",
            "           1       0.75      0.99      0.85      1135\n",
            "           2       0.75      0.43      0.55      1032\n",
            "           3       0.41      0.88      0.56      1010\n",
            "           4       0.86      0.58      0.69       982\n",
            "           5       0.68      0.33      0.44       892\n",
            "           6       0.78      0.59      0.67       958\n",
            "           7       0.63      0.91      0.74      1028\n",
            "           8       0.87      0.39      0.54       974\n",
            "           9       0.53      0.82      0.64      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.68      0.61      0.60     10000\n",
            "weighted avg       0.68      0.62      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 215    2   26  411    1  105   18  174    4   24]\n",
            " [   0 1122    2    4    0    0    3    2    2    0]\n",
            " [   7  150  446  223   14    4   70   63   36   19]\n",
            " [  30   10    4  892    0    2    0   16    6   50]\n",
            " [  13   16    4    2  569    0   29   81    2  266]\n",
            " [  29   53    3  327   20  295   16   40    2  107]\n",
            " [  61   33   96   30   29   11  566   67    2   63]\n",
            " [   0   44    3    3    1    0    2  935    2   38]\n",
            " [  27   67   12  256   13   10   18   13  378  180]\n",
            " [   9    8    1   30   14    7    5  103    2  830]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59750, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [ 1 65  2 32 23 15  4 73 10 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.510 s \n",
            "\n",
            "Accuracy rate for 60.680000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.22      0.32       980\n",
            "           1       0.72      0.99      0.84      1135\n",
            "           2       0.80      0.36      0.50      1032\n",
            "           3       0.37      0.92      0.53      1010\n",
            "           4       0.85      0.56      0.67       982\n",
            "           5       0.69      0.30      0.41       892\n",
            "           6       0.78      0.57      0.66       958\n",
            "           7       0.64      0.90      0.75      1028\n",
            "           8       0.86      0.33      0.48       974\n",
            "           9       0.53      0.80      0.64      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.68      0.60      0.58     10000\n",
            "weighted avg       0.68      0.61      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 218    4   10  470    1   88   21  140   10   18]\n",
            " [   0 1127    0    4    0    0    2    1    1    0]\n",
            " [   4  175  373  320    7    2   64   49   24   14]\n",
            " [  23    6    3  929    0    1    0   17    4   27]\n",
            " [   9   20    4   28  548    0   26   81    2  264]\n",
            " [  15   50    4  339   24  264   18   40    5  133]\n",
            " [  78   47   56   60   39    7  549   61    3   58]\n",
            " [   0   49    2   11    0    0    2  929    0   35]\n",
            " [  17   70   11  315   14   14   19   13  320  181]\n",
            " [   5    8    2   48   13    5    4  111    2  811]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['3' '4' '1' ... '5' '9' '9']\n",
            "probabilities: (59725, 10) \n",
            " [3 4 1 ... 5 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 1 73  2 33 25 18  4 78 12 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.111 s \n",
            "\n",
            "Accuracy rate for 61.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.21      0.32       980\n",
            "           1       0.72      0.99      0.84      1135\n",
            "           2       0.63      0.42      0.50      1032\n",
            "           3       0.39      0.91      0.55      1010\n",
            "           4       0.81      0.64      0.71       982\n",
            "           5       0.67      0.34      0.45       892\n",
            "           6       0.79      0.47      0.59       958\n",
            "           7       0.64      0.91      0.75      1028\n",
            "           8       0.89      0.39      0.54       974\n",
            "           9       0.56      0.80      0.66      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.68      0.61      0.59     10000\n",
            "weighted avg       0.68      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 208    2   37  445    0  107   22  137    5   17]\n",
            " [   0 1129    0    4    0    0    0    0    1    1]\n",
            " [   2  169  431  263   15    3   47   66   25   11]\n",
            " [  22   11    5  919    0    2    0   15    2   34]\n",
            " [   7   15    5   15  625    0   21   77    0  217]\n",
            " [  16   53   11  320   33  302   11   39    5  102]\n",
            " [  49   49  170   52   63   16  446   61    4   48]\n",
            " [   0   48    3    8    0    0    1  931    1   36]\n",
            " [  19   74   19  270   17   13   13   12  375  162]\n",
            " [   2    8    2   46   20    6    3  109    1  812]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '3' '1' ... '5' '9' '9']\n",
            "probabilities: (59700, 10) \n",
            " [3 3 1 ... 5 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [ 1 78  2 35 27 20  4 84 13 61] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.641 s \n",
            "\n",
            "Accuracy rate for 61.180000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.21      0.31       980\n",
            "           1       0.71      0.99      0.83      1135\n",
            "           2       0.66      0.36      0.47      1032\n",
            "           3       0.39      0.92      0.54      1010\n",
            "           4       0.79      0.59      0.68       982\n",
            "           5       0.63      0.36      0.46       892\n",
            "           6       0.82      0.49      0.61       958\n",
            "           7       0.65      0.90      0.76      1028\n",
            "           8       0.91      0.37      0.52       974\n",
            "           9       0.55      0.83      0.66      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.68      0.60      0.58     10000\n",
            "weighted avg       0.68      0.61      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 202    3   28  450    1  142   18  120    3   13]\n",
            " [   0 1126    1    4    0    0    1    0    2    1]\n",
            " [   3  199  375  278   17    4   50   68   22   16]\n",
            " [  16    8    3  932    1    1    0   17    1   31]\n",
            " [   6   15    3   24  582    0   18   73    1  260]\n",
            " [  17   54    7  331   23  319    8   34    0   99]\n",
            " [  40   54  128   57   78   18  465   63    6   49]\n",
            " [   0   48    3   10    0    0    0  924    0   43]\n",
            " [  19   62   21  295   21   17    9   11  358  161]\n",
            " [   2    8    2   38   14    5    1  104    0  835]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['3' '3' '1' ... '5' '7' '9']\n",
            "probabilities: (59675, 10) \n",
            " [3 3 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 1 83  2 40 28 21  4 90 13 68] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.002 s \n",
            "\n",
            "Accuracy rate for 61.000000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.21      0.32       980\n",
            "           1       0.72      0.99      0.84      1135\n",
            "           2       0.65      0.40      0.50      1032\n",
            "           3       0.39      0.92      0.55      1010\n",
            "           4       0.81      0.54      0.65       982\n",
            "           5       0.65      0.36      0.46       892\n",
            "           6       0.80      0.50      0.62       958\n",
            "           7       0.64      0.89      0.75      1028\n",
            "           8       0.90      0.33      0.49       974\n",
            "           9       0.54      0.84      0.66      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.68      0.60      0.58     10000\n",
            "weighted avg       0.68      0.61      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 203    2   27  448    0  128   17  141    3   11]\n",
            " [   0 1126    1    4    0    0    1    0    2    1]\n",
            " [   4  182  411  263    8    4   47   69   22   22]\n",
            " [  13    8    4  931    1    1    0   16    1   35]\n",
            " [   9   14    4    3  535    1   27   74    0  315]\n",
            " [  12   55    8  342   19  321   10   35    2   88]\n",
            " [  41   46  145   38   77   14  479   64    7   47]\n",
            " [   0   50    3    7    0    0    2  918    0   48]\n",
            " [  13   66   23  323   11   20   11   11  324  172]\n",
            " [   2    8    2   30    6    5    2  102    0  852]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '4' '1' ... '5' '9' '9']\n",
            "probabilities: (59650, 10) \n",
            " [3 4 1 ... 5 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [ 1 86  2 47 28 22  5 99 13 72] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.752 s \n",
            "\n",
            "Accuracy rate for 59.840000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.19      0.29       980\n",
            "           1       0.74      0.99      0.85      1135\n",
            "           2       0.68      0.32      0.44      1032\n",
            "           3       0.37      0.93      0.53      1010\n",
            "           4       0.84      0.49      0.61       982\n",
            "           5       0.73      0.36      0.48       892\n",
            "           6       0.79      0.55      0.65       958\n",
            "           7       0.61      0.89      0.72      1028\n",
            "           8       0.94      0.32      0.48       974\n",
            "           9       0.53      0.84      0.65      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.69      0.59      0.57     10000\n",
            "weighted avg       0.68      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 183    2   19  493    0   85   25  164    1    8]\n",
            " [   0 1126    0    5    0    0    2    0    1    1]\n",
            " [   3  177  330  327    7    2   62   87   13   24]\n",
            " [  13    6    3  944    0    0    0   14    1   29]\n",
            " [   9   15    1    3  477    0   17   91    1  368]\n",
            " [  10   51    4  342   22  317   12   46    1   87]\n",
            " [  47   38  117   50   48   16  525   83    3   31]\n",
            " [   0   47    1   13    0    0    2  917    0   48]\n",
            " [  12   55    8  367   11   14   16   10  314  167]\n",
            " [   3    8    2   36    6    3    1   99    0  851]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59625, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [  1  91   2  49  34  23   8 105  13  74] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.349 s \n",
            "\n",
            "Accuracy rate for 62.910000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.20      0.32       980\n",
            "           1       0.76      0.99      0.86      1135\n",
            "           2       0.74      0.35      0.47      1032\n",
            "           3       0.38      0.93      0.54      1010\n",
            "           4       0.84      0.66      0.74       982\n",
            "           5       0.72      0.35      0.47       892\n",
            "           6       0.76      0.69      0.72       958\n",
            "           7       0.62      0.89      0.73      1028\n",
            "           8       0.95      0.29      0.45       974\n",
            "           9       0.60      0.84      0.70      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.71      0.62      0.60     10000\n",
            "weighted avg       0.71      0.63      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 200    2   21  436    0   94   34  182    0   11]\n",
            " [   0 1124    1    5    0    0    3    1    1    0]\n",
            " [   3  159  358  302   22    2   92   72   10   12]\n",
            " [  13    9    4  940    0    0    0   16    1   27]\n",
            " [   4   14    4    3  646    0   26   84    0  201]\n",
            " [  12   46    4  335   30  312   17   44    0   92]\n",
            " [  38   22   78   28   36   13  658   68    2   15]\n",
            " [   0   45    1   16    0    0    0  920    0   46]\n",
            " [  12   51   12  375   22   10   29    6  287  170]\n",
            " [   2    8    2   37   14    2    3   95    0  846]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59600, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [  1 100   2  51  37  23   8 108  14  81] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.928 s \n",
            "\n",
            "Accuracy rate for 62.990000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.21      0.31       980\n",
            "           1       0.76      0.99      0.86      1135\n",
            "           2       0.73      0.34      0.47      1032\n",
            "           3       0.38      0.92      0.53      1010\n",
            "           4       0.86      0.67      0.75       982\n",
            "           5       0.71      0.34      0.46       892\n",
            "           6       0.77      0.66      0.71       958\n",
            "           7       0.64      0.90      0.75      1028\n",
            "           8       0.93      0.33      0.48       974\n",
            "           9       0.60      0.84      0.70      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.70      0.62      0.60     10000\n",
            "weighted avg       0.70      0.63      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 205    2   29  457    0   94   23  155    4   11]\n",
            " [   0 1124    1    5    0    0    2    0    2    1]\n",
            " [   4  154  356  311   20    2   93   65   13   14]\n",
            " [  16   10    3  932    1    1    0   15    2   30]\n",
            " [   6    9    2    0  657    0   23   73    1  211]\n",
            " [  16   53    7  346   28  301   16   43    0   82]\n",
            " [  79   26   77   22   32   12  636   54    1   19]\n",
            " [   0   41    1   14    0    0    0  922    0   50]\n",
            " [  19   52   10  365   15   10   27    8  317  151]\n",
            " [   3    8    1   31   12    3    3   99    0  849]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59575, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [  1 107   2  54  37  24   8 115  18  84] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.009 s \n",
            "\n",
            "Accuracy rate for 63.560000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.18      0.29       980\n",
            "           1       0.77      0.99      0.86      1135\n",
            "           2       0.68      0.34      0.45      1032\n",
            "           3       0.38      0.93      0.54      1010\n",
            "           4       0.86      0.68      0.76       982\n",
            "           5       0.61      0.37      0.46       892\n",
            "           6       0.81      0.65      0.72       958\n",
            "           7       0.66      0.90      0.76      1028\n",
            "           8       0.88      0.38      0.53       974\n",
            "           9       0.61      0.84      0.71      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.69      0.63      0.61     10000\n",
            "weighted avg       0.69      0.64      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 179    6   30  395    0  178   21  153    6   12]\n",
            " [   0 1123    0    5    2    0    2    0    2    1]\n",
            " [   3  152  347  330   22    3   64   61   31   19]\n",
            " [  11    9    3  939    1    1    0   14    2   30]\n",
            " [   4    7    8    1  671    0   22   54    2  213]\n",
            " [  17   56    4  327   27  326   18   32    1   84]\n",
            " [  40   28  103   26   36   12  623   61    5   24]\n",
            " [   0   31    3   18    0    0    0  924    0   52]\n",
            " [  14   42   12  366   11   14   18    9  374  114]\n",
            " [   5    8    2   34   13    3    0   92    2  850]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59550, 10) \n",
            " [3 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [  1 118   3  57  37  25   8 121  19  86] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.351 s \n",
            "\n",
            "Accuracy rate for 64.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.23      0.34       980\n",
            "           1       0.75      0.99      0.85      1135\n",
            "           2       0.63      0.40      0.49      1032\n",
            "           3       0.40      0.93      0.56      1010\n",
            "           4       0.88      0.68      0.77       982\n",
            "           5       0.63      0.35      0.45       892\n",
            "           6       0.85      0.58      0.69       958\n",
            "           7       0.64      0.91      0.75      1028\n",
            "           8       0.90      0.41      0.56       974\n",
            "           9       0.62      0.84      0.71      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.70      0.63      0.62     10000\n",
            "weighted avg       0.70      0.64      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 224    4   30  373    0  153   16  167    5    8]\n",
            " [   0 1123    5    3    0    0    1    0    2    1]\n",
            " [   4  167  413  286   21    3   33   63   28   14]\n",
            " [  14    9    6  935    0    0    0   15    2   29]\n",
            " [   5   11   10    2  665    0   17   66    1  205]\n",
            " [  14   59    9  348   25  311   11   39    1   75]\n",
            " [  56   37  157   24   24   13  554   61    6   26]\n",
            " [   0   35    3   12    1    0    0  931    0   46]\n",
            " [  14   39   21  340   10    8   16    9  399  118]\n",
            " [   3    8    3   32    9    4    1   97    1  851]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['5' '4' '1' ... '5' '7' '9']\n",
            "probabilities: (59525, 10) \n",
            " [5 4 1 ... 5 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [  1 121   4  58  40  26   9 127  20  94] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.437 s \n",
            "\n",
            "Accuracy rate for 65.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.19      0.29       980\n",
            "           1       0.78      0.99      0.88      1135\n",
            "           2       0.83      0.38      0.52      1032\n",
            "           3       0.40      0.93      0.56      1010\n",
            "           4       0.88      0.67      0.76       982\n",
            "           5       0.60      0.38      0.47       892\n",
            "           6       0.80      0.73      0.76       958\n",
            "           7       0.64      0.91      0.75      1028\n",
            "           8       0.90      0.41      0.57       974\n",
            "           9       0.63      0.84      0.72      1009\n",
            "\n",
            "    accuracy                           0.65     10000\n",
            "   macro avg       0.71      0.64      0.63     10000\n",
            "weighted avg       0.71      0.65      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 185    3   14  384    0  194   25  164    2    9]\n",
            " [   0 1127    0    3    1    0    2    0    1    1]\n",
            " [   1  146  391  277   22    4   74   62   30   25]\n",
            " [   9   10    4  937    0    0    1   15    3   31]\n",
            " [   6    6    1    1  662    0   25   78    2  201]\n",
            " [   8   52    3  337   23  342   19   40    0   68]\n",
            " [  55   20   43   28   21   11  698   61    5   16]\n",
            " [   0   30    3   14    0    0    0  932    3   46]\n",
            " [  11   34   11  343   10   14   24   11  402  114]\n",
            " [   2    8    2   27   13    3    1  100    1  852]]\n",
            "--------------------------------\n",
            "final active learning accuracies [41.730000000000004, 45.42, 46.589999999999996, 49.2, 50.44, 53.239999999999995, 57.08, 57.879999999999995, 60.47, 62.480000000000004, 60.68, 61.78, 61.18, 61.0, 59.84, 62.91, 62.99, 63.56, 64.05999999999999, 65.28]\n",
            "saved Active-learning-experiment-29.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 30, using model = RfModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [0 1 1 1 0 0 2 2 2 1] [1 2 3 6 7 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.417 s \n",
            "\n",
            "Accuracy rate for 33.950000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.52      0.60      0.56      1135\n",
            "           2       0.94      0.18      0.30      1032\n",
            "           3       0.59      0.35      0.44      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.26      0.77      0.39       958\n",
            "           7       0.23      0.87      0.37      1028\n",
            "           8       0.58      0.46      0.51       974\n",
            "           9       0.22      0.10      0.13      1009\n",
            "\n",
            "    accuracy                           0.34     10000\n",
            "   macro avg       0.34      0.33      0.27     10000\n",
            "weighted avg       0.34      0.34      0.28     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   2   0  71   0   0 357 508  21  21]\n",
            " [  0 682   0   0   0   0 265 185   3   0]\n",
            " [  0 345 185   3   0   0 298 159  31  11]\n",
            " [  0 130   1 349   0   0 224 160 142   4]\n",
            " [  0  13   5   0   0   0 212 613  18 121]\n",
            " [  0  13   0 125   0   0 396 258  76  24]\n",
            " [  0   2   4   1   0   0 740 200  11   0]\n",
            " [  0  52   0   0   0   0   4 898   1  73]\n",
            " [  0  55   1  34   0   0 242 113 444  85]\n",
            " [  0   7   0   7   0   0 136 744  18  97]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['6' '6' '6' ... '6' '6' '9']\n",
            "probabilities: (59990, 7) \n",
            " [3 3 3 ... 3 3 6]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [0 1 1 6 1 0 2 2 6 1] [1 2 3 4 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.293 s \n",
            "\n",
            "Accuracy rate for 37.770000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.79      0.57      0.66      1135\n",
            "           2       0.84      0.16      0.27      1032\n",
            "           3       0.27      0.89      0.42      1010\n",
            "           4       0.69      0.03      0.06       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.46      0.59      0.52       958\n",
            "           7       0.36      0.84      0.50      1028\n",
            "           8       0.29      0.53      0.38       974\n",
            "           9       0.38      0.08      0.13      1009\n",
            "\n",
            "    accuracy                           0.38     10000\n",
            "   macro avg       0.41      0.37      0.29     10000\n",
            "weighted avg       0.42      0.38      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   4 553   3   0 111 185 123   1]\n",
            " [  0 649   0 330   0   0  91  37  28   0]\n",
            " [  0  97 166 364   0   0 106  52 245   2]\n",
            " [  0   5   2 902   0   0   7  32  62   0]\n",
            " [  0   7   0 115  33   0 127 386 255  59]\n",
            " [  0   5   0 482   0   0 118 160 124   3]\n",
            " [  0   2  25  48   6   0 565 170 142   0]\n",
            " [  0  30   0  44   1   0   2 861  32  58]\n",
            " [  0  17   0 365   0   0  46  16 519  11]\n",
            " [  0   5   1  93   5   0  45 515 263  82]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['3' '3' '3' ... '3' '6' '8']\n",
            "probabilities: (59980, 8) \n",
            " [2 2 2 ... 2 4 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [0 1 1 9 1 5 2 2 7 2] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.533 s \n",
            "\n",
            "Accuracy rate for 36.390000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.56      0.33      0.41      1135\n",
            "           2       0.72      0.17      0.28      1032\n",
            "           3       0.36      0.89      0.52      1010\n",
            "           4       0.35      0.04      0.08       982\n",
            "           5       0.23      0.29      0.26       892\n",
            "           6       0.71      0.49      0.58       958\n",
            "           7       0.46      0.62      0.53      1028\n",
            "           8       0.23      0.72      0.34       974\n",
            "           9       0.35      0.07      0.12      1009\n",
            "\n",
            "    accuracy                           0.36     10000\n",
            "   macro avg       0.40      0.36      0.31     10000\n",
            "weighted avg       0.40      0.36      0.31     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0  28 409  48 281  41  38 113  22]\n",
            " [  0 375   0 173   0   0  11 160 416   0]\n",
            " [  0 195 176 288   1   2  53  17 300   0]\n",
            " [  0   5   2 896   0  21   6   9  69   2]\n",
            " [  0  15   4  35  43 118  36 178 530  23]\n",
            " [  0   7   2 325   1 259  30  59 205   4]\n",
            " [  0   1  30  28  22  35 473 107 262   0]\n",
            " [  0  61   0  30   3 120   2 641  92  79]\n",
            " [  0   6   0 230   0  14  11   5 704   4]\n",
            " [  0   8   1  54   6 270   0 166 432  72]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['3' '5' '3' ... '5' '6' '8']\n",
            "probabilities: (59970, 9) \n",
            " [2 4 2 ... 4 5 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 0  1  1  9  1  9  2  2 13  2] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.366 s \n",
            "\n",
            "Accuracy rate for 31.170000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.67      0.01      0.02      1135\n",
            "           2       0.82      0.08      0.15      1032\n",
            "           3       0.65      0.79      0.71      1010\n",
            "           4       0.26      0.04      0.08       982\n",
            "           5       0.27      0.56      0.36       892\n",
            "           6       0.86      0.17      0.28       958\n",
            "           7       0.76      0.58      0.66      1028\n",
            "           8       0.16      0.92      0.27       974\n",
            "           9       0.49      0.02      0.04      1009\n",
            "\n",
            "    accuracy                           0.31     10000\n",
            "   macro avg       0.49      0.32      0.26     10000\n",
            "weighted avg       0.50      0.31      0.26     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    0    4   89   93  521    5   26  242    0]\n",
            " [   0   12    0   39    0   23    6   37 1018    0]\n",
            " [   0    6   85   68    0    2    6    8  857    0]\n",
            " [   0    0    4  800    0   86    0    4  116    0]\n",
            " [   0    0    2   22   44  155    4   29  725    1]\n",
            " [   0    0    0  127    0  503    6   12  244    0]\n",
            " [   0    0    9    4   24   53  163   38  667    0]\n",
            " [   0    0    0    8    2  132    0  595  269   22]\n",
            " [   0    0    0   43    1   36    0    1  893    0]\n",
            " [   0    0    0   29    7  358    0   35  558   22]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['5' '5' '3' ... '5' '5' '8']\n",
            "probabilities: (59960, 9) \n",
            " [4 4 2 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 0  1  2  9  1 16  2  2 15  2] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.546 s \n",
            "\n",
            "Accuracy rate for 33.330000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.80      0.16      0.27      1135\n",
            "           2       0.84      0.18      0.30      1032\n",
            "           3       0.79      0.64      0.71      1010\n",
            "           4       0.31      0.07      0.11       982\n",
            "           5       0.21      0.80      0.33       892\n",
            "           6       0.90      0.20      0.32       958\n",
            "           7       0.84      0.44      0.58      1028\n",
            "           8       0.20      0.89      0.33       974\n",
            "           9       0.41      0.02      0.05      1009\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.53      0.34      0.30     10000\n",
            "weighted avg       0.54      0.33      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   9  27  90 681   5   3 162   3]\n",
            " [  0 187   0   4   0 412   1   2 529   0]\n",
            " [  0  38 185  63   1  26   7   7 705   0]\n",
            " [  0   0  14 648   0 257   0   3  88   0]\n",
            " [  0   2   0   3  64 331   4  23 554   1]\n",
            " [  0   0   1  31   0 718   3   2 137   0]\n",
            " [  0   0  12   1  38 138 189  22 558   0]\n",
            " [  0   7   0  10   4 298   0 455 222  32]\n",
            " [  0   0   0  16   1  92   2   1 862   0]\n",
            " [  0   0   0  14  11 545   0  26 388  25]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '5' '5' ... '5' '5' '8']\n",
            "probabilities: (59950, 9) \n",
            " [4 4 4 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 0  5  2 10  1 19  3  2 15  3] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.780 s \n",
            "\n",
            "Accuracy rate for 39.300000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.72      0.84      0.77      1135\n",
            "           2       0.88      0.11      0.20      1032\n",
            "           3       0.85      0.61      0.71      1010\n",
            "           4       0.22      0.05      0.08       982\n",
            "           5       0.22      0.79      0.34       892\n",
            "           6       0.80      0.21      0.33       958\n",
            "           7       0.90      0.42      0.57      1028\n",
            "           8       0.23      0.85      0.37       974\n",
            "           9       0.73      0.04      0.07      1009\n",
            "\n",
            "    accuracy                           0.39     10000\n",
            "   macro avg       0.56      0.39      0.34     10000\n",
            "weighted avg       0.57      0.39      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   2   3  12 113 725   7   1 117   0]\n",
            " [  0 950   0   1   0  36   2   0 146   0]\n",
            " [  0 121 115  29   2  48  17   2 698   0]\n",
            " [  0  21  12 613   0 277   1   1  85   0]\n",
            " [  0  51   0   3  46 305  11  14 540  12]\n",
            " [  0  53   1  37   1 708  13   1  78   0]\n",
            " [  0   8   0   0  35 217 200   6 492   0]\n",
            " [  0  65   0   0   1 327   0 430 204   1]\n",
            " [  0  23   0  11   1 106   0   1 832   0]\n",
            " [  0  27   0  11   8 539   0  23 365  36]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['5' '5' '8' ... '5' '5' '8']\n",
            "probabilities: (59940, 9) \n",
            " [4 4 7 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 0  9  3 12  1 20  3  3 16  3] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.739 s \n",
            "\n",
            "Accuracy rate for 42.730000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.62      0.90      0.73      1135\n",
            "           2       0.86      0.19      0.31      1032\n",
            "           3       0.75      0.68      0.72      1010\n",
            "           4       0.15      0.04      0.06       982\n",
            "           5       0.26      0.75      0.39       892\n",
            "           6       0.81      0.19      0.31       958\n",
            "           7       0.77      0.61      0.68      1028\n",
            "           8       0.24      0.83      0.38       974\n",
            "           9       0.73      0.05      0.09      1009\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.52      0.42      0.37     10000\n",
            "weighted avg       0.53      0.43      0.37     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    4    3   53  143  662    9    5  101    0]\n",
            " [   0 1023    0    2    0   10    2    0   98    0]\n",
            " [   0  186  195   41    3   27   12    3  565    0]\n",
            " [   0   30   10  689    0  197    0    2   82    0]\n",
            " [   0   80    0    7   36  220    8   55  567    9]\n",
            " [   0   75    1   82    0  666   10    1   57    0]\n",
            " [   0   37   15    0   45  171  180   22  488    0]\n",
            " [   0  134    1    1    5  120    0  630  129    8]\n",
            " [   0   48    1   25    2   88    1    2  807    0]\n",
            " [   0   41    0   17   11  390    0   99  404   47]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['5' '5' '1' ... '5' '5' '8']\n",
            "probabilities: (59930, 9) \n",
            " [4 4 0 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 0 10  3 15  1 21  3  4 20  3] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.971 s \n",
            "\n",
            "Accuracy rate for 44.960000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.66      0.91      0.77      1135\n",
            "           2       0.89      0.20      0.32      1032\n",
            "           3       0.77      0.77      0.77      1010\n",
            "           4       0.16      0.04      0.06       982\n",
            "           5       0.31      0.69      0.43       892\n",
            "           6       0.83      0.18      0.29       958\n",
            "           7       0.81      0.72      0.76      1028\n",
            "           8       0.23      0.90      0.37       974\n",
            "           9       0.89      0.04      0.08      1009\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.55      0.44      0.38     10000\n",
            "weighted avg       0.56      0.45      0.39     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    5    2   42  134  576   10    9  202    0]\n",
            " [   0 1038    0    2    0    7    2    0   86    0]\n",
            " [   0  150  202   40    1   16    8    8  607    0]\n",
            " [   0   20    7  778    0  107    0    5   93    0]\n",
            " [   0   58    0   29   37  147    9   39  660    3]\n",
            " [   0   93    2   62    1  618    7    2  107    0]\n",
            " [   0   46   14    3   38  117  171   21  548    0]\n",
            " [   0   85    0    6    3   71    0  736  125    2]\n",
            " [   0   27    0   21    1   49    0    1  875    0]\n",
            " [   0   49    0   30   10  283    0   93  503   41]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['5' '3' '1' ... '5' '5' '8']\n",
            "probabilities: (59920, 9) \n",
            " [4 2 0 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 0 13  3 15  1 23  3  7 22  3] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.458 s \n",
            "\n",
            "Accuracy rate for 45.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.69      0.95      0.80      1135\n",
            "           2       0.90      0.15      0.25      1032\n",
            "           3       0.76      0.77      0.77      1010\n",
            "           4       0.19      0.04      0.07       982\n",
            "           5       0.31      0.71      0.43       892\n",
            "           6       0.89      0.20      0.33       958\n",
            "           7       0.61      0.81      0.69      1028\n",
            "           8       0.25      0.88      0.39       974\n",
            "           9       0.75      0.03      0.05      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.54      0.45      0.38     10000\n",
            "weighted avg       0.54      0.46      0.39     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[   0    5    3   45  119  592    8   20  188    0]\n",
            " [   0 1082    0    2    0    5    2    0   44    0]\n",
            " [   0  146  150   36    3   12    7   18  660    0]\n",
            " [   0   14    5  777    0  111    0   10   93    0]\n",
            " [   0   67    0   22   39  150    3  189  503    9]\n",
            " [   0   86    0   79    1  633    5   16   72    0]\n",
            " [   0   36    9    2   33  148  194   29  507    0]\n",
            " [   0   57    0    5    3   49    0  835   79    0]\n",
            " [   0   28    0   26    1   47    0   12  860    0]\n",
            " [   0   38    0   22   10  272    0  247  393   27]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['5' '5' '1' ... '5' '5' '8']\n",
            "probabilities: (59910, 9) \n",
            " [4 4 0 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 0 17  3 15  1 25  4  7 24  4] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.342 s \n",
            "\n",
            "Accuracy rate for 46.720000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.67      0.95      0.79      1135\n",
            "           2       0.94      0.15      0.26      1032\n",
            "           3       0.82      0.72      0.76      1010\n",
            "           4       0.18      0.03      0.05       982\n",
            "           5       0.33      0.77      0.46       892\n",
            "           6       0.85      0.16      0.27       958\n",
            "           7       0.75      0.78      0.77      1028\n",
            "           8       0.24      0.91      0.39       974\n",
            "           9       0.75      0.15      0.25      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.55      0.46      0.40     10000\n",
            "weighted avg       0.56      0.47      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    6    2   12  100  602    9   19  230    0]\n",
            " [   0 1080    0    2    0   15    2    0   36    0]\n",
            " [   0  177  159   32    0   21    7   13  623    0]\n",
            " [   0   28    4  726    0  144    0   10   98    0]\n",
            " [   0   72    0   18   30  167    4   69  575   47]\n",
            " [   0   80    0   47    0  684    5    4   72    0]\n",
            " [   0   41    4    1   28  145  153   27  559    0]\n",
            " [   0   74    0    8    2   51    0  801   89    3]\n",
            " [   0   27    0   19    1   36    0    6  885    0]\n",
            " [   0   29    0   24    8  231    0  112  451  154]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['5' '3' '1' ... '3' '5' '5']\n",
            "probabilities: (59900, 9) \n",
            " [4 2 0 ... 2 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 0 25  4 15  1 25  4  8 24  4] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.502 s \n",
            "\n",
            "Accuracy rate for 46.380000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.54      0.99      0.70      1135\n",
            "           2       0.97      0.17      0.30      1032\n",
            "           3       0.83      0.72      0.77      1010\n",
            "           4       0.15      0.04      0.07       982\n",
            "           5       0.32      0.75      0.45       892\n",
            "           6       0.89      0.14      0.24       958\n",
            "           7       0.70      0.76      0.73      1028\n",
            "           8       0.28      0.86      0.42       974\n",
            "           9       0.78      0.14      0.24      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.54      0.46      0.39     10000\n",
            "weighted avg       0.55      0.46      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    8    1   17  162  584    5   12  191    0]\n",
            " [   0 1125    0    2    0    3    1    0    4    0]\n",
            " [   0  275  180   31    1   19    7   11  508    0]\n",
            " [   0   43    2  726    0  139    0    6   94    0]\n",
            " [   0  173    0    8   41  167    2  120  430   41]\n",
            " [   0  116    0   47    2  670    1    3   53    0]\n",
            " [   0  111    3    1   50  170  131   18  474    0]\n",
            " [   0  110    0    5    4   62    0  785   61    1]\n",
            " [   0   60    0   16    2   54    0    7  835    0]\n",
            " [   0   68    0   18   11  245    0  163  359  145]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['5' '5' '1' ... '3' '5' '5']\n",
            "probabilities: (59890, 9) \n",
            " [4 4 0 ... 2 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 0 28  5 16  1 27  4 10 24  5] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.985 s \n",
            "\n",
            "Accuracy rate for 47.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.49      0.99      0.65      1135\n",
            "           2       0.85      0.32      0.46      1032\n",
            "           3       0.74      0.72      0.73      1010\n",
            "           4       0.11      0.03      0.05       982\n",
            "           5       0.31      0.71      0.43       892\n",
            "           6       0.86      0.13      0.23       958\n",
            "           7       0.64      0.81      0.71      1028\n",
            "           8       0.35      0.80      0.49       974\n",
            "           9       0.71      0.21      0.32      1009\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.51      0.47      0.41     10000\n",
            "weighted avg       0.51      0.48      0.41     10000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[   0   12   14   50  156  635    6   13   94    0]\n",
            " [   0 1126    0    2    0    4    0    0    3    0]\n",
            " [   0  269  328   43    4   19    7   21  341    0]\n",
            " [   0   57    7  724    0  139    0    5   77    1]\n",
            " [   0  329    1   26   29  106    5  182  223   81]\n",
            " [   0  131    1   70    1  636    3   11   37    2]\n",
            " [   0  131   35    2   55  218  129   18  370    0]\n",
            " [   0  102    0    5    2   60    0  828   31    0]\n",
            " [   0   78    1   35    2   68    0   11  779    0]\n",
            " [   0   85    0   18   11  199    0  206  280  210]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['5' '5' '1' ... '3' '5' '5']\n",
            "probabilities: (59880, 9) \n",
            " [4 4 0 ... 2 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 1 29  5 18  1 28  4 11 27  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.429 s \n",
            "\n",
            "Accuracy rate for 49.120000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00       980\n",
            "           1       0.57      0.99      0.73      1135\n",
            "           2       0.92      0.29      0.44      1032\n",
            "           3       0.72      0.74      0.73      1010\n",
            "           4       0.18      0.06      0.09       982\n",
            "           5       0.34      0.68      0.45       892\n",
            "           6       0.91      0.11      0.20       958\n",
            "           7       0.69      0.85      0.76      1028\n",
            "           8       0.30      0.84      0.44       974\n",
            "           9       0.67      0.27      0.39      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.63      0.48      0.42     10000\n",
            "weighted avg       0.63      0.49      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   1    9    2   70  182  557    4   22  133    0]\n",
            " [   0 1126    0    2    0    3    0    0    4    0]\n",
            " [   0  249  298   44    5   14    5   24  393    0]\n",
            " [   0   42    3  748    0  121    0    6   89    1]\n",
            " [   0  159    0   39   57  105    1  114  378  129]\n",
            " [   0  119    1   77    3  608    0   11   68    5]\n",
            " [   0   95   21    1   53  142  105   25  516    0]\n",
            " [   0   84    0    4    3   28    0  873   34    2]\n",
            " [   0   55    0   33    1   55    0    9  821    0]\n",
            " [   0   33    0   24   14  169    0  173  321  275]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['5' '3' '1' ... '3' '5' '5']\n",
            "probabilities: (59870, 10) \n",
            " [5 3 1 ... 3 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 1 32  5 18  1 30  4 13 30  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.019 s \n",
            "\n",
            "Accuracy rate for 49.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.91      0.27      0.42      1032\n",
            "           3       0.76      0.73      0.75      1010\n",
            "           4       0.17      0.04      0.07       982\n",
            "           5       0.32      0.72      0.44       892\n",
            "           6       0.89      0.13      0.23       958\n",
            "           7       0.66      0.84      0.74      1028\n",
            "           8       0.29      0.86      0.43       974\n",
            "           9       0.70      0.25      0.37      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.64      0.48      0.42     10000\n",
            "weighted avg       0.64      0.49      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   1    7    4   46  136  642    5   25  114    0]\n",
            " [   0 1121    0    2    0    4    1    0    7    0]\n",
            " [   0  203  278   44    2   15    7   28  455    0]\n",
            " [   0   32    4  740    0  138    0    9   87    0]\n",
            " [   0   90    0   20   44  115    2  133  468  110]\n",
            " [   0   87    0   60    1  639    0   15   90    0]\n",
            " [   0   66   18    3   60  173  124   24  490    0]\n",
            " [   0   69    0    2    3   47    0  864   42    1]\n",
            " [   0   33    0   29    2   61    0    9  840    0]\n",
            " [   0   35    0   23   10  171    0  194  319  257]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['5' '3' '1' ... '3' '5' '5']\n",
            "probabilities: (59860, 10) \n",
            " [5 3 1 ... 3 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 1 37  5 19  2 30  4 14 32  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.758 s \n",
            "\n",
            "Accuracy rate for 48.380000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00       980\n",
            "           1       0.59      0.99      0.74      1135\n",
            "           2       0.82      0.26      0.39      1032\n",
            "           3       0.72      0.76      0.74      1010\n",
            "           4       0.80      0.04      0.08       982\n",
            "           5       0.34      0.70      0.45       892\n",
            "           6       0.87      0.10      0.17       958\n",
            "           7       0.62      0.86      0.72      1028\n",
            "           8       0.28      0.85      0.42       974\n",
            "           9       0.68      0.21      0.32      1009\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.67      0.48      0.40     10000\n",
            "weighted avg       0.67      0.48      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   1   14   13   91    1  667    5   63  125    0]\n",
            " [   0 1126    0    2    0    4    0    0    3    0]\n",
            " [   0  234  268   43    2   15    7   42  421    0]\n",
            " [   0   40    5  765    0   99    0    8   93    0]\n",
            " [   0  120    0   32   41   90    0  135  469   95]\n",
            " [   0  110    0   55    0  626    2   21   76    2]\n",
            " [   0   95   40    5    0  150   92   49  527    0]\n",
            " [   0   81    0    4    1   21    0  879   41    1]\n",
            " [   0   49    0   35    1   53    0    8  828    0]\n",
            " [   0   43    2   35    5  141    0  202  369  212]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['5' '3' '1' ... '3' '5' '5']\n",
            "probabilities: (59850, 10) \n",
            " [5 3 1 ... 3 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 1 45  6 19  2 30  4 14 33  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.883 s \n",
            "\n",
            "Accuracy rate for 49.020000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.57      0.99      0.73      1135\n",
            "           2       0.83      0.33      0.48      1032\n",
            "           3       0.68      0.76      0.72      1010\n",
            "           4       0.83      0.02      0.05       982\n",
            "           5       0.35      0.66      0.46       892\n",
            "           6       0.89      0.11      0.20       958\n",
            "           7       0.64      0.85      0.73      1028\n",
            "           8       0.28      0.86      0.43       974\n",
            "           9       0.69      0.23      0.34      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.58      0.48      0.41     10000\n",
            "weighted avg       0.58      0.49      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0   17   11   82    1  639    7   53  170    0]\n",
            " [   0 1126    0    2    0    2    0    0    5    0]\n",
            " [   0  244  345   38    2   11    6   34  352    0]\n",
            " [   0   55    5  766    0   86    0    7   91    0]\n",
            " [   0  115    1   58   24   59    0  149  473  103]\n",
            " [   0  133    0   77    0  589    0   10   80    3]\n",
            " [   0  101   53    5    0  132  110   48  509    0]\n",
            " [   0   81    1   14    0   23    0  871   38    0]\n",
            " [   0   50    0   28    0   48    0    8  840    0]\n",
            " [   0   44    1   50    2  102    0  184  395  231]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['5' '3' '1' ... '3' '5' '5']\n",
            "probabilities: (59840, 10) \n",
            " [5 3 1 ... 3 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 1 51  6 20  2 31  4 14 33  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.288 s \n",
            "\n",
            "Accuracy rate for 50.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       980\n",
            "           1       0.59      0.99      0.74      1135\n",
            "           2       0.86      0.31      0.46      1032\n",
            "           3       0.67      0.78      0.72      1010\n",
            "           4       0.86      0.04      0.07       982\n",
            "           5       0.36      0.66      0.47       892\n",
            "           6       0.90      0.09      0.17       958\n",
            "           7       0.63      0.85      0.73      1028\n",
            "           8       0.31      0.85      0.45       974\n",
            "           9       0.66      0.44      0.52      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.63      0.50      0.43     10000\n",
            "weighted avg       0.64      0.51      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   1   12    4  123    1  616    5   73  145    0]\n",
            " [   0 1127    0    2    0    2    1    0    3    0]\n",
            " [   0  248  323   57    1   14    4   37  348    0]\n",
            " [   0   43    2  786    0   85    0    8   85    1]\n",
            " [   0  113    0   33   37   46    0  147  398  208]\n",
            " [   0  106    0   95    0  590    0   11   84    6]\n",
            " [   1   99   47   11    0  153   90   52  505    0]\n",
            " [   0   86    0   11    0   14    0  878   31    8]\n",
            " [   0   55    0   34    1   44    0   10  825    5]\n",
            " [   0   36    1   21    3   58    0  175  276  439]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['5' '5' '1' ... '3' '5' '5']\n",
            "probabilities: (59830, 10) \n",
            " [5 5 1 ... 3 5 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 1 55  6 20  2 31  5 17 34  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.198 s \n",
            "\n",
            "Accuracy rate for 51.510000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00       980\n",
            "           1       0.60      0.99      0.75      1135\n",
            "           2       0.88      0.32      0.47      1032\n",
            "           3       0.70      0.76      0.73      1010\n",
            "           4       0.82      0.05      0.09       982\n",
            "           5       0.41      0.68      0.51       892\n",
            "           6       0.73      0.16      0.26       958\n",
            "           7       0.57      0.87      0.69      1028\n",
            "           8       0.30      0.86      0.45       974\n",
            "           9       0.68      0.39      0.50      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.64      0.51      0.44     10000\n",
            "weighted avg       0.64      0.52      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   2    6    8   96    1  547   28   82  210    0]\n",
            " [   0 1128    0    2    0    3    0    0    2    0]\n",
            " [   0  240  326   43    3   11   12   51  346    0]\n",
            " [   0   38    3  770    0   85    0    9  103    2]\n",
            " [   0  119    0   41   45   41    7  194  367  168]\n",
            " [   0   94    0   76    0  604    8   23   81    6]\n",
            " [   1   86   31    6    0   82  152   95  505    0]\n",
            " [   0   72    0    7    1   13    0  894   38    3]\n",
            " [   0   54    0   33    1   36    0    9  837    4]\n",
            " [   0   32    2   26    4   62    0  225  265  393]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['5' '3' '1' ... '8' '3' '5']\n",
            "probabilities: (59820, 10) \n",
            " [5 3 1 ... 8 3 5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 1 59  6 21  3 33  5 19 34  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.631 s \n",
            "\n",
            "Accuracy rate for 52.630000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.56      0.99      0.72      1135\n",
            "           2       0.91      0.31      0.46      1032\n",
            "           3       0.75      0.78      0.76      1010\n",
            "           4       0.79      0.11      0.20       982\n",
            "           5       0.41      0.69      0.52       892\n",
            "           6       0.75      0.19      0.31       958\n",
            "           7       0.56      0.89      0.69      1028\n",
            "           8       0.32      0.83      0.46       974\n",
            "           9       0.73      0.40      0.51      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.58      0.52      0.46     10000\n",
            "weighted avg       0.58      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    9    5   77    1  553   40   93  202    0]\n",
            " [   0 1128    0    2    0    2    1    0    2    0]\n",
            " [   0  285  318   48    4    7    8   70  292    0]\n",
            " [   0   52    2  784    1   73    1   10   86    1]\n",
            " [   0  138    0   12  112   34    5  188  355  138]\n",
            " [   0  119    0   65    2  614    6   24   60    2]\n",
            " [   0  101   23    3    1   90  185   82  473    0]\n",
            " [   0   77    0    4    3   10    0  912   20    2]\n",
            " [   0   64    0   35    1   47    0   10  811    6]\n",
            " [   0   32    2   19   16   56    0  233  252  399]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59810, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 1 64  6 23  4 34  5 19 34 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.653 s \n",
            "\n",
            "Accuracy rate for 53.430000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00       980\n",
            "           1       0.61      0.99      0.75      1135\n",
            "           2       0.86      0.32      0.46      1032\n",
            "           3       0.74      0.80      0.77      1010\n",
            "           4       0.81      0.17      0.28       982\n",
            "           5       0.41      0.68      0.51       892\n",
            "           6       0.80      0.18      0.29       958\n",
            "           7       0.59      0.87      0.70      1028\n",
            "           8       0.31      0.85      0.45       974\n",
            "           9       0.78      0.41      0.54      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.66      0.53      0.48     10000\n",
            "weighted avg       0.66      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   2   11   10   75    1  556   22   82  221    0]\n",
            " [   0 1127    0    2    0    2    1    0    3    0]\n",
            " [   0  235  327   50    2    9   10   73  326    0]\n",
            " [   0   34    3  808    1   76    1    9   75    3]\n",
            " [   0  103    0   16  166   38    4  169  390   96]\n",
            " [   0   91    0   74   13  607    5   16   82    4]\n",
            " [   1   95   39    2    0   79  171   69  502    0]\n",
            " [   0   81    1    9    2   13    0  896   20    6]\n",
            " [   0   59    0   28    1   44    0    9  827    6]\n",
            " [   0   26    1   30   18   65    0  198  259  412]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59800, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 1 71  7 23  4 34  5 19 35 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.699 s \n",
            "\n",
            "Accuracy rate for 53.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00       980\n",
            "           1       0.54      1.00      0.70      1135\n",
            "           2       0.86      0.29      0.44      1032\n",
            "           3       0.70      0.82      0.76      1010\n",
            "           4       0.82      0.15      0.25       982\n",
            "           5       0.44      0.64      0.52       892\n",
            "           6       0.81      0.18      0.30       958\n",
            "           7       0.58      0.87      0.69      1028\n",
            "           8       0.33      0.83      0.47       974\n",
            "           9       0.72      0.47      0.57      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.65      0.53      0.47     10000\n",
            "weighted avg       0.65      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   2   20   11   98    1  518   25   90  215    0]\n",
            " [   0 1130    0    2    0    2    0    0    1    0]\n",
            " [   0  288  304   58    1    8    7   60  306    0]\n",
            " [   0   51    4  824    1   49    0    9   68    4]\n",
            " [   0  177    2   15  146   17    5  167  293  160]\n",
            " [   0  121    0   90    9  572    5   18   74    3]\n",
            " [   1  116   30    4    0   73  177   74  483    0]\n",
            " [   0   84    0    9    4    5    0  898   20    8]\n",
            " [   0   68    0   45    1   32    0   12  809    7]\n",
            " [   0   41    1   27   15   37    0  231  179  478]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59790, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 1 76  7 24  4 34  5 20 37 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.366 s \n",
            "\n",
            "Accuracy rate for 52.620000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.63      1.00      0.77      1135\n",
            "           2       0.92      0.27      0.42      1032\n",
            "           3       0.74      0.82      0.78      1010\n",
            "           4       0.77      0.11      0.20       982\n",
            "           5       0.44      0.64      0.52       892\n",
            "           6       0.81      0.17      0.29       958\n",
            "           7       0.58      0.88      0.70      1028\n",
            "           8       0.28      0.85      0.42       974\n",
            "           9       0.71      0.44      0.54      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.59      0.52      0.46     10000\n",
            "weighted avg       0.59      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    9    3   94    1  527   24   77  245    0]\n",
            " [   0 1130    0    2    0    2    1    0    0    0]\n",
            " [   0  207  280   42    2    7    8   81  405    0]\n",
            " [   0   34    2  830    1   50    0   11   81    1]\n",
            " [   0   83    0    5  110   14    2  159  458  151]\n",
            " [   0  105    0   87    6  570    5   16   97    6]\n",
            " [   0   73   17    2    0   68  167  100  531    0]\n",
            " [   0   71    1    5    3    8    0  909   21   10]\n",
            " [   0   57    0   43    2   27    0   11  826    8]\n",
            " [   0   28    1   17   18   24    0  194  287  440]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['5' '8' '1' ... '1' '8' '3']\n",
            "probabilities: (59780, 10) \n",
            " [5 8 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [ 1 80  7 27  4 35  5 21 38 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.964 s \n",
            "\n",
            "Accuracy rate for 53.330000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.58      0.99      0.73      1135\n",
            "           2       0.91      0.26      0.41      1032\n",
            "           3       0.69      0.83      0.75      1010\n",
            "           4       0.80      0.15      0.25       982\n",
            "           5       0.43      0.64      0.51       892\n",
            "           6       0.80      0.19      0.31       958\n",
            "           7       0.53      0.89      0.66      1028\n",
            "           8       0.33      0.85      0.48       974\n",
            "           9       0.75      0.45      0.57      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.58      0.53      0.47     10000\n",
            "weighted avg       0.59      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    9    8  126    1  541   28  113  154    0]\n",
            " [   0 1129    0    2    0    2    1    0    1    0]\n",
            " [   0  260  270   58    1    9    9   86  339    0]\n",
            " [   0   28    1  842    1   51    0   11   73    3]\n",
            " [   0  142    0   10  144   17    5  192  343  129]\n",
            " [   0  117    0   99   11  570    4   25   63    3]\n",
            " [   1   99   16    5    0   82  185  103  467    0]\n",
            " [   0   75    2   11    3    7    0  910   10   10]\n",
            " [   0   56    0   55    1   22    0    9  824    7]\n",
            " [   0   31    1   16   17   34    0  264  187  459]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59770, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [ 1 86  7 28  5 35  5 22 38 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.923 s \n",
            "\n",
            "Accuracy rate for 52.720000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.60      1.00      0.75      1135\n",
            "           2       0.92      0.27      0.41      1032\n",
            "           3       0.69      0.83      0.75      1010\n",
            "           4       0.75      0.14      0.23       982\n",
            "           5       0.46      0.63      0.53       892\n",
            "           6       0.79      0.18      0.29       958\n",
            "           7       0.58      0.89      0.70      1028\n",
            "           8       0.29      0.85      0.43       974\n",
            "           9       0.78      0.42      0.54      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.58      0.52      0.46     10000\n",
            "weighted avg       0.59      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0    9    5  120    1  482   30   85  247    1]\n",
            " [   0 1130    0    2    0    2    0    0    1    0]\n",
            " [   0  247  276   55    2    8    8   83  353    0]\n",
            " [   0   36    3  835    1   48    1   10   73    3]\n",
            " [   0  104    0   13  135   14    4  174  436  102]\n",
            " [   0  113    0  101   15  562    3   17   77    4]\n",
            " [   0   90   14    3    1   58  173   81  538    0]\n",
            " [   0   75    1    7    3    6    0  911   18    7]\n",
            " [   0   62    0   51    1   17    0   12  827    4]\n",
            " [   0   27    1   25   21   36    0  205  271  423]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59760, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 1 90  7 32  6 35  5 23 38 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.339 s \n",
            "\n",
            "Accuracy rate for 53.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.01       980\n",
            "           1       0.61      1.00      0.76      1135\n",
            "           2       0.92      0.25      0.40      1032\n",
            "           3       0.64      0.87      0.74      1010\n",
            "           4       0.77      0.22      0.34       982\n",
            "           5       0.43      0.63      0.51       892\n",
            "           6       0.82      0.16      0.27       958\n",
            "           7       0.55      0.88      0.68      1028\n",
            "           8       0.31      0.82      0.45       974\n",
            "           9       0.78      0.42      0.55      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.68      0.52      0.47     10000\n",
            "weighted avg       0.69      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   3    8    6  124    1  540   18  104  176    0]\n",
            " [   0 1130    0    3    0    2    0    0    0    0]\n",
            " [   0  240  261   67    3   11    8   88  354    0]\n",
            " [   0   27    1  874    1   27    2   11   65    2]\n",
            " [   0   99    0   45  212   20    2  192  313   99]\n",
            " [   0  109    0  115   15  563    3   16   70    1]\n",
            " [   0   88   15    6    0   87  153  111  498    0]\n",
            " [   0   68    0   16    2    7    0  900   22   13]\n",
            " [   0   54    0   76    2   26    0   14  798    4]\n",
            " [   0   29    1   40   38   36    0  200  242  423]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59750, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [ 1 96  7 32  6 35  5 24 39 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.536 s \n",
            "\n",
            "Accuracy rate for 54.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.00      0.00       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.90      0.26      0.41      1032\n",
            "           3       0.68      0.85      0.76      1010\n",
            "           4       0.77      0.27      0.40       982\n",
            "           5       0.43      0.64      0.52       892\n",
            "           6       0.81      0.16      0.27       958\n",
            "           7       0.56      0.89      0.69      1028\n",
            "           8       0.31      0.84      0.46       974\n",
            "           9       0.82      0.47      0.60      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.63      0.54      0.49     10000\n",
            "weighted avg       0.64      0.55      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   2    5    9  110    2  532   23  106  190    1]\n",
            " [   0 1128    0    3    0    2    1    0    1    0]\n",
            " [   0  226  272   67    5    7    8   92  355    0]\n",
            " [   0   22    4  863    1   36    0    8   72    4]\n",
            " [   0   70    0   20  265   14    0  177  359   77]\n",
            " [   0   96    0  100   31  567    4   19   72    3]\n",
            " [   3   76   14    6    0   97  154  123  485    0]\n",
            " [   0   65    1    9    4    3    0  915   17   14]\n",
            " [   0   55    0   66    2   22    0    8  814    7]\n",
            " [   0   23    1   27   34   28    0  189  232  475]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59740, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [  1 100   8  33   6  37   5  24  39  17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.300 s \n",
            "\n",
            "Accuracy rate for 55.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.00      0.01       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.85      0.29      0.43      1032\n",
            "           3       0.64      0.87      0.73      1010\n",
            "           4       0.80      0.23      0.36       982\n",
            "           5       0.44      0.62      0.52       892\n",
            "           6       0.81      0.15      0.26       958\n",
            "           7       0.60      0.86      0.71      1028\n",
            "           8       0.33      0.84      0.47       974\n",
            "           9       0.71      0.58      0.63      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.64      0.54      0.49     10000\n",
            "weighted avg       0.64      0.55      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   3    9   16  151    1  533   21   80  166    0]\n",
            " [   0 1128    0    3    0    2    1    0    1    0]\n",
            " [   0  202  301   71    4    8    8   86  352    0]\n",
            " [   0   16    1  877    1   29    0    8   74    4]\n",
            " [   0   94    0   28  230   10    1  163  272  184]\n",
            " [   0  106    0  122   18  552    3   19   61   11]\n",
            " [   2   84   34   18    1   75  147   89  508    0]\n",
            " [   0   62    0   26    2    1    0  889   19   29]\n",
            " [   0   49    1   63    2   22    0    9  815   13]\n",
            " [   0   25    1   22   28   15    0  146  191  581]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59730, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [  1 104   9  33   7  40   5  24  39  18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.721 s \n",
            "\n",
            "Accuracy rate for 57.370000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00       980\n",
            "           1       0.66      1.00      0.80      1135\n",
            "           2       0.78      0.38      0.51      1032\n",
            "           3       0.66      0.87      0.75      1010\n",
            "           4       0.79      0.31      0.44       982\n",
            "           5       0.44      0.64      0.52       892\n",
            "           6       0.81      0.17      0.29       958\n",
            "           7       0.59      0.87      0.71      1028\n",
            "           8       0.35      0.83      0.49       974\n",
            "           9       0.75      0.60      0.67      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.64      0.57      0.52     10000\n",
            "weighted avg       0.64      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   1    7   34   98    3  534   25   85  193    0]\n",
            " [   0 1130    0    2    0    2    1    0    0    0]\n",
            " [   0  192  389   71    6    9    8   77  279    1]\n",
            " [   0   17    4  880    1   32    0   10   62    4]\n",
            " [   0   78    3   32  300    9    3  164  253  140]\n",
            " [   0   90    0  111   27  567    3   17   71    6]\n",
            " [   1   72   61   13    1   74  167   83  485    1]\n",
            " [   0   57    1   15    7    3    0  894   15   36]\n",
            " [   0   41    1   75    2   29    0    9  805   12]\n",
            " [   0   21    3   27   31   24    0  165  134  604]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59720, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [  2 107  10  34   7  41   5  25  40  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.415 s \n",
            "\n",
            "Accuracy rate for 57.560000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.02      0.04       980\n",
            "           1       0.66      1.00      0.79      1135\n",
            "           2       0.79      0.41      0.54      1032\n",
            "           3       0.68      0.86      0.76      1010\n",
            "           4       0.83      0.24      0.37       982\n",
            "           5       0.44      0.67      0.53       892\n",
            "           6       0.79      0.17      0.28       958\n",
            "           7       0.59      0.88      0.70      1028\n",
            "           8       0.37      0.82      0.51       974\n",
            "           9       0.70      0.61      0.66      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.67      0.57      0.52     10000\n",
            "weighted avg       0.67      0.58      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  22    5   31   97    1  570   25   90  139    0]\n",
            " [   0 1131    0    2    0    2    0    0    0    0]\n",
            " [   1  204  419   57    4    7    9   96  234    1]\n",
            " [   0   23    3  872    1   38    2    9   56    6]\n",
            " [   1   61    9   32  235    8    5  170  260  201]\n",
            " [   1   88    0   90   20  594    3   18   64   14]\n",
            " [   0   76   61    9    0   87  162   81  482    0]\n",
            " [   0   65    3   15    2    2    0  903   11   27]\n",
            " [   0   41    2   79    2   30    0    7  798   15]\n",
            " [   0   17    2   26   18   19    0  168  139  620]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59710, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [  2 114  12  35   7  41   5  25  40  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.902 s \n",
            "\n",
            "Accuracy rate for 58.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.02      0.03       980\n",
            "           1       0.65      0.99      0.79      1135\n",
            "           2       0.76      0.48      0.59      1032\n",
            "           3       0.66      0.86      0.75      1010\n",
            "           4       0.79      0.27      0.40       982\n",
            "           5       0.44      0.64      0.52       892\n",
            "           6       0.79      0.20      0.32       958\n",
            "           7       0.62      0.86      0.72      1028\n",
            "           8       0.38      0.82      0.52       974\n",
            "           9       0.71      0.63      0.67      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.67      0.58      0.53     10000\n",
            "weighted avg       0.67      0.59      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  17    7   31  131    1  548   28   70  147    0]\n",
            " [   0 1127    1    2    0    2    1    0    2    0]\n",
            " [   0  188  494   64    4    8   10   63  200    1]\n",
            " [   1   22    5  873    1   35    1    9   57    6]\n",
            " [   0   81   22   20  264    7    7  149  235  197]\n",
            " [   0   98    0  101   26  575    3   15   66    8]\n",
            " [   1   80   87   13    3   79  192   78  425    0]\n",
            " [   0   67    4   17    3    3    0  885   16   33]\n",
            " [   0   40    2   80    2   32    0    8  800   10]\n",
            " [   0   19    6   27   29   19    0  142  130  637]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59700, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [  2 118  12  37   8  42   5  25  41  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.306 s \n",
            "\n",
            "Accuracy rate for 59.610000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.01      0.03       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.72      0.47      0.57      1032\n",
            "           3       0.69      0.87      0.77      1010\n",
            "           4       0.84      0.31      0.45       982\n",
            "           5       0.44      0.66      0.53       892\n",
            "           6       0.83      0.23      0.36       958\n",
            "           7       0.61      0.86      0.71      1028\n",
            "           8       0.41      0.82      0.55       974\n",
            "           9       0.72      0.66      0.69      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.67      0.59      0.54     10000\n",
            "weighted avg       0.67      0.60      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  13    8   44   92    2  552   24   80  163    2]\n",
            " [   0 1128    1    2    0    2    1    0    1    0]\n",
            " [   1  204  487   60    5    8   11   57  198    1]\n",
            " [   0   27    4  881    1   35    0    9   47    6]\n",
            " [   1   81   21   26  300    6    6  175  181  185]\n",
            " [   0   99    1   96   25  585    3   15   53   15]\n",
            " [   1   83  103    5    4   87  222   74  379    0]\n",
            " [   0   73    6   14    3    2    1  884   12   33]\n",
            " [   0   44    2   80    3   24    0    8  796   17]\n",
            " [   0   17    6   23   16   16    0  149  117  665]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59690, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [  2 125  12  38   8  42   5  27  41  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.878 s \n",
            "\n",
            "Accuracy rate for 58.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.02      0.03       980\n",
            "           1       0.61      0.99      0.76      1135\n",
            "           2       0.77      0.47      0.58      1032\n",
            "           3       0.69      0.87      0.77      1010\n",
            "           4       0.85      0.29      0.43       982\n",
            "           5       0.42      0.65      0.51       892\n",
            "           6       0.82      0.18      0.29       958\n",
            "           7       0.60      0.87      0.71      1028\n",
            "           8       0.40      0.83      0.54       974\n",
            "           9       0.76      0.62      0.68      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.68      0.58      0.53     10000\n",
            "weighted avg       0.68      0.59      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  16   14   39   78    1  608   19   78  127    0]\n",
            " [   0 1129    1    3    0    1    0    0    1    0]\n",
            " [   1  203  485   57    3    8    7   58  209    1]\n",
            " [   0   37    4  874    1   35    1    9   43    6]\n",
            " [   0  119   16   39  281    9    6  168  206  138]\n",
            " [   0  113    0   95   19  578    4   18   56    9]\n",
            " [   1  105   74    4    2   94  168   97  413    0]\n",
            " [   0   69    5   15    2    2    0  890   14   31]\n",
            " [   0   43    4   67    3   26    0    8  807   16]\n",
            " [   0   16    5   28   19   25    0  165  124  627]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59680, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [  2 127  12  39   8  43   5  30  42  22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.203 s \n",
            "\n",
            "Accuracy rate for 59.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.02      0.03       980\n",
            "           1       0.62      0.99      0.76      1135\n",
            "           2       0.76      0.46      0.58      1032\n",
            "           3       0.65      0.89      0.75      1010\n",
            "           4       0.82      0.32      0.46       982\n",
            "           5       0.46      0.62      0.53       892\n",
            "           6       0.80      0.20      0.32       958\n",
            "           7       0.60      0.86      0.71      1028\n",
            "           8       0.42      0.81      0.56       974\n",
            "           9       0.72      0.68      0.70      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.65      0.59      0.54     10000\n",
            "weighted avg       0.65      0.59      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  15   11   37  138    2  496   31   85  165    0]\n",
            " [   0 1128    1    3    0    1    1    0    1    0]\n",
            " [   3  201  478   72    5   11    9   72  179    2]\n",
            " [   0   25    5  903    1   24    1   12   34    5]\n",
            " [   1  116   16   30  313    6    5  143  162  190]\n",
            " [   0  110    0  109   30  556    2   20   48   17]\n",
            " [   3  103   77   16    8   71  191   90  399    0]\n",
            " [   0   67    4   16    2    3    0  884    9   43]\n",
            " [   0   43    5   83    3   23    0    9  793   15]\n",
            " [   0   14    5   23   16   16    0  157   91  687]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59670, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [  2 132  13  40   8  44   5  32  42  22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.944 s \n",
            "\n",
            "Accuracy rate for 58.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.02      0.04       980\n",
            "           1       0.62      0.99      0.76      1135\n",
            "           2       0.75      0.47      0.58      1032\n",
            "           3       0.68      0.89      0.77      1010\n",
            "           4       0.84      0.29      0.44       982\n",
            "           5       0.43      0.65      0.52       892\n",
            "           6       0.84      0.17      0.28       958\n",
            "           7       0.59      0.86      0.70      1028\n",
            "           8       0.42      0.80      0.55       974\n",
            "           9       0.72      0.66      0.69      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.68      0.58      0.53     10000\n",
            "weighted avg       0.68      0.59      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  21   16   41  110    1  572   17   75  127    0]\n",
            " [   0 1128    1    2    0    2    1    0    1    0]\n",
            " [   0  206  490   62    5    9   10   72  177    1]\n",
            " [   0   34    6  894    1   26    1    8   34    6]\n",
            " [   0  103    7   19  289   11    2  192  172  187]\n",
            " [   1  114    1  100   24  580    1   18   39   14]\n",
            " [   1   92   94    8    3  108  163   80  409    0]\n",
            " [   0   69    6   10    3    1    0  886   12   41]\n",
            " [   0   51    2   89    3   24    0   11  778   16]\n",
            " [   0   19    4   23   16   17    0  167   96  667]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59660, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [  2 135  13  42   9  45   5  33  43  23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.467 s \n",
            "\n",
            "Accuracy rate for 59.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.02      0.03       980\n",
            "           1       0.62      0.99      0.76      1135\n",
            "           2       0.75      0.47      0.58      1032\n",
            "           3       0.63      0.89      0.74      1010\n",
            "           4       0.85      0.34      0.49       982\n",
            "           5       0.45      0.65      0.53       892\n",
            "           6       0.81      0.19      0.31       958\n",
            "           7       0.62      0.82      0.71      1028\n",
            "           8       0.41      0.81      0.55       974\n",
            "           9       0.73      0.66      0.69      1009\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.68      0.58      0.54     10000\n",
            "weighted avg       0.68      0.59      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  15   12   44  128    2  549   23   71  134    2]\n",
            " [   0 1126    1    3    0    1    2    0    2    0]\n",
            " [   0  201  481   71    4    8    7   68  191    1]\n",
            " [   0   32    5  894    1   28    1   10   33    6]\n",
            " [   0  115   11   32  335   11    7  148  160  163]\n",
            " [   1  104    0  101   26  583    4   12   47   14]\n",
            " [   0   90   87   13    4   79  186   61  437    1]\n",
            " [   0   68    5   58    3    3    0  846   10   35]\n",
            " [   0   48    1   76    3   26    0    9  791   20]\n",
            " [   0   13    5   41   16   21    0  143  104  666]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59650, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [  2 140  14  44   9  45   5  34  43  24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.506 s \n",
            "\n",
            "Accuracy rate for 60.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.02      0.05       980\n",
            "           1       0.66      1.00      0.79      1135\n",
            "           2       0.74      0.49      0.59      1032\n",
            "           3       0.67      0.90      0.77      1010\n",
            "           4       0.83      0.37      0.51       982\n",
            "           5       0.43      0.65      0.52       892\n",
            "           6       0.86      0.18      0.29       958\n",
            "           7       0.67      0.86      0.75      1028\n",
            "           8       0.40      0.83      0.54       974\n",
            "           9       0.74      0.66      0.70      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.69      0.59      0.55     10000\n",
            "weighted avg       0.69      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  24   13   33  113    3  597   14   57  125    1]\n",
            " [   0 1130    1    3    0    1    0    0    0    0]\n",
            " [   1  158  507   66    8    9    7   61  215    0]\n",
            " [   0   22    5  910    1   25    0   11   30    6]\n",
            " [   0   86   14   18  361    8    4  118  215  158]\n",
            " [   1  103    0  105   30  576    2   13   47   15]\n",
            " [   1   90  104   12    7   86  168   42  448    0]\n",
            " [   0   66    6   22    3    3    0  881   10   37]\n",
            " [   0   41    6   72    2   20    0    8  809   16]\n",
            " [   0   13    5   29   19   19    0  130  131  663]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['5' '4' '1' ... '1' '8' '3']\n",
            "probabilities: (59640, 10) \n",
            " [5 4 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [  2 149  14  44   9  45   5  35  43  24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.538 s \n",
            "\n",
            "Accuracy rate for 60.350000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.03      0.06       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.70      0.50      0.58      1032\n",
            "           3       0.70      0.88      0.78      1010\n",
            "           4       0.84      0.36      0.51       982\n",
            "           5       0.44      0.67      0.53       892\n",
            "           6       0.82      0.18      0.30       958\n",
            "           7       0.67      0.84      0.75      1028\n",
            "           8       0.41      0.83      0.55       974\n",
            "           9       0.73      0.67      0.70      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.68      0.60      0.55     10000\n",
            "weighted avg       0.68      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  29   11   57   93    1  584   25   56  121    3]\n",
            " [   0 1127    1    2    0    2    1    0    2    0]\n",
            " [   2  179  512   52    4   14    8   61  199    1]\n",
            " [   1   33    6  889    2   30    0    8   35    6]\n",
            " [   1  101   22   26  357    7    4  124  171  169]\n",
            " [   1  105    0   89   26  600    1    6   48   16]\n",
            " [   0   96  114    3   10   90  173   38  434    0]\n",
            " [   0   70    7   22    4    3    0  868   12   42]\n",
            " [   0   51    5   66    3   18    0    8  805   18]\n",
            " [   0   13    7   31   16   22    0  124  121  675]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59630, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [  2 155  15  45  10  45   5  36  43  24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.799 s \n",
            "\n",
            "Accuracy rate for 60.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.03      0.05       980\n",
            "           1       0.64      1.00      0.78      1135\n",
            "           2       0.75      0.48      0.59      1032\n",
            "           3       0.66      0.89      0.76      1010\n",
            "           4       0.84      0.36      0.50       982\n",
            "           5       0.45      0.67      0.54       892\n",
            "           6       0.87      0.21      0.34       958\n",
            "           7       0.63      0.87      0.73      1028\n",
            "           8       0.43      0.83      0.57       974\n",
            "           9       0.74      0.68      0.71      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.70      0.60      0.56     10000\n",
            "weighted avg       0.70      0.61      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  27    9   37  126    1  548   17   68  145    2]\n",
            " [   0 1130    1    3    0    1    0    0    0    0]\n",
            " [   1  205  495   64    4   12    7   71  172    1]\n",
            " [   0   21    6  901    2   26    0   11   37    6]\n",
            " [   0   97   19   36  349    8    4  148  157  164]\n",
            " [   0   89    0  101   30  596    3   13   46   14]\n",
            " [   0   91   84   12   10   89  205   74  391    2]\n",
            " [   0   64    8   13    4    2    0  897    7   33]\n",
            " [   0   41    4   67    3   24    0   10  805   20]\n",
            " [   0   11    6   41   11   20    0  140   91  689]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59620, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [  2 160  15  48  10  45   5  37  43  25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.426 s \n",
            "\n",
            "Accuracy rate for 60.660000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.03      0.06       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.72      0.51      0.60      1032\n",
            "           3       0.67      0.90      0.77      1010\n",
            "           4       0.84      0.34      0.48       982\n",
            "           5       0.43      0.66      0.53       892\n",
            "           6       0.82      0.20      0.32       958\n",
            "           7       0.63      0.87      0.73      1028\n",
            "           8       0.44      0.80      0.57       974\n",
            "           9       0.74      0.66      0.70      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.69      0.60      0.55     10000\n",
            "weighted avg       0.69      0.61      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  28   11   45  119    1  580   21   76   97    2]\n",
            " [   0 1128    1    3    0    1    1    0    1    0]\n",
            " [   0  192  531   63    4   10    9   64  159    0]\n",
            " [   0   27    8  910    2   24    0   10   24    5]\n",
            " [   0   99   22   29  331   10    9  139  175  168]\n",
            " [   1  106    0   97   27  593    2   17   41    8]\n",
            " [   0   90  115   11    9   99  193   68  373    0]\n",
            " [   0   67    9   10    3    2    0  898   10   29]\n",
            " [   0   49    3   84    3   22    0    9  784   20]\n",
            " [   0   11    4   31   14   23    0  142  114  670]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59610, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [  2 165  15  48  10  45   5  37  45  28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.674 s \n",
            "\n",
            "Accuracy rate for 60.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.03      0.07       980\n",
            "           1       0.62      0.99      0.76      1135\n",
            "           2       0.73      0.47      0.57      1032\n",
            "           3       0.69      0.89      0.78      1010\n",
            "           4       0.84      0.35      0.49       982\n",
            "           5       0.45      0.64      0.53       892\n",
            "           6       0.82      0.20      0.32       958\n",
            "           7       0.64      0.86      0.74      1028\n",
            "           8       0.41      0.82      0.54       974\n",
            "           9       0.73      0.68      0.71      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.69      0.59      0.55     10000\n",
            "weighted avg       0.69      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  33   14   50  106    1  546   24   71  133    2]\n",
            " [   0 1128    2    2    0    1    1    0    1    0]\n",
            " [   1  210  481   59    4   10    9   60  198    0]\n",
            " [   0   29    6  901    2   21    1    8   34    8]\n",
            " [   0  103   17   14  340    9    5  141  189  164]\n",
            " [   0  112    0  108   24  572    3   10   45   18]\n",
            " [   0   93   89    8   11   74  193   65  423    2]\n",
            " [   0   72    7   11    4    3    0  887    8   36]\n",
            " [   0   42    6   79    3   19    0    7  794   24]\n",
            " [   0   14    4   25   14   20    0  128  116  688]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59600, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [  2 169  15  49  11  47   5  37  46  29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.505 s \n",
            "\n",
            "Accuracy rate for 60.690000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.02      0.03       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.71      0.50      0.59      1032\n",
            "           3       0.69      0.89      0.78      1010\n",
            "           4       0.82      0.41      0.55       982\n",
            "           5       0.44      0.65      0.52       892\n",
            "           6       0.79      0.17      0.29       958\n",
            "           7       0.63      0.86      0.73      1028\n",
            "           8       0.44      0.83      0.57       974\n",
            "           9       0.76      0.67      0.71      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.68      0.60      0.55     10000\n",
            "weighted avg       0.69      0.61      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  16   15   58   92    2  557   25   97  115    3]\n",
            " [   0 1128    1    3    0    1    1    0    1    0]\n",
            " [   1  189  516   61    4   13    9   63  175    1]\n",
            " [   0   32    7  901    1   23    0   10   30    6]\n",
            " [   0  114   16   20  402   11    7  113  159  140]\n",
            " [   0   97    0  102   37  577    3   15   46   15]\n",
            " [   0  101  112    4   25   89  167   60  400    0]\n",
            " [   0   73    4   18    6    2    0  879   14   32]\n",
            " [   0   42    3   71    3   23    0    6  807   19]\n",
            " [   0   12    5   35   13   19    0  143  106  676]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59590, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [  2 174  16  49  11  48   5  39  47  29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.269 s \n",
            "\n",
            "Accuracy rate for 60.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.03      0.05       980\n",
            "           1       0.62      0.99      0.76      1135\n",
            "           2       0.74      0.51      0.60      1032\n",
            "           3       0.68      0.89      0.77      1010\n",
            "           4       0.83      0.41      0.55       982\n",
            "           5       0.45      0.65      0.53       892\n",
            "           6       0.85      0.16      0.27       958\n",
            "           7       0.65      0.87      0.74      1028\n",
            "           8       0.42      0.82      0.55       974\n",
            "           9       0.77      0.66      0.71      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.69      0.60      0.56     10000\n",
            "weighted avg       0.69      0.61      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  26   15   52  105    1  542   14   75  148    2]\n",
            " [   0 1129    1    3    0    1    1    0    0    0]\n",
            " [   2  190  525   69    3   10    5   51  176    1]\n",
            " [   0   27    7  900    1   26    1    8   35    5]\n",
            " [   1  115   27   27  400   10    4  120  155  123]\n",
            " [   1  109    0   99   22  580    2   14   50   15]\n",
            " [   0  107   81    6   32   87  157   64  424    0]\n",
            " [   0   68    6   15    6    2    0  895    9   27]\n",
            " [   0   48    4   65    3   25    0    7  800   22]\n",
            " [   0   14    6   34   15   15    0  144  113  668]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['5' '3' '1' ... '1' '8' '3']\n",
            "probabilities: (59580, 10) \n",
            " [5 3 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [  2 178  16  50  12  48   6  41  47  30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.379 s \n",
            "\n",
            "Accuracy rate for 62.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.01      0.03       980\n",
            "           1       0.61      0.99      0.76      1135\n",
            "           2       0.74      0.52      0.61      1032\n",
            "           3       0.72      0.89      0.80      1010\n",
            "           4       0.82      0.46      0.59       982\n",
            "           5       0.44      0.66      0.53       892\n",
            "           6       0.86      0.20      0.33       958\n",
            "           7       0.68      0.87      0.76      1028\n",
            "           8       0.44      0.83      0.57       974\n",
            "           9       0.76      0.70      0.73      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.69      0.61      0.57     10000\n",
            "weighted avg       0.70      0.62      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  13   16   53   84    2  560   19   80  153    0]\n",
            " [   0 1127    2    2    0    1    1    0    2    0]\n",
            " [   1  201  534   49    4   10    8   54  170    1]\n",
            " [   0   29    8  897    1   29    0   10   29    7]\n",
            " [   0  124   17   11  449   11    2   87  139  142]\n",
            " [   0  107    0   93   32  586    3   12   46   13]\n",
            " [   1  102   94    5   27   78  196   45  410    0]\n",
            " [   0   69    4   10    7    2    0  890   10   36]\n",
            " [   0   45    3   65    3   22    0    6  808   22]\n",
            " [   0   13    5   22   22   23    0  130   88  706]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59570, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [  2 185  17  50  13  48   6  42  47  30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.333 s \n",
            "\n",
            "Accuracy rate for 63.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.04       980\n",
            "           1       0.66      0.99      0.79      1135\n",
            "           2       0.75      0.53      0.62      1032\n",
            "           3       0.71      0.89      0.79      1010\n",
            "           4       0.84      0.59      0.69       982\n",
            "           5       0.46      0.66      0.54       892\n",
            "           6       0.89      0.23      0.37       958\n",
            "           7       0.70      0.87      0.77      1028\n",
            "           8       0.44      0.84      0.58       974\n",
            "           9       0.77      0.68      0.72      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.72      0.63      0.59     10000\n",
            "weighted avg       0.72      0.64      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  21   13   61   89    3  519   11   74  188    1]\n",
            " [   0 1128    1    2    0    2    1    0    1    0]\n",
            " [   0  176  549   66   11    9    7   53  160    1]\n",
            " [   0   27    6  898    2   28    0    8   34    7]\n",
            " [   0   63   14    6  582    7    4   52  123  131]\n",
            " [   0   98    0   93   35  590    3   13   43   17]\n",
            " [   0   78   86    5   29   92  220   58  390    0]\n",
            " [   0   67    4   10    9    2    0  892   12   32]\n",
            " [   0   43    2   61    3   19    0    7  821   18]\n",
            " [   0   10    6   30   22   22    0  125  106  688]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['5' '4' '1' ... '1' '8' '3']\n",
            "probabilities: (59560, 10) \n",
            " [5 4 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [  2 192  17  51  13  48   6  43  48  30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.585 s \n",
            "\n",
            "Accuracy rate for 63.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.04      0.07       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.78      0.52      0.62      1032\n",
            "           3       0.69      0.89      0.78      1010\n",
            "           4       0.82      0.57      0.68       982\n",
            "           5       0.45      0.63      0.53       892\n",
            "           6       0.86      0.23      0.36       958\n",
            "           7       0.70      0.87      0.78      1028\n",
            "           8       0.43      0.83      0.57       974\n",
            "           9       0.77      0.68      0.72      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.71      0.62      0.59     10000\n",
            "weighted avg       0.71      0.63      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  35   17   43   99    3  516   20   74  171    2]\n",
            " [   0 1129    1    3    0    1    1    0    0    0]\n",
            " [   0  182  533   63    9    9    6   50  179    1]\n",
            " [   0   26    7  900    2   20    1   11   34    9]\n",
            " [   1   79    9   12  564    7    3   55  124  128]\n",
            " [   1  110    0  102   32  563    3   15   49   17]\n",
            " [   1   87   80    9   42   96  217   35  390    1]\n",
            " [   0   68    5    7   10    2    0  894   11   31]\n",
            " [   0   46    3   75    3   17    0    7  804   19]\n",
            " [   0   10    5   29   23   20    0  133  100  689]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '4' '1' ... '1' '8' '3']\n",
            "probabilities: (59550, 10) \n",
            " [5 4 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [  2 197  17  52  13  49   6  44  48  32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.879 s \n",
            "\n",
            "Accuracy rate for 63.840000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.03      0.06       980\n",
            "           1       0.65      0.99      0.79      1135\n",
            "           2       0.75      0.52      0.62      1032\n",
            "           3       0.69      0.90      0.78      1010\n",
            "           4       0.84      0.61      0.71       982\n",
            "           5       0.45      0.64      0.53       892\n",
            "           6       0.88      0.20      0.33       958\n",
            "           7       0.70      0.88      0.78      1028\n",
            "           8       0.44      0.82      0.57       974\n",
            "           9       0.79      0.71      0.75      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.72      0.63      0.59     10000\n",
            "weighted avg       0.72      0.64      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  29   13   48   95    4  532   16   77  165    1]\n",
            " [   0 1128    1    2    0    1    1    1    1    0]\n",
            " [   0  177  538   66    9    9    6   59  167    1]\n",
            " [   0   26    7  905    2   23    0   11   29    7]\n",
            " [   0   71   12    9  598    6    2   45  117  122]\n",
            " [   0  113    0   98   32  572    3   13   47   14]\n",
            " [   1   86   96    3   30   81  196   54  411    0]\n",
            " [   0   62    6    7    9    2    0  901   10   31]\n",
            " [   0   44    3   79    3   19    0    8  797   21]\n",
            " [   0    9    6   39   23   18    0  112   82  720]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['5' '4' '1' ... '1' '8' '3']\n",
            "probabilities: (59540, 10) \n",
            " [5 4 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [  2 203  17  52  15  49   6  45  48  33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.383 s \n",
            "\n",
            "Accuracy rate for 63.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.01      0.02       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.74      0.54      0.62      1032\n",
            "           3       0.71      0.89      0.79      1010\n",
            "           4       0.82      0.55      0.66       982\n",
            "           5       0.44      0.64      0.52       892\n",
            "           6       0.89      0.20      0.33       958\n",
            "           7       0.70      0.87      0.78      1028\n",
            "           8       0.46      0.83      0.59       974\n",
            "           9       0.76      0.75      0.76      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.69      0.63      0.59     10000\n",
            "weighted avg       0.69      0.64      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  12   13   61   94    3  550   12   82  151    2]\n",
            " [   0 1128    2    2    0    1    1    0    1    0]\n",
            " [   2  187  560   45    8   10    7   53  157    3]\n",
            " [   0   33   12  895    1   23    0   10   29    7]\n",
            " [   1   74   16   16  545    6    2   65  100  157]\n",
            " [   0  108    1  101   32  569    2   18   49   12]\n",
            " [   1   98   89    5   44   88  194   55  383    1]\n",
            " [   0   63    7    7    6    2    0  897   10   36]\n",
            " [   0   45    3   71    3   14    0    8  808   22]\n",
            " [   0   13    9   25   25   17    0   93   68  759]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59530, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [  2 210  17  53  15  49   6  46  48  34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.537 s \n",
            "\n",
            "Accuracy rate for 63.710000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.01      0.03       980\n",
            "           1       0.65      0.99      0.79      1135\n",
            "           2       0.76      0.54      0.63      1032\n",
            "           3       0.71      0.89      0.79      1010\n",
            "           4       0.85      0.52      0.65       982\n",
            "           5       0.46      0.63      0.53       892\n",
            "           6       0.89      0.23      0.36       958\n",
            "           7       0.69      0.89      0.78      1028\n",
            "           8       0.43      0.83      0.57       974\n",
            "           9       0.76      0.75      0.76      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.71      0.63      0.59     10000\n",
            "weighted avg       0.71      0.64      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  14   13   50   84    1  510   12   87  209    0]\n",
            " [   0 1128    1    3    0    1    1    0    1    0]\n",
            " [   1  177  556   56    5   13    7   53  163    1]\n",
            " [   0   24    9  895    1   24    0    9   38   10]\n",
            " [   0   76   11   12  514    6    4   63  131  165]\n",
            " [   0  113    1  103   26  565    3   16   53   12]\n",
            " [   1   87   92    3   32   70  216   66  390    1]\n",
            " [   0   58    6    8    6    2    0  911   10   27]\n",
            " [   0   44    3   68    3   16    0    7  813   20]\n",
            " [   0   13    7   26   17   15    0  101   71  759]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['5' '4' '1' ... '1' '8' '3']\n",
            "probabilities: (59520, 10) \n",
            " [5 4 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [  2 216  18  55  15  49   6  47  48  34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.746 s \n",
            "\n",
            "Accuracy rate for 63.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.04       980\n",
            "           1       0.67      0.99      0.80      1135\n",
            "           2       0.73      0.58      0.65      1032\n",
            "           3       0.69      0.90      0.79      1010\n",
            "           4       0.82      0.51      0.63       982\n",
            "           5       0.45      0.63      0.53       892\n",
            "           6       0.89      0.23      0.36       958\n",
            "           7       0.70      0.88      0.78      1028\n",
            "           8       0.46      0.82      0.59       974\n",
            "           9       0.74      0.74      0.74      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.71      0.63      0.59     10000\n",
            "weighted avg       0.72      0.64      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  22   13   66  109    3  536   18   85  126    2]\n",
            " [   0 1127    1    3    0    1    1    0    2    0]\n",
            " [   0  149  603   57    5    7    6   52  152    1]\n",
            " [   0   27    9  912    1   22    0    8   27    4]\n",
            " [   0   66   14   10  499    4    1   66  141  181]\n",
            " [   0  107    0  100   29  564    2   17   51   22]\n",
            " [   0   87  122    4   39   75  216   51  364    0]\n",
            " [   0   56    6   10    7    1    0  904   10   34]\n",
            " [   0   46    2   75    3   17    0    9  802   20]\n",
            " [   0   10    7   33   25   14    0   94   77  749]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['5' '1' '1' ... '1' '8' '3']\n",
            "probabilities: (59510, 10) \n",
            " [5 1 1 ... 1 8 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [  2 219  18  57  15  49   6  48  49  37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.578 s \n",
            "\n",
            "Accuracy rate for 63.920000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.02      0.04       980\n",
            "           1       0.69      0.99      0.82      1135\n",
            "           2       0.79      0.56      0.65      1032\n",
            "           3       0.64      0.91      0.75      1010\n",
            "           4       0.81      0.53      0.64       982\n",
            "           5       0.47      0.63      0.54       892\n",
            "           6       0.88      0.22      0.35       958\n",
            "           7       0.68      0.88      0.77      1028\n",
            "           8       0.44      0.82      0.58       974\n",
            "           9       0.77      0.74      0.76      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.71      0.63      0.59     10000\n",
            "weighted avg       0.71      0.64      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  19   10   36  130    3  488   15   89  190    0]\n",
            " [   0 1128    1    3    0    1    1    0    1    0]\n",
            " [   1  142  575   83    6    9    5   61  149    1]\n",
            " [   0   17    6  924    1   22    0    9   26    5]\n",
            " [   0   63   14   41  523    5    4   66  113  153]\n",
            " [   0   88    0  113   46  565    2   22   43   13]\n",
            " [   1   75   87   10   34   82  207   67  395    0]\n",
            " [   0   59    5   14    6    1    0  900   10   33]\n",
            " [   0   41    2   85    2   15    0    8  802   19]\n",
            " [   0   10    6   37   21   14    0   97   75  749]]\n",
            "--------------------------------\n",
            "final active learning accuracies [33.95, 37.769999999999996, 36.39, 31.169999999999998, 33.33, 39.300000000000004, 42.730000000000004, 44.96, 45.97, 46.72, 46.379999999999995, 47.89, 49.120000000000005, 49.08, 48.38, 49.02, 50.96000000000001, 51.51, 52.629999999999995, 53.43, 53.400000000000006, 52.62, 53.33, 52.72, 53.169999999999995, 54.55, 55.230000000000004, 57.37, 57.56, 58.64, 59.61, 58.550000000000004, 59.48, 58.96, 59.230000000000004, 60.29, 60.35, 60.940000000000005, 60.660000000000004, 60.17, 60.69, 60.8, 62.06, 63.89, 63.28, 63.839999999999996, 63.67, 63.71, 63.980000000000004, 63.92]\n",
            "saved Active-learning-experiment-30.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.95,\n",
            "          37.769999999999996,\n",
            "          36.39,\n",
            "          31.169999999999998,\n",
            "          33.33,\n",
            "          39.300000000000004,\n",
            "          42.730000000000004,\n",
            "          44.96,\n",
            "          45.97,\n",
            "          46.72,\n",
            "          46.379999999999995,\n",
            "          47.89,\n",
            "          49.120000000000005,\n",
            "          49.08,\n",
            "          48.38,\n",
            "          49.02,\n",
            "          50.96000000000001,\n",
            "          51.51,\n",
            "          52.629999999999995,\n",
            "          53.43,\n",
            "          53.400000000000006,\n",
            "          52.62,\n",
            "          53.33,\n",
            "          52.72,\n",
            "          53.169999999999995,\n",
            "          54.55,\n",
            "          55.230000000000004,\n",
            "          57.37,\n",
            "          57.56,\n",
            "          58.64,\n",
            "          59.61,\n",
            "          58.550000000000004,\n",
            "          59.48,\n",
            "          58.96,\n",
            "          59.230000000000004,\n",
            "          60.29,\n",
            "          60.35,\n",
            "          60.940000000000005,\n",
            "          60.660000000000004,\n",
            "          60.17,\n",
            "          60.69,\n",
            "          60.8,\n",
            "          62.06,\n",
            "          63.89,\n",
            "          63.28,\n",
            "          63.839999999999996,\n",
            "          63.67,\n",
            "          63.71,\n",
            "          63.980000000000004,\n",
            "          63.92\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.10000000000001,\n",
            "          73.02,\n",
            "          73.33,\n",
            "          72.53\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.730000000000004,\n",
            "          45.42,\n",
            "          46.589999999999996,\n",
            "          49.2,\n",
            "          50.44,\n",
            "          53.239999999999995,\n",
            "          57.08,\n",
            "          57.879999999999995,\n",
            "          60.47,\n",
            "          62.480000000000004,\n",
            "          60.68,\n",
            "          61.78,\n",
            "          61.18,\n",
            "          61.0,\n",
            "          59.84,\n",
            "          62.91,\n",
            "          62.99,\n",
            "          63.56,\n",
            "          64.05999999999999,\n",
            "          65.28\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          80.9,\n",
            "          81.05\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.98,\n",
            "          62.150000000000006,\n",
            "          62.67,\n",
            "          61.28,\n",
            "          60.5,\n",
            "          59.29,\n",
            "          60.480000000000004,\n",
            "          60.17,\n",
            "          60.86,\n",
            "          59.550000000000004\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.610000000000003,\n",
            "          39.07,\n",
            "          52.59,\n",
            "          60.88,\n",
            "          61.24000000000001,\n",
            "          67.75999999999999,\n",
            "          72.24000000000001,\n",
            "          74.92,\n",
            "          78.81,\n",
            "          79.96,\n",
            "          81.24,\n",
            "          82.33,\n",
            "          83.39999999999999,\n",
            "          85.04,\n",
            "          84.06,\n",
            "          85.28999999999999,\n",
            "          84.85000000000001,\n",
            "          85.45,\n",
            "          86.29,\n",
            "          86.78,\n",
            "          87.19,\n",
            "          87.11,\n",
            "          88.28,\n",
            "          88.01,\n",
            "          88.49000000000001,\n",
            "          88.3,\n",
            "          89.01,\n",
            "          89.29,\n",
            "          89.67,\n",
            "          90.22,\n",
            "          90.2,\n",
            "          90.22,\n",
            "          90.53,\n",
            "          91.07,\n",
            "          90.64,\n",
            "          90.96,\n",
            "          91.17,\n",
            "          91.47999999999999,\n",
            "          91.64999999999999,\n",
            "          91.74,\n",
            "          91.96,\n",
            "          91.63,\n",
            "          91.86,\n",
            "          91.9,\n",
            "          91.79,\n",
            "          91.9,\n",
            "          92.23,\n",
            "          92.08,\n",
            "          92.41,\n",
            "          92.54\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.8,\n",
            "          83.47,\n",
            "          89.21,\n",
            "          91.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.74999999999999,\n",
            "          66.17,\n",
            "          70.77,\n",
            "          77.29,\n",
            "          81.23,\n",
            "          82.98,\n",
            "          86.08,\n",
            "          88.09,\n",
            "          88.42,\n",
            "          88.94999999999999,\n",
            "          89.01,\n",
            "          89.88000000000001,\n",
            "          90.82000000000001,\n",
            "          91.28,\n",
            "          91.4,\n",
            "          92.01,\n",
            "          92.36999999999999,\n",
            "          91.9,\n",
            "          92.80000000000001,\n",
            "          93.22\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.06,\n",
            "          90.36\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          54.059999999999995,\n",
            "          71.72,\n",
            "          78.44,\n",
            "          83.62,\n",
            "          86.50999999999999,\n",
            "          88.63,\n",
            "          89.85,\n",
            "          91.10000000000001,\n",
            "          91.59,\n",
            "          91.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 31, using model = LogModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [24 15 34 34 27 17 25 29 25 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.394 s \n",
            "\n",
            "Accuracy rate for 74.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.87       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.79      0.64      0.71      1032\n",
            "           3       0.61      0.83      0.70      1010\n",
            "           4       0.70      0.76      0.73       982\n",
            "           5       0.97      0.24      0.38       892\n",
            "           6       0.80      0.83      0.81       958\n",
            "           7       0.86      0.81      0.83      1028\n",
            "           8       0.65      0.62      0.64       974\n",
            "           9       0.71      0.69      0.70      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.72     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    1    6    3    2    0   14    2    5    0]\n",
            " [   0 1086    1   15    1    0    3    2   27    0]\n",
            " [  48  122  659   21   68    1   50   22   35    6]\n",
            " [  42   13   25  834    6    0   10   12   60    8]\n",
            " [   3   22    4   19  742    0   41    2   30  119]\n",
            " [  95   47   18  276   44  210   36   31   97   38]\n",
            " [  38   11   26    5   74    1  795    0    8    0]\n",
            " [  10   53   17    4   20    0    3  828   18   75]\n",
            " [  12   79   52  130    9    4   34    8  608   38]\n",
            " [  12   20   21   52   96    0    7   51   49  701]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [56 39 64 60 52 43 50 49 44 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.418 s \n",
            "\n",
            "Accuracy rate for 75.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84       980\n",
            "           1       0.76      0.97      0.85      1135\n",
            "           2       0.82      0.58      0.68      1032\n",
            "           3       0.64      0.82      0.72      1010\n",
            "           4       0.76      0.79      0.78       982\n",
            "           5       0.87      0.42      0.56       892\n",
            "           6       0.74      0.86      0.79       958\n",
            "           7       0.80      0.87      0.83      1028\n",
            "           8       0.72      0.63      0.67       974\n",
            "           9       0.79      0.66      0.72      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 901    2   17    4    2    1   35   11    7    0]\n",
            " [   0 1097    2    6    0    0    3    3   24    0]\n",
            " [  52  111  594   29   49    1   87   48   53    8]\n",
            " [  42   17   21  831    5   11    5   18   41   19]\n",
            " [   2   18    1   25  777    6   56   10   20   67]\n",
            " [ 113   35   14  187   54  371   44   18   36   20]\n",
            " [  36   11   30    7   28    2  827    2   15    0]\n",
            " [   2   48   15    8   19    1    5  893   12   25]\n",
            " [  12   76   23  128    8   18   48   11  614   36]\n",
            " [   7   22    9   72   79   17   15  100   26  662]]\n",
            "--------------------------------\n",
            "final active learning accuracies [74.1, 75.67]\n",
            "saved Active-learning-experiment-31.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 32, using model = LogModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [15  9 12 16 12 10 12 12 19  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.256 s \n",
            "\n",
            "Accuracy rate for 67.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.85       980\n",
            "           1       0.67      0.96      0.79      1135\n",
            "           2       0.73      0.59      0.65      1032\n",
            "           3       0.63      0.72      0.67      1010\n",
            "           4       0.61      0.79      0.69       982\n",
            "           5       0.48      0.44      0.46       892\n",
            "           6       0.68      0.87      0.76       958\n",
            "           7       0.85      0.75      0.80      1028\n",
            "           8       0.68      0.32      0.44       974\n",
            "           9       0.59      0.45      0.51      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.68      0.67      0.66     10000\n",
            "weighted avg       0.68      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 814    2    1   28    4   42   82    3    0    4]\n",
            " [   0 1094   30    3    0    1    4    3    0    0]\n",
            " [  29  137  609   44   21   10  145   24    6    7]\n",
            " [   5   82   11  729    4   69   49   16   39    6]\n",
            " [   2   23   29    1  776   43   12    2   15   79]\n",
            " [  33   46    3  167   82  393   58   30   29   51]\n",
            " [   9   21   10    3   32   52  830    0    0    1]\n",
            " [  13   49   50    1   15   12    9  768    4  107]\n",
            " [   8  148   78  178   23  122   24   12  314   67]\n",
            " [  13   25   11   12  314   73    7   45   55  454]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 4 ... 5 6 2]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [31 28 27 27 23 21 22 20 32 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.362 s \n",
            "\n",
            "Accuracy rate for 73.410000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       980\n",
            "           1       0.76      0.97      0.85      1135\n",
            "           2       0.78      0.63      0.70      1032\n",
            "           3       0.70      0.70      0.70      1010\n",
            "           4       0.71      0.81      0.76       982\n",
            "           5       0.57      0.45      0.50       892\n",
            "           6       0.73      0.89      0.80       958\n",
            "           7       0.80      0.72      0.76      1028\n",
            "           8       0.71      0.59      0.64       974\n",
            "           9       0.68      0.64      0.66      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 870    2    2   17    8   33   44    0    1    3]\n",
            " [   0 1102   16    2    0    1    6    0    8    0]\n",
            " [  43   92  654   56   38    8  102   16   12   11]\n",
            " [  14   30   19  708    4   96   33   29   69    8]\n",
            " [  10   26    9    0  800   24   20    7   23   63]\n",
            " [  25   33   14   88   93  402   54   37   67   79]\n",
            " [   8   11   11    1   21   51  850    0    3    2]\n",
            " [  23   44   77    0   21    8    5  742    5  103]\n",
            " [  11   86   28  127   14   50   39   14  571   34]\n",
            " [  18   24    8   12  135   32    6   87   45  642]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [47 46 37 36 31 28 39 32 45 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.370 s \n",
            "\n",
            "Accuracy rate for 74.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.86       980\n",
            "           1       0.74      0.98      0.84      1135\n",
            "           2       0.78      0.61      0.68      1032\n",
            "           3       0.67      0.74      0.70      1010\n",
            "           4       0.73      0.80      0.76       982\n",
            "           5       0.67      0.48      0.56       892\n",
            "           6       0.73      0.90      0.81       958\n",
            "           7       0.78      0.73      0.75      1028\n",
            "           8       0.79      0.59      0.68       974\n",
            "           9       0.74      0.62      0.67      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    2    4   16    4    6   31    2    5    1]\n",
            " [   0 1114    4    2    0    1    8    0    6    0]\n",
            " [  49  130  630   53   28    5   80   15   32   10]\n",
            " [  18   36   36  752    6   54   36   28   35    9]\n",
            " [  25   25    5    1  782   50   28   19   12   35]\n",
            " [  26   29   13  162   70  426   72   18   31   45]\n",
            " [  22   12    8    1   15   22  864    1   13    0]\n",
            " [  37   47   68    3   28    5    6  751    3   80]\n",
            " [  14   94   32  112   13   42   43   11  574   39]\n",
            " [  27   23   12   22  130   28    8  123   15  621]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['6' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [6 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [56 60 50 49 49 41 55 39 58 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.421 s \n",
            "\n",
            "Accuracy rate for 73.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.80      0.63      0.70      1032\n",
            "           3       0.67      0.72      0.70      1010\n",
            "           4       0.68      0.83      0.75       982\n",
            "           5       0.74      0.39      0.51       892\n",
            "           6       0.72      0.88      0.79       958\n",
            "           7       0.77      0.75      0.76      1028\n",
            "           8       0.70      0.60      0.65       974\n",
            "           9       0.77      0.60      0.68      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 902    2    1   17    5    7   36    2    6    2]\n",
            " [   0 1114    3    2    0    1    9    0    6    0]\n",
            " [  39  124  649   39   36    5   95   12   31    2]\n",
            " [   8   47   57  732    7   40   34   30   51    4]\n",
            " [  23   23    1    2  817    9   20   15   30   42]\n",
            " [  18   23   11  155  111  348   78   31   72   45]\n",
            " [  26   16    5    1   29   26  844    1   10    0]\n",
            " [  29   64   50    1   41    1    5  770    5   62]\n",
            " [  13  105   26  123   19   17   52   11  585   23]\n",
            " [  30   29    7   21  130   17    7  127   35  606]]\n",
            "--------------------------------\n",
            "final active learning accuracies [67.81, 73.41, 74.22999999999999, 73.67]\n",
            "saved Active-learning-experiment-32.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 33, using model = LogModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [7 7 7 1 3 6 4 4 5 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.241 s \n",
            "\n",
            "Accuracy rate for 60.310000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84       980\n",
            "           1       0.77      0.94      0.84      1135\n",
            "           2       0.57      0.69      0.62      1032\n",
            "           3       0.81      0.14      0.24      1010\n",
            "           4       0.52      0.38      0.44       982\n",
            "           5       0.43      0.32      0.37       892\n",
            "           6       0.73      0.62      0.67       958\n",
            "           7       0.70      0.64      0.66      1028\n",
            "           8       0.44      0.60      0.51       974\n",
            "           9       0.46      0.78      0.58      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.62      0.60      0.58     10000\n",
            "weighted avg       0.63      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 844    0   24    2    5   35   14    7   42    7]\n",
            " [   0 1062   43    0    0    2   15    5    7    1]\n",
            " [  49   89  709    2    3   14   26   40   81   19]\n",
            " [  10   12   58  143    2  229   13   97  411   35]\n",
            " [  17   51   34    2  378   11   85    5   35  364]\n",
            " [  38   33   73   21   84  283   44   44  138  134]\n",
            " [  43   11  174    2   78   35  593    0   13    9]\n",
            " [   8   47   20    3   74    1    2  654    4  215]\n",
            " [  15   60   93    1   36   28    7   20  581  133]\n",
            " [  15   23   10    1   69   17   11   67   12  784]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['7' '0' '8' ... '9' '0' '2']\n",
            "probabilities: (59950, 10) \n",
            " [7 0 8 ... 9 0 2]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [13 10 12  5  6 10  8 13 11 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.293 s \n",
            "\n",
            "Accuracy rate for 67.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       980\n",
            "           1       0.83      0.93      0.87      1135\n",
            "           2       0.62      0.67      0.65      1032\n",
            "           3       0.70      0.70      0.70      1010\n",
            "           4       0.52      0.56      0.54       982\n",
            "           5       0.72      0.28      0.40       892\n",
            "           6       0.81      0.78      0.79       958\n",
            "           7       0.77      0.64      0.70      1028\n",
            "           8       0.60      0.66      0.63       974\n",
            "           9       0.49      0.64      0.56      1009\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.69      0.67      0.67     10000\n",
            "weighted avg       0.69      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    0   18    9    3   27   28    2   36    4]\n",
            " [   0 1053   59    0    1    0    3    4   15    0]\n",
            " [  26   76  692   94    8    5   34   41   40   16]\n",
            " [   8    5   39  710    3   11   10   57  146   21]\n",
            " [  21   23   32    0  549    1   17    2   17  320]\n",
            " [  32   16   85  129  132  249   54   42  136   17]\n",
            " [  46    7   79    3   42   21  745    0   12    3]\n",
            " [  13   42   26    0   56    0    3  660    2  226]\n",
            " [  12   37   63   63   39   23   19   14  644   60]\n",
            " [  19   13   15    8  223   10    6   39   32  644]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['7' '0' '9' ... '8' '6' '2']\n",
            "probabilities: (59900, 10) \n",
            " [7 0 9 ... 8 6 2]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [18 14 17 13 11 16 14 16 16 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.288 s \n",
            "\n",
            "Accuracy rate for 68.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82       980\n",
            "           1       0.77      0.95      0.85      1135\n",
            "           2       0.58      0.59      0.58      1032\n",
            "           3       0.59      0.81      0.68      1010\n",
            "           4       0.76      0.51      0.61       982\n",
            "           5       0.75      0.32      0.45       892\n",
            "           6       0.73      0.83      0.77       958\n",
            "           7       0.81      0.60      0.69      1028\n",
            "           8       0.67      0.66      0.66       974\n",
            "           9       0.55      0.75      0.63      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.70      0.68      0.68     10000\n",
            "weighted avg       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 795    0   18   41    1   26   56    5   36    2]\n",
            " [   0 1080   35    3    0    1    6    1    9    0]\n",
            " [  42  109  605   50    6    3   86   28   89   14]\n",
            " [  10   26   19  814    4   11   25   25   57   19]\n",
            " [  16   35   87   15  503    9   37    5   33  242]\n",
            " [  25   20   75  307   32  285   39   39   55   15]\n",
            " [  28    8   88    7    8   12  791    1   14    1]\n",
            " [  17   58   25    1   18    1    6  617   10  275]\n",
            " [   9   50   36  110    9   17   31   11  641   60]\n",
            " [  15   16   49   26   84   14    8   26   16  755]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '8' ... '5' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 8 ... 5 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [22 21 19 20 15 23 18 19 23 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.320 s \n",
            "\n",
            "Accuracy rate for 69.490000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       980\n",
            "           1       0.79      0.95      0.86      1135\n",
            "           2       0.56      0.56      0.56      1032\n",
            "           3       0.61      0.80      0.69      1010\n",
            "           4       0.64      0.76      0.70       982\n",
            "           5       0.67      0.32      0.43       892\n",
            "           6       0.70      0.80      0.75       958\n",
            "           7       0.81      0.69      0.74      1028\n",
            "           8       0.69      0.62      0.65       974\n",
            "           9       0.64      0.54      0.59      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.69      0.69      0.68     10000\n",
            "weighted avg       0.70      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 822    0   20   12    3   32   43   12   36    0]\n",
            " [   0 1073   42    4    0    1    6    1    8    0]\n",
            " [  42   87  578   63   24    4  135   24   70    5]\n",
            " [   9   22   19  813    8   32   18   33   37   19]\n",
            " [   5   28   75    3  750   16   29    3   14   59]\n",
            " [  28   23   70  283   58  283   38   40   66    3]\n",
            " [  36    6   96    3   20   13  766    1   16    1]\n",
            " [  12   57   25    2   28    3    8  709    5  179]\n",
            " [   5   52   47  127   23   17   39   10  608   46]\n",
            " [  11   18   54   21  258   24    8   44   24  547]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '5' '2']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 5 2]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [24 28 27 23 24 24 21 26 27 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.329 s \n",
            "\n",
            "Accuracy rate for 71.480000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       980\n",
            "           1       0.76      0.96      0.85      1135\n",
            "           2       0.61      0.56      0.58      1032\n",
            "           3       0.64      0.79      0.70      1010\n",
            "           4       0.67      0.79      0.73       982\n",
            "           5       0.68      0.35      0.46       892\n",
            "           6       0.72      0.82      0.77       958\n",
            "           7       0.82      0.75      0.78      1028\n",
            "           8       0.69      0.60      0.64       974\n",
            "           9       0.71      0.60      0.65      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    1   23    4    3   18   41   14   23    0]\n",
            " [   0 1091   28    4    0    1    7    0    4    0]\n",
            " [  49  104  578   78   24    4  108   25   52   10]\n",
            " [  17   24   19  794    6   30   22   24   51   23]\n",
            " [   0   25   61    4  773   24   22    2   19   52]\n",
            " [  45   28   61  227   67  310   48   42   62    2]\n",
            " [  30   10   65    2   28   17  789    2   13    2]\n",
            " [  11   60   33    2   26    3    5  770    4  114]\n",
            " [   9   73   35  118   22   24   51   14  580   48]\n",
            " [   9   19   44   15  198   28    8   51   27  610]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '5' '2']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 5 2]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [27 39 32 35 26 29 22 28 29 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.351 s \n",
            "\n",
            "Accuracy rate for 72.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.68      0.61      0.64      1032\n",
            "           3       0.62      0.79      0.69      1010\n",
            "           4       0.69      0.78      0.73       982\n",
            "           5       0.66      0.43      0.52       892\n",
            "           6       0.72      0.84      0.77       958\n",
            "           7       0.78      0.78      0.78      1028\n",
            "           8       0.79      0.56      0.65       974\n",
            "           9       0.74      0.58      0.65      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.72      0.71     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    1    9    3    3   31   36   28   14    1]\n",
            " [   0 1085   35    3    0    1    8    0    3    0]\n",
            " [  48  112  628   32   28    6  100   39   31    8]\n",
            " [  19   28   19  800    6   45   22   24   29   18]\n",
            " [   5   26   43   11  770   23   29    5   11   59]\n",
            " [  35   25   44  246   52  382   45   37   26    0]\n",
            " [  31    9   56    4   24   23  802    2    5    2]\n",
            " [   8   63   22    5   27    5    6  806    4   82]\n",
            " [   8   69   38  152   24   30   59   19  542   33]\n",
            " [  12   21   26   43  187   30   11   74   20  585]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '5' '2']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 5 2]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [32 44 37 38 32 37 25 30 35 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.326 s \n",
            "\n",
            "Accuracy rate for 73.430000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       980\n",
            "           1       0.76      0.96      0.85      1135\n",
            "           2       0.65      0.61      0.63      1032\n",
            "           3       0.63      0.83      0.72      1010\n",
            "           4       0.68      0.80      0.73       982\n",
            "           5       0.72      0.42      0.53       892\n",
            "           6       0.77      0.81      0.79       958\n",
            "           7       0.81      0.77      0.79      1028\n",
            "           8       0.76      0.60      0.67       974\n",
            "           9       0.74      0.61      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 872    2   11    5   10    9   21   19   31    0]\n",
            " [   0 1086   33    2    0    1    8    0    5    0]\n",
            " [  45  110  627   55   25    5   85   37   35    8]\n",
            " [  16   19   22  834    3   24   17   21   36   18]\n",
            " [   3   31   39   11  783   24   10    2   13   66]\n",
            " [  36   26   56  229   63  371   40   30   39    2]\n",
            " [  30    9   77    7   40   17  773    0    4    1]\n",
            " [   8   62   27    6   31    3    2  793    5   91]\n",
            " [  11   61   43  141   11   30   43   15  588   31]\n",
            " [  10   21   32   31  185   29    9   61   15  616]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '5' '2']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 5 2]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [35 50 41 43 38 39 32 36 41 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.405 s \n",
            "\n",
            "Accuracy rate for 74.140000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       980\n",
            "           1       0.74      0.96      0.84      1135\n",
            "           2       0.66      0.58      0.62      1032\n",
            "           3       0.64      0.80      0.71      1010\n",
            "           4       0.72      0.81      0.76       982\n",
            "           5       0.70      0.45      0.54       892\n",
            "           6       0.76      0.83      0.79       958\n",
            "           7       0.82      0.81      0.81      1028\n",
            "           8       0.78      0.57      0.66       974\n",
            "           9       0.78      0.65      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    2   10    1    3   10   27   18   17    0]\n",
            " [   0 1090   30    3    0    1    7    1    3    0]\n",
            " [  58  117  597   50   30    6   84   54   31    5]\n",
            " [  28   35   18  809    3   35   17   20   30   15]\n",
            " [   0   27   39    6  794   19   22    1   14   60]\n",
            " [  54   26   51  197   64  397   45   19   36    3]\n",
            " [  32   12   54    6   26   24  794    2    8    0]\n",
            " [   5   55   34    5   21    2    5  829    3   69]\n",
            " [  10   80   38  146   12   42   39   14  556   37]\n",
            " [   6   27   32   33  145   29    8   58   15  656]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '3' '5' '2']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 3 5 2]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [39 57 47 48 46 42 36 43 46 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.449 s \n",
            "\n",
            "Accuracy rate for 74.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.92      0.87       980\n",
            "           1       0.77      0.95      0.85      1135\n",
            "           2       0.67      0.57      0.61      1032\n",
            "           3       0.63      0.79      0.70      1010\n",
            "           4       0.71      0.79      0.75       982\n",
            "           5       0.68      0.48      0.56       892\n",
            "           6       0.76      0.85      0.80       958\n",
            "           7       0.81      0.83      0.82      1028\n",
            "           8       0.83      0.57      0.68       974\n",
            "           9       0.78      0.65      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    2    4    4    4    9   32   16    5    0]\n",
            " [   0 1078   44    2    0    1    6    1    3    0]\n",
            " [  58   85  588   62   42    5   87   71   31    3]\n",
            " [  23   35   16  799    2   49   18   16   31   21]\n",
            " [   2   25   34    8  776   27   20    5   11   74]\n",
            " [  57   24   54  197   67  424   37   15   12    5]\n",
            " [  21   10   49    9   26   27  810    1    5    0]\n",
            " [  12   48   29    7   26    2    5  855    3   41]\n",
            " [   9   70   42  151   11   45   36   11  556   43]\n",
            " [  10   23   22   35  139   33   12   66   13  656]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '3' '5' '2']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 3 5 2]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [42 59 56 52 51 46 39 53 54 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.507 s \n",
            "\n",
            "Accuracy rate for 74.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       980\n",
            "           1       0.77      0.96      0.85      1135\n",
            "           2       0.66      0.55      0.60      1032\n",
            "           3       0.62      0.80      0.70      1010\n",
            "           4       0.71      0.77      0.73       982\n",
            "           5       0.67      0.46      0.55       892\n",
            "           6       0.76      0.85      0.80       958\n",
            "           7       0.81      0.83      0.82      1028\n",
            "           8       0.83      0.57      0.67       974\n",
            "           9       0.76      0.66      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    2    6    2    7   17   32   10    5    0]\n",
            " [   0 1087   34    1    0    1    6    2    4    0]\n",
            " [  47  100  571   68   38    3   91   69   39    6]\n",
            " [  19   30   17  808    2   45   16   17   32   24]\n",
            " [   1   24   45    6  753   33   22   10    6   82]\n",
            " [  52   16   50  210   66  412   39   22   18    7]\n",
            " [  26   11   39   13   20   30  813    1    5    0]\n",
            " [   8   46   32    8   23    3    6  854    1   47]\n",
            " [  10   77   39  157   14   39   38    9  553   38]\n",
            " [   9   21   27   32  145   29   13   65    7  661]]\n",
            "--------------------------------\n",
            "final active learning accuracies [60.309999999999995, 67.99, 68.86, 69.49, 71.48, 72.54, 73.42999999999999, 74.14, 74.46000000000001, 74.11]\n",
            "saved Active-learning-experiment-33.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 34, using model = LogModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [5 1 3 3 3 1 1 2 4 2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.255 s \n",
            "\n",
            "Accuracy rate for 60.000000 \n",
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.94      0.76       980\n",
            "           1       0.86      0.79      0.82      1135\n",
            "           2       0.58      0.45      0.51      1032\n",
            "           3       0.52      0.68      0.59      1010\n",
            "           4       0.52      0.84      0.64       982\n",
            "           5       0.32      0.21      0.25       892\n",
            "           6       0.63      0.56      0.59       958\n",
            "           7       0.73      0.75      0.74      1028\n",
            "           8       0.53      0.52      0.53       974\n",
            "           9       0.60      0.21      0.31      1009\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.59      0.59      0.57     10000\n",
            "weighted avg       0.60      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[920   0   2  13   0   7  23   0  15   0]\n",
            " [  0 895  30  51   4  10   4   8 127   6]\n",
            " [ 94  28 467  78  23   2 235  33  69   3]\n",
            " [ 16   3  69 688   7 148  34  22  12  11]\n",
            " [ 23  14  17   6 821   0   6  17  43  35]\n",
            " [155  19  48 263  86 186   9  16  92  18]\n",
            " [144  30  71   3  29 132 532   1  15   1]\n",
            " [ 19  15   3  38  63  29   0 770  46  45]\n",
            " [ 44  36  78 151  48  60   4  22 511  20]\n",
            " [ 28   1  26  27 511  13   0 167  26 210]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '0' '4' ... '3' '0' '8']\n",
            "probabilities: (59975, 10) \n",
            " [3 0 4 ... 3 0 8]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [6 7 5 6 4 1 3 6 7 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.249 s \n",
            "\n",
            "Accuracy rate for 61.910000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.88      0.79       980\n",
            "           1       0.77      0.77      0.77      1135\n",
            "           2       0.71      0.61      0.65      1032\n",
            "           3       0.63      0.65      0.64      1010\n",
            "           4       0.53      0.80      0.64       982\n",
            "           5       0.35      0.25      0.29       892\n",
            "           6       0.62      0.47      0.54       958\n",
            "           7       0.66      0.84      0.74      1028\n",
            "           8       0.54      0.67      0.60       974\n",
            "           9       0.54      0.19      0.29      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.61      0.61      0.59     10000\n",
            "weighted avg       0.61      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[863   0   2  10   0  10  81   3  11   0]\n",
            " [  0 878  18   9   0   7   0   3 220   0]\n",
            " [ 90  56 626  58  11   7  35  32 112   5]\n",
            " [  6  39  27 654   4 174   0  42  59   5]\n",
            " [ 19  37   6   2 782   0  61   6  23  46]\n",
            " [ 57  39  33 189  57 226  58 122  55  56]\n",
            " [118  20 118   6  49 143 453   1  50   0]\n",
            " [ 12  22  25  15  37  20   2 859  20  16]\n",
            " [ 28  33  22  75  26  54  18  22 654  42]\n",
            " [ 23  15   6  16 505  11  19 209   9 196]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '4' ... '7' '0' '8']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 4 ... 7 0 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 8  9  7  7  6  4  4 10  8 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.243 s \n",
            "\n",
            "Accuracy rate for 66.950000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.88      0.79       980\n",
            "           1       0.78      0.76      0.77      1135\n",
            "           2       0.67      0.65      0.66      1032\n",
            "           3       0.63      0.78      0.70      1010\n",
            "           4       0.56      0.72      0.63       982\n",
            "           5       0.76      0.33      0.46       892\n",
            "           6       0.68      0.63      0.66       958\n",
            "           7       0.77      0.83      0.80      1028\n",
            "           8       0.56      0.68      0.61       974\n",
            "           9       0.63      0.37      0.47      1009\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.68      0.66      0.66     10000\n",
            "weighted avg       0.68      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[859   0   3   6   3   6  90   3  10   0]\n",
            " [  0 868  45   1   0   1   3   3 213   1]\n",
            " [ 90  53 675  29   6   3  48  40  70  18]\n",
            " [  9  34  59 785   1  36   7  21  34  24]\n",
            " [ 22  37   6   1 711   1  39   8  42 115]\n",
            " [ 31  23  23 297  42 295  49  32  89  11]\n",
            " [105  15 109   3  74  20 607   0  23   2]\n",
            " [ 25  35  13  14  27   0   2 857  27  28]\n",
            " [ 21  38  66  85  24  20  24  13 661  22]\n",
            " [ 31  17   2  22 387   5  21 130  17 377]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '4' ... '8' '0' '8']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 4 ... 8 0 8]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [10 13  9  8  8  5  8 15  9 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.274 s \n",
            "\n",
            "Accuracy rate for 69.600000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       980\n",
            "           1       0.77      0.93      0.84      1135\n",
            "           2       0.66      0.70      0.68      1032\n",
            "           3       0.64      0.72      0.68      1010\n",
            "           4       0.57      0.81      0.67       982\n",
            "           5       0.78      0.35      0.48       892\n",
            "           6       0.69      0.74      0.71       958\n",
            "           7       0.84      0.78      0.81      1028\n",
            "           8       0.68      0.64      0.66       974\n",
            "           9       0.63      0.41      0.49      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.69      0.68     10000\n",
            "weighted avg       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 815    0   28   16    2    2  102    3    9    3]\n",
            " [   0 1051   52    2    0    0    3    2   24    1]\n",
            " [  62   80  723   17   33    5   45   26   31   10]\n",
            " [   5   26   88  729   15   24    8   14   82   19]\n",
            " [  22   18    4    1  798    0   47    5   18   69]\n",
            " [  27   31   25  236   63  311   60   24   96   19]\n",
            " [  88   11   87   12   21   16  705    0   17    1]\n",
            " [  19   60   12   14   21    3    3  797   11   88]\n",
            " [  12   57   71   85   16   33   27   17  622   34]\n",
            " [  29   23    3   19  431    5   25   56    9  409]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '8' '5' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 8 5 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [12 16 10 12 13  8  9 16 10 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.323 s \n",
            "\n",
            "Accuracy rate for 71.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79       980\n",
            "           1       0.78      0.93      0.85      1135\n",
            "           2       0.71      0.73      0.72      1032\n",
            "           3       0.72      0.68      0.70      1010\n",
            "           4       0.61      0.73      0.66       982\n",
            "           5       0.62      0.49      0.55       892\n",
            "           6       0.71      0.66      0.68       958\n",
            "           7       0.83      0.81      0.82      1028\n",
            "           8       0.78      0.68      0.72       974\n",
            "           9       0.57      0.53      0.55      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 816    1   13   14    3   40   81    1    9    2]\n",
            " [   0 1059   50    2    0    0    4    5   15    0]\n",
            " [  39   70  749   17   15    7   58   29   32   16]\n",
            " [   4   21   79  685    3  106    6   21   43   42]\n",
            " [  20   26    5    0  712    5   24    1   23  166]\n",
            " [  26   37   13  149   52  439   37   31   38   70]\n",
            " [ 129    4   77    2   42   57  632    0   12    3]\n",
            " [  13   59   15    5   24    1    1  832    8   70]\n",
            " [  12   55   52   63    7   34   33   15  658   45]\n",
            " [  28   19    3   16  305   16   13   62    8  539]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [16 17 15 14 14 13 11 18 11 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.346 s \n",
            "\n",
            "Accuracy rate for 71.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.80       980\n",
            "           1       0.76      0.96      0.85      1135\n",
            "           2       0.72      0.71      0.72      1032\n",
            "           3       0.68      0.74      0.70      1010\n",
            "           4       0.62      0.69      0.65       982\n",
            "           5       0.63      0.46      0.53       892\n",
            "           6       0.74      0.68      0.71       958\n",
            "           7       0.83      0.82      0.82      1028\n",
            "           8       0.70      0.67      0.68       974\n",
            "           9       0.61      0.51      0.55      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.70      0.70      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 796    1   18   15    2   50   79    2   17    0]\n",
            " [   0 1088    9    2    0    0    3    5   28    0]\n",
            " [  31   89  735   55   14    7   37   26   34    4]\n",
            " [   4   20   47  743    2   69    5   28   71   21]\n",
            " [  18   28   13    0  678    7   37    0   17  184]\n",
            " [  21   38   25  183   37  413   33   35   86   21]\n",
            " [  97   11  120    0   16   40  653    0   16    5]\n",
            " [  14   65   16    6   18    0    1  838    7   63]\n",
            " [  10   76   24   70    5   60   32   15  648   34]\n",
            " [  28   21    9   24  323   12    8   66    8  510]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '8' '5' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 8 5 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [16 18 16 21 17 16 14 22 13 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.349 s \n",
            "\n",
            "Accuracy rate for 72.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.84      0.81       980\n",
            "           1       0.78      0.96      0.86      1135\n",
            "           2       0.80      0.71      0.75      1032\n",
            "           3       0.68      0.74      0.71      1010\n",
            "           4       0.66      0.73      0.69       982\n",
            "           5       0.60      0.45      0.51       892\n",
            "           6       0.76      0.76      0.76       958\n",
            "           7       0.80      0.82      0.81      1028\n",
            "           8       0.72      0.65      0.68       974\n",
            "           9       0.61      0.55      0.58      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.72      0.72      0.72     10000\n",
            "weighted avg       0.72      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 819    1   10    5    4   58   63    5   14    1]\n",
            " [   0 1090   19    9    0    1    4    3    8    1]\n",
            " [  34   76  730   54   16    6   59   27   22    8]\n",
            " [   5   16   36  746    1   65   11   29   71   30]\n",
            " [  16   24    8    0  719    7   24    2   13  169]\n",
            " [  20   29   18  162   55  397   28   53   91   39]\n",
            " [ 104    7   46    0   14   50  726    0    8    3]\n",
            " [  13   62   23    2   13    1    3  839    5   67]\n",
            " [  13   69   18  100    5   63   28   15  630   33]\n",
            " [  27   20    3   19  267   13   14   74   18  554]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '4' ... '8' '5' '8']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 4 ... 8 5 8]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [20 20 20 25 18 20 15 25 13 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.297 s \n",
            "\n",
            "Accuracy rate for 72.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       980\n",
            "           1       0.78      0.97      0.87      1135\n",
            "           2       0.82      0.71      0.76      1032\n",
            "           3       0.66      0.79      0.72      1010\n",
            "           4       0.66      0.72      0.68       982\n",
            "           5       0.64      0.42      0.51       892\n",
            "           6       0.73      0.82      0.77       958\n",
            "           7       0.81      0.82      0.82      1028\n",
            "           8       0.70      0.61      0.65       974\n",
            "           9       0.63      0.55      0.58      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.72      0.72      0.72     10000\n",
            "weighted avg       0.72      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 785    1   15   17    6   48   84    9   15    0]\n",
            " [   0 1098   14   10    0    0    4    2    7    0]\n",
            " [  25   72  734   31   21    6   73   34   24   12]\n",
            " [   6   16   39  798    1   14   11   28   72   25]\n",
            " [  16   28    2    3  703   15   33    4   10  168]\n",
            " [  21   31   19  208   44  376   34   32  102   25]\n",
            " [  88    7   26    2   11   28  783    0   10    3]\n",
            " [  12   70   18    3   11    0    1  847    5   61]\n",
            " [   6   58   31  112    3   82   39   15  593   35]\n",
            " [  23   20    2   20  273   17   13   79   11  551]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '8' '5' '5']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 8 5 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [21 22 21 27 23 23 19 27 15 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 73.580000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.83      0.81       980\n",
            "           1       0.79      0.95      0.86      1135\n",
            "           2       0.84      0.72      0.78      1032\n",
            "           3       0.70      0.80      0.74      1010\n",
            "           4       0.67      0.69      0.68       982\n",
            "           5       0.66      0.43      0.52       892\n",
            "           6       0.75      0.79      0.77       958\n",
            "           7       0.78      0.83      0.81      1028\n",
            "           8       0.67      0.70      0.68       974\n",
            "           9       0.66      0.56      0.61      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 812    1   14    8    8   48   60   13   16    0]\n",
            " [   0 1075    4   20    0    0    4    3   29    0]\n",
            " [  29   70  746   27    9    9   63   36   37    6]\n",
            " [   6   11   29  808    0   17    9   32   81   17]\n",
            " [  22   31    8    2  679   12   40    3   21  164]\n",
            " [  24   25   16  192   46  386   32   35  109   27]\n",
            " [  85    7   29    0   18   39  754    0   25    1]\n",
            " [  13   62   20    4   13    0    4  856    8   48]\n",
            " [   7   55   20   80    7   61   26   15  679   24]\n",
            " [  26   19    3   21  241   14   12   98   12  563]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['3' '0' '4' ... '8' '5' '8']\n",
            "probabilities: (59775, 10) \n",
            " [3 0 4 ... 8 5 8]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 27 22 31 24 25 19 33 18 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.338 s \n",
            "\n",
            "Accuracy rate for 73.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.85      0.82       980\n",
            "           1       0.80      0.95      0.87      1135\n",
            "           2       0.82      0.71      0.76      1032\n",
            "           3       0.66      0.82      0.73      1010\n",
            "           4       0.67      0.73      0.70       982\n",
            "           5       0.67      0.42      0.52       892\n",
            "           6       0.74      0.79      0.77       958\n",
            "           7       0.78      0.86      0.82      1028\n",
            "           8       0.72      0.63      0.67       974\n",
            "           9       0.70      0.56      0.62      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 836    1   10    9    8   39   47   16   14    0]\n",
            " [   0 1079   13   32    0    0    5    3    3    0]\n",
            " [  34   67  737   24   12    5   69   47   33    4]\n",
            " [   5   14   44  827    1    9    7   25   61   17]\n",
            " [  22   30    4    5  712   13   46    3   11  136]\n",
            " [  31   30   20  208   57  374   28   28   90   26]\n",
            " [  97    7   25    3   13   41  758    0   13    1]\n",
            " [  11   54   20    4   17    0    5  883    6   28]\n",
            " [  10   55   22  123    5   62   40   12  614   31]\n",
            " [  25   17    2   26  231   15   13  108   11  561]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '8' '5' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 8 5 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [27 30 28 32 26 26 19 36 20 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.400 s \n",
            "\n",
            "Accuracy rate for 73.590000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       980\n",
            "           1       0.79      0.96      0.87      1135\n",
            "           2       0.83      0.70      0.76      1032\n",
            "           3       0.67      0.80      0.73      1010\n",
            "           4       0.64      0.72      0.68       982\n",
            "           5       0.66      0.44      0.53       892\n",
            "           6       0.74      0.81      0.77       958\n",
            "           7       0.82      0.82      0.82      1028\n",
            "           8       0.69      0.66      0.67       974\n",
            "           9       0.69      0.53      0.60      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 837    1   11    8   14   37   52    3   17    0]\n",
            " [   0 1092    2   31    0    0    4    3    3    0]\n",
            " [  36   74  724   30   17    1   81   31   32    6]\n",
            " [   8   14   42  805    0   14    8   22   82   15]\n",
            " [  15   30    3    5  711   28   48    4   10  128]\n",
            " [  32   31   16  188   56  395   28   18  114   14]\n",
            " [  79   11   18    2   14   44  777    0   12    1]\n",
            " [  18   57   23    5   23    2    5  842    7   46]\n",
            " [  10   57   28   98    8   57   40    8  638   30]\n",
            " [  23   19    3   27  265   18   13   92   11  538]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['3' '0' '4' ... '8' '5' '5']\n",
            "probabilities: (59725, 10) \n",
            " [3 0 4 ... 8 5 5]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [32 34 29 33 29 28 21 40 21 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 73.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       980\n",
            "           1       0.79      0.97      0.87      1135\n",
            "           2       0.81      0.68      0.74      1032\n",
            "           3       0.66      0.81      0.73      1010\n",
            "           4       0.67      0.70      0.69       982\n",
            "           5       0.75      0.44      0.55       892\n",
            "           6       0.71      0.81      0.76       958\n",
            "           7       0.83      0.81      0.82      1028\n",
            "           8       0.75      0.56      0.64       974\n",
            "           9       0.62      0.63      0.62      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    2   12    8    6   14   56    3    8    0]\n",
            " [   0 1096    3   24    0    0    4    2    6    0]\n",
            " [  44   74  701   30   17    0  100   32   17   17]\n",
            " [   8   11   48  817    1   14    3   20   52   36]\n",
            " [  13   27    1    3  688   13   58    3    4  172]\n",
            " [  36   31   23  203   57  392   27   18   76   29]\n",
            " [  84    7   25    1   28   22  778    0   12    1]\n",
            " [  22   54   21    4   21    0    3  828    2   73]\n",
            " [  12   65   30  126    7   53   56   10  548   67]\n",
            " [  23   12    2   23  201   15   14   83    5  631]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '8' '0' '5']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 8 0 5]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [34 40 31 37 30 30 24 43 22 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.336 s \n",
            "\n",
            "Accuracy rate for 72.750000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83       980\n",
            "           1       0.78      0.97      0.87      1135\n",
            "           2       0.80      0.70      0.75      1032\n",
            "           3       0.67      0.77      0.71      1010\n",
            "           4       0.61      0.74      0.67       982\n",
            "           5       0.69      0.42      0.52       892\n",
            "           6       0.76      0.80      0.78       958\n",
            "           7       0.83      0.81      0.82      1028\n",
            "           8       0.65      0.61      0.63       974\n",
            "           9       0.66      0.53      0.59      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.72      0.72      0.72     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    2   10    6   12   27   48    9   12    0]\n",
            " [   0 1100    5   21    0    0    4    3    2    0]\n",
            " [  41   88  725   29   19    0   67   30   24    9]\n",
            " [   7   17   43  777    2   11    3   20  110   20]\n",
            " [  13   27    5    4  726   17   42    4    8  136]\n",
            " [  33   29   23  182   65  371   23   19  138    9]\n",
            " [  74    8   30    0   31   41  768    0    5    1]\n",
            " [  21   56   27    5   23    1    3  828    4   60]\n",
            " [   9   61   37  120    7   51   48   11  595   35]\n",
            " [  21   14    2   20  300   18    9   78   16  531]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['3' '0' '4' ... '8' '5' '5']\n",
            "probabilities: (59675, 10) \n",
            " [3 0 4 ... 8 5 5]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [37 40 33 39 33 33 26 47 25 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.350 s \n",
            "\n",
            "Accuracy rate for 73.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83       980\n",
            "           1       0.78      0.96      0.86      1135\n",
            "           2       0.80      0.70      0.74      1032\n",
            "           3       0.68      0.77      0.72      1010\n",
            "           4       0.65      0.73      0.69       982\n",
            "           5       0.67      0.45      0.53       892\n",
            "           6       0.75      0.81      0.78       958\n",
            "           7       0.82      0.79      0.81      1028\n",
            "           8       0.70      0.63      0.67       974\n",
            "           9       0.68      0.60      0.64      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 850    1   11    4   13   31   42    9   19    0]\n",
            " [   0 1091    5   27    0    2    4    2    4    0]\n",
            " [  37   92  721   25   16    1   79   27   25    9]\n",
            " [   9   16   54  780    2   19    5   22   77   26]\n",
            " [  11   27    3    7  721   20   49    5    8  131]\n",
            " [  30   33   19  168   78  397   26   23  105   13]\n",
            " [  72    8   21    0   23   47  776    0   10    1]\n",
            " [  20   53   35    6   26    2    5  817    3   61]\n",
            " [  11   59   31  108    7   57   38    8  614   41]\n",
            " [  18   13    4   28  218   20   11   85    7  605]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '8' '5' '5']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 8 5 5]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [41 40 38 43 36 34 29 50 27 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.384 s \n",
            "\n",
            "Accuracy rate for 73.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       980\n",
            "           1       0.77      0.96      0.86      1135\n",
            "           2       0.81      0.65      0.72      1032\n",
            "           3       0.67      0.80      0.73      1010\n",
            "           4       0.67      0.73      0.70       982\n",
            "           5       0.66      0.46      0.54       892\n",
            "           6       0.74      0.82      0.77       958\n",
            "           7       0.82      0.78      0.80      1028\n",
            "           8       0.73      0.63      0.68       974\n",
            "           9       0.68      0.62      0.65      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 842    2    4    4   19   37   39    9   24    0]\n",
            " [   0 1088    5   32    0    2    3    3    2    0]\n",
            " [  54   97  675   32   21    1   85   22   37    8]\n",
            " [   9   22   34  812    2   27    3   18   56   27]\n",
            " [  16   28    1    4  717   20   61    5    4  126]\n",
            " [  33   33   16  184   77  411   21   23   74   20]\n",
            " [  60   10   22    0   28   47  782    1    7    1]\n",
            " [  22   52   43    6   26    4    4  799    5   67]\n",
            " [   8   60   26  116    6   48   52    5  612   41]\n",
            " [  20   16    8   23  181   22   12   87   12  628]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '5' '7']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 5 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [46 41 40 43 40 37 32 53 28 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.387 s \n",
            "\n",
            "Accuracy rate for 74.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.84       980\n",
            "           1       0.79      0.96      0.86      1135\n",
            "           2       0.82      0.65      0.73      1032\n",
            "           3       0.66      0.81      0.72      1010\n",
            "           4       0.65      0.76      0.70       982\n",
            "           5       0.68      0.44      0.53       892\n",
            "           6       0.75      0.85      0.80       958\n",
            "           7       0.83      0.80      0.82      1028\n",
            "           8       0.71      0.66      0.69       974\n",
            "           9       0.70      0.56      0.62      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    1    3    6   10   26   40   11   27    0]\n",
            " [   0 1087    5   32    0    2    4    2    3    0]\n",
            " [  55   98  669   35   23    3   80   23   40    6]\n",
            " [  12   16   32  814    1   19    9   20   65   22]\n",
            " [  11   23    1    8  748   17   52    7    6  109]\n",
            " [  34   37   18  194   69  389   26   15   90   20]\n",
            " [  52    7   16    1   16   43  813    0    9    1]\n",
            " [  22   48   39    6   29    4    5  821    8   46]\n",
            " [   9   51   22  118    5   40   47    5  643   34]\n",
            " [  19   15    7   26  257   25   10   80    9  561]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59600, 10) \n",
            " [5 0 4 ... 5 5 5]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [48 42 42 44 40 42 36 55 32 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.402 s \n",
            "\n",
            "Accuracy rate for 74.380000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.85       980\n",
            "           1       0.77      0.96      0.86      1135\n",
            "           2       0.81      0.67      0.73      1032\n",
            "           3       0.68      0.80      0.73      1010\n",
            "           4       0.69      0.76      0.72       982\n",
            "           5       0.67      0.42      0.52       892\n",
            "           6       0.76      0.86      0.81       958\n",
            "           7       0.82      0.78      0.80      1028\n",
            "           8       0.67      0.65      0.66       974\n",
            "           9       0.72      0.61      0.66      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.74      0.73     10000\n",
            "weighted avg       0.74      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 867    2    3    3    7   27   26    8   35    2]\n",
            " [   0 1088    7   28    0    2    6    2    2    0]\n",
            " [  48  105  687   33   18    3   71   25   37    5]\n",
            " [   9   18   35  804    0   25    6   22   64   27]\n",
            " [  13   31    5    7  743   26   45    8   10   94]\n",
            " [  33   38   17  167   58  379   30   20  134   16]\n",
            " [  48    7   19    1   18   37  820    1    7    0]\n",
            " [  18   46   40    5   24    4    5  806    5   75]\n",
            " [  10   61   27  122    5   37   51    6  633   22]\n",
            " [  18   13    7   18  205   25   12   83   17  611]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['5' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59575, 10) \n",
            " [5 0 4 ... 5 5 5]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [49 45 46 46 41 45 40 59 33 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.387 s \n",
            "\n",
            "Accuracy rate for 73.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       980\n",
            "           1       0.79      0.95      0.86      1135\n",
            "           2       0.80      0.63      0.71      1032\n",
            "           3       0.64      0.80      0.71      1010\n",
            "           4       0.69      0.74      0.72       982\n",
            "           5       0.67      0.36      0.47       892\n",
            "           6       0.71      0.88      0.79       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.67      0.63      0.65       974\n",
            "           9       0.72      0.62      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 838    2    2    3   15   33   37   12   38    0]\n",
            " [   0 1083   12   29    0    1    7    2    1    0]\n",
            " [  48   84  652   40   28    1   98   24   50    7]\n",
            " [   9   18   29  806    0   23   12   19   65   29]\n",
            " [   9   24    2   10  728   29   58   11    5  106]\n",
            " [  28   41   24  195   72  323   47   21  119   22]\n",
            " [  39   10   14    6   15   22  844    1    7    0]\n",
            " [  21   42   44    6   20    4    5  825    7   54]\n",
            " [   8   54   27  143    5   23   66    5  614   29]\n",
            " [  19   13    8   28  170   22   15   90   15  629]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 4 ... 5 0 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [54 47 49 46 45 48 41 62 36 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.428 s \n",
            "\n",
            "Accuracy rate for 73.050000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       980\n",
            "           1       0.79      0.94      0.86      1135\n",
            "           2       0.78      0.63      0.70      1032\n",
            "           3       0.64      0.79      0.71      1010\n",
            "           4       0.65      0.77      0.71       982\n",
            "           5       0.64      0.49      0.55       892\n",
            "           6       0.72      0.87      0.79       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.72      0.60      0.65       974\n",
            "           9       0.75      0.56      0.64      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 813    2    2    3   29   50   31   11   38    1]\n",
            " [   0 1070   15   39    0    2    6    2    1    0]\n",
            " [  53   83  648   48   29    2  103   25   34    7]\n",
            " [  13   22   35  797    2   33    9   21   54   24]\n",
            " [  16   23    1    8  754   40   53   11    7   69]\n",
            " [  31   38   21  158   75  437   34   19   66   13]\n",
            " [  40   11   13    2   18   37  832    1    4    0]\n",
            " [  20   44   56    6   23    8    5  809    7   50]\n",
            " [   9   54   33  160    6   40   60    6  585   21]\n",
            " [  20   15    6   15  220   39   18   98   18  560]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['6' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59525, 10) \n",
            " [6 0 4 ... 5 5 5]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [55 50 52 49 46 50 42 66 38 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.462 s \n",
            "\n",
            "Accuracy rate for 73.240000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       980\n",
            "           1       0.77      0.94      0.85      1135\n",
            "           2       0.78      0.58      0.66      1032\n",
            "           3       0.65      0.80      0.71      1010\n",
            "           4       0.68      0.75      0.71       982\n",
            "           5       0.63      0.49      0.55       892\n",
            "           6       0.71      0.86      0.78       958\n",
            "           7       0.83      0.78      0.80      1028\n",
            "           8       0.75      0.62      0.68       974\n",
            "           9       0.74      0.61      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.72     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 830    2    2    4   21   46   34   10   30    1]\n",
            " [   0 1066   21   39    0    1    5    2    1    0]\n",
            " [  59   99  596   57   30    3  112   25   44    7]\n",
            " [  12   24   38  805    3   32    9   17   44   26]\n",
            " [  19   25    0    7  733   49   59   10    5   75]\n",
            " [  32   43   20  161   75  438   37   15   49   22]\n",
            " [  46   12   10    3   19   34  828    0    5    1]\n",
            " [  22   46   52    6   21    7    4  802    7   61]\n",
            " [   8   53   23  145    6   42   55    5  607   30]\n",
            " [  20   15    3   18  176   43   21   82   12  619]]\n",
            "--------------------------------\n",
            "final active learning accuracies [60.0, 61.91, 66.95, 69.6, 71.21, 71.02000000000001, 72.5, 72.68, 73.58, 73.81, 73.59, 73.5, 72.75, 73.72, 73.66, 74.00999999999999, 74.38, 73.42, 73.05, 73.24000000000001]\n",
            "saved Active-learning-experiment-34.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 35, using model = LogModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 1 0 0 0 3 0 2 1 1] [0 1 5 7 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.208 s \n",
            "\n",
            "Accuracy rate for 31.180000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.62      0.44       980\n",
            "           1       0.63      0.61      0.62      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.26      0.38      0.31       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.31      0.85      0.46      1028\n",
            "           8       0.19      0.56      0.28       974\n",
            "           9       0.42      0.06      0.11      1009\n",
            "\n",
            "    accuracy                           0.31     10000\n",
            "   macro avg       0.22      0.31      0.22     10000\n",
            "weighted avg       0.22      0.31      0.23     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[607   1   0   0   0  67   0   8 296   1]\n",
            " [  5 697   0   0   0 315   0  67  51   0]\n",
            " [219 211   0   0   0  20   0 261 310  11]\n",
            " [ 92  17   0   0   0 222   0 142 531   6]\n",
            " [ 48  53   0   0   0  72   0 502 264  43]\n",
            " [ 68   9   0   0   0 340   0  75 398   2]\n",
            " [668  14   0   0   0 125   0  39 111   1]\n",
            " [  4  28   0   0   0   5   0 869 103  19]\n",
            " [ 18  79   0   0   0 102   0 231 543   1]\n",
            " [ 29   3   0   0   0  36   0 583 296  62]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['5' '0' '8' ... '8' '0' '5']\n",
            "probabilities: (59990, 6) \n",
            " [2 0 4 ... 4 0 2]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [6 1 1 3 0 4 1 2 1 1] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.254 s \n",
            "\n",
            "Accuracy rate for 40.350000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.84      0.62       980\n",
            "           1       0.61      0.61      0.61      1135\n",
            "           2       0.73      0.26      0.38      1032\n",
            "           3       0.29      0.85      0.43      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.28      0.47      0.35       892\n",
            "           6       0.52      0.15      0.24       958\n",
            "           7       0.41      0.72      0.52      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.33      0.08      0.12      1009\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.36      0.40      0.33     10000\n",
            "weighted avg       0.37      0.40      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[828   1   2  10   0 136   0   2   0   1]\n",
            " [  0 698   0 389   0  18   0  30   0   0]\n",
            " [ 55 265 269 164   0  39 100 135   0   5]\n",
            " [ 16   5  17 854   0  69  19  17   0  13]\n",
            " [131  30  49 205   0 171  10 322   0  64]\n",
            " [104   9   3 329   0 421   3   5   0  18]\n",
            " [361  12   8 164   0 190 147  76   0   0]\n",
            " [ 38  30  10 109   0  43   3 741   0  54]\n",
            " [ 56  96   8 416   0 238   1 155   0   4]\n",
            " [119   4   4 290   0 184   0 331   0  77]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['3' '0' '9' ... '3' '5' '5']\n",
            "probabilities: (59980, 9) \n",
            " [3 0 8 ... 3 4 4]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [6 1 1 4 3 5 3 2 3 2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.247 s \n",
            "\n",
            "Accuracy rate for 50.010000 \n",
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79       980\n",
            "           1       0.98      0.32      0.48      1135\n",
            "           2       1.00      0.01      0.02      1032\n",
            "           3       0.51      0.66      0.58      1010\n",
            "           4       0.37      0.56      0.45       982\n",
            "           5       0.54      0.43      0.48       892\n",
            "           6       0.54      0.71      0.61       958\n",
            "           7       0.48      0.50      0.49      1028\n",
            "           8       0.37      0.69      0.48       974\n",
            "           9       0.38      0.33      0.35      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.59      0.51      0.47     10000\n",
            "weighted avg       0.60      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[826   0   0  18   6 104   8   4  13   1]\n",
            " [  0 360   0  78  35   9  30  86 537   0]\n",
            " [ 32   3   8 140  68  41 422  89 216  13]\n",
            " [ 11   0   0 666  20 108  21  10 146  28]\n",
            " [ 26   1   0   8 554  11  22 151   6 203]\n",
            " [ 59   0   0 206  34 388  48  11 117  29]\n",
            " [ 66   2   0  46 137  18 679   0   9   1]\n",
            " [ 26   1   0   5 193   5   9 516  32 241]\n",
            " [ 11   0   0 124  62  29  15  45 673  15]\n",
            " [ 41   1   0   6 398   5   6 168  53 331]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59970, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [8 1 2 5 4 6 3 3 4 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.305 s \n",
            "\n",
            "Accuracy rate for 57.870000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.89      0.82       980\n",
            "           1       0.70      0.51      0.59      1135\n",
            "           2       0.77      0.42      0.54      1032\n",
            "           3       0.50      0.72      0.59      1010\n",
            "           4       0.49      0.65      0.56       982\n",
            "           5       0.57      0.36      0.44       892\n",
            "           6       0.72      0.57      0.64       958\n",
            "           7       0.55      0.55      0.55      1028\n",
            "           8       0.43      0.65      0.52       974\n",
            "           9       0.52      0.48      0.50      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.60      0.58      0.57     10000\n",
            "weighted avg       0.60      0.58      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[868   1   2  21   1  77   2   4   4   0]\n",
            " [  0 578   0  29   0  22   4   4 439  59]\n",
            " [ 22 175 431  36  41   8 133  52 112  22]\n",
            " [ 20   1  23 723  11  32   7  11 150  32]\n",
            " [ 21  13  38   4 640  13  19 136   3  95]\n",
            " [ 50   8   8 337  40 318  26  15  75  15]\n",
            " [ 80   5  23 100 161  41 544   0   4   0]\n",
            " [ 38  30   0  25 135   5   4 565  26 200]\n",
            " [ 12  17   9 159  29  42   9  46 632  19]\n",
            " [ 39   2  24   9 235   4   4 189  15 488]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['3' '0' '4' ... '3' '6' '5']\n",
            "probabilities: (59960, 10) \n",
            " [3 0 4 ... 3 6 5]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [9 1 3 5 8 6 5 3 5 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.319 s \n",
            "\n",
            "Accuracy rate for 61.540000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       980\n",
            "           1       0.56      0.74      0.64      1135\n",
            "           2       0.73      0.39      0.51      1032\n",
            "           3       0.49      0.74      0.59      1010\n",
            "           4       0.69      0.70      0.69       982\n",
            "           5       0.60      0.33      0.42       892\n",
            "           6       0.65      0.75      0.69       958\n",
            "           7       0.65      0.45      0.54      1028\n",
            "           8       0.60      0.56      0.58       974\n",
            "           9       0.53      0.62      0.57      1009\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.63      0.61      0.61     10000\n",
            "weighted avg       0.63      0.62      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[830   1   5  28   2  72  20   3  19   0]\n",
            " [  0 840   0  78   0  18  78   0  49  72]\n",
            " [ 18 343 405  20  29   7 132  24  26  28]\n",
            " [ 14  15  48 749   9  18  11   8 105  33]\n",
            " [ 13  20  49  11 684  14  55  61   0  75]\n",
            " [ 33  21   9 342  28 294  51   6  99   9]\n",
            " [ 41  21   2  79  67  31 717   0   0   0]\n",
            " [ 36  68   2  38  44   6  13 467  24 330]\n",
            " [  3 152   4 171  19  27  22  16 547  13]\n",
            " [ 30   7  31  22 108   7  12 132  39 621]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [10  4  4  6  9  8  5  4  5  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.302 s \n",
            "\n",
            "Accuracy rate for 67.060000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       980\n",
            "           1       0.74      0.95      0.83      1135\n",
            "           2       0.75      0.47      0.58      1032\n",
            "           3       0.49      0.80      0.60      1010\n",
            "           4       0.68      0.72      0.70       982\n",
            "           5       0.73      0.33      0.46       892\n",
            "           6       0.66      0.80      0.72       958\n",
            "           7       0.63      0.62      0.63      1028\n",
            "           8       0.75      0.52      0.61       974\n",
            "           9       0.63      0.57      0.60      1009\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.69      0.66      0.66     10000\n",
            "weighted avg       0.69      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 839    1    7   48    1   55   23    3    3    0]\n",
            " [   0 1083    1   34    0    1    6    1    1    8]\n",
            " [  19  161  488   24   34    5  187   40   62   12]\n",
            " [   6   14   58  803    9    6   12   14   55   33]\n",
            " [  15   11   28    6  710    1   72   77    0   62]\n",
            " [  31   15   15  402   35  298   45   12   20   19]\n",
            " [  33   10    5   63   64   16  767    0    0    0]\n",
            " [  41   56    4   55   28    1    4  636   11  192]\n",
            " [   4  112   20  194   35   25   26   33  508   17]\n",
            " [  27    6   24   23  123    3   20  189   20  574]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59940, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [10  5  6  9 10 10  5  4  6  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.298 s \n",
            "\n",
            "Accuracy rate for 69.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       980\n",
            "           1       0.74      0.99      0.85      1135\n",
            "           2       0.89      0.56      0.69      1032\n",
            "           3       0.61      0.79      0.69      1010\n",
            "           4       0.70      0.65      0.68       982\n",
            "           5       0.66      0.32      0.43       892\n",
            "           6       0.70      0.83      0.76       958\n",
            "           7       0.60      0.61      0.61      1028\n",
            "           8       0.74      0.63      0.68       974\n",
            "           9       0.57      0.63      0.59      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.69      0.68     10000\n",
            "weighted avg       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 864    2    5   25    1   49   22    3    9    0]\n",
            " [   0 1124    0    3    0    2    4    0    0    2]\n",
            " [  13  142  577   32   22    5  134   57   37   13]\n",
            " [  20   19   44  801   11    6   14   12   56   27]\n",
            " [  18   17    4    0  639    2   60   95    1  146]\n",
            " [  45   18    5  326   30  287   57   13   93   18]\n",
            " [  33   17    5   11   61   39  791    0    1    0]\n",
            " [  39   55    2    4   34    0    1  624    6  263]\n",
            " [   8  109    6   94   25   39   29   33  615   16]\n",
            " [  26   14    2   16   88    5   14  195   17  632]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59930, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [10  7  6 10 11 11  7  5  7  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.307 s \n",
            "\n",
            "Accuracy rate for 72.590000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83       980\n",
            "           1       0.77      0.99      0.86      1135\n",
            "           2       0.89      0.60      0.72      1032\n",
            "           3       0.62      0.79      0.69      1010\n",
            "           4       0.69      0.75      0.72       982\n",
            "           5       0.64      0.36      0.46       892\n",
            "           6       0.74      0.87      0.80       958\n",
            "           7       0.72      0.74      0.73      1028\n",
            "           8       0.76      0.68      0.72       974\n",
            "           9       0.63      0.59      0.61      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.72      0.71     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 820    1   12   19    1   94   21    4    8    0]\n",
            " [   0 1121    0    3    0    1    5    0    2    3]\n",
            " [  13  122  620   25   26    6   98   54   53   15]\n",
            " [  21   12   41  793    9   17   16   13   44   44]\n",
            " [   7   16    4    0  736    1   45   53    2  118]\n",
            " [  41   24    6  317   33  319   61    6   61   24]\n",
            " [  24    8    4   13   46   19  837    1    5    1]\n",
            " [  36   61    2    1   29    1    2  756   10  130]\n",
            " [   7   82    4  100   23   31   28   15  664   20]\n",
            " [  21   14    4   12  168    9   14  151   23  593]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [10  7  9 11 12 12  7  7  9  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.267 s \n",
            "\n",
            "Accuracy rate for 71.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83       980\n",
            "           1       0.76      0.99      0.86      1135\n",
            "           2       0.85      0.64      0.73      1032\n",
            "           3       0.58      0.82      0.68      1010\n",
            "           4       0.65      0.82      0.73       982\n",
            "           5       0.77      0.28      0.41       892\n",
            "           6       0.71      0.85      0.77       958\n",
            "           7       0.79      0.69      0.74      1028\n",
            "           8       0.68      0.65      0.66       974\n",
            "           9       0.72      0.54      0.61      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.71      0.70     10000\n",
            "weighted avg       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 841    2   16   44    1   32   36    4    4    0]\n",
            " [   0 1122    0    2    0    1    5    0    5    0]\n",
            " [  17  103  659   26   21    0  107   41   55    3]\n",
            " [  10   21   37  824   11    8   12    6   65   16]\n",
            " [  10   16    2    3  806    2   51   26    4   62]\n",
            " [  43   25   21  347   44  249   81    4   63   15]\n",
            " [  28    8   13   15   54   19  814    0    7    0]\n",
            " [  51   66    3    6   42    0    3  713   35  109]\n",
            " [   5   92   15  142   30    9   32    9  630   10]\n",
            " [  31   16    7   12  222    4   12  101   63  541]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59910, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [12  8 10 11 13 15  7  8  9  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.308 s \n",
            "\n",
            "Accuracy rate for 72.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       980\n",
            "           1       0.75      0.98      0.85      1135\n",
            "           2       0.85      0.61      0.71      1032\n",
            "           3       0.59      0.82      0.68      1010\n",
            "           4       0.71      0.74      0.73       982\n",
            "           5       0.82      0.33      0.47       892\n",
            "           6       0.68      0.84      0.75       958\n",
            "           7       0.75      0.79      0.77      1028\n",
            "           8       0.72      0.58      0.64       974\n",
            "           9       0.70      0.67      0.68      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.72     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 843    2    8   46    1   21   48    4    6    1]\n",
            " [   0 1108    1    4    1    1    4    1   14    1]\n",
            " [  17  109  630   27   17    3  124   56   42    7]\n",
            " [   8   27   34  828    8    1   11   10   56   27]\n",
            " [   5   12    2    0  725    3   72   64    3   96]\n",
            " [  27   22   19  313   53  297   60    8   31   62]\n",
            " [  24   12   15   20   54   13  809    1   10    0]\n",
            " [  28   58    1    8   29    1    2  814   17   70]\n",
            " [   6  104   30  154   22   14   35   15  565   29]\n",
            " [  18   16    5    9  106    6   21  110   40  678]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [12 10 11 12 14 15 10  8  9  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.304 s \n",
            "\n",
            "Accuracy rate for 71.830000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       980\n",
            "           1       0.74      0.98      0.84      1135\n",
            "           2       0.83      0.66      0.73      1032\n",
            "           3       0.64      0.79      0.71      1010\n",
            "           4       0.71      0.66      0.68       982\n",
            "           5       0.80      0.39      0.52       892\n",
            "           6       0.74      0.87      0.80       958\n",
            "           7       0.72      0.56      0.63      1028\n",
            "           8       0.69      0.62      0.66       974\n",
            "           9       0.57      0.71      0.63      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.71      0.71     10000\n",
            "weighted avg       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 863    2    8   22    1   30   38    5    9    2]\n",
            " [   0 1112    2    2    2    1    5    0   11    0]\n",
            " [  18  103  678   28   15    2   82   55   46    5]\n",
            " [  12   33   32  800    9    3   11    7   87   16]\n",
            " [   8   15   14    1  648    0   63   69    3  161]\n",
            " [  25   29   14  260   60  346   50    4   56   48]\n",
            " [  31   16   18   10   27   18  836    0    2    0]\n",
            " [  38   65    7    5   21    3    3  580   20  286]\n",
            " [   5  106   26  110   27   24   38    8  607   23]\n",
            " [  20   19   17    9  104    8   11   73   35  713]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59890, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [14 11 12 13 15 16 11  9  9 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.321 s \n",
            "\n",
            "Accuracy rate for 71.080000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.84      0.66      0.74      1032\n",
            "           3       0.59      0.81      0.68      1010\n",
            "           4       0.71      0.55      0.62       982\n",
            "           5       0.77      0.35      0.48       892\n",
            "           6       0.75      0.85      0.79       958\n",
            "           7       0.82      0.64      0.72      1028\n",
            "           8       0.69      0.58      0.63       974\n",
            "           9       0.55      0.76      0.64      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.73      0.70      0.70     10000\n",
            "weighted avg       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    2    6   45    1   34   26    3    7    0]\n",
            " [   0 1107    0    2    2    1    3    1   19    0]\n",
            " [  19  121  679   37   11    4   75   37   40    9]\n",
            " [  11   42   18  815    7    4    9    5   77   22]\n",
            " [  15   18    9    0  541    0   75   37    2  285]\n",
            " [  24   32   20  317   45  313   34    2   37   68]\n",
            " [  38   21   26   15   27   19  812    0    0    0]\n",
            " [  39   66    4    5   19    4    6  657   32  196]\n",
            " [   3  114   31  144   21   23   31   10  565   32]\n",
            " [  19   21   11    9   84    6   14   45   37  763]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59880, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [15 12 13 15 16 16 11  9 12 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.265 s \n",
            "\n",
            "Accuracy rate for 72.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.85       980\n",
            "           1       0.75      0.97      0.85      1135\n",
            "           2       0.88      0.62      0.72      1032\n",
            "           3       0.55      0.87      0.68      1010\n",
            "           4       0.68      0.75      0.72       982\n",
            "           5       0.94      0.14      0.25       892\n",
            "           6       0.77      0.81      0.79       958\n",
            "           7       0.78      0.79      0.78      1028\n",
            "           8       0.72      0.61      0.66       974\n",
            "           9       0.73      0.70      0.71      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.76      0.72      0.70     10000\n",
            "weighted avg       0.76      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    1    0   33    2    1   25    4   18    0]\n",
            " [   0 1106   15    2    1    1    2    0    8    0]\n",
            " [  30  115  637   62   24    0   73   54   29    8]\n",
            " [   6   26   15  874   11    0    3   15   38   22]\n",
            " [  27   19    4    0  735    0   62   46    1   88]\n",
            " [  40   42    9  400   81  128   34   14   98   46]\n",
            " [  66   19   12   19   42    2  777    0   21    0]\n",
            " [  33   58   15    6   15    0    2  812    6   81]\n",
            " [   8   78   18  164   37    4   20   25  599   21]\n",
            " [  32   17    3   18  125    0   16   77   17  704]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59870, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [15 15 14 17 19 16 12  9 12 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.271 s \n",
            "\n",
            "Accuracy rate for 73.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.84       980\n",
            "           1       0.79      0.97      0.87      1135\n",
            "           2       0.85      0.60      0.70      1032\n",
            "           3       0.58      0.86      0.70      1010\n",
            "           4       0.70      0.69      0.69       982\n",
            "           5       0.74      0.40      0.52       892\n",
            "           6       0.75      0.86      0.80       958\n",
            "           7       0.77      0.76      0.77      1028\n",
            "           8       0.73      0.58      0.65       974\n",
            "           9       0.67      0.69      0.68      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 833    1    3   33    2   53   32    2   21    0]\n",
            " [   0 1098   23    7    1    1    3    1    1    0]\n",
            " [  23   87  621   79   27    3   94   64   26    8]\n",
            " [   7   13   14  873    9    1    7   13   57   16]\n",
            " [  23   18    3    4  676    4   44   44    2  164]\n",
            " [  22   27   15  286   53  357   38    6   47   41]\n",
            " [  49   11   14    6   33   17  820    2    6    0]\n",
            " [  27   60   10    6   36    3    7  786    7   86]\n",
            " [   4   64   22  183   22   38   30   21  563   27]\n",
            " [  23   19    5   19  111    8   16   78   36  694]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59860, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [16 15 15 18 19 18 13 11 14 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.287 s \n",
            "\n",
            "Accuracy rate for 73.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82       980\n",
            "           1       0.78      0.97      0.86      1135\n",
            "           2       0.85      0.64      0.73      1032\n",
            "           3       0.64      0.84      0.73      1010\n",
            "           4       0.75      0.73      0.74       982\n",
            "           5       0.78      0.39      0.52       892\n",
            "           6       0.71      0.85      0.78       958\n",
            "           7       0.81      0.69      0.74      1028\n",
            "           8       0.67      0.65      0.66       974\n",
            "           9       0.64      0.71      0.67      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 809    2    4   25    1   55   49    5   26    4]\n",
            " [   0 1105   12    9    0    1    3    0    5    0]\n",
            " [  25   96  661   61   16    2  102   36   29    4]\n",
            " [   6   14   14  851    9    4    7   11   71   23]\n",
            " [  24   16    7    1  715    1   59   19    7  133]\n",
            " [  22   30   12  221   57  350   47    6   99   48]\n",
            " [  55    9   22    5   25   10  818    0   14    0]\n",
            " [  30   71   12    4   34    2    6  706    7  156]\n",
            " [   5   61   24  134   16   18   36   13  637   30]\n",
            " [  23   16    6   13   85    6   18   73   56  713]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 0 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [16 18 16 18 19 19 13 12 17 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.259 s \n",
            "\n",
            "Accuracy rate for 74.300000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       980\n",
            "           1       0.77      0.98      0.86      1135\n",
            "           2       0.85      0.60      0.70      1032\n",
            "           3       0.64      0.82      0.72      1010\n",
            "           4       0.74      0.78      0.76       982\n",
            "           5       0.75      0.44      0.56       892\n",
            "           6       0.72      0.84      0.77       958\n",
            "           7       0.77      0.72      0.75      1028\n",
            "           8       0.72      0.64      0.68       974\n",
            "           9       0.70      0.70      0.70      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 834    1    3   15    1   55   50    4   15    2]\n",
            " [   0 1107    3    1    1    2    5    1   15    0]\n",
            " [  25  116  618   43   20    3  104   62   40    1]\n",
            " [   6   23   24  832    9    3    6    9   70   28]\n",
            " [  19    9    6    2  769    5   63   41    3   65]\n",
            " [  26   24   15  238   66  395   32   11   44   41]\n",
            " [  63    7   16    7   27   22  802    1   13    0]\n",
            " [  29   59    5    2   34    9    6  744   11  129]\n",
            " [   5   66   25  143   17   19   30   15  622   32]\n",
            " [  25   17    8   12  100   11   23   81   25  707]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59840, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [18 20 18 19 21 19 14 12 17 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.274 s \n",
            "\n",
            "Accuracy rate for 74.060000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       980\n",
            "           1       0.80      0.96      0.87      1135\n",
            "           2       0.83      0.63      0.71      1032\n",
            "           3       0.61      0.84      0.71      1010\n",
            "           4       0.75      0.74      0.74       982\n",
            "           5       0.77      0.43      0.55       892\n",
            "           6       0.70      0.85      0.77       958\n",
            "           7       0.79      0.71      0.75      1028\n",
            "           8       0.73      0.62      0.67       974\n",
            "           9       0.68      0.74      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.73     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 817    1    7   17    2   56   55    4   19    2]\n",
            " [   0 1091   19    9    1    1    3    1   10    0]\n",
            " [  20   72  647   79   16    1  113   52   26    6]\n",
            " [   7   18   29  851    9    3    7    9   57   20]\n",
            " [  14   15    3    7  729    3   62   46    6   97]\n",
            " [  22   21   12  242   51  385   46    7   61   45]\n",
            " [  53    5   15    5   37   17  811    1   14    0]\n",
            " [  28   59   18    5   31    6    8  729    2  142]\n",
            " [   5   60   22  156   19   22   38   13  603   36]\n",
            " [  21   17    7   16   82    8   19   63   33  743]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59830, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [18 21 18 20 21 23 15 13 19 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.280 s \n",
            "\n",
            "Accuracy rate for 75.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       980\n",
            "           1       0.79      0.96      0.87      1135\n",
            "           2       0.85      0.65      0.74      1032\n",
            "           3       0.64      0.85      0.73      1010\n",
            "           4       0.74      0.70      0.72       982\n",
            "           5       0.79      0.41      0.54       892\n",
            "           6       0.71      0.83      0.77       958\n",
            "           7       0.78      0.82      0.80      1028\n",
            "           8       0.72      0.65      0.69       974\n",
            "           9       0.74      0.73      0.73      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 839    1    7   11    0   48   53    5   16    0]\n",
            " [   0 1093    8    3    1    1    3    1   25    0]\n",
            " [  22   85  666   62   11    1   93   53   37    2]\n",
            " [   6   19   25  856    8    1    9   12   51   23]\n",
            " [  19   15    5    3  686    2   70   72    4  106]\n",
            " [  26   20   12  248   61  366   42   13   57   47]\n",
            " [  58    7   20    5   40   11  797    3   17    0]\n",
            " [  24   63   12    2   21    6    5  839    9   47]\n",
            " [   5   64   21  139   18   17   26   13  637   34]\n",
            " [  25   17    4   15   85    9   22   67   29  736]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59820, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [18 22 19 21 22 23 17 13 19 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.269 s \n",
            "\n",
            "Accuracy rate for 75.620000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82       980\n",
            "           1       0.82      0.95      0.88      1135\n",
            "           2       0.85      0.69      0.76      1032\n",
            "           3       0.66      0.84      0.74      1010\n",
            "           4       0.69      0.82      0.75       982\n",
            "           5       0.62      0.56      0.59       892\n",
            "           6       0.72      0.82      0.77       958\n",
            "           7       0.80      0.81      0.81      1028\n",
            "           8       0.81      0.57      0.67       974\n",
            "           9       0.81      0.62      0.70      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 807    1    4    9    1  112   39    2    5    0]\n",
            " [   0 1082   28    5    1    1    4    1   13    0]\n",
            " [  18   57  711   62   27    8   87   45   16    1]\n",
            " [   8   17   25  846   10   25   13   14   41   11]\n",
            " [  10   14    2    3  806   11   53   38    2   43]\n",
            " [  32   19    6  188   51  502   53    5   17   19]\n",
            " [  53    5   11    3   60   21  789    2   14    0]\n",
            " [  23   52   19    3   35    9    7  832    2   46]\n",
            " [   5   57   26  149   27   76   31   16  560   27]\n",
            " [  21   17    5   10  157   46   19   83   24  627]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['3' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59810, 10) \n",
            " [3 0 4 ... 5 0 5]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [19 24 21 22 23 24 19 13 19 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.304 s \n",
            "\n",
            "Accuracy rate for 74.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83       980\n",
            "           1       0.79      0.97      0.87      1135\n",
            "           2       0.82      0.71      0.76      1032\n",
            "           3       0.64      0.85      0.73      1010\n",
            "           4       0.73      0.71      0.72       982\n",
            "           5       0.80      0.45      0.58       892\n",
            "           6       0.72      0.78      0.75       958\n",
            "           7       0.75      0.82      0.78      1028\n",
            "           8       0.74      0.61      0.67       974\n",
            "           9       0.72      0.69      0.70      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 801    1    8   18    1   51   79    7   14    0]\n",
            " [   0 1097   17    3    1    1    2    1   13    0]\n",
            " [  23   75  731   55   17    3   53   55   19    1]\n",
            " [   4   17   28  858    6    6    9   14   44   24]\n",
            " [  12   15    4    3  700    1   66   60    6  115]\n",
            " [  22   25   17  229   37  405   38   19   50   50]\n",
            " [  47    7   32    3   74   14  748    2   31    0]\n",
            " [  22   64   14    2   25    5    2  839    3   52]\n",
            " [   4   72   39  160   17   17   26   13  591   35]\n",
            " [  26   18    6   11   87    6   19  109   28  699]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [19 26 24 22 23 25 20 14 20 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.308 s \n",
            "\n",
            "Accuracy rate for 74.030000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       980\n",
            "           1       0.81      0.97      0.88      1135\n",
            "           2       0.85      0.66      0.74      1032\n",
            "           3       0.63      0.82      0.71      1010\n",
            "           4       0.67      0.79      0.73       982\n",
            "           5       0.85      0.37      0.52       892\n",
            "           6       0.66      0.81      0.73       958\n",
            "           7       0.80      0.79      0.80      1028\n",
            "           8       0.70      0.65      0.68       974\n",
            "           9       0.72      0.65      0.68      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 810    1    5   17    1   31   93    7   15    0]\n",
            " [   0 1099    3    3    4    1    3    0   22    0]\n",
            " [  27   58  684   57   36    1  112   37   16    4]\n",
            " [   6   21   17  832    8    2   12   12   74   26]\n",
            " [   8   14    3    2  774    0   74   30    4   73]\n",
            " [  24   22   17  266   58  331   42   21   70   41]\n",
            " [  56    6   16    5   64    6  775    1   29    0]\n",
            " [  16   64   19    3   31    2    5  812    3   73]\n",
            " [   5   63   35  131   19   11   30   14  633   33]\n",
            " [  25   16    6    9  157    5   30   75   33  653]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59790, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [20 27 24 22 23 25 21 16 21 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.315 s \n",
            "\n",
            "Accuracy rate for 75.140000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       980\n",
            "           1       0.78      0.97      0.86      1135\n",
            "           2       0.86      0.63      0.73      1032\n",
            "           3       0.63      0.85      0.72      1010\n",
            "           4       0.71      0.82      0.76       982\n",
            "           5       0.93      0.27      0.42       892\n",
            "           6       0.70      0.87      0.78       958\n",
            "           7       0.80      0.84      0.82      1028\n",
            "           8       0.66      0.66      0.66       974\n",
            "           9       0.79      0.64      0.71      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.77      0.74      0.73     10000\n",
            "weighted avg       0.77      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 876    1    1   14    1    3   59    6   19    0]\n",
            " [   0 1100    6    2    2    1    4    0   20    0]\n",
            " [  29   90  654   55   29    1  110   39   19    6]\n",
            " [   8   17   10  856    7    1   10   21   67   13]\n",
            " [   9   13    3    4  804    1   64   23    4   57]\n",
            " [  26   27   16  284   59  239   53   16  148   24]\n",
            " [  38   10   16    6   31    2  835    3   17    0]\n",
            " [  11   58   16    2   23    0    5  860    4   49]\n",
            " [   6   75   35  116   22    7   26   17  646   24]\n",
            " [  23   22    5   20  147    3   22   92   31  644]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59780, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [20 28 24 24 24 28 23 16 21 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.305 s \n",
            "\n",
            "Accuracy rate for 75.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       980\n",
            "           1       0.78      0.97      0.87      1135\n",
            "           2       0.83      0.67      0.74      1032\n",
            "           3       0.66      0.85      0.74      1010\n",
            "           4       0.74      0.76      0.75       982\n",
            "           5       0.84      0.37      0.51       892\n",
            "           6       0.69      0.84      0.76       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.70      0.67      0.68       974\n",
            "           9       0.73      0.70      0.71      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    1    7    9    1   11   65    9   22    0]\n",
            " [   0 1105    4    2    1    1    3    0   19    0]\n",
            " [  22   66  692   67   21    3  102   34   18    7]\n",
            " [   8   20   19  855    3    9   15   12   49   20]\n",
            " [   7   20    4    4  745    9   70   18    9   96]\n",
            " [  29   34   19  217   52  328   46   30  107   30]\n",
            " [  41    9   32    2   32    9  803    2   28    0]\n",
            " [  13   70   17    2   20    2    7  816    4   77]\n",
            " [   3   64   34  124   22    9   21   14  649   34]\n",
            " [  23   22    7   16  106   11   32   69   21  702]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59770, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [20 31 27 24 25 29 24 17 21 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.317 s \n",
            "\n",
            "Accuracy rate for 75.240000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       980\n",
            "           1       0.82      0.96      0.88      1135\n",
            "           2       0.84      0.63      0.72      1032\n",
            "           3       0.65      0.84      0.73      1010\n",
            "           4       0.68      0.79      0.73       982\n",
            "           5       0.85      0.33      0.48       892\n",
            "           6       0.68      0.87      0.76       958\n",
            "           7       0.84      0.84      0.84      1028\n",
            "           8       0.65      0.68      0.67       974\n",
            "           9       0.75      0.65      0.70      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.77      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 850    1    4   11    1   20   64    5   24    0]\n",
            " [   0 1091    4    3    3    0    3    1   30    0]\n",
            " [  19   54  647   89   27    0  132   29   24   11]\n",
            " [   7   15   18  845    8    6   15   13   57   26]\n",
            " [   8   13    3    2  779    4   63   16    5   89]\n",
            " [  27   20   19  215   72  298   48   25  153   15]\n",
            " [  36    8    9    2   38    7  830    2   26    0]\n",
            " [   9   51   22    1   20    1    7  866    5   46]\n",
            " [   3   58   35  120   26    7   23   13  662   27]\n",
            " [  24   20    5   12  169    7   30   57   29  656]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59760, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 33 27 26 25 29 25 17 23 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.367 s \n",
            "\n",
            "Accuracy rate for 75.260000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       980\n",
            "           1       0.79      0.96      0.87      1135\n",
            "           2       0.84      0.65      0.73      1032\n",
            "           3       0.64      0.80      0.71      1010\n",
            "           4       0.66      0.82      0.73       982\n",
            "           5       0.82      0.38      0.52       892\n",
            "           6       0.70      0.84      0.77       958\n",
            "           7       0.85      0.82      0.84      1028\n",
            "           8       0.68      0.66      0.67       974\n",
            "           9       0.76      0.63      0.69      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    1    4   13    2   16   47    6   11    0]\n",
            " [   0 1095    8    5    1    1    3    0   22    0]\n",
            " [  20   62  674   82   28    3  118   25   16    4]\n",
            " [  11   31   21  810    8    6   18   14   70   21]\n",
            " [   8   18    6    1  801    5   51   17   10   65]\n",
            " [  21   33   14  204   72  342   50   22  102   32]\n",
            " [  29   10   16    4   50   14  805    1   29    0]\n",
            " [  11   55   28    1   24    2    8  842    4   53]\n",
            " [   4   57   28  140   29   14   20   11  639   32]\n",
            " [  18   24    8   12  191   12   23   49   34  638]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [22 33 28 28 25 30 25 19 24 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.299 s \n",
            "\n",
            "Accuracy rate for 74.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.85       980\n",
            "           1       0.80      0.97      0.88      1135\n",
            "           2       0.83      0.67      0.74      1032\n",
            "           3       0.62      0.79      0.70      1010\n",
            "           4       0.67      0.79      0.72       982\n",
            "           5       0.88      0.36      0.51       892\n",
            "           6       0.75      0.80      0.77       958\n",
            "           7       0.85      0.82      0.83      1028\n",
            "           8       0.66      0.65      0.65       974\n",
            "           9       0.77      0.63      0.69      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    1    2    6    1    6   31    8   11    0]\n",
            " [   0 1100    9    2    1    1    3    0   19    0]\n",
            " [  32   63  695   84   23    0   87   27   14    7]\n",
            " [  22   18   24  801   10    4   12   10   95   14]\n",
            " [  16   15    2    4  772    5   46   16    9   97]\n",
            " [  66   32   12  210   72  322   41   16  106   15]\n",
            " [  64   13   15    5   62   12  762    0   25    0]\n",
            " [  22   57   32    1   20    0    5  845    3   43]\n",
            " [  10   49   44  156   24    9   17   14  634   17]\n",
            " [  36   21    5   15  163    8   18   60   47  636]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59740, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [23 36 28 30 26 31 25 19 25 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.368 s \n",
            "\n",
            "Accuracy rate for 75.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       980\n",
            "           1       0.80      0.95      0.87      1135\n",
            "           2       0.85      0.67      0.75      1032\n",
            "           3       0.64      0.81      0.71      1010\n",
            "           4       0.72      0.79      0.75       982\n",
            "           5       0.90      0.33      0.48       892\n",
            "           6       0.71      0.83      0.76       958\n",
            "           7       0.86      0.82      0.84      1028\n",
            "           8       0.64      0.68      0.66       974\n",
            "           9       0.75      0.71      0.73      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    1    1   10    1    8   50    6   13    1]\n",
            " [   0 1083    4    2    1    0    3    1   41    0]\n",
            " [  28   58  689   77   24    0  103   25   20    8]\n",
            " [  13   26   20  817    7    2   19    8   71   27]\n",
            " [  12   16    3    2  771    3   51   16   13   95]\n",
            " [  47   26   11  220   68  292   48   27  125   28]\n",
            " [  40    9   15    1   51    6  792    0   44    0]\n",
            " [  14   55   32    1   19    0    8  841    5   53]\n",
            " [   7   57   31  136   21    8   21    9  659   25]\n",
            " [  28   21    4   14  115    6   19   43   42  717]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59730, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [24 37 28 31 27 32 27 21 25 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.339 s \n",
            "\n",
            "Accuracy rate for 75.530000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87       980\n",
            "           1       0.79      0.96      0.87      1135\n",
            "           2       0.82      0.67      0.74      1032\n",
            "           3       0.64      0.82      0.72      1010\n",
            "           4       0.70      0.81      0.75       982\n",
            "           5       0.87      0.39      0.54       892\n",
            "           6       0.69      0.83      0.75       958\n",
            "           7       0.82      0.82      0.82      1028\n",
            "           8       0.67      0.67      0.67       974\n",
            "           9       0.79      0.66      0.72      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 846    1    6   21    1    9   69   12   15    0]\n",
            " [   0 1088    8    2    1    1    3    0   32    0]\n",
            " [  22   69  695   80   19    1  103   22   16    5]\n",
            " [   6   21   27  829    8    4   17   11   69   18]\n",
            " [   8   19    2    2  796    4   64   21    9   57]\n",
            " [  19   26   21  196   65  347   48   44  106   20]\n",
            " [  28   11   13    1   61   11  796    0   37    0]\n",
            " [  15   56   30    1   18    0    7  844    4   53]\n",
            " [   4   59   36  141   20   11   23   10  650   20]\n",
            " [  18   23    6   18  148   11   29   60   34  662]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59720, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [24 37 28 32 30 33 27 23 26 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.365 s \n",
            "\n",
            "Accuracy rate for 74.850000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       980\n",
            "           1       0.78      0.95      0.86      1135\n",
            "           2       0.84      0.63      0.72      1032\n",
            "           3       0.64      0.82      0.72      1010\n",
            "           4       0.70      0.80      0.75       982\n",
            "           5       0.78      0.34      0.48       892\n",
            "           6       0.70      0.83      0.76       958\n",
            "           7       0.79      0.83      0.81      1028\n",
            "           8       0.65      0.67      0.66       974\n",
            "           9       0.81      0.67      0.73      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 867    1    5   14    2    9   53   14   15    0]\n",
            " [   0 1074    9    2    1    1    3    0   45    0]\n",
            " [  20   66  647   82   39    3  109   33   25    8]\n",
            " [   8   25   15  832   12    6   20   12   66   14]\n",
            " [   8   19    2    3  785    9   55   33   14   54]\n",
            " [  24   30   19  217   52  305   52   59  112   22]\n",
            " [  25   12   13    2   55   15  791    1   44    0]\n",
            " [  13   59   27    1   20    5    7  855    5   36]\n",
            " [   5   63   29  130   19   17   21    8  656   26]\n",
            " [  17   25    6   19  136   21   21   64   27  673]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59710, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [24 38 28 34 30 33 27 24 29 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.314 s \n",
            "\n",
            "Accuracy rate for 74.300000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88       980\n",
            "           1       0.78      0.93      0.85      1135\n",
            "           2       0.82      0.64      0.72      1032\n",
            "           3       0.65      0.80      0.71      1010\n",
            "           4       0.66      0.83      0.73       982\n",
            "           5       0.83      0.37      0.51       892\n",
            "           6       0.69      0.83      0.76       958\n",
            "           7       0.78      0.83      0.80      1028\n",
            "           8       0.65      0.66      0.66       974\n",
            "           9       0.83      0.59      0.69      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 881    1    5   13    1    6   49   10   14    0]\n",
            " [   0 1056    5    1    1    0    4    1   67    0]\n",
            " [  26   59  658   86   36    0  105   24   34    4]\n",
            " [  10   31   16  805   16    8   23   13   75   13]\n",
            " [   8   20    6    3  812    7   55   28   10   33]\n",
            " [  26   34   20  194   70  331   60   69   77   11]\n",
            " [  27   13   18    1   53   13  797    1   35    0]\n",
            " [  11   54   31    2   23    4    7  853    7   36]\n",
            " [   6   64   40  124   24   14   20   17  645   20]\n",
            " [  18   28    8   18  196   17   31   80   21  592]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59700, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [24 39 28 36 31 33 28 27 31 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.305 s \n",
            "\n",
            "Accuracy rate for 76.030000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.79      0.92      0.85      1135\n",
            "           2       0.76      0.72      0.74      1032\n",
            "           3       0.66      0.82      0.73      1010\n",
            "           4       0.68      0.81      0.74       982\n",
            "           5       0.79      0.47      0.59       892\n",
            "           6       0.81      0.70      0.75       958\n",
            "           7       0.82      0.85      0.83      1028\n",
            "           8       0.67      0.67      0.67       974\n",
            "           9       0.81      0.68      0.74      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    1    8   14    1   12   31    6   16    0]\n",
            " [   0 1045    8    3    1    1    2    0   75    0]\n",
            " [  22   54  746   73   26    3   40   28   34    6]\n",
            " [  12   30   29  825    7   12    9   15   60   11]\n",
            " [   8   20    5    3  799   15   33   19   12   68]\n",
            " [  27   29   31  177   72  419   24   42   62    9]\n",
            " [  58   11   45    5   95   29  671    3   41    0]\n",
            " [   9   50   30    1   12    6    4  870    7   39]\n",
            " [   4   53   58  125   18   18    6   13  655   24]\n",
            " [  20   25   17   18  138   18    7   63   21  682]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['5' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59690, 10) \n",
            " [5 0 4 ... 5 0 8]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [26 40 28 36 32 35 28 28 32 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.334 s \n",
            "\n",
            "Accuracy rate for 76.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.90       980\n",
            "           1       0.79      0.95      0.86      1135\n",
            "           2       0.83      0.63      0.72      1032\n",
            "           3       0.66      0.84      0.74      1010\n",
            "           4       0.73      0.81      0.77       982\n",
            "           5       0.81      0.43      0.56       892\n",
            "           6       0.72      0.87      0.79       958\n",
            "           7       0.84      0.81      0.82      1028\n",
            "           8       0.73      0.64      0.68       974\n",
            "           9       0.75      0.71      0.73      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    1    2    7    1   10   36    3   12    2]\n",
            " [   0 1082    8    1    1    1    4    0   38    0]\n",
            " [  27   72  650   79   29    2  118   19   24   12]\n",
            " [   8   22   19  844    9   14   18   15   43   18]\n",
            " [   8   19    1    2  800   10   49   12   10   71]\n",
            " [  33   30   21  188   77  383   55   36   45   24]\n",
            " [  21   12   10    0   33   11  838    0   33    0]\n",
            " [  13   53   29    1   14    5    7  828    5   73]\n",
            " [   5   60   33  144   22   18   25   12  623   32]\n",
            " [  23   20    7   19  114   18   19   58   17  714]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59680, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [26 40 29 38 33 36 30 28 33 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.308 s \n",
            "\n",
            "Accuracy rate for 75.820000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       980\n",
            "           1       0.77      0.95      0.85      1135\n",
            "           2       0.83      0.66      0.73      1032\n",
            "           3       0.68      0.81      0.74      1010\n",
            "           4       0.70      0.82      0.76       982\n",
            "           5       0.77      0.39      0.51       892\n",
            "           6       0.69      0.84      0.76       958\n",
            "           7       0.84      0.81      0.82      1028\n",
            "           8       0.72      0.64      0.68       974\n",
            "           9       0.77      0.70      0.74      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    1    4    5    1   15   51    4   17    2]\n",
            " [   0 1082    4    2    1    0    3    1   42    0]\n",
            " [  23   63  679   56   24    3  113   26   36    9]\n",
            " [   8   50   24  819    6   20   23   13   33   14]\n",
            " [   9   21    2    1  805    6   58   18    8   54]\n",
            " [  44   36   24  171   76  344   59   45   66   27]\n",
            " [  20    9   15    1   64   15  809    0   25    0]\n",
            " [  14   53   28    1   17    8    4  831    5   67]\n",
            " [   4   67   31  139   24   15   30    5  623   36]\n",
            " [  23   26    9   18  131   18   18   45   11  710]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59670, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [28 41 30 38 34 36 31 29 34 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.356 s \n",
            "\n",
            "Accuracy rate for 75.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       980\n",
            "           1       0.76      0.95      0.85      1135\n",
            "           2       0.83      0.63      0.72      1032\n",
            "           3       0.65      0.81      0.72      1010\n",
            "           4       0.70      0.81      0.75       982\n",
            "           5       0.76      0.42      0.54       892\n",
            "           6       0.70      0.85      0.77       958\n",
            "           7       0.82      0.82      0.82      1028\n",
            "           8       0.75      0.63      0.68       974\n",
            "           9       0.80      0.67      0.73      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    1    1    8    2    7   37    2   16    1]\n",
            " [   0 1074   15    2    1    0    3    1   39    0]\n",
            " [  32   68  650   90   28    3  104   23   24   10]\n",
            " [  14   39   19  816    7   31   19   19   30   16]\n",
            " [   8   21    3    1  794   13   67   16   10   49]\n",
            " [  41   37   11  174   84  377   52   46   57   13]\n",
            " [  29   11   11    2   53   18  815    0   19    0]\n",
            " [  17   56   31    1   13    7    5  843    3   52]\n",
            " [   9   72   35  138   22   18   28   12  611   29]\n",
            " [  23   26    7   18  130   21   28   65   10  681]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59660, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [28 43 30 38 36 38 33 30 35 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.311 s \n",
            "\n",
            "Accuracy rate for 75.470000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88       980\n",
            "           1       0.77      0.96      0.85      1135\n",
            "           2       0.83      0.65      0.73      1032\n",
            "           3       0.65      0.81      0.72      1010\n",
            "           4       0.70      0.82      0.76       982\n",
            "           5       0.72      0.42      0.53       892\n",
            "           6       0.70      0.82      0.76       958\n",
            "           7       0.83      0.80      0.82      1028\n",
            "           8       0.74      0.63      0.68       974\n",
            "           9       0.78      0.67      0.72      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    2    6    8    3    9   45    6   10    2]\n",
            " [   0 1091   10    2    1    4    3    0   24    0]\n",
            " [  22   71  670   97   23    4   96   21   18   10]\n",
            " [  10   39   22  823    6   22   14   15   39   20]\n",
            " [   9   19    3    2  807   18   62   12   13   37]\n",
            " [  34   37   17  172   69  374   55   41   73   20]\n",
            " [  27   15   13    1   64   29  784    1   24    0]\n",
            " [  17   55   33    1   17    8    4  819    5   69]\n",
            " [   5   68   25  147   21   24   29    8  613   34]\n",
            " [  21   22    5   19  141   25   26   58   15  677]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [28 44 30 41 40 38 33 32 35 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 76.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       980\n",
            "           1       0.78      0.95      0.86      1135\n",
            "           2       0.83      0.67      0.74      1032\n",
            "           3       0.66      0.83      0.74      1010\n",
            "           4       0.74      0.83      0.78       982\n",
            "           5       0.80      0.42      0.56       892\n",
            "           6       0.70      0.88      0.78       958\n",
            "           7       0.86      0.82      0.84      1028\n",
            "           8       0.73      0.64      0.68       974\n",
            "           9       0.78      0.68      0.73      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.78      0.76      0.76     10000\n",
            "weighted avg       0.78      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    1    2    5    1    7   42    4   10    2]\n",
            " [   0 1082    6    2    1    2    4    1   37    0]\n",
            " [  24   71  687   67   21    0   99   21   31   11]\n",
            " [  10   34   22  836    5   17   20   10   37   19]\n",
            " [   6   19    2    3  812    8   71    6   10   45]\n",
            " [  33   39   15  186   50  378   63   42   70   16]\n",
            " [  20   14   16    1   34   10  842    2   19    0]\n",
            " [  11   48   32    1   13    5    6  846    8   58]\n",
            " [   6   56   35  141   11   20   31    9  622   43]\n",
            " [  17   18   10   18  148   23   31   43   13  688]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59640, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [28 46 30 44 42 40 33 32 35 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.330 s \n",
            "\n",
            "Accuracy rate for 74.640000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.94      0.85       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.83      0.62      0.71      1032\n",
            "           3       0.66      0.81      0.73      1010\n",
            "           4       0.70      0.81      0.75       982\n",
            "           5       0.75      0.36      0.49       892\n",
            "           6       0.73      0.77      0.75       958\n",
            "           7       0.84      0.79      0.81      1028\n",
            "           8       0.70      0.64      0.67       974\n",
            "           9       0.77      0.70      0.73      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    3    4    2    3   26    4   13    2]\n",
            " [   0 1084    8    3    0    0    3    1   36    0]\n",
            " [  43   89  637   58   35    2   85   25   47   11]\n",
            " [  23   45   22  818    6   23   16   12   31   14]\n",
            " [   8   23    2    3  793   12   60   11   15   55]\n",
            " [  71   44   18  199   62  325   44   46   58   25]\n",
            " [  42   13   15    1   75   26  742    1   43    0]\n",
            " [  29   58   27    1   18    3    3  813   10   66]\n",
            " [  13   71   30  128   20   19   24    7  627   35]\n",
            " [  30   23    5   19  124   22   18   52   13  703]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59630, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [28 47 31 44 42 42 34 34 37 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.337 s \n",
            "\n",
            "Accuracy rate for 75.270000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       980\n",
            "           1       0.75      0.95      0.84      1135\n",
            "           2       0.84      0.62      0.71      1032\n",
            "           3       0.68      0.79      0.73      1010\n",
            "           4       0.72      0.79      0.75       982\n",
            "           5       0.76      0.42      0.54       892\n",
            "           6       0.71      0.83      0.76       958\n",
            "           7       0.81      0.80      0.81      1028\n",
            "           8       0.70      0.65      0.67       974\n",
            "           9       0.77      0.70      0.73      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.75      0.74     10000\n",
            "weighted avg       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    2    2    7    7    5   34    5   10    2]\n",
            " [   0 1080    6    3    0    1    3    1   41    0]\n",
            " [  34   92  635   56   32    1  106   21   44   11]\n",
            " [  21   52   13  796    6   30   19   13   45   15]\n",
            " [   8   22    2    4  778   13   57   15   17   66]\n",
            " [  49   38   13  172   53  376   50   55   71   15]\n",
            " [  30   13   10    0   66   19  791    1   28    0]\n",
            " [  14   52   35    1   14    5    4  827    6   70]\n",
            " [  10   68   32  118   17   21   29    9  636   34]\n",
            " [  19   23    8   18  107   24   18   74   16  702]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59620, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [28 48 33 45 44 43 34 37 37 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.306 s \n",
            "\n",
            "Accuracy rate for 76.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       980\n",
            "           1       0.77      0.96      0.85      1135\n",
            "           2       0.83      0.71      0.77      1032\n",
            "           3       0.65      0.83      0.73      1010\n",
            "           4       0.69      0.83      0.75       982\n",
            "           5       0.79      0.40      0.53       892\n",
            "           6       0.74      0.83      0.78       958\n",
            "           7       0.87      0.78      0.82      1028\n",
            "           8       0.79      0.61      0.69       974\n",
            "           9       0.77      0.72      0.75      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    2    3    9    5   10   40    3    8    2]\n",
            " [   0 1092   21    2    1    0    4    1   14    0]\n",
            " [  23   75  737   49   27    1   74   21   17    8]\n",
            " [  13   39   25  838    5   16   14   12   31   17]\n",
            " [  10   19    4    2  812   11   55    9    9   51]\n",
            " [  41   35   11  207   84  360   52   24   50   28]\n",
            " [  32   13    9    1   74   16  798    1   14    0]\n",
            " [  18   51   40    1   25    3    6  801    5   78]\n",
            " [   7   72   30  154   30   21   28    8  592   32]\n",
            " [  27   24    8   18  121   19   10   40   13  729]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59610, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [28 54 33 46 44 44 35 38 37 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.367 s \n",
            "\n",
            "Accuracy rate for 77.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       980\n",
            "           1       0.81      0.96      0.88      1135\n",
            "           2       0.85      0.69      0.76      1032\n",
            "           3       0.62      0.86      0.72      1010\n",
            "           4       0.74      0.81      0.77       982\n",
            "           5       0.78      0.42      0.54       892\n",
            "           6       0.77      0.81      0.79       958\n",
            "           7       0.85      0.83      0.84      1028\n",
            "           8       0.70      0.65      0.67       974\n",
            "           9       0.79      0.72      0.76      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.78      0.77      0.76     10000\n",
            "weighted avg       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    1    3   14    3    7   39    3   16    2]\n",
            " [   0 1094    5    6    0    0    3    1   26    0]\n",
            " [  17   65  716   64   26    4   62   26   41   11]\n",
            " [   7   22   17  867    5   18   13    9   37   15]\n",
            " [   7   18    2    4  796   16   49    5   15   70]\n",
            " [  26   25   15  245   44  373   37   37   74   16]\n",
            " [  29   10   19    0   55   18  778    1   48    0]\n",
            " [  11   50   29    2   19    5    4  850    7   51]\n",
            " [   4   54   28  167   18   15   16   11  637   24]\n",
            " [  14   20    6   23  114   23   15   52   14  728]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [29 55 34 46 45 45 36 39 39 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.332 s \n",
            "\n",
            "Accuracy rate for 76.900000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.78      0.96      0.86      1135\n",
            "           2       0.82      0.69      0.75      1032\n",
            "           3       0.66      0.82      0.73      1010\n",
            "           4       0.72      0.81      0.76       982\n",
            "           5       0.73      0.48      0.58       892\n",
            "           6       0.74      0.83      0.78       958\n",
            "           7       0.85      0.80      0.82      1028\n",
            "           8       0.77      0.64      0.70       974\n",
            "           9       0.79      0.71      0.74      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 895    2    4   11    3    7   38    5   13    2]\n",
            " [   0 1092   20    2    0    5    3    1   12    0]\n",
            " [  19   76  709   62   27    3   77   25   24   10]\n",
            " [   9   37   24  825    6   31   19   10   33   16]\n",
            " [   8   19    4    5  795   19   49   10   15   58]\n",
            " [  37   35   11  173   56  428   56   33   49   14]\n",
            " [  31   14    9    1   58   32  794    3   16    0]\n",
            " [  25   51   37    1   17    4    3  819    8   63]\n",
            " [   6   62   31  142   18   33   25    6  619   32]\n",
            " [  19   21   14   19  120   25   10   52   15  714]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59590, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [30 56 36 46 45 48 37 40 39 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 76.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       980\n",
            "           1       0.77      0.96      0.86      1135\n",
            "           2       0.83      0.64      0.72      1032\n",
            "           3       0.66      0.83      0.73      1010\n",
            "           4       0.72      0.79      0.75       982\n",
            "           5       0.86      0.39      0.54       892\n",
            "           6       0.74      0.84      0.79       958\n",
            "           7       0.87      0.79      0.83      1028\n",
            "           8       0.65      0.71      0.68       974\n",
            "           9       0.80      0.71      0.75      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.78      0.76      0.75     10000\n",
            "weighted avg       0.78      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    1    2    7    4    1   38    3   26    2]\n",
            " [   0 1090    9    3    0    1    4    1   27    0]\n",
            " [  27   84  664   60   20    0   73   23   75    6]\n",
            " [  12   35   21  834    5   14   13    8   56   12]\n",
            " [   8   22    8    5  775    5   61    9   20   69]\n",
            " [  35   37    7  216   62  351   49   35   86   14]\n",
            " [  28   12    5    0   63    9  804    4   33    0]\n",
            " [  18   51   48    1   15    1    5  816   13   60]\n",
            " [   6   56   27  115   14   12   24    6  696   18]\n",
            " [  20   23   11   22  119   14   15   35   32  718]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59580, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [31 57 37 47 45 49 38 41 40 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.405 s \n",
            "\n",
            "Accuracy rate for 76.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       980\n",
            "           1       0.76      0.96      0.85      1135\n",
            "           2       0.78      0.65      0.71      1032\n",
            "           3       0.67      0.81      0.73      1010\n",
            "           4       0.74      0.79      0.76       982\n",
            "           5       0.80      0.44      0.57       892\n",
            "           6       0.71      0.87      0.78       958\n",
            "           7       0.84      0.82      0.83      1028\n",
            "           8       0.78      0.64      0.70       974\n",
            "           9       0.81      0.72      0.76      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.77      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 902    2    3   11    0    1   41    5   13    2]\n",
            " [   0 1085   30    1    0    2    4    1   12    0]\n",
            " [  33   82  667   63   20    0   99   24   35    9]\n",
            " [  15   44   27  818    5   22   19    8   36   16]\n",
            " [  10   20    8    2  776   13   54   25   12   62]\n",
            " [  41   43   12  186   63  391   67   36   34   19]\n",
            " [  31   14    9    1   44   11  830    3   15    0]\n",
            " [  26   46   47    1   16    3    5  838    9   37]\n",
            " [  10   68   33  131   17   23   32    8  622   30]\n",
            " [  25   23   16   16  106   22   14   50   12  725]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59570, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [35 58 38 48 45 50 38 41 42 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.332 s \n",
            "\n",
            "Accuracy rate for 75.770000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       980\n",
            "           1       0.76      0.96      0.85      1135\n",
            "           2       0.82      0.61      0.70      1032\n",
            "           3       0.65      0.82      0.73      1010\n",
            "           4       0.68      0.85      0.75       982\n",
            "           5       0.82      0.38      0.52       892\n",
            "           6       0.73      0.86      0.79       958\n",
            "           7       0.86      0.79      0.82      1028\n",
            "           8       0.74      0.65      0.69       974\n",
            "           9       0.81      0.69      0.74      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.75     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 890    2    3    9    3    2   41    3   25    2]\n",
            " [   0 1093   25    3    0    0    3    1   10    0]\n",
            " [  40   98  630   56   46    0   94   24   39    5]\n",
            " [  16   41   20  833   11   17   15    9   35   13]\n",
            " [  12   16    5    4  832    4   45    8   15   41]\n",
            " [  38   35    9  217   81  341   64   33   51   23]\n",
            " [  33   11    4    0   50   11  820    3   26    0]\n",
            " [  27   53   45    1   29    2    5  809    7   50]\n",
            " [   7   74   20  127   29   20   26    5  633   33]\n",
            " [  26   24   12   22  144   20   13   41   11  696]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59560, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [36 58 40 49 45 50 40 43 43 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.363 s \n",
            "\n",
            "Accuracy rate for 77.260000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.86       980\n",
            "           1       0.77      0.94      0.84      1135\n",
            "           2       0.79      0.70      0.74      1032\n",
            "           3       0.69      0.81      0.74      1010\n",
            "           4       0.76      0.78      0.77       982\n",
            "           5       0.84      0.47      0.60       892\n",
            "           6       0.75      0.85      0.80       958\n",
            "           7       0.84      0.82      0.83      1028\n",
            "           8       0.77      0.64      0.70       974\n",
            "           9       0.77      0.74      0.76      1009\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.78      0.77      0.76     10000\n",
            "weighted avg       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    1    1    8    0    1   33    4   23    1]\n",
            " [   0 1063   48    2    1    0    4    1   16    0]\n",
            " [  40   72  722   51   17    0   68   23   30    9]\n",
            " [  17   44   28  821    5   19   15   12   28   21]\n",
            " [  13   21    9    1  768    9   54   18   16   73]\n",
            " [  42   34   11  176   70  422   56   35   26   20]\n",
            " [  50   10    8    0   26   10  816    7   31    0]\n",
            " [  18   49   45    1   11    1    5  838    9   51]\n",
            " [  12   69   29  119   19   26   28    7  619   46]\n",
            " [  26   23   11   16   98   17   11   50    8  749]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [37 58 41 49 47 51 41 43 46 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.408 s \n",
            "\n",
            "Accuracy rate for 76.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.87       980\n",
            "           1       0.77      0.96      0.85      1135\n",
            "           2       0.80      0.68      0.73      1032\n",
            "           3       0.67      0.82      0.74      1010\n",
            "           4       0.74      0.79      0.76       982\n",
            "           5       0.78      0.41      0.54       892\n",
            "           6       0.73      0.83      0.78       958\n",
            "           7       0.84      0.80      0.82      1028\n",
            "           8       0.75      0.64      0.69       974\n",
            "           9       0.77      0.73      0.75      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.75     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 894    2    4    8    0    1   43    4   22    2]\n",
            " [   0 1089   25    1    0    3    4    1   12    0]\n",
            " [  36   84  699   48   18    2   80   20   34   11]\n",
            " [  17   40   28  827    4   20   16    9   33   16]\n",
            " [  11   19   11    3  774   15   49   16   15   69]\n",
            " [  33   38   15  204   67  369   63   47   39   17]\n",
            " [  33   14    6    0   50   15  797    3   40    0]\n",
            " [  25   47   47    1   10    2    6  826    7   57]\n",
            " [  10   70   24  125   18   27   28    7  623   42]\n",
            " [  25   20   17   20  103   19   12   51    9  733]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59540, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [37 59 42 50 47 53 41 45 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.345 s \n",
            "\n",
            "Accuracy rate for 76.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       980\n",
            "           1       0.73      0.96      0.83      1135\n",
            "           2       0.80      0.65      0.72      1032\n",
            "           3       0.69      0.80      0.74      1010\n",
            "           4       0.74      0.81      0.77       982\n",
            "           5       0.83      0.42      0.56       892\n",
            "           6       0.70      0.84      0.76       958\n",
            "           7       0.81      0.82      0.81      1028\n",
            "           8       0.77      0.65      0.70       974\n",
            "           9       0.80      0.71      0.75      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.75     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 885    2    2    7    0    1   53    5   23    2]\n",
            " [   0 1090   30    1    0    1    4    1    8    0]\n",
            " [  41  102  674   40   25    0   89   25   26   10]\n",
            " [  16   59   26  813    5   13   20    9   29   20]\n",
            " [  12   20    8    4  792   12   49   25   15   45]\n",
            " [  36   41   13  195   61  372   75   52   27   20]\n",
            " [  30   13    4    1   50    7  801    4   48    0]\n",
            " [  19   50   47    1   14    2    3  842    6   44]\n",
            " [  10   89   24   99   18   21   32    9  633   39]\n",
            " [  23   21   12   22  112   19   11   67    9  713]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59530, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [37 60 42 54 47 53 45 46 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 76.320000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85       980\n",
            "           1       0.75      0.95      0.84      1135\n",
            "           2       0.79      0.67      0.73      1032\n",
            "           3       0.70      0.82      0.75      1010\n",
            "           4       0.71      0.80      0.75       982\n",
            "           5       0.86      0.44      0.59       892\n",
            "           6       0.71      0.82      0.76       958\n",
            "           7       0.83      0.80      0.82      1028\n",
            "           8       0.75      0.67      0.71       974\n",
            "           9       0.80      0.70      0.75      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.75     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    1    2    7    1    2   52    4   26    2]\n",
            " [   0 1078   38    2    0    0    4    1   12    0]\n",
            " [  43   78  696   46   25    0   83   21   32    8]\n",
            " [  18   49   23  824    9   16   18    7   30   16]\n",
            " [  11   19    5    3  784   11   52   29   17   51]\n",
            " [  37   36   12  194   65  396   68   38   32   14]\n",
            " [  37    9    9    0   58    3  782    4   56    0]\n",
            " [  24   53   51    1   13    2    3  826    8   47]\n",
            " [   9   85   31   84   23   18   27    6  654   37]\n",
            " [  26   24   12   20  126   13   10   59   10  709]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59520, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [37 63 43 55 48 53 45 47 51 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.354 s \n",
            "\n",
            "Accuracy rate for 75.710000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       980\n",
            "           1       0.74      0.96      0.83      1135\n",
            "           2       0.80      0.59      0.68      1032\n",
            "           3       0.69      0.83      0.75      1010\n",
            "           4       0.73      0.81      0.77       982\n",
            "           5       0.81      0.44      0.57       892\n",
            "           6       0.69      0.85      0.76       958\n",
            "           7       0.80      0.82      0.81      1028\n",
            "           8       0.78      0.61      0.68       974\n",
            "           9       0.79      0.70      0.74      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    2    2    7    0    2   51    5   20    2]\n",
            " [   0 1091   29    1    1    0    4    2    7    0]\n",
            " [  41  107  614   53   29    0  106   31   42    9]\n",
            " [  18   42   23  835    5   18   16    8   23   22]\n",
            " [  10   19    3    4  791   10   52   27   12   54]\n",
            " [  35   38   13  175   69  391   81   55   20   15]\n",
            " [  37    9    5    0   44   13  816    4   30    0]\n",
            " [  22   52   48    1   12    2    4  844    5   38]\n",
            " [  11   99   25  106   18   31   37    9  594   44]\n",
            " [  29   24    8   22  116   15   12   67   10  706]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59510, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [39 64 44 57 51 53 45 48 51 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.419 s \n",
            "\n",
            "Accuracy rate for 76.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       980\n",
            "           1       0.74      0.96      0.84      1135\n",
            "           2       0.80      0.64      0.71      1032\n",
            "           3       0.67      0.83      0.74      1010\n",
            "           4       0.76      0.79      0.77       982\n",
            "           5       0.86      0.38      0.53       892\n",
            "           6       0.72      0.85      0.78       958\n",
            "           7       0.81      0.81      0.81      1028\n",
            "           8       0.76      0.65      0.70       974\n",
            "           9       0.77      0.74      0.75      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.75     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 885    2    2   10    0    1   49    7   22    2]\n",
            " [   0 1092   28    1    0    0    3    3    8    0]\n",
            " [  31  104  656   57   17    0   91   33   33   10]\n",
            " [  21   45   17  834    2   14   17    9   29   22]\n",
            " [   9   20    7    3  774    8   51   24   19   67]\n",
            " [  38   36   16  220   63  339   63   49   31   37]\n",
            " [  35   11    8    0   36    3  817    4   44    0]\n",
            " [  26   54   48    1   15    1    3  831    5   44]\n",
            " [   7   89   26  101   16   18   28    9  637   43]\n",
            " [  23   24   12   23   95   12   14   55    6  745]]\n",
            "--------------------------------\n",
            "final active learning accuracies [31.180000000000003, 40.35, 50.01, 57.87, 61.53999999999999, 67.06, 69.54, 72.59, 71.99, 72.97, 71.83, 71.08, 72.68, 73.21, 73.65, 74.3, 74.06, 75.14999999999999, 75.62, 74.69, 74.03, 75.14, 75.5, 75.24, 75.26, 74.81, 75.5, 75.53, 74.85000000000001, 74.3, 76.03, 76.68, 75.82, 75.66000000000001, 75.47, 76.99000000000001, 74.64, 75.27000000000001, 76.57000000000001, 77.31, 76.9, 76.44, 76.53999999999999, 75.77000000000001, 77.25999999999999, 76.31, 76.14999999999999, 76.32, 75.71, 76.1]\n",
            "saved Active-learning-experiment-35.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.180000000000003,\n",
            "          40.35,\n",
            "          50.01,\n",
            "          57.87,\n",
            "          61.53999999999999,\n",
            "          67.06,\n",
            "          69.54,\n",
            "          72.59,\n",
            "          71.99,\n",
            "          72.97,\n",
            "          71.83,\n",
            "          71.08,\n",
            "          72.68,\n",
            "          73.21,\n",
            "          73.65,\n",
            "          74.3,\n",
            "          74.06,\n",
            "          75.14999999999999,\n",
            "          75.62,\n",
            "          74.69,\n",
            "          74.03,\n",
            "          75.14,\n",
            "          75.5,\n",
            "          75.24,\n",
            "          75.26,\n",
            "          74.81,\n",
            "          75.5,\n",
            "          75.53,\n",
            "          74.85000000000001,\n",
            "          74.3,\n",
            "          76.03,\n",
            "          76.68,\n",
            "          75.82,\n",
            "          75.66000000000001,\n",
            "          75.47,\n",
            "          76.99000000000001,\n",
            "          74.64,\n",
            "          75.27000000000001,\n",
            "          76.57000000000001,\n",
            "          77.31,\n",
            "          76.9,\n",
            "          76.44,\n",
            "          76.53999999999999,\n",
            "          75.77000000000001,\n",
            "          77.25999999999999,\n",
            "          76.31,\n",
            "          76.14999999999999,\n",
            "          76.32,\n",
            "          75.71,\n",
            "          76.1\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          67.81,\n",
            "          73.41,\n",
            "          74.22999999999999,\n",
            "          73.67\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          60.0,\n",
            "          61.91,\n",
            "          66.95,\n",
            "          69.6,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          72.5,\n",
            "          72.68,\n",
            "          73.58,\n",
            "          73.81,\n",
            "          73.59,\n",
            "          73.5,\n",
            "          72.75,\n",
            "          73.72,\n",
            "          73.66,\n",
            "          74.00999999999999,\n",
            "          74.38,\n",
            "          73.42,\n",
            "          73.05,\n",
            "          73.24000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          74.1,\n",
            "          75.67\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          60.309999999999995,\n",
            "          67.99,\n",
            "          68.86,\n",
            "          69.49,\n",
            "          71.48,\n",
            "          72.54,\n",
            "          73.42999999999999,\n",
            "          74.14,\n",
            "          74.46000000000001,\n",
            "          74.11\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.95,\n",
            "          37.769999999999996,\n",
            "          36.39,\n",
            "          31.169999999999998,\n",
            "          33.33,\n",
            "          39.300000000000004,\n",
            "          42.730000000000004,\n",
            "          44.96,\n",
            "          45.97,\n",
            "          46.72,\n",
            "          46.379999999999995,\n",
            "          47.89,\n",
            "          49.120000000000005,\n",
            "          49.08,\n",
            "          48.38,\n",
            "          49.02,\n",
            "          50.96000000000001,\n",
            "          51.51,\n",
            "          52.629999999999995,\n",
            "          53.43,\n",
            "          53.400000000000006,\n",
            "          52.62,\n",
            "          53.33,\n",
            "          52.72,\n",
            "          53.169999999999995,\n",
            "          54.55,\n",
            "          55.230000000000004,\n",
            "          57.37,\n",
            "          57.56,\n",
            "          58.64,\n",
            "          59.61,\n",
            "          58.550000000000004,\n",
            "          59.48,\n",
            "          58.96,\n",
            "          59.230000000000004,\n",
            "          60.29,\n",
            "          60.35,\n",
            "          60.940000000000005,\n",
            "          60.660000000000004,\n",
            "          60.17,\n",
            "          60.69,\n",
            "          60.8,\n",
            "          62.06,\n",
            "          63.89,\n",
            "          63.28,\n",
            "          63.839999999999996,\n",
            "          63.67,\n",
            "          63.71,\n",
            "          63.980000000000004,\n",
            "          63.92\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.10000000000001,\n",
            "          73.02,\n",
            "          73.33,\n",
            "          72.53\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.730000000000004,\n",
            "          45.42,\n",
            "          46.589999999999996,\n",
            "          49.2,\n",
            "          50.44,\n",
            "          53.239999999999995,\n",
            "          57.08,\n",
            "          57.879999999999995,\n",
            "          60.47,\n",
            "          62.480000000000004,\n",
            "          60.68,\n",
            "          61.78,\n",
            "          61.18,\n",
            "          61.0,\n",
            "          59.84,\n",
            "          62.91,\n",
            "          62.99,\n",
            "          63.56,\n",
            "          64.05999999999999,\n",
            "          65.28\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          80.9,\n",
            "          81.05\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.98,\n",
            "          62.150000000000006,\n",
            "          62.67,\n",
            "          61.28,\n",
            "          60.5,\n",
            "          59.29,\n",
            "          60.480000000000004,\n",
            "          60.17,\n",
            "          60.86,\n",
            "          59.550000000000004\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.610000000000003,\n",
            "          39.07,\n",
            "          52.59,\n",
            "          60.88,\n",
            "          61.24000000000001,\n",
            "          67.75999999999999,\n",
            "          72.24000000000001,\n",
            "          74.92,\n",
            "          78.81,\n",
            "          79.96,\n",
            "          81.24,\n",
            "          82.33,\n",
            "          83.39999999999999,\n",
            "          85.04,\n",
            "          84.06,\n",
            "          85.28999999999999,\n",
            "          84.85000000000001,\n",
            "          85.45,\n",
            "          86.29,\n",
            "          86.78,\n",
            "          87.19,\n",
            "          87.11,\n",
            "          88.28,\n",
            "          88.01,\n",
            "          88.49000000000001,\n",
            "          88.3,\n",
            "          89.01,\n",
            "          89.29,\n",
            "          89.67,\n",
            "          90.22,\n",
            "          90.2,\n",
            "          90.22,\n",
            "          90.53,\n",
            "          91.07,\n",
            "          90.64,\n",
            "          90.96,\n",
            "          91.17,\n",
            "          91.47999999999999,\n",
            "          91.64999999999999,\n",
            "          91.74,\n",
            "          91.96,\n",
            "          91.63,\n",
            "          91.86,\n",
            "          91.9,\n",
            "          91.79,\n",
            "          91.9,\n",
            "          92.23,\n",
            "          92.08,\n",
            "          92.41,\n",
            "          92.54\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.8,\n",
            "          83.47,\n",
            "          89.21,\n",
            "          91.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.74999999999999,\n",
            "          66.17,\n",
            "          70.77,\n",
            "          77.29,\n",
            "          81.23,\n",
            "          82.98,\n",
            "          86.08,\n",
            "          88.09,\n",
            "          88.42,\n",
            "          88.94999999999999,\n",
            "          89.01,\n",
            "          89.88000000000001,\n",
            "          90.82000000000001,\n",
            "          91.28,\n",
            "          91.4,\n",
            "          92.01,\n",
            "          92.36999999999999,\n",
            "          91.9,\n",
            "          92.80000000000001,\n",
            "          93.22\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.06,\n",
            "          90.36\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          54.059999999999995,\n",
            "          71.72,\n",
            "          78.44,\n",
            "          83.62,\n",
            "          86.50999999999999,\n",
            "          88.63,\n",
            "          89.85,\n",
            "          91.10000000000001,\n",
            "          91.59,\n",
            "          91.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 36, using model = LogModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [27 28 22 30 20 25 24 26 26 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.305 s \n",
            "\n",
            "Accuracy rate for 74.580000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       980\n",
            "           1       0.71      0.97      0.82      1135\n",
            "           2       0.73      0.68      0.70      1032\n",
            "           3       0.66      0.80      0.72      1010\n",
            "           4       0.70      0.82      0.76       982\n",
            "           5       0.73      0.41      0.53       892\n",
            "           6       0.79      0.85      0.82       958\n",
            "           7       0.88      0.76      0.82      1028\n",
            "           8       0.67      0.58      0.62       974\n",
            "           9       0.79      0.60      0.68      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 901    2    8   10    0    5   43    1   10    0]\n",
            " [   0 1099   24    3    0    1    5    0    3    0]\n",
            " [  49  112  703   14   23    2   51   31   43    4]\n",
            " [   8   38   74  805    4   36    9    8   21    7]\n",
            " [  14   35    9    5  804    9   26   10   23   47]\n",
            " [  35   65   17  177   68  367   43    9   88   23]\n",
            " [  24   19   29    1   32   19  817    0   17    0]\n",
            " [  22   68   26    6   37    4    2  784   18   61]\n",
            " [  13   68   66  164   12   30   28    5  569   19]\n",
            " [  23   33    8   28  165   30    9   41   63  609]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [35 30 52 56 40 71 37 57 50 72] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.435 s \n",
            "\n",
            "Accuracy rate for 71.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.96      0.84       980\n",
            "           1       0.68      0.98      0.81      1135\n",
            "           2       0.74      0.50      0.60      1032\n",
            "           3       0.66      0.78      0.72      1010\n",
            "           4       0.67      0.76      0.71       982\n",
            "           5       0.80      0.39      0.53       892\n",
            "           6       0.67      0.88      0.76       958\n",
            "           7       0.76      0.82      0.79      1028\n",
            "           8       0.74      0.60      0.67       974\n",
            "           9       0.84      0.45      0.58      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.71      0.70     10000\n",
            "weighted avg       0.73      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    3    2    2    0    0   31    2    3    0]\n",
            " [   0 1111   12    1    0    1    4    2    4    0]\n",
            " [  66  188  516   18   13    1  138   40   48    4]\n",
            " [  39   55   19  792    5   19   21   24   27    9]\n",
            " [  32   25   32    9  742   20   56   34   19   13]\n",
            " [  86   36   19  219   15  350   66   53   46    2]\n",
            " [  42   15   17    5   14   10  841    4   10    0]\n",
            " [  18   67   40    2   18    0    2  844    6   31]\n",
            " [  14   97   15  114   24   13   79    5  589   24]\n",
            " [  25   26   30   29  278   21   10   97   43  450]]\n",
            "--------------------------------\n",
            "final active learning accuracies [74.58, 71.72]\n",
            "saved Active-learning-experiment-36.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 37, using model = LogModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [17 18  6 11 14  9 13 10 15 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.311 s \n",
            "\n",
            "Accuracy rate for 73.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84       980\n",
            "           1       0.70      0.99      0.82      1135\n",
            "           2       0.72      0.54      0.62      1032\n",
            "           3       0.64      0.79      0.71      1010\n",
            "           4       0.74      0.74      0.74       982\n",
            "           5       0.86      0.46      0.59       892\n",
            "           6       0.79      0.81      0.80       958\n",
            "           7       0.80      0.71      0.76      1028\n",
            "           8       0.76      0.64      0.70       974\n",
            "           9       0.64      0.69      0.66      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    1   27    5    0    7   14   14   11    1]\n",
            " [   0 1122    0    1    0    0    5    4    3    0]\n",
            " [  80  140  555  121   23    0   49   27   34    3]\n",
            " [  36   14   14  796    2   34   22   57   22   13]\n",
            " [   3   47   27   17  725    0   34    1   10  118]\n",
            " [  75   45   14  152   17  406   42   38   71   32]\n",
            " [  29   10   70   13   20    8  774    3   31    0]\n",
            " [  10   73   17   11   15    0    5  734    5  158]\n",
            " [  15  108    4  111    7    8   31    5  627   58]\n",
            " [   9   35   39   17  167   10    1   31    8  692]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['5' '0' '4' ... '8' '0' '8']\n",
            "probabilities: (59875, 10) \n",
            " [5 0 4 ... 8 0 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [19 18 20 22 31 33 23 23 28 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.297 s \n",
            "\n",
            "Accuracy rate for 74.140000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81       980\n",
            "           1       0.70      0.99      0.82      1135\n",
            "           2       0.81      0.59      0.68      1032\n",
            "           3       0.65      0.76      0.70      1010\n",
            "           4       0.74      0.78      0.76       982\n",
            "           5       0.78      0.41      0.54       892\n",
            "           6       0.73      0.87      0.80       958\n",
            "           7       0.80      0.78      0.79      1028\n",
            "           8       0.83      0.58      0.68       974\n",
            "           9       0.80      0.64      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    2    3    5    0    1   11   13    6    0]\n",
            " [   0 1121    2    2    0    1    4    1    4    0]\n",
            " [  90  156  609   16   10    1   88   38   12   12]\n",
            " [  61   46   38  767    4   13   17   33   18   13]\n",
            " [  13   33    2    5  765   17   64   13   18   52]\n",
            " [ 103   39    3  223   57  365   50   22   26    4]\n",
            " [  50   18   13   10   17    4  835    2    9    0]\n",
            " [  34   54   43    1   29    5    3  799    5   55]\n",
            " [  31   99   26  127   17   25   58    2  566   23]\n",
            " [  24   25   10   29  134   34   12   75   18  648]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [24 19 28 32 46 60 32 31 47 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.392 s \n",
            "\n",
            "Accuracy rate for 73.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.98      0.85       980\n",
            "           1       0.69      0.99      0.81      1135\n",
            "           2       0.78      0.65      0.71      1032\n",
            "           3       0.71      0.70      0.70      1010\n",
            "           4       0.70      0.81      0.75       982\n",
            "           5       0.84      0.35      0.49       892\n",
            "           6       0.75      0.81      0.78       958\n",
            "           7       0.74      0.86      0.79      1028\n",
            "           8       0.75      0.51      0.61       974\n",
            "           9       0.81      0.64      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 964    2    1    1    1    0    4    5    2    0]\n",
            " [   0 1119    2    2    0    0    3    5    4    0]\n",
            " [  50  159  670    5   30    0   44   67    5    2]\n",
            " [  67   58   41  706    5   13   15   52   42   11]\n",
            " [   8   25    7    2  796    6   31   16   17   74]\n",
            " [ 111   44    3  150   81  313   68   44   51   27]\n",
            " [  42   22    8   15   70    7  779   10    5    0]\n",
            " [  13   53   30    1   19    0    2  884    4   22]\n",
            " [  19  122   82   94   14   22   86   14  501   20]\n",
            " [  21   27   14   20  126   12    4  103   35  647]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 2]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [24 19 37 42 58 90 40 36 67 87] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.363 s \n",
            "\n",
            "Accuracy rate for 72.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.99      0.85       980\n",
            "           1       0.69      0.98      0.81      1135\n",
            "           2       0.76      0.66      0.71      1032\n",
            "           3       0.72      0.69      0.70      1010\n",
            "           4       0.69      0.79      0.74       982\n",
            "           5       0.84      0.33      0.48       892\n",
            "           6       0.74      0.87      0.80       958\n",
            "           7       0.70      0.88      0.78      1028\n",
            "           8       0.67      0.53      0.59       974\n",
            "           9       0.87      0.50      0.64      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 966    2    3    0    0    1    4    3    1    0]\n",
            " [   0 1114    4    2    0    0    7    4    4    0]\n",
            " [  53  155  678    7   22    0   52   61    2    2]\n",
            " [  71   56   48  692    8   16   18   44   49    8]\n",
            " [  11   29   14   10  780    3   45   44   24   22]\n",
            " [ 108   43   11  153   63  295   55   53  108    3]\n",
            " [  47   16   22    6   15    5  834   12    1    0]\n",
            " [  10   56   18    0   10    0    6  903    4   21]\n",
            " [  17  120   80   59   25   21   91   24  520   17]\n",
            " [  16   24   13   26  203    9   14  137   63  504]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.31, 74.14, 73.79, 72.86]\n",
            "saved Active-learning-experiment-37.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 38, using model = LogModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [6 6 1 9 4 4 9 2 3 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.251 s \n",
            "\n",
            "Accuracy rate for 58.220000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.65      0.71       980\n",
            "           1       0.67      0.95      0.78      1135\n",
            "           2       0.75      0.03      0.06      1032\n",
            "           3       0.51      0.72      0.60      1010\n",
            "           4       0.65      0.67      0.66       982\n",
            "           5       0.58      0.35      0.44       892\n",
            "           6       0.57      0.82      0.67       958\n",
            "           7       0.84      0.36      0.51      1028\n",
            "           8       0.54      0.53      0.54       974\n",
            "           9       0.40      0.70      0.50      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.63      0.58      0.55     10000\n",
            "weighted avg       0.63      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 637    1    0   36    5   79  189    0   20   13]\n",
            " [   0 1074    0    6    3    0    4    0   48    0]\n",
            " [   9  162   30  279  117    8  231    3   97   96]\n",
            " [   6   48    0  732    2   21   26    2  109   64]\n",
            " [  12   63    3   11  657    8   23   30   13  162]\n",
            " [  22   30    2  185   22  311   64    5  125  126]\n",
            " [  94   24    5    7   29    5  783    2    5    4]\n",
            " [   4   67    0   42   15   33    5  374   17  471]\n",
            " [   7   99    0   93   18   61   32    2  520  142]\n",
            " [  16   47    0   40  147    9    9   27   10  704]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '9' '6' '5']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 9 6 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9  7  9 16  9 12 11 10  6 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.240 s \n",
            "\n",
            "Accuracy rate for 65.960000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.82       980\n",
            "           1       0.67      0.87      0.76      1135\n",
            "           2       0.60      0.53      0.56      1032\n",
            "           3       0.78      0.71      0.75      1010\n",
            "           4       0.67      0.63      0.65       982\n",
            "           5       0.88      0.31      0.45       892\n",
            "           6       0.89      0.55      0.68       958\n",
            "           7       0.66      0.71      0.69      1028\n",
            "           8       0.47      0.75      0.58       974\n",
            "           9       0.58      0.54      0.56      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.69      0.65      0.65     10000\n",
            "weighted avg       0.69      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[921   1   1   6   2   3  10   7  29   0]\n",
            " [  0 990   3   1   0   1   1   1 137   1]\n",
            " [ 35 126 544  24  47   0  13  13 215  15]\n",
            " [ 31  93  16 718  12  20   7  24  56  33]\n",
            " [ 16  40  34   1 619   0   5  58  54 155]\n",
            " [102  43  15 143  21 273  23  62 191  19]\n",
            " [ 67  31 222   6  29   5 526   1  71   0]\n",
            " [ 39  50  28   0  13   3   0 729  35 131]\n",
            " [ 22  80  10  12  44   4   6  18 728  50]\n",
            " [ 40  18  37   6 131   3   0 186  40 548]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '8' '0' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 8 0 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [10  7 13 25 15 20 17 15  9 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.266 s \n",
            "\n",
            "Accuracy rate for 63.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.95      0.84       980\n",
            "           1       0.75      0.84      0.79      1135\n",
            "           2       0.71      0.33      0.45      1032\n",
            "           3       0.77      0.69      0.73      1010\n",
            "           4       0.58      0.82      0.68       982\n",
            "           5       0.91      0.22      0.35       892\n",
            "           6       0.71      0.87      0.78       958\n",
            "           7       0.81      0.32      0.45      1028\n",
            "           8       0.43      0.77      0.55       974\n",
            "           9       0.47      0.55      0.51      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.69      0.64      0.61     10000\n",
            "weighted avg       0.69      0.64      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[931   1   1   5   4   2  26   3   7   0]\n",
            " [  0 953   0   1   0   0   6   1 173   1]\n",
            " [ 46  94 345  29  86   0 146   7 263  16]\n",
            " [ 28  39   8 700   7   5  23  19 143  38]\n",
            " [  7  32  16   0 808   0  23   7  28  61]\n",
            " [ 87  40  17 118  56 193  66  14 267  34]\n",
            " [ 36  12  16   1  29   2 832   0  30   0]\n",
            " [ 67  39  50   0  75   1   3 324  33 436]\n",
            " [ 16  47   5  43  35   8  29   4 752  35]\n",
            " [ 27  15  31  10 290   0  13  21  43 559]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['8' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59850, 10) \n",
            " [8 0 4 ... 8 6 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [11  8 22 31 19 28 21 20 11 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.285 s \n",
            "\n",
            "Accuracy rate for 70.620000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.96      0.84       980\n",
            "           1       0.73      0.93      0.82      1135\n",
            "           2       0.75      0.47      0.57      1032\n",
            "           3       0.77      0.74      0.76      1010\n",
            "           4       0.63      0.85      0.73       982\n",
            "           5       0.92      0.38      0.54       892\n",
            "           6       0.64      0.89      0.75       958\n",
            "           7       0.87      0.56      0.68      1028\n",
            "           8       0.63      0.68      0.65       974\n",
            "           9       0.61      0.56      0.58      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.73      0.70      0.69     10000\n",
            "weighted avg       0.73      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    1    2    4    2    1   24    1    6    0]\n",
            " [   0 1055    8    1    0    0    7    2   62    0]\n",
            " [  32  149  482   25   28    1  192    9  101   13]\n",
            " [  39   38   15  752    6   10   32   20   67   31]\n",
            " [  10   18   11    2  837    0   52    8    7   37]\n",
            " [  83   32   31  129   55  341   83    9  103   26]\n",
            " [  45    8   19    2   21    2  857    1    3    0]\n",
            " [  66   47   39    0   49    2    7  571   21  226]\n",
            " [  18   74   12   46   46   12   64    4  663   35]\n",
            " [  28   17   26   12  281    2   22   33   23  565]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 9 6 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [11 10 25 38 21 35 23 33 16 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 73.630000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.97      0.84       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.88      0.45      0.59      1032\n",
            "           3       0.71      0.76      0.73      1010\n",
            "           4       0.72      0.85      0.77       982\n",
            "           5       0.92      0.34      0.50       892\n",
            "           6       0.62      0.91      0.73       958\n",
            "           7       0.83      0.80      0.81      1028\n",
            "           8       0.68      0.70      0.69       974\n",
            "           9       0.81      0.57      0.67      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.72     10000\n",
            "weighted avg       0.76      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2    1    0    1    0   18    0    6    0]\n",
            " [   0 1108    0    2    0    0    9    2   14    0]\n",
            " [  42  129  463   11   35    0  241   24   79    8]\n",
            " [  48   43   21  763    7    9   27   13   63   16]\n",
            " [   6   24    0   10  830    3   63   16    8   22]\n",
            " [  92   60    8  206   46  305   60   11   85   19]\n",
            " [  44   12   11    5    7    3  867    3    6    0]\n",
            " [  47   57   15    0   13    0   11  819   16   50]\n",
            " [  22   66    6   46   29    7   86   10  678   24]\n",
            " [  24   28    2   25  192    5   23   91   41  578]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [12 11 29 44 24 49 23 41 18 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.306 s \n",
            "\n",
            "Accuracy rate for 75.530000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.96      0.84       980\n",
            "           1       0.74      0.98      0.84      1135\n",
            "           2       0.86      0.41      0.55      1032\n",
            "           3       0.78      0.76      0.77      1010\n",
            "           4       0.80      0.79      0.80       982\n",
            "           5       0.84      0.51      0.64       892\n",
            "           6       0.61      0.91      0.73       958\n",
            "           7       0.82      0.80      0.81      1028\n",
            "           8       0.70      0.70      0.70       974\n",
            "           9       0.82      0.70      0.76      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    4    1    0    2   26    1    3    0]\n",
            " [   0 1116    0    3    0    1   11    2    2    0]\n",
            " [  56  143  420   16   38    0  243   53   58    5]\n",
            " [  31   28   17  766    2   14   29   17   91   15]\n",
            " [  15   26    1    2  780   16   59   27   24   32]\n",
            " [  62   37    9  135   40  457   66    6   68   12]\n",
            " [  36   11    9    4    7   11  871    3    6    0]\n",
            " [  64   50   18    0   10    1   10  818   10   47]\n",
            " [  22   62    7   38    7   19   92    9  677   41]\n",
            " [  29   32    6   13   90   21   15   67   29  707]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [12 12 33 50 28 61 24 47 26 57] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 73.960000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.97      0.78       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.85      0.42      0.57      1032\n",
            "           3       0.84      0.66      0.74      1010\n",
            "           4       0.83      0.68      0.75       982\n",
            "           5       0.81      0.53      0.64       892\n",
            "           6       0.58      0.90      0.70       958\n",
            "           7       0.86      0.78      0.82      1028\n",
            "           8       0.72      0.68      0.70       974\n",
            "           9       0.81      0.74      0.77      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.77      0.74      0.73     10000\n",
            "weighted avg       0.77      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    2    2    0    0    0   18    0    5    0]\n",
            " [   0 1115    1    2    0    1   10    2    4    0]\n",
            " [  91  141  437    6   20    1  256   26   47    7]\n",
            " [  49   37   25  669    6   37   45   15  109   18]\n",
            " [  51   30    7    0  669   23   84   28   15   75]\n",
            " [ 105   60    5   80   35  473   69    8   46   11]\n",
            " [  62   10    4    0    2    8  859    2   11    0]\n",
            " [  70   71   18    4   12    1   12  806    2   32]\n",
            " [  37   58    7   26   12   20  109    7  667   31]\n",
            " [  51   33    6   11   50   22   18   46   24  748]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['5' '0' '6' ... '5' '0' '9']\n",
            "probabilities: (59650, 10) \n",
            " [5 0 6 ... 5 0 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [12 12 39 59 36 73 27 48 29 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.374 s \n",
            "\n",
            "Accuracy rate for 73.170000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.81       980\n",
            "           1       0.69      0.98      0.81      1135\n",
            "           2       0.85      0.46      0.60      1032\n",
            "           3       0.85      0.59      0.70      1010\n",
            "           4       0.76      0.73      0.74       982\n",
            "           5       0.80      0.51      0.62       892\n",
            "           6       0.60      0.89      0.72       958\n",
            "           7       0.83      0.80      0.82      1028\n",
            "           8       0.63      0.66      0.65       974\n",
            "           9       0.82      0.69      0.75      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.76      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    2    2    0    0    0   27    0    5    0]\n",
            " [   0 1112    3    1    3    1    8    2    5    0]\n",
            " [  69  167  476    7   25    2  205   35   38    8]\n",
            " [  37   57   21  593    6   47   45   22  167   15]\n",
            " [  33   35    1    1  712   21   62   26   24   67]\n",
            " [  81   50    7   71   38  451   73   14   86   21]\n",
            " [  55   10   11    0   12    3  857    2    8    0]\n",
            " [  62   68   20    0   18    0    6  825    8   21]\n",
            " [  18   72   14   16   17   22  134    8  646   27]\n",
            " [  38   39    2    5  103   16   13   57   35  701]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [12 14 44 70 41 78 30 49 42 70] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.488 s \n",
            "\n",
            "Accuracy rate for 72.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.96      0.80       980\n",
            "           1       0.71      0.98      0.83      1135\n",
            "           2       0.86      0.50      0.63      1032\n",
            "           3       0.79      0.64      0.70      1010\n",
            "           4       0.81      0.63      0.71       982\n",
            "           5       0.73      0.51      0.60       892\n",
            "           6       0.58      0.91      0.71       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.64      0.62      0.63       974\n",
            "           9       0.81      0.67      0.73      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    1    0    1    1   32    0    2    0]\n",
            " [   0 1114    5    1    0    1    6    2    6    0]\n",
            " [  79  152  515    1   11    4  215   26   18   11]\n",
            " [  30   57   24  643    2   59   42   18  121   14]\n",
            " [  53   16    1    7  617   38   81   47   50   72]\n",
            " [  54   44    8  104   28  455   98   13   71   17]\n",
            " [  42   12    6    0    6   10  874    3    5    0]\n",
            " [  84   48   25    1    7    2    8  816   14   23]\n",
            " [  19   89    7   49   18   34  124   10  601   23]\n",
            " [  57   30    5   10   75   20   16   70   51  675]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '6' ... '5' '0' '5']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 6 ... 5 0 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [13 15 49 72 51 86 30 52 49 83] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.444 s \n",
            "\n",
            "Accuracy rate for 71.740000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82       980\n",
            "           1       0.71      0.96      0.82      1135\n",
            "           2       0.80      0.51      0.62      1032\n",
            "           3       0.77      0.66      0.71      1010\n",
            "           4       0.82      0.63      0.71       982\n",
            "           5       0.79      0.44      0.57       892\n",
            "           6       0.58      0.92      0.71       958\n",
            "           7       0.75      0.80      0.77      1028\n",
            "           8       0.61      0.64      0.62       974\n",
            "           9       0.83      0.61      0.71      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.71      0.71     10000\n",
            "weighted avg       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    2    2    0    0    1   32    0    1    0]\n",
            " [   0 1093   25    1    0    1    6    2    7    0]\n",
            " [  66  148  523   18   13    3  212   24   19    6]\n",
            " [  35   64   14  667    0   35   39   19  126   11]\n",
            " [  23   12    6    9  615   28   91   69   60   69]\n",
            " [  91   48   13  111   19  396   92   14  102    6]\n",
            " [  30   13    7    1    9   10  878    3    7    0]\n",
            " [  79   49   37    2    9    2    8  818    8   16]\n",
            " [  22   73   24   44   13   15  133    9  622   19]\n",
            " [  36   29    4   10   73   13   20  130   74  620]]\n",
            "--------------------------------\n",
            "final active learning accuracies [58.220000000000006, 65.96, 63.970000000000006, 70.62, 73.63, 75.53, 73.96000000000001, 73.17, 72.50999999999999, 71.74000000000001]\n",
            "saved Active-learning-experiment-38.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 39, using model = LogModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [1 0 2 2 5 3 3 4 3 2] [0 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.227 s \n",
            "\n",
            "Accuracy rate for 45.940000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.59      0.64       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.48      0.79      0.60      1032\n",
            "           3       0.38      0.45      0.41      1010\n",
            "           4       0.75      0.61      0.67       982\n",
            "           5       0.33      0.47      0.38       892\n",
            "           6       0.57      0.41      0.48       958\n",
            "           7       0.48      0.68      0.56      1028\n",
            "           8       0.29      0.41      0.34       974\n",
            "           9       0.35      0.24      0.28      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.43      0.46      0.44     10000\n",
            "weighted avg       0.43      0.46      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[577   0  74  11   5 139 122  21  16  15]\n",
            " [  0   0  14 378   0 266  42   1 406  28]\n",
            " [ 18   0 813   5   8  13  69  16  81   9]\n",
            " [ 15   0 184 453   3 121   1  47 174  12]\n",
            " [  6   0  76  22 597  16  26 112  68  59]\n",
            " [ 79   0  45 147  16 416  11  41  89  48]\n",
            " [ 45   0 337  10  25 140 397   0   3   1]\n",
            " [  2   0  32   2  12   1   3 703  82 191]\n",
            " [ 57   0  63 165  29 134  19  26 399  82]\n",
            " [ 13   0  43   9  97  25   2 501  80 239]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['8' '0' '7' ... '8' '5' '8']\n",
            "probabilities: (59975, 9) \n",
            " [7 0 6 ... 7 4 7]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 3 2 5 9 8 4 5 7 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.241 s \n",
            "\n",
            "Accuracy rate for 60.820000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81       980\n",
            "           1       0.76      0.92      0.84      1135\n",
            "           2       0.90      0.23      0.36      1032\n",
            "           3       0.61      0.76      0.68      1010\n",
            "           4       0.61      0.75      0.68       982\n",
            "           5       0.47      0.49      0.48       892\n",
            "           6       0.76      0.56      0.64       958\n",
            "           7       0.52      0.67      0.58      1028\n",
            "           8       0.45      0.59      0.51       974\n",
            "           9       0.39      0.29      0.33      1009\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.63      0.60      0.59     10000\n",
            "weighted avg       0.64      0.61      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 761    1    2   19   20  143   10   18    4    2]\n",
            " [   0 1049    0    4    0    3    3    1   75    0]\n",
            " [  28   81  234  107   72    6   85   38  330   51]\n",
            " [  13   12   16  772    1   49    3   57   73   14]\n",
            " [   6   37    0    5  738   33   13   24   15  111]\n",
            " [  35   32    1  197   27  436   19   49   70   26]\n",
            " [  48    9    3    3   82  176  533    3   97    4]\n",
            " [   8   68    1    2   23   10    2  688   26  200]\n",
            " [   3   63    0  151   15   46   19   51  579   47]\n",
            " [   8   24    2   12  225   19   10  405   12  292]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['8' '0' '4' ... '5' '5' '5']\n",
            "probabilities: (59950, 10) \n",
            " [8 0 4 ... 5 5 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 4  3  7  6 12 14  8  6  9  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.244 s \n",
            "\n",
            "Accuracy rate for 69.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       980\n",
            "           1       0.70      0.92      0.80      1135\n",
            "           2       0.68      0.58      0.63      1032\n",
            "           3       0.70      0.69      0.70      1010\n",
            "           4       0.71      0.78      0.74       982\n",
            "           5       0.63      0.54      0.58       892\n",
            "           6       0.79      0.78      0.78       958\n",
            "           7       0.62      0.74      0.67      1028\n",
            "           8       0.59      0.73      0.65       974\n",
            "           9       0.63      0.36      0.45      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.70      0.69      0.69     10000\n",
            "weighted avg       0.70      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 780    1   12   16   15   88   46    8   14    0]\n",
            " [   0 1045    2    1    0    2    3    1   81    0]\n",
            " [  18  116  602   49   13    2   26   26  177    3]\n",
            " [   2   15   84  695    0   91   16   60   41    6]\n",
            " [   1   38   22    0  763    2   29   21   19   87]\n",
            " [   9   34   27  155   19  481   42   32   49   44]\n",
            " [   7   10   75    4   14   38  744    1   65    0]\n",
            " [   8  104   23    9   28   15    3  764   34   40]\n",
            " [   3   84   15   48   10   31   22   18  709   34]\n",
            " [  13   44   22    9  214   10    9  310   19  359]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6  3 10 11 15 18 11  8 10  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.254 s \n",
            "\n",
            "Accuracy rate for 71.080000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       980\n",
            "           1       0.75      0.92      0.83      1135\n",
            "           2       0.79      0.67      0.73      1032\n",
            "           3       0.68      0.80      0.73      1010\n",
            "           4       0.77      0.69      0.73       982\n",
            "           5       0.70      0.36      0.48       892\n",
            "           6       0.75      0.86      0.80       958\n",
            "           7       0.58      0.78      0.66      1028\n",
            "           8       0.63      0.67      0.65       974\n",
            "           9       0.64      0.42      0.51      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    1   16    7    2   22   64    1   11    2]\n",
            " [   0 1046    0    1    0    2    5    1   80    0]\n",
            " [  30   90  689   28   15    0   41   31  100    8]\n",
            " [  14   11   52  813    3   31   19   32   26    9]\n",
            " [  12   29    8    2  681    9   45   87   36   73]\n",
            " [  56   28   20  242   38  324   54   53   24   53]\n",
            " [  29    8   24    0   12   11  823    2   49    0]\n",
            " [  10   78   27    1    6    2    6  800   24   74]\n",
            " [   3   69   17   94   25   48   24   22  652   20]\n",
            " [  10   31   14   16  106   14   14  353   25  426]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 6  4 12 14 20 22 13 10 11 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.249 s \n",
            "\n",
            "Accuracy rate for 69.890000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       980\n",
            "           1       0.76      0.98      0.85      1135\n",
            "           2       0.73      0.66      0.70      1032\n",
            "           3       0.67      0.69      0.68      1010\n",
            "           4       0.79      0.64      0.70       982\n",
            "           5       0.70      0.29      0.41       892\n",
            "           6       0.75      0.87      0.81       958\n",
            "           7       0.59      0.72      0.65      1028\n",
            "           8       0.62      0.68      0.65       974\n",
            "           9       0.56      0.54      0.55      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.69      0.68     10000\n",
            "weighted avg       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 833    1   20    9    1   13   34   10   59    0]\n",
            " [   0 1109    2    5    0    2    5    1   11    0]\n",
            " [  33   95  683   11    8    0   77   19   99    7]\n",
            " [  16   29  111  696    2   50   11   23   37   35]\n",
            " [  14   29    3    3  625    6   60   89   41  112]\n",
            " [  39   25   19  228   58  263   47   67   68   78]\n",
            " [  31   12   11    0    7    6  835    2   54    0]\n",
            " [  12   60   44    0    5    3    4  741   18  141]\n",
            " [   4   85   23   71   16   22   29   14  659   51]\n",
            " [  11   18   16   18   70   13   10  289   19  545]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['2' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59875, 10) \n",
            " [2 0 4 ... 9 6 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 7  5 17 17 25 26 14 11 11 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.297 s \n",
            "\n",
            "Accuracy rate for 70.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.92      0.82       980\n",
            "           1       0.76      0.96      0.84      1135\n",
            "           2       0.71      0.75      0.73      1032\n",
            "           3       0.69      0.75      0.72      1010\n",
            "           4       0.74      0.65      0.70       982\n",
            "           5       0.77      0.35      0.49       892\n",
            "           6       0.77      0.80      0.79       958\n",
            "           7       0.57      0.60      0.59      1028\n",
            "           8       0.67      0.62      0.64       974\n",
            "           9       0.59      0.53      0.56      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.69      0.69     10000\n",
            "weighted avg       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    1   14    0    2    4   11   11   39    0]\n",
            " [   0 1087    5   18    0    1    3    1   20    0]\n",
            " [  51   27  775    6   34    1   64   20   50    4]\n",
            " [  38   18   96  762    5   19    6   17   29   20]\n",
            " [  24   61    2    5  643    3   74   91   25   54]\n",
            " [  80   33   12  213   46  316   31   70   36   55]\n",
            " [  71   13   20    1   20    8  767    7   51    0]\n",
            " [  18   81   63    5   19    7    1  621   10  203]\n",
            " [   8   67   84   72   20   38   29   16  600   40]\n",
            " [  14   51   27   24   77   11    7  232   33  533]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [ 8  5 19 22 28 32 15 12 12 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.285 s \n",
            "\n",
            "Accuracy rate for 73.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.93      0.80       980\n",
            "           1       0.74      0.98      0.84      1135\n",
            "           2       0.76      0.76      0.76      1032\n",
            "           3       0.73      0.78      0.75      1010\n",
            "           4       0.80      0.70      0.75       982\n",
            "           5       0.74      0.45      0.56       892\n",
            "           6       0.74      0.85      0.79       958\n",
            "           7       0.74      0.71      0.73      1028\n",
            "           8       0.72      0.61      0.66       974\n",
            "           9       0.74      0.58      0.65      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    1    6    0    1   10   17    1   36    0]\n",
            " [   0 1109    2   10    0    1    5    1    6    1]\n",
            " [  74   26  786    3   17    1   72   10   36    7]\n",
            " [  23   13   83  783    6   33   16   17   24   12]\n",
            " [  48   66    2    0  683    5   62   35   29   52]\n",
            " [  97   43   10  184   25  403   55   25   30   20]\n",
            " [  62   10    9    2   14   14  816    0   31    0]\n",
            " [  26   82   70   10   14   11    4  735    8   68]\n",
            " [  19   83   47   54   18   57   53   10  591   42]\n",
            " [  37   62   20   23   73   12    8  159   32  583]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 8  5 20 23 31 40 15 18 12 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.332 s \n",
            "\n",
            "Accuracy rate for 74.130000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.93      0.79       980\n",
            "           1       0.73      0.97      0.83      1135\n",
            "           2       0.78      0.73      0.75      1032\n",
            "           3       0.72      0.80      0.75      1010\n",
            "           4       0.69      0.79      0.73       982\n",
            "           5       0.73      0.44      0.55       892\n",
            "           6       0.76      0.85      0.80       958\n",
            "           7       0.85      0.69      0.76      1028\n",
            "           8       0.74      0.65      0.69       974\n",
            "           9       0.81      0.51      0.63      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    1    8    1    1    6   18    1   30    0]\n",
            " [   0 1104    2   15    0    0    8    1    4    1]\n",
            " [  81   45  754   10   30    0   62   13   33    4]\n",
            " [  33   11   67  803    2   30   13    9   34    8]\n",
            " [  33   71    3    2  773   15   44    1   16   24]\n",
            " [ 104   40   17  191   30  393   45   17   49    6]\n",
            " [  62    8   16    3   14   15  811    0   29    0]\n",
            " [  45   86   54    6   64    8    9  710    7   39]\n",
            " [  20   76   36   60   19   42   45    2  635   39]\n",
            " [  36   74   15   29  193   32    8   84   22  516]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [ 8  5 21 26 33 44 15 24 13 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.304 s \n",
            "\n",
            "Accuracy rate for 73.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.94      0.79       980\n",
            "           1       0.72      0.97      0.83      1135\n",
            "           2       0.75      0.75      0.75      1032\n",
            "           3       0.69      0.76      0.72      1010\n",
            "           4       0.73      0.77      0.75       982\n",
            "           5       0.72      0.40      0.52       892\n",
            "           6       0.79      0.83      0.81       958\n",
            "           7       0.87      0.72      0.79      1028\n",
            "           8       0.68      0.60      0.64       974\n",
            "           9       0.79      0.58      0.67      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    7    0    2    4   23    2   19    0]\n",
            " [   0 1104    9   13    0    3    3    1    1    1]\n",
            " [  79   37  769    8   35    1   55   11   33    4]\n",
            " [  28   22   73  764    8   45   10    9   42    9]\n",
            " [  32   66    3    4  759    6   40    0   30   42]\n",
            " [ 115   43   17  197   51  359   40   19   42    9]\n",
            " [  68   13   16    4   30   14  792    0   21    0]\n",
            " [  47   86   55   10   33    4    3  737   13   40]\n",
            " [  22   89   65   72   17   41   35    2  582   49]\n",
            " [  33   74   12   42  103   19    6   66   70  584]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['3' '0' '4' ... '5' '0' '8']\n",
            "probabilities: (59775, 10) \n",
            " [3 0 4 ... 5 0 8]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 8  5 23 27 39 47 19 26 17 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.375 s \n",
            "\n",
            "Accuracy rate for 72.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.92      0.79       980\n",
            "           1       0.71      0.96      0.82      1135\n",
            "           2       0.72      0.67      0.69      1032\n",
            "           3       0.68      0.79      0.73      1010\n",
            "           4       0.75      0.77      0.76       982\n",
            "           5       0.78      0.42      0.55       892\n",
            "           6       0.64      0.89      0.74       958\n",
            "           7       0.83      0.76      0.79      1028\n",
            "           8       0.86      0.44      0.58       974\n",
            "           9       0.80      0.59      0.68      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.72      0.71     10000\n",
            "weighted avg       0.75      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 901    1   11    1    2    9   49    2    4    0]\n",
            " [   0 1095    4   28    0    0    6    1    1    0]\n",
            " [  87   59  691   16   37    1  110   18    9    4]\n",
            " [  20   24   65  797    5   27   26   13   20   13]\n",
            " [  35   65    5    5  755    8   54    4    6   45]\n",
            " [ 113   36   12  178   42  376   86   33   13    3]\n",
            " [  52   12    7    2   19    8  854    0    4    0]\n",
            " [  29   73   59   11   28    7    5  782    1   33]\n",
            " [  24  104   89   92   21   23  137    1  432   51]\n",
            " [  34   75   17   45  102   22   12   90   14  598]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [ 9  7 25 29 40 51 22 29 20 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.329 s \n",
            "\n",
            "Accuracy rate for 74.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.84       980\n",
            "           1       0.70      0.96      0.81      1135\n",
            "           2       0.74      0.73      0.74      1032\n",
            "           3       0.70      0.73      0.71      1010\n",
            "           4       0.79      0.76      0.77       982\n",
            "           5       0.76      0.32      0.45       892\n",
            "           6       0.70      0.90      0.79       958\n",
            "           7       0.84      0.78      0.81      1028\n",
            "           8       0.69      0.64      0.66       974\n",
            "           9       0.82      0.61      0.70      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 912    1   21    2    1    4   25    4   10    0]\n",
            " [   0 1094   21    5    0    0    7    1    6    1]\n",
            " [  49   66  755   13   24    1   89   14   16    5]\n",
            " [  35   32   79  733    3   43   22   10   49    4]\n",
            " [  21   41    7    7  747    4   57    9   13   76]\n",
            " [  85   66    3  169   37  289   81   23  137    2]\n",
            " [  33   10   11    2   17    9  864    2   10    0]\n",
            " [  22   80   59   11   22    4    5  797    4   24]\n",
            " [  14  116   45   57   10   11   73    2  619   27]\n",
            " [  20   68   21   52   89   14   10   84   38  613]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59725, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [10  8 29 33 43 54 23 34 21 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.398 s \n",
            "\n",
            "Accuracy rate for 72.960000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.97      0.79       980\n",
            "           1       0.69      0.94      0.80      1135\n",
            "           2       0.75      0.66      0.70      1032\n",
            "           3       0.71      0.77      0.74      1010\n",
            "           4       0.83      0.71      0.77       982\n",
            "           5       0.82      0.28      0.42       892\n",
            "           6       0.72      0.88      0.79       958\n",
            "           7       0.78      0.76      0.77      1028\n",
            "           8       0.68      0.67      0.67       974\n",
            "           9       0.80      0.58      0.67      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    1   10    0    0    1   13    1    8    0]\n",
            " [   0 1068   45    4    0    0    6    1   11    0]\n",
            " [  98   65  685   14   20    0   88   28   27    7]\n",
            " [  57   18   36  781    2   22   15   17   51   11]\n",
            " [  27   49   12    9  701    7   54   33    9   81]\n",
            " [ 149   74   13  163   24  254   63   21  127    4]\n",
            " [  59   10   11    7    8    5  844    5    9    0]\n",
            " [  43   90   53    9   15    1    7  780    8   22]\n",
            " [  20   95   32   59   13   11   71    1  650   22]\n",
            " [  31   76   16   50   66   10   11  107   55  587]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [11 10 31 33 46 59 24 35 25 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.353 s \n",
            "\n",
            "Accuracy rate for 74.480000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.97      0.81       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.79      0.60      0.68      1032\n",
            "           3       0.68      0.78      0.73      1010\n",
            "           4       0.81      0.74      0.78       982\n",
            "           5       0.81      0.38      0.52       892\n",
            "           6       0.71      0.91      0.80       958\n",
            "           7       0.83      0.76      0.79      1028\n",
            "           8       0.74      0.66      0.69       974\n",
            "           9       0.80      0.62      0.70      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    3    1    0    2   13    1    7    0]\n",
            " [   0 1107    8    6    0    0    8    1    5    0]\n",
            " [  88  117  616   25   31    1  102   27   17    8]\n",
            " [  53   21   26  792    0   31   17   16   45    9]\n",
            " [  24   34    4   12  731    9   58   16   11   83]\n",
            " [ 138   35    4  172   33  338   75   14   80    3]\n",
            " [  33   15    2    3    9   11  870    5   10    0]\n",
            " [  54   56   58   10   16    1    8  777   14   34]\n",
            " [  16   92   43   72   13   14   64    0  638   22]\n",
            " [  25   53   19   75   66   11   14   84   35  627]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59675, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [11 10 34 35 47 65 26 37 27 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.362 s \n",
            "\n",
            "Accuracy rate for 75.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81       980\n",
            "           1       0.70      0.98      0.81      1135\n",
            "           2       0.77      0.62      0.69      1032\n",
            "           3       0.72      0.78      0.75      1010\n",
            "           4       0.80      0.75      0.77       982\n",
            "           5       0.82      0.43      0.57       892\n",
            "           6       0.75      0.90      0.82       958\n",
            "           7       0.82      0.74      0.78      1028\n",
            "           8       0.76      0.63      0.69       974\n",
            "           9       0.77      0.65      0.71      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    2    8    0    2    2   13    3    8    0]\n",
            " [   0 1109    8    4    0    0    8    1    5    0]\n",
            " [  93  113  643   19   35    1   80   28   10   10]\n",
            " [  51   33   25  789    2   26   13   13   47   11]\n",
            " [  21   46    7    4  739    9   40   21   12   83]\n",
            " [ 124   34   11  148   32  386   77   23   50    7]\n",
            " [  28   13    8    1   16   13  863    5   11    0]\n",
            " [  36   63   66    8   16    0    5  759   16   59]\n",
            " [  15  108   43   90   13   15   48    1  616   25]\n",
            " [  28   71   20   32   71   16    9   72   34  656]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [14 11 38 37 49 70 26 38 29 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.385 s \n",
            "\n",
            "Accuracy rate for 74.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.83       980\n",
            "           1       0.70      0.97      0.81      1135\n",
            "           2       0.82      0.61      0.70      1032\n",
            "           3       0.67      0.78      0.72      1010\n",
            "           4       0.81      0.75      0.78       982\n",
            "           5       0.84      0.40      0.55       892\n",
            "           6       0.74      0.90      0.81       958\n",
            "           7       0.79      0.74      0.76      1028\n",
            "           8       0.70      0.67      0.68       974\n",
            "           9       0.78      0.61      0.69      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2    3    1    0    1    9    7    5    0]\n",
            " [   0 1098   10    3    0    0    7    1   16    0]\n",
            " [  88  120  625   18   30    1   86   25   29   10]\n",
            " [  48   33   25  783    1   27   18   11   53   11]\n",
            " [  12   30    6   13  736    6   50   35   28   66]\n",
            " [ 113   47    5  184   32  361   66   23   55    6]\n",
            " [  33   16    4    3   12   12  861    8    9    0]\n",
            " [  29   68   58   11   14    0    5  761   28   54]\n",
            " [  16  105   20   86   15   13   45    2  648   24]\n",
            " [  19   49   10   72   64   10   14   95   59  617]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['5' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [5 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [14 11 42 40 53 72 26 42 31 69] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.347 s \n",
            "\n",
            "Accuracy rate for 74.170000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.99      0.77       980\n",
            "           1       0.70      0.96      0.81      1135\n",
            "           2       0.74      0.62      0.68      1032\n",
            "           3       0.69      0.75      0.72      1010\n",
            "           4       0.81      0.74      0.78       982\n",
            "           5       0.88      0.40      0.55       892\n",
            "           6       0.76      0.88      0.82       958\n",
            "           7       0.83      0.77      0.80      1028\n",
            "           8       0.81      0.57      0.66       974\n",
            "           9       0.77      0.68      0.72      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    1    1    0    1    5    1    1    0]\n",
            " [   0 1093   29    2    0    0    8    1    2    0]\n",
            " [ 151  102  639   15   25    0   61   22    9    8]\n",
            " [  87   36   33  757    2   22   17   10   34   12]\n",
            " [  26   28    9    9  726    4   38   24    9  109]\n",
            " [ 165   43    9  147   34  357   64   20   43   10]\n",
            " [  50   15    9    2   16   11  844    5    6    0]\n",
            " [  33   75   61    6    9    0    6  795   12   31]\n",
            " [  30  129   52   98   17   10   55    1  551   31]\n",
            " [  34   48   16   58   62    3    9   75   17  687]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [14 12 44 41 55 75 29 43 39 73] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.394 s \n",
            "\n",
            "Accuracy rate for 73.780000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.98      0.81       980\n",
            "           1       0.70      0.97      0.81      1135\n",
            "           2       0.76      0.61      0.68      1032\n",
            "           3       0.67      0.79      0.72      1010\n",
            "           4       0.82      0.73      0.77       982\n",
            "           5       0.83      0.35      0.49       892\n",
            "           6       0.68      0.91      0.78       958\n",
            "           7       0.83      0.77      0.80      1028\n",
            "           8       0.74      0.58      0.65       974\n",
            "           9       0.83      0.62      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    1    2    1    0    0   13    1    3    0]\n",
            " [   0 1106   15    3    0    0    8    1    2    0]\n",
            " [ 120  117  628   19   17    0   93   21    7   10]\n",
            " [  60   30   23  798    1   26   19    8   36    9]\n",
            " [  17   30    9   12  717    5   95   28    7   62]\n",
            " [ 120   38    9  182   34  313   78   19   97    2]\n",
            " [  35   12    8    2    5    7  874    8    7    0]\n",
            " [  20   80   70   11   10    0    8  795    8   26]\n",
            " [  20  123   48   99   10   14   77    0  562   21]\n",
            " [  25   54   15   70   79   10   19   82   29  626]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59575, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [14 12 46 42 60 81 29 48 43 75] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.436 s \n",
            "\n",
            "Accuracy rate for 74.320000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82       980\n",
            "           1       0.66      0.98      0.79      1135\n",
            "           2       0.76      0.62      0.68      1032\n",
            "           3       0.71      0.75      0.73      1010\n",
            "           4       0.84      0.74      0.79       982\n",
            "           5       0.83      0.48      0.61       892\n",
            "           6       0.68      0.92      0.78       958\n",
            "           7       0.81      0.79      0.80      1028\n",
            "           8       0.81      0.47      0.60       974\n",
            "           9       0.81      0.66      0.73      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    2    1    1    0    2   11    5    2    0]\n",
            " [   1 1111   13    1    0    0    8    1    0    0]\n",
            " [  98  130  640   12   17    1   96   20    6   12]\n",
            " [  67   46   35  758    1   36   19   12   26   10]\n",
            " [  12   28    6    6  730    4   90   33    3   70]\n",
            " [ 126   40   18  126   37  425   60   14   44    2]\n",
            " [  30   17    4    2    7    4  881   10    3    0]\n",
            " [  21   86   56    6    7    0    9  807    7   29]\n",
            " [  19  177   63   97   13   19   92    1  462   31]\n",
            " [  16   48    7   62   62   19   24   94   15  662]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['5' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59550, 10) \n",
            " [5 0 4 ... 5 6 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [14 12 51 44 66 85 30 48 47 78] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.426 s \n",
            "\n",
            "Accuracy rate for 73.060000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.98      0.77       980\n",
            "           1       0.68      0.98      0.80      1135\n",
            "           2       0.75      0.61      0.68      1032\n",
            "           3       0.72      0.74      0.73      1010\n",
            "           4       0.85      0.69      0.76       982\n",
            "           5       0.86      0.43      0.57       892\n",
            "           6       0.68      0.90      0.77       958\n",
            "           7       0.79      0.80      0.79      1028\n",
            "           8       0.78      0.48      0.60       974\n",
            "           9       0.80      0.64      0.71      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.72      0.72     10000\n",
            "weighted avg       0.75      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 958    2    2    0    1    2    7    7    1    0]\n",
            " [   0 1110   15    1    0    0    5    1    2    1]\n",
            " [ 163   88  633    8   15    1   86   23    4   11]\n",
            " [  92   37   39  745    2   18   17   12   36   12]\n",
            " [  21   27    6    8  677    3  100   46    4   90]\n",
            " [ 152   41    7  155   26  383   67   20   40    1]\n",
            " [  47   14   11    0    5    1  863   13    4    0]\n",
            " [  24   87   46    4    6    0    7  822    9   23]\n",
            " [  29  170   77   80   11   15   94    1  469   28]\n",
            " [  32   57    7   39   49   22   26  102   29  646]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59525, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [14 12 53 45 68 91 31 50 51 85] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.412 s \n",
            "\n",
            "Accuracy rate for 73.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.98      0.80       980\n",
            "           1       0.67      0.98      0.79      1135\n",
            "           2       0.78      0.60      0.68      1032\n",
            "           3       0.71      0.76      0.73      1010\n",
            "           4       0.83      0.72      0.77       982\n",
            "           5       0.86      0.42      0.57       892\n",
            "           6       0.68      0.90      0.77       958\n",
            "           7       0.78      0.80      0.79      1028\n",
            "           8       0.73      0.53      0.61       974\n",
            "           9       0.83      0.59      0.69      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.75      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    2    1    0    0    1   10    7    3    0]\n",
            " [   0 1111   10    3    0    0    8    0    2    1]\n",
            " [ 141  109  620    9   19    1   96   23    7    7]\n",
            " [  67   35   41  765    2   21   19   11   44    5]\n",
            " [  23   26    6    8  707    4   92   36    5   75]\n",
            " [ 117   44    8  157   30  375   64   18   77    2]\n",
            " [  42   17    6    0    8    7  861   12    5    0]\n",
            " [  25   91   42    6    9    0    7  823   10   15]\n",
            " [  23  170   53   74   11   13   93    1  514   22]\n",
            " [  30   61    6   59   70   12   16  119   37  599]]\n",
            "--------------------------------\n",
            "final active learning accuracies [45.94, 60.81999999999999, 69.42, 71.08, 69.89, 70.02000000000001, 73.97, 74.13, 73.72, 72.81, 74.22999999999999, 72.96000000000001, 74.48, 75.02, 74.42, 74.17, 73.78, 74.32, 73.06, 73.31]\n",
            "saved Active-learning-experiment-39.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 40, using model = LogModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 1 0 1 0 1 2 2 0 1] [0 1 3 5 6 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.272 s \n",
            "\n",
            "Accuracy rate for 36.000000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.51      0.51       980\n",
            "           1       0.77      0.53      0.63      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.20      0.76      0.32      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.46      0.19      0.27       892\n",
            "           6       0.36      0.84      0.50       958\n",
            "           7       0.45      0.51      0.48      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.37      0.22      0.28      1009\n",
            "\n",
            "    accuracy                           0.36     10000\n",
            "   macro avg       0.31      0.36      0.30     10000\n",
            "weighted avg       0.32      0.36      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[504   0   0 414   0   6  31  23   0   2]\n",
            " [  1 604   0 223   0   1 270  28   0   8]\n",
            " [174  32   0 159   0   4 609  47   0   7]\n",
            " [ 93  34   0 772   0  43  43  19   0   6]\n",
            " [ 29   3   0 417   0   5 201 154   0 173]\n",
            " [ 52  22   0 473   0 168  91  83   0   3]\n",
            " [102  12   0  34   0   6 804   0   0   0]\n",
            " [ 12  27   0 281   0   1  35 527   0 145]\n",
            " [ 24  49   0 621   0 103  86  59   0  32]\n",
            " [ 15   6   0 460   0  29  58 220   0 221]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['5' '0' '6' ... '3' '0' '7']\n",
            "probabilities: (59990, 7) \n",
            " [3 0 4 ... 2 0 5]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [4 3 0 2 2 1 2 2 1 3] [0 1 3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.277 s \n",
            "\n",
            "Accuracy rate for 41.600000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.57      0.56       980\n",
            "           1       0.71      0.81      0.75      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.21      0.78      0.34      1010\n",
            "           4       0.34      0.17      0.23       982\n",
            "           5       0.70      0.16      0.26       892\n",
            "           6       0.46      0.77      0.58       958\n",
            "           7       0.69      0.43      0.53      1028\n",
            "           8       0.34      0.06      0.10       974\n",
            "           9       0.39      0.35      0.37      1009\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.44      0.41      0.37     10000\n",
            "weighted avg       0.44      0.42      0.38     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[562   0   0 334  38   0  34   1  11   0]\n",
            " [  0 914   0 211   1   1   8   0   0   0]\n",
            " [155 126   0  94  10   2 506  32  71  36]\n",
            " [ 77  24   0 786   0  19  76  11   9   8]\n",
            " [ 15  21   0 416 166   1  93  30   6 234]\n",
            " [ 71  15   0 449 153 145  30  22   4   3]\n",
            " [131  32   0  40   6   4 733   0   9   3]\n",
            " [  1  45   0 288  24   0  35 443   1 191]\n",
            " [ 22 103   0 570  79  26  26  11  57  80]\n",
            " [ 11   7   0 485  15  10  38  88   1 354]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['5' '0' '4' ... '3' '0' '4']\n",
            "probabilities: (59980, 9) \n",
            " [4 0 3 ... 2 0 3]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [4 3 0 3 2 3 3 5 4 3] [0 1 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.227 s \n",
            "\n",
            "Accuracy rate for 51.230000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.73      0.74       980\n",
            "           1       0.79      0.91      0.85      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.76      0.39      0.52      1010\n",
            "           4       0.35      0.16      0.22       982\n",
            "           5       0.68      0.29      0.40       892\n",
            "           6       0.51      0.87      0.64       958\n",
            "           7       0.67      0.63      0.65      1028\n",
            "           8       0.25      0.78      0.37       974\n",
            "           9       0.46      0.32      0.38      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.52      0.51      0.48     10000\n",
            "weighted avg       0.52      0.51      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 716    2    0   27   13    1   29    4  187    1]\n",
            " [   0 1032    0    0    1    0    7    1   93    1]\n",
            " [  79  115    0    8   26    6  526   80  184    8]\n",
            " [  13   16    0  395    0   74   63   15  432    2]\n",
            " [  10   18    0    1  162    2   85   52  410  242]\n",
            " [  21    7    0   64  127  256   48    8  350   11]\n",
            " [  76    8    0    3    7    6  834    5   17    2]\n",
            " [   6   51    0    4   31    1    6  649  188   92]\n",
            " [  15   46    0    8   71   13   30   15  758   18]\n",
            " [  12    8    0    7   24   20   15  136  466  321]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['5' '0' '8' ... '8' '0' '4']\n",
            "probabilities: (59970, 9) \n",
            " [4 0 7 ... 7 0 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [4 3 1 5 4 7 3 6 4 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.236 s \n",
            "\n",
            "Accuracy rate for 55.860000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.75      0.77       980\n",
            "           1       0.82      0.92      0.86      1135\n",
            "           2       0.61      0.23      0.33      1032\n",
            "           3       0.68      0.49      0.57      1010\n",
            "           4       0.54      0.29      0.37       982\n",
            "           5       0.73      0.34      0.46       892\n",
            "           6       0.51      0.78      0.62       958\n",
            "           7       0.66      0.65      0.65      1028\n",
            "           8       0.28      0.73      0.40       974\n",
            "           9       0.53      0.36      0.43      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.61      0.55      0.55     10000\n",
            "weighted avg       0.62      0.56      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 739    2   18   19    1   10   31    3  156    1]\n",
            " [   0 1040    1    1    0    0    8    1   83    1]\n",
            " [  70   77  238    6   38    2  418   69  106    8]\n",
            " [   7   17   40  491    0   35   50   31  338    1]\n",
            " [  12   13   26    3  280    3   70   60  317  198]\n",
            " [  10   15   11  137   44  302   57   15  287   14]\n",
            " [  70   10   31   16   46   20  749    0   14    2]\n",
            " [  12   41    8    9   42    2    4  673  152   85]\n",
            " [  16   51    7   30   24   26   66   25  710   19]\n",
            " [  15    6    9   12   40   16   14  150  383  364]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['5' '0' '8' ... '5' '0' '9']\n",
            "probabilities: (59960, 10) \n",
            " [5 0 8 ... 5 0 9]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 4 2 7 4 8 4 7 5 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.232 s \n",
            "\n",
            "Accuracy rate for 63.160000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       980\n",
            "           1       0.77      0.97      0.86      1135\n",
            "           2       0.70      0.34      0.45      1032\n",
            "           3       0.71      0.52      0.60      1010\n",
            "           4       0.61      0.40      0.48       982\n",
            "           5       0.62      0.37      0.46       892\n",
            "           6       0.61      0.78      0.69       958\n",
            "           7       0.50      0.81      0.62      1028\n",
            "           8       0.57      0.60      0.58       974\n",
            "           9       0.49      0.55      0.52      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.64      0.63      0.61     10000\n",
            "weighted avg       0.64      0.63      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 893    1   13    7    2    3   19   22   17    3]\n",
            " [   0 1098    0    2    0    3    4    2   25    1]\n",
            " [  58   80  346   13   44    4  256  125   93   13]\n",
            " [   7   61   62  529    0  100   26   76  138   11]\n",
            " [  12    9    1    0  394    8   91  167    7  293]\n",
            " [  21   18   22  162   72  328   20   43  136   70]\n",
            " [  64    9   42    2   35   38  752    7    3    6]\n",
            " [  12   27    0    3   40    3    2  830   15   96]\n",
            " [  10  106   10   23   35   25   40   55  588   82]\n",
            " [  21   14    0    8   28   15   16  334   15  558]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['5' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59950, 10) \n",
            " [5 0 4 ... 5 0 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 4  4  4  7  4 10  6  8  7  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.264 s \n",
            "\n",
            "Accuracy rate for 66.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84       980\n",
            "           1       0.75      0.94      0.84      1135\n",
            "           2       0.66      0.60      0.63      1032\n",
            "           3       0.65      0.60      0.62      1010\n",
            "           4       0.74      0.33      0.46       982\n",
            "           5       0.59      0.42      0.49       892\n",
            "           6       0.76      0.78      0.77       958\n",
            "           7       0.55      0.80      0.65      1028\n",
            "           8       0.67      0.61      0.64       974\n",
            "           9       0.50      0.59      0.54      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.67      0.65      0.65     10000\n",
            "weighted avg       0.67      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 879    2   16   10    0   11   37   16    3    6]\n",
            " [   0 1063   61    2    0    0    2    2    4    1]\n",
            " [  49  114  620   15    6    2   64   85   69    8]\n",
            " [   6   51   62  601    0   91   12   58  118   11]\n",
            " [  21   11   39    4  325   13   67  139   37  326]\n",
            " [  18   18   34  226   62  376   15   24   36   83]\n",
            " [  77   16   38    4    2   70  743    2    3    3]\n",
            " [  20   22   45    9   19    2    5  823    5   78]\n",
            " [  16   99   23   44   18   43   27   50  590   64]\n",
            " [  23   13    7   15   10   24    7  307   12  591]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['5' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59940, 10) \n",
            " [5 0 4 ... 5 0 9]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 4  4  4  8  5 13  8  8  9  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.302 s \n",
            "\n",
            "Accuracy rate for 70.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       980\n",
            "           1       0.75      0.97      0.84      1135\n",
            "           2       0.72      0.55      0.62      1032\n",
            "           3       0.67      0.64      0.65      1010\n",
            "           4       0.70      0.66      0.68       982\n",
            "           5       0.71      0.43      0.53       892\n",
            "           6       0.75      0.74      0.74       958\n",
            "           7       0.69      0.81      0.75      1028\n",
            "           8       0.68      0.59      0.63       974\n",
            "           9       0.58      0.72      0.64      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.71      0.70      0.69     10000\n",
            "weighted avg       0.71      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 870    2   16   14    2    9   29   11   18    9]\n",
            " [   0 1096   25    4    0    1    5    2    2    0]\n",
            " [  45  127  566   23   24    5   73   84   71   14]\n",
            " [   9   51   46  646    4   61   26   43  106   18]\n",
            " [  16   12    6    5  649    4   18   40    5  227]\n",
            " [  16   20   43  198   54  381   26   11   45   98]\n",
            " [  71   13   33    5   91   30  711    2    1    1]\n",
            " [  12   26   31    3   36    2    2  835    5   76]\n",
            " [  17  105   16   50   22   31   60   16  571   86]\n",
            " [  15   12    3   15   43   15    1  163   17  725]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59930, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 4  4  6  8  6 13  9  9 13  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.251 s \n",
            "\n",
            "Accuracy rate for 71.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.91      0.82       980\n",
            "           1       0.77      0.93      0.84      1135\n",
            "           2       0.71      0.62      0.67      1032\n",
            "           3       0.70      0.66      0.68      1010\n",
            "           4       0.67      0.75      0.70       982\n",
            "           5       0.70      0.43      0.53       892\n",
            "           6       0.77      0.63      0.69       958\n",
            "           7       0.78      0.80      0.79      1028\n",
            "           8       0.69      0.56      0.62       974\n",
            "           9       0.60      0.78      0.68      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 890    2    8    2    3   10   26    6   17   16]\n",
            " [   0 1061   62    4    0    1    4    1    2    0]\n",
            " [  64  102  645   11   29    5   35   76   53   12]\n",
            " [   9   38   31  671    3   59   19   32  110   38]\n",
            " [  21    9    2    3  733    7   22   11    3  171]\n",
            " [  16   19   40  184   68  380   21    6   49  109]\n",
            " [ 102   10   50    3  156   34  602    1    0    0]\n",
            " [  25   24   41    8   38    1    1  820    3   67]\n",
            " [  31  104   20   50   23   32   52    7  544  111]\n",
            " [  23    9    8   17   48   15    1   90   13  785]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 4  4  7  8  6 17  9  9 17  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.317 s \n",
            "\n",
            "Accuracy rate for 68.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.94      0.77       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.73      0.61      0.66      1032\n",
            "           3       0.69      0.57      0.62      1010\n",
            "           4       0.70      0.75      0.72       982\n",
            "           5       0.56      0.33      0.42       892\n",
            "           6       0.75      0.59      0.66       958\n",
            "           7       0.76      0.78      0.77      1028\n",
            "           8       0.60      0.54      0.57       974\n",
            "           9       0.61      0.72      0.66      1009\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.68      0.68      0.67     10000\n",
            "weighted avg       0.68      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    2    4    0    0   11   22    2   19    1]\n",
            " [   0 1084   41    4    0    2    4    0    0    0]\n",
            " [  82  121  627   18   17    1   37   68   45   16]\n",
            " [  20   49   31  575    0  122   29   32  136   16]\n",
            " [  38    9    1    2  734    9   15   14    3  157]\n",
            " [  41   18   44  155   69  294   21    9  119  122]\n",
            " [ 196   12   39    1  116   21  570    1    1    1]\n",
            " [  41   35   41    2   36    1    2  797    4   69]\n",
            " [  41  112   23   61   16   43   62    4  528   84]\n",
            " [  39    8    6   15   56   17    1  123   18  726]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59910, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 4  4  7  8  6 20 12  9 18 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.286 s \n",
            "\n",
            "Accuracy rate for 70.060000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.92      0.83       980\n",
            "           1       0.77      0.91      0.83      1135\n",
            "           2       0.70      0.59      0.64      1032\n",
            "           3       0.63      0.63      0.63      1010\n",
            "           4       0.75      0.74      0.75       982\n",
            "           5       0.48      0.25      0.32       892\n",
            "           6       0.78      0.77      0.78       958\n",
            "           7       0.78      0.79      0.79      1028\n",
            "           8       0.67      0.56      0.61       974\n",
            "           9       0.57      0.77      0.66      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.69      0.69      0.68     10000\n",
            "weighted avg       0.69      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    2    4    6    1    7   28    2   17    8]\n",
            " [   0 1032   88    3    0    3    4    2    3    0]\n",
            " [  64   88  608   27   16    3   68   78   60   20]\n",
            " [  10   48   39  635    1  116   12   40   89   20]\n",
            " [  23    5    1    0  726   25   16   11    4  171]\n",
            " [  28   17   32  235   71  220   15   14   80  180]\n",
            " [  92   12   34    6   51   18  741    0    1    3]\n",
            " [  30   17   33    5   28   10    4  816    5   80]\n",
            " [  30  106   21   72   19   27   54    7  544   94]\n",
            " [  23   10    4   19   52   33    4   73   12  779]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '1' ... '5' '0' '5']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 1 ... 5 0 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 5  4 10  9  8 23 12  9 18 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.268 s \n",
            "\n",
            "Accuracy rate for 70.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       980\n",
            "           1       0.73      0.97      0.83      1135\n",
            "           2       0.79      0.57      0.66      1032\n",
            "           3       0.66      0.59      0.62      1010\n",
            "           4       0.71      0.78      0.74       982\n",
            "           5       0.49      0.42      0.45       892\n",
            "           6       0.77      0.80      0.78       958\n",
            "           7       0.83      0.72      0.77      1028\n",
            "           8       0.73      0.46      0.57       974\n",
            "           9       0.58      0.76      0.66      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.70      0.69     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    2    5    9    1   13   12    3    2    7]\n",
            " [   0 1100   23    5    0    2    5    0    0    0]\n",
            " [  50  135  590   24   34    4   83   52   30   30]\n",
            " [  13   64   20  594    6  156   15   31   90   21]\n",
            " [  15    9    2    1  763   33   29    5    2  123]\n",
            " [  23   21   17  168   89  371   22    7   33  141]\n",
            " [  84   15   31    6   26   24  765    0    1    6]\n",
            " [  27   32   35    5   42   10    6  743    2  126]\n",
            " [  21  124   22   75   14  107   53    6  452  100]\n",
            " [  18   10    3   13  105   34    3   49    9  765]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['3' '0' '4' ... '5' '0' '5']\n",
            "probabilities: (59890, 10) \n",
            " [3 0 4 ... 5 0 5]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 5  4 12 10  9 24 14  9 19 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.269 s \n",
            "\n",
            "Accuracy rate for 71.070000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       980\n",
            "           1       0.71      0.98      0.82      1135\n",
            "           2       0.81      0.58      0.67      1032\n",
            "           3       0.67      0.55      0.61      1010\n",
            "           4       0.71      0.75      0.73       982\n",
            "           5       0.52      0.39      0.44       892\n",
            "           6       0.84      0.85      0.84       958\n",
            "           7       0.79      0.73      0.76      1028\n",
            "           8       0.69      0.52      0.59       974\n",
            "           9       0.57      0.75      0.65      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.70      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    2   21    5    1   10    6    4    3    3]\n",
            " [   0 1109   16    4    0    2    4    0    0    0]\n",
            " [  53  152  599   18   32    3   59   73   16   27]\n",
            " [  14   70   23  558    2  174   13   32  104   20]\n",
            " [  17    9    2    4  741   12   22    8    3  164]\n",
            " [  30   25    7  173   79  344   20   14   78  122]\n",
            " [  53   20   17    3   33   10  815    1    2    4]\n",
            " [  38   35   16    5   43    7    3  750    4  127]\n",
            " [  15  127   38   49   25   79   28    9  508   96]\n",
            " [  25    9    4   13   94   24    2   63   17  758]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['3' '0' '4' ... '5' '6' '5']\n",
            "probabilities: (59880, 10) \n",
            " [3 0 4 ... 5 6 5]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 5  4 14 10  9 25 15 11 21 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.287 s \n",
            "\n",
            "Accuracy rate for 71.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.86       980\n",
            "           1       0.72      0.98      0.83      1135\n",
            "           2       0.84      0.56      0.67      1032\n",
            "           3       0.66      0.55      0.60      1010\n",
            "           4       0.71      0.78      0.74       982\n",
            "           5       0.57      0.40      0.47       892\n",
            "           6       0.84      0.85      0.85       958\n",
            "           7       0.77      0.81      0.79      1028\n",
            "           8       0.58      0.61      0.59       974\n",
            "           9       0.69      0.62      0.65      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.71      0.71      0.71     10000\n",
            "weighted avg       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    8    4    1    2    3    4   15    0]\n",
            " [   0 1111   15    3    0    2    4    0    0    0]\n",
            " [  47  162  583   28   35    3   54   75   38    7]\n",
            " [  25   48   12  559    1  123   14   31  191    6]\n",
            " [  15    8   13   10  769   23   21   16    9   98]\n",
            " [  47   25    2  162   65  355   24   16  143   53]\n",
            " [  70   13    7    2   20   24  817    3    1    1]\n",
            " [  24   44   19    6   39    8    2  830    7   49]\n",
            " [  18  106   30   48   21   55   28    3  595   70]\n",
            " [  28   15    7   24  139   25    4  106   35  626]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['3' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59870, 10) \n",
            " [3 0 4 ... 5 6 2]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 5  4 16 11 10 27 15 11 22 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.278 s \n",
            "\n",
            "Accuracy rate for 73.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.87       980\n",
            "           1       0.70      0.97      0.82      1135\n",
            "           2       0.81      0.60      0.69      1032\n",
            "           3       0.66      0.63      0.64      1010\n",
            "           4       0.72      0.75      0.73       982\n",
            "           5       0.62      0.45      0.52       892\n",
            "           6       0.81      0.86      0.84       958\n",
            "           7       0.79      0.77      0.78      1028\n",
            "           8       0.70      0.55      0.62       974\n",
            "           9       0.64      0.74      0.69      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.72      0.72     10000\n",
            "weighted avg       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    2   22   17    1    5    6    3    7    0]\n",
            " [   0 1104   19    4    0    2    4    2    0    0]\n",
            " [  36  168  616   25   19    3   56   71   22   16]\n",
            " [  13   63   18  633    0  114   21   33   96   19]\n",
            " [  16   10    7    3  732   18   24   15    4  153]\n",
            " [  34   29    3  196   64  399   29   22   77   39]\n",
            " [  49   17   14    2   28   20  826    1    1    0]\n",
            " [  17   35   22    2   34    5    2  793    5  113]\n",
            " [  13  129   34   62   31   55   41    2  535   72]\n",
            " [  22   10    5   22  101   20    5   60   18  746]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59860, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 5  4 17 15 12 30 15 11 22 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.289 s \n",
            "\n",
            "Accuracy rate for 74.120000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       980\n",
            "           1       0.69      0.99      0.81      1135\n",
            "           2       0.78      0.64      0.70      1032\n",
            "           3       0.71      0.70      0.70      1010\n",
            "           4       0.72      0.78      0.75       982\n",
            "           5       0.64      0.40      0.49       892\n",
            "           6       0.83      0.86      0.85       958\n",
            "           7       0.77      0.82      0.79      1028\n",
            "           8       0.78      0.54      0.64       974\n",
            "           9       0.66      0.71      0.69      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    2   51    9    2    5    7    7    7    1]\n",
            " [   0 1118    2    1    5    3    3    3    0    0]\n",
            " [  21  158  664   11   15    5   42   88   16   12]\n",
            " [  10   81   46  703    1   56   17   32   42   22]\n",
            " [  16    9    9    0  766   24   28   17    2  111]\n",
            " [  32   30    5  225   49  358   32   19   69   73]\n",
            " [  40   20   21    0   27   22  824    2    2    0]\n",
            " [  13   36   15    1   44    7    4  840    2   66]\n",
            " [  17  148   34   33   31   55   31    7  529   89]\n",
            " [  23   10    5   14  123   27    3   73   10  721]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 5  5 20 17 13 32 15 11 23 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.323 s \n",
            "\n",
            "Accuracy rate for 73.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       980\n",
            "           1       0.65      0.98      0.78      1135\n",
            "           2       0.75      0.71      0.73      1032\n",
            "           3       0.69      0.65      0.67      1010\n",
            "           4       0.72      0.78      0.75       982\n",
            "           5       0.70      0.40      0.51       892\n",
            "           6       0.82      0.85      0.83       958\n",
            "           7       0.75      0.84      0.79      1028\n",
            "           8       0.70      0.56      0.62       974\n",
            "           9       0.76      0.62      0.69      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.73     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 886    2   59    2    1    4    9    5   12    0]\n",
            " [   0 1111   16    0    0    2    2    4    0    0]\n",
            " [  19  126  735    1   18    4   41   64   10   14]\n",
            " [  11  101   69  659    0   47   14   32   65   12]\n",
            " [  16   23    7    4  769   25   36   24    4   74]\n",
            " [  28   37    5  223   59  356   32   25  109   18]\n",
            " [  37   23   31    2   24   17  817    1    6    0]\n",
            " [   9   42   24    9   36    5    2  859    3   39]\n",
            " [  11  214   30   29   35   23   40    7  547   38]\n",
            " [  15   24    7   29  124   28    8  119   27  628]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59840, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 5  5 20 19 14 35 16 13 23 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.292 s \n",
            "\n",
            "Accuracy rate for 73.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.96      0.86       980\n",
            "           1       0.66      0.98      0.79      1135\n",
            "           2       0.79      0.69      0.74      1032\n",
            "           3       0.66      0.64      0.65      1010\n",
            "           4       0.76      0.80      0.78       982\n",
            "           5       0.69      0.41      0.51       892\n",
            "           6       0.80      0.86      0.83       958\n",
            "           7       0.79      0.84      0.81      1028\n",
            "           8       0.72      0.52      0.60       974\n",
            "           9       0.74      0.62      0.67      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.74      0.73      0.72     10000\n",
            "weighted avg       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    2   22    1    1    2    4    4    7    0]\n",
            " [   0 1116    9    3    0    2    3    2    0    0]\n",
            " [  48  114  709    0   17    2   53   60   15   14]\n",
            " [  20   92   83  644    1   63   19   26   49   13]\n",
            " [  22   21    0    8  787   22   35    6    4   77]\n",
            " [  56   46    4  199   39  363   31   32   96   26]\n",
            " [  53   18   22    0   20   16  826    1    2    0]\n",
            " [  13   35   21    8   32    7    1  864    3   44]\n",
            " [  23  227   23   39   24   29   50    6  503   50]\n",
            " [  24   22    4   77  113   21    6   93   22  627]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['9' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59830, 10) \n",
            " [9 0 4 ... 5 6 9]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 5  5 20 22 15 38 16 13 24 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.382 s \n",
            "\n",
            "Accuracy rate for 74.450000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.95      0.86       980\n",
            "           1       0.65      0.99      0.79      1135\n",
            "           2       0.78      0.67      0.72      1032\n",
            "           3       0.71      0.69      0.70      1010\n",
            "           4       0.80      0.75      0.77       982\n",
            "           5       0.70      0.44      0.54       892\n",
            "           6       0.88      0.80      0.84       958\n",
            "           7       0.83      0.78      0.80      1028\n",
            "           8       0.76      0.52      0.62       974\n",
            "           9       0.64      0.79      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    2   26    1    0    2    1    4    9    1]\n",
            " [   0 1120    7    1    0    2    3    2    0    0]\n",
            " [  45  149  690    1   21    4   26   59   16   21]\n",
            " [  17   81   70  701    0   60   10   17   32   22]\n",
            " [  15   15    2    4  733   22   17    8   10  156]\n",
            " [  48   42    8  191   45  396   15   18   70   59]\n",
            " [  68   27   26    1   37   29  763    0    6    1]\n",
            " [  30   41   25    6   20    3    2  799    3   99]\n",
            " [  22  214   22   54   15   30   23    3  510   81]\n",
            " [  24   23    5   29   41   21    4   52   11  799]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['3' '0' '6' ... '5' '6' '9']\n",
            "probabilities: (59820, 10) \n",
            " [3 0 6 ... 5 6 9]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 5  5 21 23 16 40 16 15 26 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.333 s \n",
            "\n",
            "Accuracy rate for 75.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.98      0.86       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.86      0.63      0.73      1032\n",
            "           3       0.69      0.75      0.71      1010\n",
            "           4       0.83      0.77      0.80       982\n",
            "           5       0.76      0.40      0.52       892\n",
            "           6       0.80      0.84      0.82       958\n",
            "           7       0.82      0.81      0.81      1028\n",
            "           8       0.81      0.48      0.60       974\n",
            "           9       0.71      0.78      0.74      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.77      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    2    3    1    0    1    3    1    6    0]\n",
            " [   0 1120    7    1    0    1    3    3    0    0]\n",
            " [  52  158  652    7   18    2   49   66   17   11]\n",
            " [  22   89   36  755    0   40   16   20   18   14]\n",
            " [  14   25    3    4  754   11   32    6    2  131]\n",
            " [  53   44    3  236   43  358   28   16   57   54]\n",
            " [  76   25   11    0   20   17  805    0    4    0]\n",
            " [  32   43   25    3   23    6    2  837    2   55]\n",
            " [  19  240   18   62   20   17   57    7  470   64]\n",
            " [  23   29    4   33   29   19    8   70    7  787]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['3' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59810, 10) \n",
            " [3 0 1 ... 5 6 9]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 5  5 22 24 16 40 19 15 30 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.360 s \n",
            "\n",
            "Accuracy rate for 73.980000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.99      0.81       980\n",
            "           1       0.67      0.97      0.79      1135\n",
            "           2       0.76      0.66      0.70      1032\n",
            "           3       0.71      0.67      0.69      1010\n",
            "           4       0.81      0.77      0.79       982\n",
            "           5       0.71      0.46      0.56       892\n",
            "           6       0.81      0.78      0.79       958\n",
            "           7       0.88      0.75      0.81      1028\n",
            "           8       0.81      0.50      0.62       974\n",
            "           9       0.68      0.80      0.73      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 966    2    3    1    0    0    2    0    6    0]\n",
            " [   0 1098   29    3    0    2    2    1    0    0]\n",
            " [  60  137  679    6   14    1   46   42   19   28]\n",
            " [  35   85   81  678    1   71   12   15   18   14]\n",
            " [  23   18    3    1  754   16   36    2   13  116]\n",
            " [  96   40   20  165   42  408   22   14   38   47]\n",
            " [ 111   22   20    0   31   17  748    1    8    0]\n",
            " [  44   38   27    4   30    6    1  772    3  103]\n",
            " [  24  190   30   59   19   32   50    3  489   78]\n",
            " [  32   21    5   34   39   25   10   31    6  806]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '5' '5' '9']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 5 5 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 5  5 22 24 16 42 19 15 34 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.330 s \n",
            "\n",
            "Accuracy rate for 74.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       980\n",
            "           1       0.68      0.98      0.80      1135\n",
            "           2       0.74      0.66      0.70      1032\n",
            "           3       0.70      0.69      0.69      1010\n",
            "           4       0.80      0.78      0.79       982\n",
            "           5       0.67      0.46      0.55       892\n",
            "           6       0.77      0.84      0.81       958\n",
            "           7       0.75      0.84      0.79      1028\n",
            "           8       0.80      0.51      0.62       974\n",
            "           9       0.71      0.73      0.72      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 876    2   47    6    1    5    5   26   12    0]\n",
            " [   0 1113   12    1    0    2    3    4    0    0]\n",
            " [  27  140  676    3   13    4   54   76   17   22]\n",
            " [   6   71   82  693    1   79   16   30   18   14]\n",
            " [  11   15    3    1  766   20   42   10    9  105]\n",
            " [  30   27   15  216   45  413   35   29   46   36]\n",
            " [  36   19   17    0   36   32  809    4    5    0]\n",
            " [  10   35   25    1   24    4    2  864    1   62]\n",
            " [  12  188   31   43   21   37   73    9  494   66]\n",
            " [  16   24    5   32   51   25    9   97   12  738]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['9' '0' '6' ... '5' '5' '9']\n",
            "probabilities: (59790, 10) \n",
            " [9 0 6 ... 5 5 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 6  5 23 24 17 46 19 17 35 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.298 s \n",
            "\n",
            "Accuracy rate for 74.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       980\n",
            "           1       0.62      0.97      0.76      1135\n",
            "           2       0.73      0.75      0.74      1032\n",
            "           3       0.68      0.66      0.67      1010\n",
            "           4       0.77      0.80      0.78       982\n",
            "           5       0.75      0.44      0.56       892\n",
            "           6       0.86      0.78      0.82       958\n",
            "           7       0.79      0.84      0.82      1028\n",
            "           8       0.80      0.51      0.62       974\n",
            "           9       0.74      0.70      0.72      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    2   19    3    0    0    5    5   12    0]\n",
            " [   0 1099   27    3    0    1    2    3    0    0]\n",
            " [  22  111  773    2   19    1   21   55   15   13]\n",
            " [  11  108  101  670    1   57    9   24   18   11]\n",
            " [  10   30    4    3  781   13   34   11    9   87]\n",
            " [  30   46   21  222   55  395   23   21   48   31]\n",
            " [  40   46   37    0   56   15  751    2   11    0]\n",
            " [  17   41   26    4   29    3    1  867    2   38]\n",
            " [   9  248   49   31   24   21   22    3  499   68]\n",
            " [  18   41    6   45   54   22    5  101   10  707]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['3' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59780, 10) \n",
            " [3 0 1 ... 5 6 9]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [ 6  7 23 25 17 47 20 17 39 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.317 s \n",
            "\n",
            "Accuracy rate for 74.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.77      0.64      0.70      1032\n",
            "           3       0.68      0.77      0.72      1010\n",
            "           4       0.80      0.76      0.78       982\n",
            "           5       0.75      0.45      0.56       892\n",
            "           6       0.77      0.86      0.81       958\n",
            "           7       0.81      0.81      0.81      1028\n",
            "           8       0.83      0.45      0.58       974\n",
            "           9       0.70      0.75      0.73      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 921    2   18    4    0    1   15    5   14    0]\n",
            " [   0 1128    1    3    0    1    2    0    0    0]\n",
            " [  16  221  660    5   13    3   38   54    3   19]\n",
            " [   8   32   83  774    3   41   14   27   13   15]\n",
            " [   7   22    2    4  751   13   57    7    5  114]\n",
            " [  23   29   11  238   36  397   44   14   41   59]\n",
            " [  32   27   17    0   32   20  828    0    2    0]\n",
            " [  19   62   17    5   33    5    0  835    0   52]\n",
            " [   8  231   43   70   21   27   69    6  435   64]\n",
            " [  14   17    9   42   53   18    7   80   10  759]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59770, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [ 6  7 23 25 17 49 20 22 40 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.320 s \n",
            "\n",
            "Accuracy rate for 76.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87       980\n",
            "           1       0.75      0.99      0.85      1135\n",
            "           2       0.72      0.73      0.73      1032\n",
            "           3       0.70      0.74      0.72      1010\n",
            "           4       0.74      0.80      0.77       982\n",
            "           5       0.76      0.44      0.56       892\n",
            "           6       0.80      0.78      0.79       958\n",
            "           7       0.86      0.78      0.81      1028\n",
            "           8       0.82      0.52      0.64       974\n",
            "           9       0.70      0.78      0.74      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.75      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2   15    1    0    0    4    1    5    0]\n",
            " [   0 1120    3    4    0    2    3    3    0    0]\n",
            " [  36  122  757    3   20    2   29   39    4   20]\n",
            " [  11   14  106  751    6   48   14   16   24   20]\n",
            " [  17    8    3    2  788   11   35    6    7  105]\n",
            " [  59   16   24  201   50  392   32   16   57   45]\n",
            " [  55   19   33    0   76   20  750    2    3    0]\n",
            " [  25   46   30    5   33    3    0  798    0   88]\n",
            " [  19  132   69   69   27   23   63    5  505   62]\n",
            " [  24   12    8   44   61   14    5   46    8  787]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['3' '0' '4' ... '5' '0' '9']\n",
            "probabilities: (59760, 10) \n",
            " [3 0 4 ... 5 0 9]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 6  8 24 25 18 51 21 23 43 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.345 s \n",
            "\n",
            "Accuracy rate for 74.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       980\n",
            "           1       0.69      0.99      0.81      1135\n",
            "           2       0.72      0.74      0.73      1032\n",
            "           3       0.68      0.73      0.70      1010\n",
            "           4       0.74      0.79      0.76       982\n",
            "           5       0.76      0.38      0.50       892\n",
            "           6       0.80      0.85      0.82       958\n",
            "           7       0.82      0.78      0.80      1028\n",
            "           8       0.83      0.47      0.60       974\n",
            "           9       0.68      0.73      0.70      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    2   25    3    2    0    9    4   11    0]\n",
            " [   0 1123    4    1    0    1    4    2    0    0]\n",
            " [  28  122  762    3   23    0   33   36    3   22]\n",
            " [   7   44  117  741    3   39   11   18   12   18]\n",
            " [  10   20    4    2  776    7   38   16    5  104]\n",
            " [  33   21   19  244   68  335   35   22   52   63]\n",
            " [  40   19   23    0   37   19  812    6    2    0]\n",
            " [  24   66   21    4   37    2    0  799    1   74]\n",
            " [  15  181   78   57   25   22   66    4  456   70]\n",
            " [  19   26   12   38   76   13    8   73    7  737]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [ 7  8 25 25 18 54 21 25 43 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.355 s \n",
            "\n",
            "Accuracy rate for 75.600000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.88       980\n",
            "           1       0.69      0.99      0.81      1135\n",
            "           2       0.75      0.70      0.73      1032\n",
            "           3       0.68      0.76      0.72      1010\n",
            "           4       0.73      0.79      0.76       982\n",
            "           5       0.74      0.42      0.54       892\n",
            "           6       0.82      0.82      0.82       958\n",
            "           7       0.84      0.80      0.82      1028\n",
            "           8       0.88      0.51      0.64       974\n",
            "           9       0.71      0.74      0.72      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    1   11    4    1    0    4    1    2    0]\n",
            " [   0 1119    6    4    1    2    3    0    0    0]\n",
            " [  35  155  720    4   24    0   24   48    1   21]\n",
            " [  10   38   77  768    4   54    9   13   16   21]\n",
            " [  13   15    6    5  780   14   37    7    5  100]\n",
            " [  50   23   15  226   66  375   31   17   39   50]\n",
            " [  50   16   26    1   57   18  788    1    1    0]\n",
            " [  26   72   21    3   38    0    0  819    0   49]\n",
            " [  16  161   64   64   27   32   55    6  493   56]\n",
            " [  25   22    8   50   66   14   10   66    6  742]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59740, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [ 7  8 25 26 19 60 21 25 43 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.374 s \n",
            "\n",
            "Accuracy rate for 75.840000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       980\n",
            "           1       0.69      0.99      0.81      1135\n",
            "           2       0.76      0.70      0.73      1032\n",
            "           3       0.66      0.81      0.73      1010\n",
            "           4       0.74      0.81      0.78       982\n",
            "           5       0.75      0.36      0.49       892\n",
            "           6       0.81      0.87      0.84       958\n",
            "           7       0.84      0.79      0.81      1028\n",
            "           8       0.88      0.50      0.63       974\n",
            "           9       0.71      0.71      0.71      1009\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.75      0.74     10000\n",
            "weighted avg       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    2   21    4    2    0    3    4    2    0]\n",
            " [   0 1119    6    3    1    1    3    1    1    0]\n",
            " [  20  149  725    7   26    2   38   46    2   17]\n",
            " [   9   33   70  815    3   30   10   15   12   13]\n",
            " [   5   20    3    8  800   16   39    9    4   78]\n",
            " [  38   24   11  264   78  325   31   17   41   63]\n",
            " [  33   16   22    0   31   15  838    1    1    1]\n",
            " [  20   75   23    7   29    3    0  816    0   55]\n",
            " [  16  163   68   64   26   24   60    7  483   63]\n",
            " [  21   25   11   54   84   18   11   59    5  721]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59730, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [ 7  8 26 29 20 60 21 27 46 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.363 s \n",
            "\n",
            "Accuracy rate for 74.340000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87       980\n",
            "           1       0.65      0.99      0.79      1135\n",
            "           2       0.77      0.65      0.70      1032\n",
            "           3       0.68      0.75      0.71      1010\n",
            "           4       0.74      0.80      0.77       982\n",
            "           5       0.76      0.40      0.52       892\n",
            "           6       0.80      0.83      0.82       958\n",
            "           7       0.79      0.80      0.79      1028\n",
            "           8       0.85      0.51      0.63       974\n",
            "           9       0.72      0.68      0.70      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    2    9    2    3    0    4    4    1    0]\n",
            " [   0 1125    2    2    0    1    4    1    0    0]\n",
            " [  33  198  668    6   26    1   27   59    1   13]\n",
            " [  13   76   65  753    3   36   13   22   17   12]\n",
            " [   9   18    6    7  781   19   35   11   11   85]\n",
            " [  62   28   12  218   65  357   38   18   48   46]\n",
            " [  57   19   13    0   52   10  798    6    1    2]\n",
            " [  32   66   24    3   31    4    0  818    1   49]\n",
            " [  20  174   63   53   20   23   70    4  492   55]\n",
            " [  26   25    8   62   71   19   10   91   10  687]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59720, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [ 7  8 27 32 20 62 21 29 48 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.320 s \n",
            "\n",
            "Accuracy rate for 75.130000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       980\n",
            "           1       0.65      0.99      0.78      1135\n",
            "           2       0.75      0.67      0.71      1032\n",
            "           3       0.72      0.75      0.73      1010\n",
            "           4       0.74      0.81      0.77       982\n",
            "           5       0.78      0.42      0.55       892\n",
            "           6       0.78      0.85      0.81       958\n",
            "           7       0.79      0.81      0.80      1028\n",
            "           8       0.82      0.48      0.61       974\n",
            "           9       0.74      0.75      0.74      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    2   13    3    2    1   12   13   20    0]\n",
            " [   0 1121    5    2    1    1    4    1    0    0]\n",
            " [  26  186  689    2   35    1   24   59    3    7]\n",
            " [  10   64   69  753    3   33   15   32   14   17]\n",
            " [   6   20    6    1  792   15   37    7    7   91]\n",
            " [  19   31    6  219   72  375   48   27   51   44]\n",
            " [  38   20   11    0   59   13  814    1    1    1]\n",
            " [  27   68   24    2   32    1    0  831    0   43]\n",
            " [  17  185   79   41   22   18   76    5  468   63]\n",
            " [  17   32   15   24   53   21   10   74    7  756]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59710, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 8  8 28 33 22 64 21 29 49 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.343 s \n",
            "\n",
            "Accuracy rate for 71.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.70       980\n",
            "           1       0.67      0.99      0.80      1135\n",
            "           2       0.80      0.62      0.70      1032\n",
            "           3       0.74      0.73      0.73      1010\n",
            "           4       0.73      0.78      0.76       982\n",
            "           5       0.84      0.29      0.43       892\n",
            "           6       0.81      0.75      0.77       958\n",
            "           7       0.82      0.78      0.80      1028\n",
            "           8       0.89      0.45      0.60       974\n",
            "           9       0.74      0.71      0.73      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.76      0.71      0.70     10000\n",
            "weighted avg       0.75      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 976    2    1    0    0    0    1    0    0    0]\n",
            " [   1 1123    3    1    0    1    3    3    0    0]\n",
            " [ 119  160  636    8   25    0   23   49    2   10]\n",
            " [  88   67   47  738    2   15    9   20    8   16]\n",
            " [  28   13    4    5  768    8   35   13    4  104]\n",
            " [ 232   28    9  175   86  257   31    5   30   39]\n",
            " [ 152   14   17    0   54    3  715    2    0    1]\n",
            " [  80   53   25    3   23    0    1  806    0   37]\n",
            " [  90  195   47   44   28   15   64    5  441   45]\n",
            " [  61   30    6   25   65    8    6   79   10  719]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '5' '6' '0']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 5 6 0]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [ 8  8 29 36 23 64 21 30 51 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.389 s \n",
            "\n",
            "Accuracy rate for 74.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88       980\n",
            "           1       0.65      0.99      0.78      1135\n",
            "           2       0.76      0.62      0.68      1032\n",
            "           3       0.68      0.76      0.72      1010\n",
            "           4       0.74      0.78      0.76       982\n",
            "           5       0.81      0.31      0.44       892\n",
            "           6       0.77      0.86      0.81       958\n",
            "           7       0.76      0.83      0.79      1028\n",
            "           8       0.85      0.52      0.64       974\n",
            "           9       0.75      0.69      0.72      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    2   11    1    2    0    4    4    2    0]\n",
            " [   0 1124    3    1    0    1    4    2    0    0]\n",
            " [  32  204  643    7   21    1   41   72    5    6]\n",
            " [  20   65   60  772    1   18   17   35   11   11]\n",
            " [  11   22   11    5  767    9   47   20    7   83]\n",
            " [  63   23   18  268   82  273   40   25   52   48]\n",
            " [  38   19   22    0   43   11  821    1    2    1]\n",
            " [  26   62   25    2   27    0    0  855    0   31]\n",
            " [  16  183   47   45   27   15   76    8  504   53]\n",
            " [  25   29    8   42   73    9   10  104   11  698]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59690, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [ 9  8 29 37 24 66 21 30 54 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.392 s \n",
            "\n",
            "Accuracy rate for 74.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.98      0.86       980\n",
            "           1       0.66      0.98      0.79      1135\n",
            "           2       0.77      0.63      0.69      1032\n",
            "           3       0.67      0.79      0.73      1010\n",
            "           4       0.77      0.75      0.76       982\n",
            "           5       0.79      0.33      0.47       892\n",
            "           6       0.75      0.87      0.81       958\n",
            "           7       0.76      0.85      0.80      1028\n",
            "           8       0.84      0.52      0.64       974\n",
            "           9       0.77      0.66      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    1    1    1    2    1    4    4    3    0]\n",
            " [   0 1114   13    1    0    1    4    2    0    0]\n",
            " [  48  197  648    7   17    1   45   57    6    6]\n",
            " [  32   50   46  793    1   23   17   26   11   11]\n",
            " [   7   27   20    4  734    8   63   19    7   93]\n",
            " [  83   24   12  269   59  296   40   28   62   19]\n",
            " [  53   18   18    1   20   12  834    2    0    0]\n",
            " [  21   65   24    2   18    0    2  871    0   25]\n",
            " [  17  164   47   57   18   20   92    6  510   43]\n",
            " [  23   26    9   41   82   13    9  126   10  670]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59680, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [ 9  8 31 39 24 68 21 31 57 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 73.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.98      0.90       980\n",
            "           1       0.64      0.99      0.78      1135\n",
            "           2       0.79      0.60      0.68      1032\n",
            "           3       0.66      0.78      0.72      1010\n",
            "           4       0.74      0.73      0.74       982\n",
            "           5       0.82      0.30      0.44       892\n",
            "           6       0.71      0.88      0.79       958\n",
            "           7       0.81      0.80      0.80      1028\n",
            "           8       0.78      0.52      0.63       974\n",
            "           9       0.73      0.72      0.72      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    2    1    2    3    1    5    4    3    0]\n",
            " [   0 1122    5    1    1    0    4    2    0    0]\n",
            " [  36  217  615   10   22    1   61   51    6   13]\n",
            " [  20   68   39  791    1   17   15   16   24   19]\n",
            " [   3   24    7    8  721    5   93   18    5   98]\n",
            " [  54   24   11  266   83  268   47   21   80   38]\n",
            " [  33   18   27    2   26    8  840    2    1    1]\n",
            " [  16   74   26    5   27    0    2  819    0   59]\n",
            " [  12  164   39   70   22   15  100    2  506   44]\n",
            " [  15   34   10   35   69   11   12   79   20  724]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['3' '0' '6' ... '5' '6' '9']\n",
            "probabilities: (59670, 10) \n",
            " [3 0 6 ... 5 6 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [ 9  9 33 40 25 68 21 32 58 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.377 s \n",
            "\n",
            "Accuracy rate for 74.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.98      0.88       980\n",
            "           1       0.62      0.98      0.76      1135\n",
            "           2       0.79      0.58      0.67      1032\n",
            "           3       0.69      0.79      0.74      1010\n",
            "           4       0.71      0.75      0.73       982\n",
            "           5       0.85      0.34      0.48       892\n",
            "           6       0.76      0.87      0.81       958\n",
            "           7       0.80      0.80      0.80      1028\n",
            "           8       0.89      0.52      0.66       974\n",
            "           9       0.74      0.72      0.73      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.73     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 964    2    1    2    2    0    4    3    1    1]\n",
            " [   0 1113   14    0    2    0    4    1    1    0]\n",
            " [  53  236  598   13   20    1   42   52    3   14]\n",
            " [  22   72   35  799    4   15   11   18   16   18]\n",
            " [   8   28    4    1  741    6   67   28    5   94]\n",
            " [  71   34    7  261   93  302   36   20   23   45]\n",
            " [  42   22   20    1   30    7  831    4    1    0]\n",
            " [  20   83   25    2   32    0    0  827    2   37]\n",
            " [  14  161   48   58   32   13   87    5  511   45]\n",
            " [  24   33    5   21   91   13    5   79    9  729]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['3' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59660, 10) \n",
            " [3 0 9 ... 5 6 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 9  9 33 41 26 69 21 32 63 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 73.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85       980\n",
            "           1       0.66      0.97      0.78      1135\n",
            "           2       0.78      0.61      0.69      1032\n",
            "           3       0.67      0.79      0.72      1010\n",
            "           4       0.75      0.78      0.77       982\n",
            "           5       0.80      0.31      0.45       892\n",
            "           6       0.76      0.86      0.81       958\n",
            "           7       0.76      0.82      0.79      1028\n",
            "           8       0.86      0.52      0.65       974\n",
            "           9       0.76      0.67      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 967    2    0    1    2    0    3    3    1    1]\n",
            " [   1 1097   24    2    3    0    3    4    1    0]\n",
            " [  60  191  634   10   24    1   39   63    1    9]\n",
            " [  31   72   36  796    1   15   14   20   14   11]\n",
            " [   7   17    6    6  767    8   49   25   12   85]\n",
            " [ 106   38    5  269   69  280   39   19   30   37]\n",
            " [  54   15   19    2   33    6  823    6    0    0]\n",
            " [  23   66   27    1   26    2    0  845    2   36]\n",
            " [  19  137   53   69   26   20   99    5  511   35]\n",
            " [  24   30    7   36   65   16   12  123   19  677]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [ 9  9 35 42 29 70 22 33 63 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.419 s \n",
            "\n",
            "Accuracy rate for 74.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.99      0.87       980\n",
            "           1       0.64      0.97      0.77      1135\n",
            "           2       0.82      0.62      0.71      1032\n",
            "           3       0.69      0.78      0.73      1010\n",
            "           4       0.75      0.70      0.73       982\n",
            "           5       0.80      0.38      0.52       892\n",
            "           6       0.77      0.88      0.82       958\n",
            "           7       0.75      0.83      0.79      1028\n",
            "           8       0.76      0.57      0.65       974\n",
            "           9       0.82      0.62      0.71      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.73     10000\n",
            "weighted avg       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    1    0    3    2    1    3    1    1    0]\n",
            " [   0 1105   16    0    2    0    4    3    5    0]\n",
            " [  46  206  639   15   30    1   36   54    1    4]\n",
            " [  27   83   27  791    2   17   12   22   23    6]\n",
            " [   6   20    8   13  692   13   65   46   41   78]\n",
            " [  98   45    2  228   53  343   45   13   52   13]\n",
            " [  35   21    9    3   25   10  846    6    3    0]\n",
            " [  30   80   25    2   16    1    0  853    3   18]\n",
            " [  15  139   42   69   14   26   81   12  559   17]\n",
            " [  27   33    8   29   85   16    7  130   49  625]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59640, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [ 9  9 35 43 29 74 22 33 65 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.396 s \n",
            "\n",
            "Accuracy rate for 72.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85       980\n",
            "           1       0.63      0.98      0.76      1135\n",
            "           2       0.80      0.59      0.68      1032\n",
            "           3       0.63      0.78      0.69      1010\n",
            "           4       0.72      0.69      0.71       982\n",
            "           5       0.78      0.34      0.48       892\n",
            "           6       0.76      0.86      0.81       958\n",
            "           7       0.76      0.82      0.79      1028\n",
            "           8       0.84      0.49      0.62       974\n",
            "           9       0.79      0.64      0.71      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 969    2    0    2    1    0    3    2    1    0]\n",
            " [   0 1112    7    6    2    0    4    2    2    0]\n",
            " [  54  231  608   13   21    1   37   60    1    6]\n",
            " [  38   89   24  783    2   20   12   19   14    9]\n",
            " [   9   24   18   17  678   12   61   43   16  104]\n",
            " [ 110   34    3  276   66  305   35   17   32   14]\n",
            " [  46   20   12    4   32    9  827    6    2    0]\n",
            " [  29   83   28    4   14    2    0  843    2   23]\n",
            " [  17  143   47  106   28   27   96    6  482   22]\n",
            " [  23   39   13   38   94   15    7  105   25  650]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['3' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59630, 10) \n",
            " [3 0 9 ... 5 6 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [ 9  9 36 44 32 75 22 34 66 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.420 s \n",
            "\n",
            "Accuracy rate for 72.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88       980\n",
            "           1       0.61      0.97      0.75      1135\n",
            "           2       0.79      0.59      0.67      1032\n",
            "           3       0.67      0.77      0.72      1010\n",
            "           4       0.77      0.69      0.73       982\n",
            "           5       0.80      0.43      0.56       892\n",
            "           6       0.74      0.89      0.81       958\n",
            "           7       0.71      0.83      0.77      1028\n",
            "           8       0.78      0.49      0.61       974\n",
            "           9       0.77      0.56      0.65      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    0    1    0    1    2    4    2    0]\n",
            " [   0 1102   17    2    2    0    5    4    3    0]\n",
            " [  55  235  607   16   21    1   42   54    0    1]\n",
            " [  27  101   24  775    1   23   12   22   19    6]\n",
            " [   4   29    6    9  676   17   67   57   23   94]\n",
            " [  82   40    6  222   33  380   42   28   44   15]\n",
            " [  41   18   12    4   16    9  848    8    2    0]\n",
            " [  17   92   29    1    7    1    0  857    1   23]\n",
            " [  12  141   58   91   11   27  116    9  482   27]\n",
            " [  19   40   13   30  112   18    8  168   39  562]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59620, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [ 9 11 37 44 33 75 23 34 69 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.399 s \n",
            "\n",
            "Accuracy rate for 72.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.98      0.85       980\n",
            "           1       0.65      0.97      0.78      1135\n",
            "           2       0.77      0.58      0.66      1032\n",
            "           3       0.67      0.78      0.72      1010\n",
            "           4       0.76      0.67      0.71       982\n",
            "           5       0.80      0.36      0.49       892\n",
            "           6       0.75      0.88      0.81       958\n",
            "           7       0.71      0.87      0.78      1028\n",
            "           8       0.74      0.48      0.58       974\n",
            "           9       0.76      0.59      0.66      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 965    1    1    3    0    1    3    4    2    0]\n",
            " [   0 1103   23    2    0    1    2    4    0    0]\n",
            " [  70  185  603   16   17    1   58   74    2    6]\n",
            " [  33   82   23  790    3   19   15   24   16    5]\n",
            " [   4   11   25    9  655   16   54   56   27  125]\n",
            " [ 114   43    4  229   43  319   40   24   67    9]\n",
            " [  42   18   12    2   25    7  841   10    0    1]\n",
            " [  16   42   33    3   15    1    1  894    1   22]\n",
            " [  17  205   47   75   13   19   96    9  468   25]\n",
            " [  20   17   17   44   89   17    7  155   48  595]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59610, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 9 12 38 45 36 76 23 35 69 57] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.502 s \n",
            "\n",
            "Accuracy rate for 71.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.99      0.85       980\n",
            "           1       0.64      0.95      0.77      1135\n",
            "           2       0.70      0.62      0.66      1032\n",
            "           3       0.70      0.73      0.71      1010\n",
            "           4       0.80      0.68      0.74       982\n",
            "           5       0.78      0.33      0.47       892\n",
            "           6       0.75      0.86      0.80       958\n",
            "           7       0.69      0.88      0.77      1028\n",
            "           8       0.70      0.49      0.58       974\n",
            "           9       0.76      0.57      0.65      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.71      0.70     10000\n",
            "weighted avg       0.72      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    0    3    0    1    2    2    2    0]\n",
            " [   0 1073   49    1    0    1    2    9    0    0]\n",
            " [  71  146  644   17   17    2   56   74    0    5]\n",
            " [  39   98   28  734    3   28   17   25   31    7]\n",
            " [   5   20   27    1  669   12   45   77   17  109]\n",
            " [ 111   59    6  204   39  296   50   34   81   12]\n",
            " [  57   22   19    1   21    5  820   12    1    0]\n",
            " [  20   33   45    1    8    1    1  900    2   17]\n",
            " [  20  181   82   60    9   20   86    7  478   31]\n",
            " [  20   36   26   26   69   14   10  161   68  579]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [ 9 13 40 45 37 78 23 37 70 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.494 s \n",
            "\n",
            "Accuracy rate for 71.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.99      0.84       980\n",
            "           1       0.66      0.97      0.79      1135\n",
            "           2       0.73      0.61      0.67      1032\n",
            "           3       0.68      0.77      0.73      1010\n",
            "           4       0.80      0.68      0.73       982\n",
            "           5       0.78      0.29      0.42       892\n",
            "           6       0.73      0.88      0.80       958\n",
            "           7       0.69      0.87      0.77      1028\n",
            "           8       0.69      0.47      0.56       974\n",
            "           9       0.78      0.57      0.66      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.73      0.71      0.70     10000\n",
            "weighted avg       0.73      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    0    2    0    0    2    4    2    0]\n",
            " [   0 1098   26    1    0    1    3    6    0    0]\n",
            " [  70  153  633   16   14    2   69   69    0    6]\n",
            " [  40   67   28  781    1   18   17   24   24   10]\n",
            " [   6   19   24    3  665   11   60   80   18   96]\n",
            " [ 123   45    7  229   46  260   49   30   95    8]\n",
            " [  47   17   12    4   18    5  843   12    0    0]\n",
            " [  24   35   36    4   12    1    2  893    4   17]\n",
            " [  17  188   79   74    8   21   99    8  454   26]\n",
            " [  23   37   18   27   71   16   12  174   58  573]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59590, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [ 9 13 41 46 40 81 23 37 71 59] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.479 s \n",
            "\n",
            "Accuracy rate for 70.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.99      0.85       980\n",
            "           1       0.65      0.96      0.78      1135\n",
            "           2       0.70      0.59      0.64      1032\n",
            "           3       0.69      0.79      0.74      1010\n",
            "           4       0.75      0.66      0.70       982\n",
            "           5       0.83      0.28      0.42       892\n",
            "           6       0.72      0.87      0.79       958\n",
            "           7       0.69      0.88      0.77      1028\n",
            "           8       0.67      0.43      0.53       974\n",
            "           9       0.73      0.51      0.60      1009\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.72      0.70      0.68     10000\n",
            "weighted avg       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 970    2    0    2    0    0    2    2    2    0]\n",
            " [   0 1091   35    1    0    1    3    4    0    0]\n",
            " [  78  165  613   19   13    1   69   67    0    7]\n",
            " [  35   65   26  801    1   12   15   23   23    9]\n",
            " [   4   18   36    5  644   10   57   73   15  120]\n",
            " [ 109   41   11  207   50  254   63   39  106   12]\n",
            " [  56   19   15    2   12    4  838   12    0    0]\n",
            " [  20   36   38    7    4    1    2  903    2   15]\n",
            " [  18  194   92   84    5   12  106   14  421   28]\n",
            " [  23   39   16   29  130   12   12  175   58  515]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['3' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59580, 10) \n",
            " [3 0 9 ... 5 6 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [ 9 13 41 47 42 84 23 37 72 62] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.455 s \n",
            "\n",
            "Accuracy rate for 71.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.99      0.85       980\n",
            "           1       0.65      0.96      0.77      1135\n",
            "           2       0.71      0.60      0.65      1032\n",
            "           3       0.69      0.76      0.73      1010\n",
            "           4       0.79      0.69      0.74       982\n",
            "           5       0.80      0.39      0.53       892\n",
            "           6       0.73      0.88      0.80       958\n",
            "           7       0.67      0.88      0.76      1028\n",
            "           8       0.69      0.43      0.53       974\n",
            "           9       0.79      0.50      0.61      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.73      0.71      0.70     10000\n",
            "weighted avg       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    0    2    0    1    2    3    2    0]\n",
            " [   0 1091   34    1    0    1    3    5    0    0]\n",
            " [  72  160  620   20   17    3   64   71    0    5]\n",
            " [  39   81   28  770    0   16   17   29   23    7]\n",
            " [   5   15   22    3  678   17   55   80   26   81]\n",
            " [ 109   44   12  206   32  348   50   31   55    5]\n",
            " [  48   21   14    3   12    6  843   11    0    0]\n",
            " [  22   36   40    3    7    0    1  904    2   13]\n",
            " [  17  199   89   85    6   21  100   13  423   21]\n",
            " [  24   38   11   20  102   20   13  197   83  501]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59570, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [10 13 41 47 43 87 24 37 73 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 73.180000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.97      0.85       980\n",
            "           1       0.65      0.97      0.78      1135\n",
            "           2       0.73      0.64      0.69      1032\n",
            "           3       0.72      0.76      0.74      1010\n",
            "           4       0.79      0.68      0.73       982\n",
            "           5       0.83      0.44      0.58       892\n",
            "           6       0.73      0.90      0.81       958\n",
            "           7       0.70      0.87      0.78      1028\n",
            "           8       0.77      0.44      0.56       974\n",
            "           9       0.77      0.57      0.66      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    2    0    4    2    1    8    5    3    0]\n",
            " [   0 1097   31    0    0    1    3    3    0    0]\n",
            " [  37  138  665   31   15    2   72   66    0    6]\n",
            " [  51   68   28  771    1   15   20   24   23    9]\n",
            " [   4   31   19    3  672   10   47   78   15  103]\n",
            " [ 131   54    7  155   27  393   60   27   32    6]\n",
            " [  28   16   13    3   16   10  860   11    1    0]\n",
            " [  19   46   31    2    6    1    3  899    1   20]\n",
            " [  11  193   98   85    7   23   86   13  430   28]\n",
            " [  18   45   16   12  101   18   12  161   50  576]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['3' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59560, 10) \n",
            " [3 0 9 ... 5 6 9]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [11 13 43 47 44 88 24 37 76 67] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.404 s \n",
            "\n",
            "Accuracy rate for 73.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.97      0.84       980\n",
            "           1       0.70      0.95      0.81      1135\n",
            "           2       0.68      0.67      0.68      1032\n",
            "           3       0.71      0.79      0.75      1010\n",
            "           4       0.82      0.69      0.75       982\n",
            "           5       0.81      0.50      0.62       892\n",
            "           6       0.74      0.87      0.80       958\n",
            "           7       0.69      0.87      0.77      1028\n",
            "           8       0.78      0.41      0.54       974\n",
            "           9       0.80      0.58      0.68      1009\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.73      0.72     10000\n",
            "weighted avg       0.75      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    2    4    4    2    1    4   10    2    0]\n",
            " [   0 1073   54    1    0    1    3    3    0    0]\n",
            " [  52  109  695   28   13    7   53   68    0    7]\n",
            " [  24   51   29  801    2   19   21   30   25    8]\n",
            " [  31   19   22    0  678   13   41   76   12   90]\n",
            " [  89   39   11  165   29  443   58   27   27    4]\n",
            " [  43   12   32    2   17   11  833    8    0    0]\n",
            " [  33   36   38    2    6    0    1  897    1   14]\n",
            " [  14  152  128  111    8   27   99   13  400   22]\n",
            " [  40   34   12   15   74   25   10  161   48  590]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 9 ... 5 6 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [13 13 44 49 45 89 24 37 79 67] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.401 s \n",
            "\n",
            "Accuracy rate for 72.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.99      0.81       980\n",
            "           1       0.65      0.96      0.78      1135\n",
            "           2       0.75      0.60      0.67      1032\n",
            "           3       0.75      0.74      0.74      1010\n",
            "           4       0.82      0.70      0.76       982\n",
            "           5       0.80      0.48      0.60       892\n",
            "           6       0.71      0.89      0.79       958\n",
            "           7       0.69      0.89      0.78      1028\n",
            "           8       0.80      0.39      0.52       974\n",
            "           9       0.77      0.57      0.66      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 969    2    0    2    0    0    5    0    2    0]\n",
            " [   0 1095   31    1    0    1    3    4    0    0]\n",
            " [  71  137  623   28   14    2   84   66    0    7]\n",
            " [  66   69   24  744    3   21   20   27   26   10]\n",
            " [  20   21    9    1  688   13   45   71    7  107]\n",
            " [ 147   45   10  130   26  424   66   21   17    6]\n",
            " [  49   16    8    2   15    9  849   10    0    0]\n",
            " [  26   39   24    2    6    0    2  911    1   17]\n",
            " [  22  213   94   71    6   31  116   16  376   29]\n",
            " [  33   35    6   10   79   26   12  189   41  578]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59540, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [13 13 44 50 46 91 25 37 82 69] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.423 s \n",
            "\n",
            "Accuracy rate for 72.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.99      0.79       980\n",
            "           1       0.68      0.96      0.79      1135\n",
            "           2       0.73      0.65      0.69      1032\n",
            "           3       0.76      0.70      0.73      1010\n",
            "           4       0.81      0.69      0.75       982\n",
            "           5       0.83      0.45      0.58       892\n",
            "           6       0.70      0.89      0.78       958\n",
            "           7       0.69      0.86      0.77      1028\n",
            "           8       0.79      0.42      0.55       974\n",
            "           9       0.77      0.57      0.65      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 968    2    1    1    0    0    6    0    2    0]\n",
            " [   0 1085   39    1    0    1    4    5    0    0]\n",
            " [  65  115  668   19   11    1   71   73    1    8]\n",
            " [ 100   65   25  708    2   19   26   25   29   11]\n",
            " [  21   18   15    5  682   13   50   67    9  102]\n",
            " [ 179   43   10   98   37  399   79   22   18    7]\n",
            " [  44   14   11    2   18    6  851   11    0    1]\n",
            " [  41   36   33    1   11    0    3  888    1   14]\n",
            " [  23  186   98   69   11   20  114   12  408   33]\n",
            " [  36   35    9   25   69   24   12  176   49  574]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['5' '0' '9' ... '5' '6' '9']\n",
            "probabilities: (59530, 10) \n",
            " [5 0 9 ... 5 6 9]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [13 13 44 50 49 91 26 37 86 71] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.475 s \n",
            "\n",
            "Accuracy rate for 72.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.99      0.79       980\n",
            "           1       0.65      0.96      0.78      1135\n",
            "           2       0.71      0.62      0.67      1032\n",
            "           3       0.76      0.69      0.73      1010\n",
            "           4       0.82      0.72      0.77       982\n",
            "           5       0.84      0.42      0.56       892\n",
            "           6       0.72      0.88      0.80       958\n",
            "           7       0.72      0.86      0.78      1028\n",
            "           8       0.75      0.43      0.55       974\n",
            "           9       0.79      0.60      0.69      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 969    2    1    3    0    0    3    0    2    0]\n",
            " [   1 1091   34    0    0    1    4    4    0    0]\n",
            " [  71  138  644   25   15    0   62   68    2    7]\n",
            " [  93   80   25  699    0   22   20   20   43    8]\n",
            " [  14   22   23    0  708   10   61   54   12   78]\n",
            " [ 177   45   12  121   40  371   56   27   33   10]\n",
            " [  45   12   21    4   14    4  846   12    0    0]\n",
            " [  35   41   34    0    5    0    3  888    5   17]\n",
            " [  23  200   96   59    9   16  100   12  421   38]\n",
            " [  35   43   12    7   76   17   13  153   44  609]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59520, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [13 13 45 50 50 95 26 37 89 72] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.418 s \n",
            "\n",
            "Accuracy rate for 72.470000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.99      0.80       980\n",
            "           1       0.66      0.96      0.79      1135\n",
            "           2       0.72      0.62      0.67      1032\n",
            "           3       0.75      0.73      0.74      1010\n",
            "           4       0.81      0.71      0.75       982\n",
            "           5       0.86      0.41      0.55       892\n",
            "           6       0.71      0.88      0.79       958\n",
            "           7       0.71      0.86      0.78      1028\n",
            "           8       0.77      0.42      0.54       974\n",
            "           9       0.79      0.61      0.69      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.74      0.72      0.71     10000\n",
            "weighted avg       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 970    2    1    2    0    0    4    0    1    0]\n",
            " [   0 1092   35    1    0    1    3    3    0    0]\n",
            " [  69  142  644   22   15    1   65   66    0    8]\n",
            " [  78   64   25  738    1   17   25   23   33    6]\n",
            " [  16   22   16    3  693    5   56   66   11   94]\n",
            " [ 166   39   13  142   39  362   67   21   34    9]\n",
            " [  50   17   16    4   18    4  841    8    0    0]\n",
            " [  40   39   29    1    9    0    3  889    2   16]\n",
            " [  23  186  108   62   22   18  106   12  406   31]\n",
            " [  40   40    9   15   59   14   12  170   38  612]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['3' '0' '4' ... '5' '6' '9']\n",
            "probabilities: (59510, 10) \n",
            " [3 0 4 ... 5 6 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [13 14 46 51 50 95 26 37 93 75] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.437 s \n",
            "\n",
            "Accuracy rate for 72.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.99      0.81       980\n",
            "           1       0.66      0.97      0.78      1135\n",
            "           2       0.71      0.62      0.66      1032\n",
            "           3       0.71      0.75      0.73      1010\n",
            "           4       0.83      0.71      0.76       982\n",
            "           5       0.86      0.39      0.54       892\n",
            "           6       0.72      0.88      0.79       958\n",
            "           7       0.76      0.84      0.80      1028\n",
            "           8       0.79      0.39      0.52       974\n",
            "           9       0.75      0.67      0.71      1009\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.75      0.72      0.71     10000\n",
            "weighted avg       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 967    2    2    2    0    0    6    0    1    0]\n",
            " [   0 1102   25    0    0    1    6    1    0    0]\n",
            " [  57  164  640   32   16    1   58   56    0    8]\n",
            " [  71   63   22  758    2   15   24   17   27   11]\n",
            " [  17   20   18    6  699    7   51   45    5  114]\n",
            " [ 161   31   10  174   35  349   69   22   32    9]\n",
            " [  48   18   14    5   23    4  839    6    0    1]\n",
            " [  36   53   33    0   12    0    4  863    2   25]\n",
            " [  21  179  126   76   18   13   96   13  378   54]\n",
            " [  41   42    9   20   42   15   12  115   32  681]]\n",
            "--------------------------------\n",
            "final active learning accuracies [36.0, 41.6, 51.23, 55.86, 63.160000000000004, 66.11, 70.5, 71.31, 68.54, 70.06, 70.69, 71.07, 71.86, 73.00999999999999, 74.11999999999999, 73.67, 73.76, 74.45, 75.01, 73.98, 74.42, 74.76, 74.88, 76.0, 74.65, 75.6, 75.84, 74.33999999999999, 75.13, 71.78999999999999, 74.11, 74.33, 73.65, 74.15, 73.97, 74.21, 72.57000000000001, 72.57000000000001, 72.33000000000001, 71.61, 71.67999999999999, 70.5, 71.46000000000001, 73.18, 73.61, 72.57000000000001, 72.31, 72.46000000000001, 72.47, 72.76]\n",
            "saved Active-learning-experiment-40.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.0,\n",
            "          41.6,\n",
            "          51.23,\n",
            "          55.86,\n",
            "          63.160000000000004,\n",
            "          66.11,\n",
            "          70.5,\n",
            "          71.31,\n",
            "          68.54,\n",
            "          70.06,\n",
            "          70.69,\n",
            "          71.07,\n",
            "          71.86,\n",
            "          73.00999999999999,\n",
            "          74.11999999999999,\n",
            "          73.67,\n",
            "          73.76,\n",
            "          74.45,\n",
            "          75.01,\n",
            "          73.98,\n",
            "          74.42,\n",
            "          74.76,\n",
            "          74.88,\n",
            "          76.0,\n",
            "          74.65,\n",
            "          75.6,\n",
            "          75.84,\n",
            "          74.33999999999999,\n",
            "          75.13,\n",
            "          71.78999999999999,\n",
            "          74.11,\n",
            "          74.33,\n",
            "          73.65,\n",
            "          74.15,\n",
            "          73.97,\n",
            "          74.21,\n",
            "          72.57000000000001,\n",
            "          72.57000000000001,\n",
            "          72.33000000000001,\n",
            "          71.61,\n",
            "          71.67999999999999,\n",
            "          70.5,\n",
            "          71.46000000000001,\n",
            "          73.18,\n",
            "          73.61,\n",
            "          72.57000000000001,\n",
            "          72.31,\n",
            "          72.46000000000001,\n",
            "          72.47,\n",
            "          72.76\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.31,\n",
            "          74.14,\n",
            "          73.79,\n",
            "          72.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          45.94,\n",
            "          60.81999999999999,\n",
            "          69.42,\n",
            "          71.08,\n",
            "          69.89,\n",
            "          70.02000000000001,\n",
            "          73.97,\n",
            "          74.13,\n",
            "          73.72,\n",
            "          72.81,\n",
            "          74.22999999999999,\n",
            "          72.96000000000001,\n",
            "          74.48,\n",
            "          75.02,\n",
            "          74.42,\n",
            "          74.17,\n",
            "          73.78,\n",
            "          74.32,\n",
            "          73.06,\n",
            "          73.31\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          74.58,\n",
            "          71.72\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.220000000000006,\n",
            "          65.96,\n",
            "          63.970000000000006,\n",
            "          70.62,\n",
            "          73.63,\n",
            "          75.53,\n",
            "          73.96000000000001,\n",
            "          73.17,\n",
            "          72.50999999999999,\n",
            "          71.74000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.180000000000003,\n",
            "          40.35,\n",
            "          50.01,\n",
            "          57.87,\n",
            "          61.53999999999999,\n",
            "          67.06,\n",
            "          69.54,\n",
            "          72.59,\n",
            "          71.99,\n",
            "          72.97,\n",
            "          71.83,\n",
            "          71.08,\n",
            "          72.68,\n",
            "          73.21,\n",
            "          73.65,\n",
            "          74.3,\n",
            "          74.06,\n",
            "          75.14999999999999,\n",
            "          75.62,\n",
            "          74.69,\n",
            "          74.03,\n",
            "          75.14,\n",
            "          75.5,\n",
            "          75.24,\n",
            "          75.26,\n",
            "          74.81,\n",
            "          75.5,\n",
            "          75.53,\n",
            "          74.85000000000001,\n",
            "          74.3,\n",
            "          76.03,\n",
            "          76.68,\n",
            "          75.82,\n",
            "          75.66000000000001,\n",
            "          75.47,\n",
            "          76.99000000000001,\n",
            "          74.64,\n",
            "          75.27000000000001,\n",
            "          76.57000000000001,\n",
            "          77.31,\n",
            "          76.9,\n",
            "          76.44,\n",
            "          76.53999999999999,\n",
            "          75.77000000000001,\n",
            "          77.25999999999999,\n",
            "          76.31,\n",
            "          76.14999999999999,\n",
            "          76.32,\n",
            "          75.71,\n",
            "          76.1\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          67.81,\n",
            "          73.41,\n",
            "          74.22999999999999,\n",
            "          73.67\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          60.0,\n",
            "          61.91,\n",
            "          66.95,\n",
            "          69.6,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          72.5,\n",
            "          72.68,\n",
            "          73.58,\n",
            "          73.81,\n",
            "          73.59,\n",
            "          73.5,\n",
            "          72.75,\n",
            "          73.72,\n",
            "          73.66,\n",
            "          74.00999999999999,\n",
            "          74.38,\n",
            "          73.42,\n",
            "          73.05,\n",
            "          73.24000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          74.1,\n",
            "          75.67\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          60.309999999999995,\n",
            "          67.99,\n",
            "          68.86,\n",
            "          69.49,\n",
            "          71.48,\n",
            "          72.54,\n",
            "          73.42999999999999,\n",
            "          74.14,\n",
            "          74.46000000000001,\n",
            "          74.11\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.95,\n",
            "          37.769999999999996,\n",
            "          36.39,\n",
            "          31.169999999999998,\n",
            "          33.33,\n",
            "          39.300000000000004,\n",
            "          42.730000000000004,\n",
            "          44.96,\n",
            "          45.97,\n",
            "          46.72,\n",
            "          46.379999999999995,\n",
            "          47.89,\n",
            "          49.120000000000005,\n",
            "          49.08,\n",
            "          48.38,\n",
            "          49.02,\n",
            "          50.96000000000001,\n",
            "          51.51,\n",
            "          52.629999999999995,\n",
            "          53.43,\n",
            "          53.400000000000006,\n",
            "          52.62,\n",
            "          53.33,\n",
            "          52.72,\n",
            "          53.169999999999995,\n",
            "          54.55,\n",
            "          55.230000000000004,\n",
            "          57.37,\n",
            "          57.56,\n",
            "          58.64,\n",
            "          59.61,\n",
            "          58.550000000000004,\n",
            "          59.48,\n",
            "          58.96,\n",
            "          59.230000000000004,\n",
            "          60.29,\n",
            "          60.35,\n",
            "          60.940000000000005,\n",
            "          60.660000000000004,\n",
            "          60.17,\n",
            "          60.69,\n",
            "          60.8,\n",
            "          62.06,\n",
            "          63.89,\n",
            "          63.28,\n",
            "          63.839999999999996,\n",
            "          63.67,\n",
            "          63.71,\n",
            "          63.980000000000004,\n",
            "          63.92\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.10000000000001,\n",
            "          73.02,\n",
            "          73.33,\n",
            "          72.53\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.730000000000004,\n",
            "          45.42,\n",
            "          46.589999999999996,\n",
            "          49.2,\n",
            "          50.44,\n",
            "          53.239999999999995,\n",
            "          57.08,\n",
            "          57.879999999999995,\n",
            "          60.47,\n",
            "          62.480000000000004,\n",
            "          60.68,\n",
            "          61.78,\n",
            "          61.18,\n",
            "          61.0,\n",
            "          59.84,\n",
            "          62.91,\n",
            "          62.99,\n",
            "          63.56,\n",
            "          64.05999999999999,\n",
            "          65.28\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          80.9,\n",
            "          81.05\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.98,\n",
            "          62.150000000000006,\n",
            "          62.67,\n",
            "          61.28,\n",
            "          60.5,\n",
            "          59.29,\n",
            "          60.480000000000004,\n",
            "          60.17,\n",
            "          60.86,\n",
            "          59.550000000000004\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.610000000000003,\n",
            "          39.07,\n",
            "          52.59,\n",
            "          60.88,\n",
            "          61.24000000000001,\n",
            "          67.75999999999999,\n",
            "          72.24000000000001,\n",
            "          74.92,\n",
            "          78.81,\n",
            "          79.96,\n",
            "          81.24,\n",
            "          82.33,\n",
            "          83.39999999999999,\n",
            "          85.04,\n",
            "          84.06,\n",
            "          85.28999999999999,\n",
            "          84.85000000000001,\n",
            "          85.45,\n",
            "          86.29,\n",
            "          86.78,\n",
            "          87.19,\n",
            "          87.11,\n",
            "          88.28,\n",
            "          88.01,\n",
            "          88.49000000000001,\n",
            "          88.3,\n",
            "          89.01,\n",
            "          89.29,\n",
            "          89.67,\n",
            "          90.22,\n",
            "          90.2,\n",
            "          90.22,\n",
            "          90.53,\n",
            "          91.07,\n",
            "          90.64,\n",
            "          90.96,\n",
            "          91.17,\n",
            "          91.47999999999999,\n",
            "          91.64999999999999,\n",
            "          91.74,\n",
            "          91.96,\n",
            "          91.63,\n",
            "          91.86,\n",
            "          91.9,\n",
            "          91.79,\n",
            "          91.9,\n",
            "          92.23,\n",
            "          92.08,\n",
            "          92.41,\n",
            "          92.54\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.8,\n",
            "          83.47,\n",
            "          89.21,\n",
            "          91.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.74999999999999,\n",
            "          66.17,\n",
            "          70.77,\n",
            "          77.29,\n",
            "          81.23,\n",
            "          82.98,\n",
            "          86.08,\n",
            "          88.09,\n",
            "          88.42,\n",
            "          88.94999999999999,\n",
            "          89.01,\n",
            "          89.88000000000001,\n",
            "          90.82000000000001,\n",
            "          91.28,\n",
            "          91.4,\n",
            "          92.01,\n",
            "          92.36999999999999,\n",
            "          91.9,\n",
            "          92.80000000000001,\n",
            "          93.22\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.06,\n",
            "          90.36\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          54.059999999999995,\n",
            "          71.72,\n",
            "          78.44,\n",
            "          83.62,\n",
            "          86.50999999999999,\n",
            "          88.63,\n",
            "          89.85,\n",
            "          91.10000000000001,\n",
            "          91.59,\n",
            "          91.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 41, using model = LogModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [17 38 33 26 18 19 15 28 21 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.312 s \n",
            "\n",
            "Accuracy rate for 71.800000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       980\n",
            "           1       0.77      0.95      0.85      1135\n",
            "           2       0.65      0.72      0.69      1032\n",
            "           3       0.65      0.77      0.71      1010\n",
            "           4       0.70      0.79      0.74       982\n",
            "           5       0.62      0.51      0.56       892\n",
            "           6       0.75      0.74      0.75       958\n",
            "           7       0.75      0.79      0.77      1028\n",
            "           8       0.73      0.51      0.60       974\n",
            "           9       0.73      0.52      0.61      1009\n",
            "\n",
            "    accuracy                           0.72     10000\n",
            "   macro avg       0.72      0.71      0.71     10000\n",
            "weighted avg       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 802    2    1   14    0   31   60    7   61    2]\n",
            " [   0 1078   48    2    0    2    3    2    0    0]\n",
            " [  43   70  747   47   34    3   32   21   26    9]\n",
            " [   8   37   19  775    5   52   16   24   46   28]\n",
            " [  14   18   31   19  779   12   41   21    3   44]\n",
            " [  17   23   34  177   35  457   47   71   26    5]\n",
            " [  40   11   75   41   14   48  713    1   15    0]\n",
            " [  24   51   51    3   16    1    4  807    2   69]\n",
            " [   3   95  105   86   15  103   16   19  494   38]\n",
            " [  22   24   36   24  214   30   15  108    8  528]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['5' '0' '4' ... '5' '6' '2']\n",
            "probabilities: (59750, 10) \n",
            " [5 0 4 ... 5 6 2]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 22  47  66  43  26 129  32  43  53  39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.471 s \n",
            "\n",
            "Accuracy rate for 65.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88       980\n",
            "           1       0.63      0.99      0.77      1135\n",
            "           2       0.80      0.59      0.68      1032\n",
            "           3       0.53      0.78      0.63      1010\n",
            "           4       0.74      0.72      0.73       982\n",
            "           5       0.70      0.29      0.41       892\n",
            "           6       0.82      0.83      0.82       958\n",
            "           7       0.88      0.39      0.54      1028\n",
            "           8       0.55      0.15      0.23       974\n",
            "           9       0.44      0.78      0.56      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.69      0.65      0.63     10000\n",
            "weighted avg       0.69      0.66      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2    1    2    0    7   13    1    0    2]\n",
            " [   0 1123    4    3    0    3    2    0    0    0]\n",
            " [  43  202  613   36   19    6   40   10    6   57]\n",
            " [  18   74   22  784    4   38   16    2    9   43]\n",
            " [   9   18   16   13  710    7   16   27   28  138]\n",
            " [  51   25    8  334   42  262   50    1   49   70]\n",
            " [  38   21   22    8   35   32  796    2    4    0]\n",
            " [  41   87   11   22   17    1    4  404    2  439]\n",
            " [  14  218   63  221   27   17   36    3  142  233]\n",
            " [  28   19    2   45  103    2    1   11   16  782]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.8, 65.68]\n",
            "saved Active-learning-experiment-41.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 42, using model = LogModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [11 11 11  6 18 17 14 13 12 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.252 s \n",
            "\n",
            "Accuracy rate for 71.200000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       980\n",
            "           1       0.75      0.96      0.84      1135\n",
            "           2       0.84      0.65      0.73      1032\n",
            "           3       0.66      0.73      0.70      1010\n",
            "           4       0.75      0.76      0.76       982\n",
            "           5       0.72      0.17      0.27       892\n",
            "           6       0.74      0.87      0.80       958\n",
            "           7       0.73      0.56      0.63      1028\n",
            "           8       0.65      0.69      0.67       974\n",
            "           9       0.52      0.73      0.61      1009\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.72      0.70      0.69     10000\n",
            "weighted avg       0.72      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    1    0    4    0    1   52    3   13    1]\n",
            " [   0 1088   29    9    0    0    3    0    4    2]\n",
            " [  35   76  668   38   19    3   71   38   57   27]\n",
            " [  19   50   25  742    3   33   18   13   73   34]\n",
            " [   3   23    8    9  743    5   54   55   23   59]\n",
            " [  64   56   11  188   49  150   55   13  139  167]\n",
            " [  19   13   14    5   32    3  837    0   35    0]\n",
            " [  16   66   24    6   16    3    1  571    2  323]\n",
            " [   4   62   13   87   15    5   26   25  676   61]\n",
            " [   9   21    7   29  108    4   11   59   21  740]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['8' '0' '4' ... '9' '6' '9']\n",
            "probabilities: (59875, 10) \n",
            " [8 0 4 ... 9 6 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [13 12 21 19 21 91 16 21 18 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.314 s \n",
            "\n",
            "Accuracy rate for 63.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.92      0.82       980\n",
            "           1       0.68      0.96      0.79      1135\n",
            "           2       0.58      0.34      0.43      1032\n",
            "           3       0.64      0.54      0.58      1010\n",
            "           4       0.55      0.86      0.67       982\n",
            "           5       0.56      0.17      0.26       892\n",
            "           6       0.63      0.84      0.72       958\n",
            "           7       0.89      0.56      0.69      1028\n",
            "           8       0.57      0.68      0.62       974\n",
            "           9       0.58      0.47      0.52      1009\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.64      0.63      0.61     10000\n",
            "weighted avg       0.64      0.64      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    1    0    0    0    9   61    1    5    0]\n",
            " [   0 1086    2    2    0    0    3    0   42    0]\n",
            " [  54  129  352   13   62    5  260   17  130   10]\n",
            " [  37   62  164  545   16   51   13    7   96   19]\n",
            " [  11   29    2    0  844   14   26   21   23   12]\n",
            " [ 147   26   44  209  115  151   72    4   89   35]\n",
            " [  19   14    4    3   49   15  801    1   51    1]\n",
            " [  32  109    9   17   42    7    2  576   16  218]\n",
            " [  17   88   29   43   31   11   33    4  667   51]\n",
            " [  14   56    5   22  362    5    7   14   52  472]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [ 15  13  34  28  26 155  21  29  28  26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 57.370000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79       980\n",
            "           1       0.59      0.99      0.74      1135\n",
            "           2       0.74      0.07      0.12      1032\n",
            "           3       0.69      0.52      0.59      1010\n",
            "           4       0.47      0.83      0.60       982\n",
            "           5       0.44      0.20      0.28       892\n",
            "           6       0.47      0.79      0.59       958\n",
            "           7       0.95      0.52      0.68      1028\n",
            "           8       0.54      0.65      0.59       974\n",
            "           9       0.41      0.23      0.30      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.60      0.57      0.53     10000\n",
            "weighted avg       0.61      0.57      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 857    2    0    0    0    4  106    0    1   10]\n",
            " [   0 1125    0    2    0    1    4    0    3    0]\n",
            " [  89  245   69    4   59    2  473    9   73    9]\n",
            " [  66   85    2  522   22   61   53    1  182   16]\n",
            " [   3   39    4    0  819   39   31    5   29   13]\n",
            " [  92   42    3  167   92  181  116    3  168   28]\n",
            " [  22   20    6    3  102   20  758    2   24    1]\n",
            " [  34  123    4   10   58   13    8  539   16  223]\n",
            " [  21  167    1   36   27   11   46    1  632   32]\n",
            " [   8   59    4    9  550   78   17    5   44  235]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59625, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 17  16  46  32  39 216  32  32  42  28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.358 s \n",
            "\n",
            "Accuracy rate for 57.950000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       980\n",
            "           1       0.54      0.99      0.70      1135\n",
            "           2       0.76      0.19      0.30      1032\n",
            "           3       0.60      0.65      0.62      1010\n",
            "           4       0.56      0.80      0.66       982\n",
            "           5       0.57      0.17      0.26       892\n",
            "           6       0.53      0.54      0.53       958\n",
            "           7       0.86      0.38      0.53      1028\n",
            "           8       0.43      0.50      0.46       974\n",
            "           9       0.48      0.56      0.52      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.61      0.57      0.54     10000\n",
            "weighted avg       0.61      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    2    1    0    0    3   42    2    1    5]\n",
            " [   0 1127    0    1    0    0    3    0    4    0]\n",
            " [  63  311  192   13   63    2  231   28  106   23]\n",
            " [  35   97   21  657    1   33   16    4  117   29]\n",
            " [  12   48    0   13  788   22    3    3   58   35]\n",
            " [  46   43   11  245   42  151  107    5  195   47]\n",
            " [  44   37    8   12  280   17  519    6   31    4]\n",
            " [  22  124    0   10   26    7    4  394   35  406]\n",
            " [  11  234   14  104   13    4   58    1  483   52]\n",
            " [  14   67    5   40  191   25    1   15   91  560]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.2, 63.970000000000006, 57.37, 57.95]\n",
            "saved Active-learning-experiment-42.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 43, using model = LogModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [5 6 4 5 4 8 3 4 4 7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.269 s \n",
            "\n",
            "Accuracy rate for 66.080000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.76      0.80       980\n",
            "           1       0.81      0.94      0.87      1135\n",
            "           2       0.70      0.61      0.65      1032\n",
            "           3       0.55      0.79      0.65      1010\n",
            "           4       0.56      0.65      0.60       982\n",
            "           5       0.57      0.42      0.48       892\n",
            "           6       0.69      0.67      0.68       958\n",
            "           7       0.74      0.80      0.77      1028\n",
            "           8       0.56      0.45      0.50       974\n",
            "           9       0.57      0.45      0.51      1009\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.66      0.65      0.65     10000\n",
            "weighted avg       0.66      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 746    0   37   26   11   56   94    0    8    2]\n",
            " [   0 1065    2    3    0    0    3    2   55    5]\n",
            " [  36   52  625   64   82   12   66   25   62    8]\n",
            " [   6   11   55  798    1   40    7   11   51   30]\n",
            " [   2   49    4   13  637   18   40   71   20  128]\n",
            " [   6   22    6  293   22  373   53    3   61   53]\n",
            " [  54    9   94   20   57    3  644    4   70    3]\n",
            " [  15   58   18   15   51   34    3  821    6    7]\n",
            " [  10   24   50  207    1   89   26   16  441  110]\n",
            " [  11   22    5   24  278   26    4  162   19  458]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6  6  7 11  5 26  8 17  7  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.255 s \n",
            "\n",
            "Accuracy rate for 57.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.87      0.81       980\n",
            "           1       0.70      0.97      0.81      1135\n",
            "           2       0.67      0.58      0.62      1032\n",
            "           3       0.69      0.54      0.61      1010\n",
            "           4       0.54      0.67      0.60       982\n",
            "           5       0.65      0.17      0.27       892\n",
            "           6       0.76      0.47      0.58       958\n",
            "           7       0.78      0.35      0.48      1028\n",
            "           8       0.44      0.38      0.41       974\n",
            "           9       0.30      0.68      0.42      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.63      0.57      0.56     10000\n",
            "weighted avg       0.63      0.58      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    1    9    1   11   10   50    2   20   22]\n",
            " [   0 1098    0    0    0    0    4    0    4   29]\n",
            " [  38  154  597   15   46    2   15    9  109   47]\n",
            " [  73   55    9  544    3   17   11   37  118  143]\n",
            " [   2   45   38   12  654   11   15    3   25  177]\n",
            " [  48   14    8  133   49  154   34   28  106  318]\n",
            " [  78   27  118    8  151    0  451    6   68   51]\n",
            " [   8   77   78   31   78   19    0  359    6  372]\n",
            " [  12   83   20   31   13    3    9    4  374  425]\n",
            " [  14   24    8   12  207   22    1   12   27  682]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '9' '6' '8']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 9 6 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 7  6 11 13  5 43 15 25 17  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.327 s \n",
            "\n",
            "Accuracy rate for 57.450000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.91      0.82       980\n",
            "           1       0.61      0.99      0.75      1135\n",
            "           2       0.59      0.47      0.52      1032\n",
            "           3       0.73      0.39      0.51      1010\n",
            "           4       0.49      0.67      0.57       982\n",
            "           5       0.55      0.07      0.12       892\n",
            "           6       0.69      0.77      0.73       958\n",
            "           7       0.78      0.39      0.52      1028\n",
            "           8       0.50      0.39      0.44       974\n",
            "           9       0.34      0.61      0.44      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.60      0.57      0.54     10000\n",
            "weighted avg       0.60      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 887    1    2    5   21    5   49    6    1    3]\n",
            " [   0 1122    2    0    0    1    4    0    3    3]\n",
            " [  78  273  487    3   62    0   59   10   15   45]\n",
            " [ 114   99   10  395    6    5   24   47  174  136]\n",
            " [   1   39   21    2  654   14   76    2    6  167]\n",
            " [  73   35   15   91   57   61   78   26  142  314]\n",
            " [  15   16   10    1  125    1  740    4   25   21]\n",
            " [  12   81  258   12  107    4    3  398    1  152]\n",
            " [   9  141   10   24   18    3   31    1  381  356]\n",
            " [   7   31   16    6  275   17   14   14    9  620]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '8' '6' '9']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 8 6 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 7  9 18 21  5 60 20 27 23 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.280 s \n",
            "\n",
            "Accuracy rate for 56.360000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.73      0.82       980\n",
            "           1       0.64      0.98      0.78      1135\n",
            "           2       0.67      0.38      0.49      1032\n",
            "           3       0.71      0.38      0.50      1010\n",
            "           4       0.50      0.66      0.57       982\n",
            "           5       0.52      0.12      0.20       892\n",
            "           6       0.70      0.76      0.73       958\n",
            "           7       0.73      0.32      0.45      1028\n",
            "           8       0.41      0.46      0.44       974\n",
            "           9       0.33      0.74      0.46      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.61      0.56      0.54     10000\n",
            "weighted avg       0.62      0.56      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 718    1   81    5   72   30   37    9   15   12]\n",
            " [   0 1114    1    1    0    1    8    0    4    6]\n",
            " [  15  260  396    4   65    0  113   18   64   97]\n",
            " [  20   37   22  387    2   27   29   43  307  136]\n",
            " [   0   36    7   14  650   13   17    3   12  230]\n",
            " [   6   55   49   98   53  111   72   29  200  219]\n",
            " [   5   20   12    4  132    3  732    5   35   10]\n",
            " [   5   67    3    5  109   14    4  334    2  485]\n",
            " [   4  132   24   16   15    2   27    4  452  298]\n",
            " [   4   12    0    8  205   13    3   11   11  742]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['8' '0' '4' ... '8' '2' '2']\n",
            "probabilities: (59800, 10) \n",
            " [8 0 4 ... 8 2 2]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [10 12 33 22  7 76 21 31 25 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.388 s \n",
            "\n",
            "Accuracy rate for 51.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       980\n",
            "           1       0.55      0.99      0.71      1135\n",
            "           2       0.92      0.13      0.23      1032\n",
            "           3       0.58      0.21      0.31      1010\n",
            "           4       0.52      0.66      0.58       982\n",
            "           5       0.47      0.05      0.09       892\n",
            "           6       0.63      0.78      0.70       958\n",
            "           7       0.71      0.39      0.50      1028\n",
            "           8       0.34      0.35      0.35       974\n",
            "           9       0.28      0.60      0.38      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.57      0.51      0.46     10000\n",
            "weighted avg       0.57      0.51      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 869    2    1   12   27    4   39    7    3   16]\n",
            " [   0 1122    0    0    0    0    8    0    0    5]\n",
            " [  37  297  136    2   99    0  147   37   32  245]\n",
            " [ 122   74    2  210    2    1   35   67  314  183]\n",
            " [   1   38    5   34  653   27   47    4   49  124]\n",
            " [ 101  108    0   64   35   47   93   24  179  241]\n",
            " [  19   24    0    3  120    0  750    7   21   14]\n",
            " [  13   57    1    8   85    3    3  400    4  454]\n",
            " [  17  280    2   16   12    1   53    2  343  248]\n",
            " [  14   32    1   16  234   17   10   17   67  601]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['9' '0' '4' ... '8' '6' '5']\n",
            "probabilities: (59750, 10) \n",
            " [9 0 4 ... 8 6 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [11 13 40 27 11 95 26 31 31 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.398 s \n",
            "\n",
            "Accuracy rate for 53.700000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       980\n",
            "           1       0.60      0.99      0.74      1135\n",
            "           2       0.79      0.17      0.27      1032\n",
            "           3       0.56      0.11      0.19      1010\n",
            "           4       0.58      0.75      0.66       982\n",
            "           5       0.59      0.05      0.09       892\n",
            "           6       0.69      0.79      0.74       958\n",
            "           7       0.61      0.49      0.54      1028\n",
            "           8       0.30      0.57      0.39       974\n",
            "           9       0.32      0.49      0.39      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.59      0.53      0.49     10000\n",
            "weighted avg       0.59      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 870    2    0    3    5    5   23   16   26   30]\n",
            " [   0 1123    0    0    0    0    5    0    3    4]\n",
            " [  39  279  171    1   54    3  149   99   76  161]\n",
            " [   9   63    4  115    1    0   25  130  581   82]\n",
            " [   4   28   22   15  735   11   30    7   58   72]\n",
            " [  29   72    0   45   34   42   73   40  372  185]\n",
            " [  31   27    1    6   78    1  760    7   37   10]\n",
            " [  13   51   10    3   65    1    4  501    8  372]\n",
            " [   7  213    4   12   12    1   34    3  558  130]\n",
            " [  21   22    5    7  276    7    5   24  147  495]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['9' '0' '4' ... '8' '6' '2']\n",
            "probabilities: (59700, 10) \n",
            " [9 0 4 ... 8 6 2]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 13  13  46  31  16 119  32  32  32  16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.340 s \n",
            "\n",
            "Accuracy rate for 54.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85       980\n",
            "           1       0.55      0.99      0.71      1135\n",
            "           2       0.86      0.14      0.25      1032\n",
            "           3       0.55      0.12      0.20      1010\n",
            "           4       0.58      0.81      0.68       982\n",
            "           5       0.41      0.02      0.03       892\n",
            "           6       0.73      0.71      0.72       958\n",
            "           7       0.69      0.54      0.61      1028\n",
            "           8       0.28      0.57      0.38       974\n",
            "           9       0.41      0.56      0.47      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.59      0.53      0.49     10000\n",
            "weighted avg       0.59      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 857    2    2    2   33   10   20   18   18   18]\n",
            " [   0 1124    0    0    0    0    6    0    4    1]\n",
            " [  32  328  149    2  134    1   96   79   80  131]\n",
            " [  23   82    4  124    3    0   35   83  611   45]\n",
            " [   9   28    5    7  797    1    4    9   71   51]\n",
            " [  51   94    9   60   54   15   49   30  403  127]\n",
            " [  37   50    2    8  111    1  677    5   56   11]\n",
            " [  15   61    1    6   20    1    5  556    8  355]\n",
            " [   9  266    2   11    5    2   29    4  556   90]\n",
            " [  14   18    0    7  206    6    1   23  168  566]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['8' '0' '4' ... '8' '6' '5']\n",
            "probabilities: (59650, 10) \n",
            " [8 0 4 ... 8 6 5]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 15  13  51  32  28 134  39  34  36  18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.392 s \n",
            "\n",
            "Accuracy rate for 56.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       980\n",
            "           1       0.52      0.99      0.69      1135\n",
            "           2       0.60      0.26      0.36      1032\n",
            "           3       0.51      0.33      0.40      1010\n",
            "           4       0.74      0.61      0.67       982\n",
            "           5       0.51      0.09      0.15       892\n",
            "           6       0.84      0.68      0.75       958\n",
            "           7       0.64      0.66      0.65      1028\n",
            "           8       0.30      0.48      0.37       974\n",
            "           9       0.43      0.56      0.49      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.59      0.55      0.54     10000\n",
            "weighted avg       0.59      0.56      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 872    2    3    5    0   25    3   49   13    8]\n",
            " [   0 1126    0    1    0    0    3    2    3    0]\n",
            " [  43  333  264    8   19    4   49   99   76  137]\n",
            " [  20  129    5  331    3    3    2  112  367   38]\n",
            " [  11   22   91   27  603   11   30   26   88   73]\n",
            " [  39   97   33  141   13   77   13   39  316  124]\n",
            " [  32   61   17   33   16   11  654   14   99   21]\n",
            " [  22   54    5   14    8    1    5  681    8  230]\n",
            " [   9  303    4   51    4    6   20    2  468  107]\n",
            " [  16   19   18   38  151   12    1   46  145  563]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['8' '0' '4' ... '8' '6' '5']\n",
            "probabilities: (59600, 10) \n",
            " [8 0 4 ... 8 6 5]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [ 24  13  61  33  32 147  45  38  38  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.338 s \n",
            "\n",
            "Accuracy rate for 57.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       980\n",
            "           1       0.52      0.99      0.68      1135\n",
            "           2       0.74      0.32      0.45      1032\n",
            "           3       0.50      0.51      0.50      1010\n",
            "           4       0.68      0.70      0.69       982\n",
            "           5       0.36      0.07      0.12       892\n",
            "           6       0.85      0.66      0.74       958\n",
            "           7       0.72      0.69      0.70      1028\n",
            "           8       0.30      0.49      0.37       974\n",
            "           9       0.48      0.43      0.45      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.60      0.57      0.55     10000\n",
            "weighted avg       0.60      0.58      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 777    3    3   32    0   74   13   53   12   13]\n",
            " [   0 1129    0    1    0    1    2    2    0    0]\n",
            " [  12  334  333   10   31    3   47   92   71   99]\n",
            " [   3  135    5  512    2    0    5   52  278   18]\n",
            " [   6   21   29   37  683   18   16   14  128   30]\n",
            " [  31   92   21  210   33   64    9   34  325   73]\n",
            " [  45   68   31   49   33    6  636    8   79    3]\n",
            " [  16   51    5   22   13    2    7  707   11  194]\n",
            " [   7  333   18   64    5    4   15    2  476   50]\n",
            " [   8   22    2   87  201    7    2   22  221  437]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['8' '0' '4' ... '8' '6' '9']\n",
            "probabilities: (59550, 10) \n",
            " [8 0 4 ... 8 6 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 36  17  70  33  37 157  47  41  40  22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.385 s \n",
            "\n",
            "Accuracy rate for 57.780000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.92      0.83       980\n",
            "           1       0.52      0.99      0.68      1135\n",
            "           2       0.63      0.33      0.44      1032\n",
            "           3       0.48      0.60      0.54      1010\n",
            "           4       0.70      0.65      0.68       982\n",
            "           5       0.33      0.11      0.17       892\n",
            "           6       0.75      0.53      0.62       958\n",
            "           7       0.85      0.71      0.77      1028\n",
            "           8       0.32      0.46      0.38       974\n",
            "           9       0.53      0.37      0.44      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.59      0.57      0.55     10000\n",
            "weighted avg       0.59      0.58      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    3   25   16    0   19    5    6    4    3]\n",
            " [   0 1124    0    5    0    0    0    0    6    0]\n",
            " [  56  327  342   27    8    2   83   51   61   75]\n",
            " [  25  135    6  608    0    2    1   28  188   17]\n",
            " [   9   39   25   47  642   61   28    5  103   23]\n",
            " [  65   74   32  239   19  100   18   11  288   46]\n",
            " [  95   27   75   76   56   38  508    8   73    2]\n",
            " [  13   96    5   25    6   11    4  729    9  130]\n",
            " [   9  286   18  114    4   19   33    4  449   38]\n",
            " [  18   42   12  104  181   50    1   13  211  377]]\n",
            "--------------------------------\n",
            "final active learning accuracies [66.08000000000001, 57.67, 57.45, 56.36, 51.31, 53.7, 54.21, 56.38999999999999, 57.54, 57.78]\n",
            "saved Active-learning-experiment-43.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 44, using model = LogModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [1 3 2 3 3 4 5 2 2] [0 1 2 3 4 5 6 7 8]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.226 s \n",
            "\n",
            "Accuracy rate for 51.880000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.82       980\n",
            "           1       0.71      0.55      0.62      1135\n",
            "           2       0.73      0.29      0.42      1032\n",
            "           3       0.35      0.84      0.50      1010\n",
            "           4       0.38      0.64      0.47       982\n",
            "           5       0.43      0.53      0.47       892\n",
            "           6       0.58      0.84      0.69       958\n",
            "           7       0.62      0.50      0.56      1028\n",
            "           8       0.59      0.20      0.30       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.52      0.52      0.48     10000\n",
            "weighted avg       0.52      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[804   0  15  14  40  39  60   4   4   0]\n",
            " [  1 620  14 423   6   0  64   0   7   0]\n",
            " [ 18  16 302 259  45   5 284  28  75   0]\n",
            " [ 39  30   6 849   5  27  27  18   9   0]\n",
            " [  3  21   4  42 627 139  25 116   5   0]\n",
            " [ 49  20  18 189  38 471  74   4  29   0]\n",
            " [ 24   2   5   4  74  31 807  11   0   0]\n",
            " [ 17  59  22 100 269  27  15 515   4   0]\n",
            " [ 26  48  22 458  33 134  32  28 193   0]\n",
            " [ 11  59   4  66 521 235   8 102   3   0]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) ['3' '0' '7' ... '5' '6' '5']\n",
            "probabilities: (59975, 9) \n",
            " [3 0 7 ... 5 6 5]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 4  3  3  5  4 14  5  6  3  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.273 s \n",
            "\n",
            "Accuracy rate for 51.820000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62       980\n",
            "           1       0.77      0.94      0.85      1135\n",
            "           2       0.73      0.32      0.45      1032\n",
            "           3       0.51      0.77      0.61      1010\n",
            "           4       0.41      0.82      0.54       982\n",
            "           5       0.97      0.07      0.14       892\n",
            "           6       0.54      0.86      0.67       958\n",
            "           7       0.48      0.06      0.11      1028\n",
            "           8       0.54      0.38      0.45       974\n",
            "           9       0.22      0.28      0.24      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.58      0.51      0.47     10000\n",
            "weighted avg       0.58      0.52      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 594    1   44   70   10    0  192    1   32   36]\n",
            " [   0 1062    0    5    0    0   13   11    3   41]\n",
            " [   3   24  334  151   78    0  262    1  137   42]\n",
            " [  38   39   28  777    7    0   32    5   32   52]\n",
            " [   0   31   11    5  808    2   28   31    3   63]\n",
            " [ 191   38   10  227   80   65  116    2   75   88]\n",
            " [  31    3    5   11   57    0  828    1   20    2]\n",
            " [  41   43    2   11  276    0   16   62    8  569]\n",
            " [  34   94   14  268   39    0   36    7  372  110]\n",
            " [  14   39    7   13  632    0    9    7    8  280]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '7' ... '0' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 7 ... 0 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 4  3  4  7  4 30  7  6  7  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.249 s \n",
            "\n",
            "Accuracy rate for 51.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.69      0.59       980\n",
            "           1       0.74      0.90      0.81      1135\n",
            "           2       0.57      0.47      0.52      1032\n",
            "           3       0.48      0.58      0.53      1010\n",
            "           4       0.40      0.77      0.53       982\n",
            "           5       0.81      0.14      0.24       892\n",
            "           6       0.61      0.79      0.69       958\n",
            "           7       0.45      0.15      0.22      1028\n",
            "           8       0.61      0.39      0.47       974\n",
            "           9       0.22      0.20      0.21      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.54      0.51      0.48     10000\n",
            "weighted avg       0.54      0.52      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 676    1  169   14    8   13   71   16    8    4]\n",
            " [   0 1027    6    5    0    0   30    2   47   18]\n",
            " [   9   55  489   96   77    0  231    9   37   29]\n",
            " [ 143   79  126  588    5    0   14   12   10   33]\n",
            " [   3   29    5    8  760    8   18   82   26   43]\n",
            " [ 283   20   15  200   52  125   58   10   75   54]\n",
            " [  50    3   10    7   97    1  757    6   27    0]\n",
            " [  80   52    2   13  233    3    6  152    6  481]\n",
            " [  50   88   33  255   23    1   60   13  375   76]\n",
            " [  30   41    0   40  644    4    4   35    6  205]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) ['3' '0' '7' ... '0' '6' '8']\n",
            "probabilities: (59925, 10) \n",
            " [3 0 7 ... 0 6 8]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  3  6  7  6 34  7  9 15  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.295 s \n",
            "\n",
            "Accuracy rate for 57.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.64      0.66       980\n",
            "           1       0.77      0.94      0.85      1135\n",
            "           2       0.61      0.42      0.50      1032\n",
            "           3       0.53      0.75      0.62      1010\n",
            "           4       0.46      0.89      0.61       982\n",
            "           5       0.85      0.03      0.06       892\n",
            "           6       0.58      0.88      0.70       958\n",
            "           7       0.77      0.41      0.53      1028\n",
            "           8       0.46      0.63      0.53       974\n",
            "           9       0.29      0.09      0.14      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.60      0.57      0.52     10000\n",
            "weighted avg       0.60      0.58      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 629    1  175   69    9    0   45    6   46    0]\n",
            " [   0 1070    5    4    0    0   40    3    8    5]\n",
            " [   8   33  434  125   23    0  310    4   87    8]\n",
            " [   9   73   38  757    6    0   14   18   87    8]\n",
            " [   0   19    2    3  877    1   39   12   18   11]\n",
            " [ 214   29   13  272   60   29   63   13  192    7]\n",
            " [   9    2   10   10   77    0  844    3    3    0]\n",
            " [  41   64   12   11  156    2   14  418  138  172]\n",
            " [   1   57   15  153   26    0   85   17  613    7]\n",
            " [   5   33    3   18  659    2    4   46  149   90]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '7' ... '8' '6' '7']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 7 ... 8 6 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 7  3  6  7  6 37  8 27 16  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.258 s \n",
            "\n",
            "Accuracy rate for 58.070000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.60      0.64       980\n",
            "           1       0.75      0.94      0.83      1135\n",
            "           2       0.57      0.38      0.46      1032\n",
            "           3       0.50      0.75      0.60      1010\n",
            "           4       0.46      0.90      0.61       982\n",
            "           5       0.72      0.10      0.18       892\n",
            "           6       0.55      0.80      0.65       958\n",
            "           7       0.79      0.66      0.72      1028\n",
            "           8       0.56      0.52      0.54       974\n",
            "           9       0.28      0.07      0.12      1009\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.59      0.57      0.53     10000\n",
            "weighted avg       0.59      0.58      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 587    1  179   88   24    1   82    8    5    5]\n",
            " [   0 1070    0    6    0    1   35    0   23    0]\n",
            " [   6   60  392  129   38    1  289   27   85    5]\n",
            " [  16   69   62  760    3    1   19   28   47    5]\n",
            " [   3   25    3    4  888    3   22    5   20    9]\n",
            " [ 207   23   11  299   78   89   82   11   77   15]\n",
            " [  13    4    7   10  151    0  762    3    8    0]\n",
            " [  19   59    5    7   57   14    8  675   40  144]\n",
            " [   9   82   20  204   40    8   81   15  509    6]\n",
            " [   6   36    3   27  666    5    3   85  103   75]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) ['3' '0' '4' ... '8' '6' '5']\n",
            "probabilities: (59875, 10) \n",
            " [3 0 4 ... 8 6 5]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 8  3 13 12  7 42  9 28 17 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.285 s \n",
            "\n",
            "Accuracy rate for 52.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.63      0.61       980\n",
            "           1       0.75      0.72      0.73      1135\n",
            "           2       0.62      0.18      0.27      1032\n",
            "           3       0.49      0.63      0.55      1010\n",
            "           4       0.49      0.85      0.63       982\n",
            "           5       0.54      0.02      0.05       892\n",
            "           6       0.48      0.81      0.60       958\n",
            "           7       0.71      0.71      0.71      1028\n",
            "           8       0.37      0.65      0.47       974\n",
            "           9       0.23      0.05      0.08      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.53      0.52      0.47     10000\n",
            "weighted avg       0.53      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[616   0  64  20  53   1 145  11  42  28]\n",
            " [  5 814   0  24   0   0  25   0 266   1]\n",
            " [ 34  27 181  49  45   0 461  29 201   5]\n",
            " [ 36  95   3 636   9   1  42  48 137   3]\n",
            " [  4  20  12  15 837   9  17  28  38   2]\n",
            " [242  11   6 245  75  22  77  22 179  13]\n",
            " [ 21   3  11  13 120   1 776   1  12   0]\n",
            " [ 34  30   5  22  37   4   6 725  46 119]\n",
            " [ 34  57   3 132  25   1  64  24 630   4]\n",
            " [  7  31   8 133 493   2   6 133 145  51]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '8' '0' '0']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 8 0 0]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [ 8  3 14 13 14 48 10 28 20 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.369 s \n",
            "\n",
            "Accuracy rate for 52.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.59      0.58       980\n",
            "           1       0.74      0.95      0.83      1135\n",
            "           2       0.43      0.25      0.31      1032\n",
            "           3       0.46      0.59      0.52      1010\n",
            "           4       0.48      0.61      0.54       982\n",
            "           5       0.50      0.02      0.04       892\n",
            "           6       0.58      0.85      0.69       958\n",
            "           7       0.56      0.72      0.63      1028\n",
            "           8       0.38      0.60      0.46       974\n",
            "           9       0.21      0.02      0.03      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.49      0.52      0.46     10000\n",
            "weighted avg       0.49      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 580    0   97   16    0    5   61   14  204    3]\n",
            " [   1 1075    1   21    0    1    8    0   28    0]\n",
            " [  42   98  257   58   23    1  333   65  155    0]\n",
            " [  27   72    6  595   18    3   17   44  227    1]\n",
            " [  12   16  127    7  595    1   45  161   16    2]\n",
            " [ 260   17   16  214   51   17   59   17  231   10]\n",
            " [  29    9   24   17   33    2  815    8   21    0]\n",
            " [  25   60    8   27   87    2    8  742   14   55]\n",
            " [  45   87    7  143   39    1   48   23  581    0]\n",
            " [  13   20   58  185  386    1    7  261   59   19]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) ['3' '0' '2' ... '4' '0' '0']\n",
            "probabilities: (59825, 10) \n",
            " [3 0 2 ... 4 0 0]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 8  3 15 14 24 52 11 30 23 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.363 s \n",
            "\n",
            "Accuracy rate for 52.520000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.68      0.63       980\n",
            "           1       0.52      0.99      0.68      1135\n",
            "           2       0.48      0.25      0.33      1032\n",
            "           3       0.51      0.57      0.53      1010\n",
            "           4       0.48      0.70      0.57       982\n",
            "           5       0.32      0.02      0.04       892\n",
            "           6       0.57      0.83      0.68       958\n",
            "           7       0.70      0.71      0.71      1028\n",
            "           8       0.37      0.39      0.38       974\n",
            "           9       0.26      0.03      0.05      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.48      0.52      0.46     10000\n",
            "weighted avg       0.48      0.53      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 663    2   75    7    7    3   52   30  138    3]\n",
            " [   0 1125    0    3    0    1    5    0    1    0]\n",
            " [  47  248  254   21   43    2  299   61   55    2]\n",
            " [  29  198    4  572   15    3   19   28  141    1]\n",
            " [  11   41   90   11  687   11   42   75   14    0]\n",
            " [ 266   43   14  236   54   20   60   17  172   10]\n",
            " [  34   21   30   28   31    3  791    5   15    0]\n",
            " [  23  104    8   11   46    8   30  735    6   57]\n",
            " [  55  318   10  109   10    4   72   16  379    1]\n",
            " [  10   58   40  134  543    8   13   86   91   26]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '1' ... '8' '0' '0']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 1 ... 8 0 0]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [ 9  3 19 17 26 54 12 36 26 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.384 s \n",
            "\n",
            "Accuracy rate for 55.410000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.86      0.74       980\n",
            "           1       0.53      0.99      0.69      1135\n",
            "           2       0.57      0.29      0.39      1032\n",
            "           3       0.45      0.32      0.37      1010\n",
            "           4       0.52      0.75      0.61       982\n",
            "           5       0.41      0.03      0.06       892\n",
            "           6       0.62      0.83      0.71       958\n",
            "           7       0.70      0.84      0.76      1028\n",
            "           8       0.40      0.55      0.46       974\n",
            "           9       0.06      0.00      0.00      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.49      0.55      0.48     10000\n",
            "weighted avg       0.49      0.55      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 843    2   22    3    1    3   34   24   48    0]\n",
            " [   0 1118    3    2    0    0    7    0    5    0]\n",
            " [  49  224  300   16   33    1  263   59   87    0]\n",
            " [  79  275    6  321   16    5   21   61  226    0]\n",
            " [  11   35   78   20  734   13   28   46   17    0]\n",
            " [ 215   50   10  168   52   27   66   17  283    4]\n",
            " [  33   19   35    6   42    6  798    1   18    0]\n",
            " [  18   68   11    9   17    3   11  867   13   11]\n",
            " [  22  276   21   36   10    4   60   13  532    0]\n",
            " [  16   47   37  139  501    4    5  155  104    1]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) ['8' '0' '1' ... '5' '0' '0']\n",
            "probabilities: (59775, 10) \n",
            " [8 0 1 ... 5 0 0]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 9  3 23 21 28 58 13 41 28 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.305 s \n",
            "\n",
            "Accuracy rate for 53.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.81      0.71       980\n",
            "           1       0.64      0.97      0.77      1135\n",
            "           2       0.67      0.21      0.32      1032\n",
            "           3       0.44      0.18      0.25      1010\n",
            "           4       0.50      0.80      0.61       982\n",
            "           5       0.41      0.02      0.04       892\n",
            "           6       0.55      0.85      0.67       958\n",
            "           7       0.69      0.82      0.75      1028\n",
            "           8       0.33      0.67      0.44       974\n",
            "           9       0.41      0.01      0.02      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.53      0.53      0.46     10000\n",
            "weighted avg       0.53      0.54      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 792    1    7    2    0    1   58    4  115    0]\n",
            " [   0 1097    0    7    0    1   11    0   19    0]\n",
            " [  42  161  217   23   21    2  292   87  187    0]\n",
            " [  46  136    4  178   10    5   71   37  521    2]\n",
            " [  22   22   41    4  789    3   34   51   16    0]\n",
            " [ 239   24    8  101   59   17   94    6  342    2]\n",
            " [  22   16    8    8   61    2  811    4   26    0]\n",
            " [  41   65    5    1   35    3   19  841   11    7]\n",
            " [  15  154   11   21   20    3   86   14  648    2]\n",
            " [  27   26   21   60  595    4    5  183   79    9]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['6' '0' '1' ... '5' '6' '9']\n",
            "probabilities: (59750, 10) \n",
            " [6 0 1 ... 5 6 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [ 9  4 27 28 31 61 13 43 30 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.352 s \n",
            "\n",
            "Accuracy rate for 53.700000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.86      0.67       980\n",
            "           1       0.78      0.89      0.83      1135\n",
            "           2       0.61      0.23      0.33      1032\n",
            "           3       0.46      0.13      0.21      1010\n",
            "           4       0.53      0.71      0.61       982\n",
            "           5       0.42      0.03      0.05       892\n",
            "           6       0.59      0.85      0.70       958\n",
            "           7       0.62      0.84      0.71      1028\n",
            "           8       0.32      0.77      0.46       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.49      0.53      0.46     10000\n",
            "weighted avg       0.49      0.54      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 845    0    4    0    0    2   51    7   71    0]\n",
            " [   0 1011    4    8    0    1   13    4   94    0]\n",
            " [ 118  102  233    3   36    1  256  103  180    0]\n",
            " [ 102   49    7  134    7    7   60   35  609    0]\n",
            " [  27    7   67   13  694    6   26  107   34    1]\n",
            " [ 308   16    4   51   36   23   77    9  366    2]\n",
            " [  46    9    6    3   44    4  817    3   26    0]\n",
            " [  38   31   13    9   21    5   20  859   25    7]\n",
            " [  37   57    9   14   16    3   68   15  754    1]\n",
            " [  30   10   37   56  456    3    5  248  164    0]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) ['6' '0' '1' ... '8' '0' '0']\n",
            "probabilities: (59725, 10) \n",
            " [6 0 1 ... 8 0 0]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 9  5 29 30 33 64 15 53 31 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.326 s \n",
            "\n",
            "Accuracy rate for 54.740000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.87      0.64       980\n",
            "           1       0.77      0.95      0.85      1135\n",
            "           2       0.54      0.23      0.32      1032\n",
            "           3       0.46      0.20      0.28      1010\n",
            "           4       0.51      0.75      0.61       982\n",
            "           5       0.47      0.03      0.05       892\n",
            "           6       0.59      0.84      0.69       958\n",
            "           7       0.82      0.79      0.81      1028\n",
            "           8       0.33      0.75      0.46       974\n",
            "           9       0.11      0.00      0.01      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.51      0.54      0.47     10000\n",
            "weighted avg       0.52      0.55      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 848    0    9    0    0    0   13   13   97    0]\n",
            " [   2 1082    2   12    0    0   12    1   24    0]\n",
            " [ 169  115  237    2   19    0  233   29  228    0]\n",
            " [ 121   28    5  200   12    8   37   41  557    1]\n",
            " [  18    8   88   17  732    6   76   10   27    0]\n",
            " [ 351   21    7   55   42   23   55   16  321    1]\n",
            " [  62   15   10    2   18    0  802    0   49    0]\n",
            " [  27   51   16   12   26    3   24  816   26   27]\n",
            " [  46   68    5   23   12    3   79    6  730    2]\n",
            " [  19   11   61  113  568    6   22   61  144    4]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['6' '0' '1' ... '5' '0' '8']\n",
            "probabilities: (59700, 10) \n",
            " [6 0 1 ... 5 0 8]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [ 9  6 34 31 34 71 15 60 34 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 51.870000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.94      0.64       980\n",
            "           1       0.69      0.72      0.70      1135\n",
            "           2       0.68      0.12      0.20      1032\n",
            "           3       0.39      0.18      0.24      1010\n",
            "           4       0.51      0.78      0.61       982\n",
            "           5       0.51      0.06      0.10       892\n",
            "           6       0.63      0.82      0.71       958\n",
            "           7       0.84      0.74      0.79      1028\n",
            "           8       0.31      0.79      0.45       974\n",
            "           9       0.33      0.02      0.04      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.54      0.52      0.45     10000\n",
            "weighted avg       0.54      0.52      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[920   7   0   0   5   3  10   8  27   0]\n",
            " [  8 816   4  56   0   1  10   1 239   0]\n",
            " [220 180 121   7  69   2 192  47 193   1]\n",
            " [157  24   1 179   9  12  45  32 547   4]\n",
            " [ 39  13  19  20 763  12  53   9  52   2]\n",
            " [350  25   1  42  54  50  47   5 315   3]\n",
            " [ 77  24   3   1  36   4 784   2  27   0]\n",
            " [ 41  61   6  12  47   4  26 762  38  31]\n",
            " [ 54  31   1  31  12   6  62   4 771   2]\n",
            " [ 33   8  23 115 508   4  19  39 239  21]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) ['6' '0' '1' ... '8' '0' '9']\n",
            "probabilities: (59675, 10) \n",
            " [6 0 1 ... 8 0 9]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 9 26 36 31 35 72 15 61 34 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.366 s \n",
            "\n",
            "Accuracy rate for 45.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.93      0.69       980\n",
            "           1       0.43      0.24      0.31      1135\n",
            "           2       0.64      0.17      0.27      1032\n",
            "           3       0.30      0.25      0.27      1010\n",
            "           4       0.53      0.70      0.60       982\n",
            "           5       0.56      0.05      0.09       892\n",
            "           6       0.39      0.87      0.54       958\n",
            "           7       0.87      0.65      0.74      1028\n",
            "           8       0.32      0.70      0.43       974\n",
            "           9       0.51      0.04      0.08      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.51      0.46      0.40     10000\n",
            "weighted avg       0.51      0.46      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[914   1   1   0   3   1  24   1  35   0]\n",
            " [  0 273   1 275   0   0 471   7 108   0]\n",
            " [171 240 178  16  41   1 252  24 109   0]\n",
            " [ 96  18   1 257   9   7  74  22 523   3]\n",
            " [ 36   3  43  25 690  14  99  14  57   1]\n",
            " [264   1   1  94  39  46  89   3 349   6]\n",
            " [ 58   6   5   4  21   3 838   1  22   0]\n",
            " [ 50  22  20  18  37   2 121 670  57  31]\n",
            " [ 32  77   1  62   9   5 103   2 682   1]\n",
            " [ 35   1  25 120 460   3  74  28 220  43]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['6' '0' '1' ... '8' '0' '8']\n",
            "probabilities: (59650, 10) \n",
            " [6 0 1 ... 8 0 8]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [11 39 37 31 36 74 15 61 38 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.340 s \n",
            "\n",
            "Accuracy rate for 56.630000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.96      0.72       980\n",
            "           1       0.58      0.97      0.72      1135\n",
            "           2       0.78      0.25      0.38      1032\n",
            "           3       0.51      0.40      0.45      1010\n",
            "           4       0.52      0.82      0.64       982\n",
            "           5       0.65      0.06      0.11       892\n",
            "           6       0.56      0.86      0.68       958\n",
            "           7       0.92      0.56      0.69      1028\n",
            "           8       0.46      0.52      0.49       974\n",
            "           9       0.40      0.20      0.27      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.59      0.56      0.51     10000\n",
            "weighted avg       0.60      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    2    0    1    3    3   20    0    9    4]\n",
            " [   0 1101    0   11    0    0   20    0    3    0]\n",
            " [  81  345  256   14   52    1  206   16   42   19]\n",
            " [ 151   97    1  403    7    8   54   11  261   17]\n",
            " [   9   23   30   17  802    5   69    2   12   13]\n",
            " [ 326    7    4  130   73   53   95    4  181   19]\n",
            " [  47   41    4    2   25    2  827    0   10    0]\n",
            " [  31   85    8   11   59    3   56  573   12  190]\n",
            " [  36  188    2   83   13    5  102    1  506   38]\n",
            " [  18   25   22  125  497    2   35   19   62  204]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) ['6' '0' '1' ... '5' '4' '9']\n",
            "probabilities: (59625, 10) \n",
            " [6 0 1 ... 5 4 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [11 40 38 38 38 81 15 65 40 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.342 s \n",
            "\n",
            "Accuracy rate for 52.890000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.92      0.73       980\n",
            "           1       0.59      0.95      0.73      1135\n",
            "           2       0.70      0.24      0.36      1032\n",
            "           3       0.49      0.11      0.18      1010\n",
            "           4       0.47      0.76      0.58       982\n",
            "           5       0.74      0.09      0.16       892\n",
            "           6       0.48      0.90      0.62       958\n",
            "           7       0.83      0.59      0.69      1028\n",
            "           8       0.35      0.65      0.46       974\n",
            "           9       0.31      0.02      0.04      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.56      0.52      0.45     10000\n",
            "weighted avg       0.56      0.53      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    2    1    2    6    3   32    1   29    0]\n",
            " [   0 1082    0    1    0    0   46    0    6    0]\n",
            " [  87  333  247    4   33    1  229   42   55    1]\n",
            " [ 171   78    4  110    7    5   92   11  528    4]\n",
            " [   6   22   50    5  742    8  102   25   21    1]\n",
            " [ 246    9    5   37   74   81  114    2  321    3]\n",
            " [  26   26    4    1   22    2  861    3   13    0]\n",
            " [  23   93    7    5   95    3  128  610   30   34]\n",
            " [  29  156    2   18   19    3  113    1  632    1]\n",
            " [  14   37   34   40  578    3   83   40  160   20]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['6' '0' '1' ... '8' '4' '4']\n",
            "probabilities: (59600, 10) \n",
            " [6 0 1 ... 8 4 4]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [11 40 39 52 38 86 15 65 43 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.388 s \n",
            "\n",
            "Accuracy rate for 54.940000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.93      0.76       980\n",
            "           1       0.55      0.97      0.70      1135\n",
            "           2       0.77      0.23      0.35      1032\n",
            "           3       0.44      0.44      0.44      1010\n",
            "           4       0.52      0.70      0.60       982\n",
            "           5       0.60      0.09      0.15       892\n",
            "           6       0.48      0.90      0.63       958\n",
            "           7       0.72      0.68      0.70      1028\n",
            "           8       0.46      0.48      0.47       974\n",
            "           9       0.28      0.01      0.03      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.55      0.54      0.48     10000\n",
            "weighted avg       0.55      0.55      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    2    1    5    3    4   47    1    8    0]\n",
            " [   0 1100    0    1    0    2   31    0    1    0]\n",
            " [  54  349  233   34   17    5  231   75   33    1]\n",
            " [ 113   80    1  442    8   10   83   28  243    2]\n",
            " [  10   28   33   17  690    8  121   66    6    3]\n",
            " [ 235    9    3  218   57   77  111    5  177    0]\n",
            " [  26   27    6    2   21    7  860    3    6    0]\n",
            " [  24  102    3    4   56    3   94  704    8   30]\n",
            " [  24  261    1   58   20   11  130    3  464    2]\n",
            " [  14   43   20  231  450    1   77   96   62   15]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) ['6' '0' '1' ... '3' '4' '4']\n",
            "probabilities: (59575, 10) \n",
            " [6 0 1 ... 3 4 4]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [11 40 40 55 40 92 17 65 54 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.433 s \n",
            "\n",
            "Accuracy rate for 56.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.97      0.69       980\n",
            "           1       0.55      0.98      0.70      1135\n",
            "           2       0.74      0.23      0.35      1032\n",
            "           3       0.49      0.48      0.49      1010\n",
            "           4       0.50      0.75      0.60       982\n",
            "           5       0.61      0.05      0.10       892\n",
            "           6       0.56      0.83      0.67       958\n",
            "           7       0.81      0.71      0.76      1028\n",
            "           8       0.50      0.52      0.51       974\n",
            "           9       0.46      0.01      0.01      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.58      0.55      0.49     10000\n",
            "weighted avg       0.58      0.56      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    2    1    3    3    4    7    2    7    0]\n",
            " [   0 1111    0    0    0    0   19    1    4    0]\n",
            " [  97  371  236   17   42    1  179   69   20    0]\n",
            " [ 175   88    1  489    7    6   46   22  176    0]\n",
            " [  14   27   31   40  736    4   82   18   29    1]\n",
            " [ 374    8    5  156   66   46   78    4  155    0]\n",
            " [  51   46    7    7   28    3  796    4   16    0]\n",
            " [  40  103   13    7   53    3   70  727    7    5]\n",
            " [  53  241    2   56   18    6   90    4  503    1]\n",
            " [  23   37   22  217  512    3   49   43   97    6]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['6' '0' '1' ... '8' '4' '4']\n",
            "probabilities: (59550, 10) \n",
            " [6 0 1 ... 8 4 4]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [11 40 41 58 41 97 19 69 61 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.423 s \n",
            "\n",
            "Accuracy rate for 56.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.97      0.69       980\n",
            "           1       0.53      0.99      0.69      1135\n",
            "           2       0.84      0.15      0.26      1032\n",
            "           3       0.51      0.54      0.52      1010\n",
            "           4       0.51      0.79      0.62       982\n",
            "           5       0.54      0.10      0.16       892\n",
            "           6       0.63      0.76      0.69       958\n",
            "           7       0.81      0.74      0.78      1028\n",
            "           8       0.47      0.52      0.50       974\n",
            "           9       0.70      0.01      0.01      1009\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.61      0.56      0.49     10000\n",
            "weighted avg       0.61      0.56      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2    0    2    4    6    5    3    6    0]\n",
            " [   0 1118    0    1    0    1   12    0    3    0]\n",
            " [ 159  383  157   10   78    6   82   85   72    0]\n",
            " [ 147  109    1  542    9   25   47   16  114    0]\n",
            " [  16   29   12   34  780    6   57   17   28    3]\n",
            " [ 338   10    0  171   75   86   87    2  123    0]\n",
            " [  58   55    3    8   69   11  731    4   19    0]\n",
            " [  34  101    4    7   44    3   42  765   28    0]\n",
            " [  44  268    1   57   21   12   61    2  508    0]\n",
            " [  24   41    8  223  454    3   30   49  170    7]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) ['3' '0' '1' ... '5' '4' '8']\n",
            "probabilities: (59525, 10) \n",
            " [3 0 1 ... 5 4 8]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 12  40  48  61  46 101  19  69  64  40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.365 s \n",
            "\n",
            "Accuracy rate for 56.520000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.98      0.61       980\n",
            "           1       0.54      0.99      0.70      1135\n",
            "           2       0.73      0.27      0.39      1032\n",
            "           3       0.47      0.46      0.46      1010\n",
            "           4       0.62      0.70      0.66       982\n",
            "           5       0.50      0.12      0.20       892\n",
            "           6       0.68      0.75      0.72       958\n",
            "           7       0.86      0.76      0.81      1028\n",
            "           8       0.48      0.50      0.49       974\n",
            "           9       0.51      0.05      0.09      1009\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.58      0.56      0.51     10000\n",
            "weighted avg       0.58      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    2    0    1    3    9    3    1    4    0]\n",
            " [   0 1121    0    1    0    1    9    1    2    0]\n",
            " [ 171  360  278    8   20    5   97   56   37    0]\n",
            " [ 262  100    3  460    6   37   23   17  101    1]\n",
            " [  32   29   37   56  691   17   54   10   33   23]\n",
            " [ 473   11    1  130   27  109   48    1   89    3]\n",
            " [  94   53   23   14   11   19  720    1   23    0]\n",
            " [  38   99    5    5   15    7   30  781   27   21]\n",
            " [ 107  265    9   44    3   12   45    3  485    1]\n",
            " [  35   42   23  252  346    4   24   34  199   50]]\n",
            "--------------------------------\n",
            "final active learning accuracies [51.88, 51.82, 51.54, 57.60999999999999, 58.07, 52.88, 52.76, 52.52, 55.410000000000004, 53.99, 53.7, 54.74, 51.870000000000005, 45.910000000000004, 56.63, 52.89, 54.94, 56.010000000000005, 56.46, 56.52]\n",
            "saved Active-learning-experiment-44.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 45, using model = LogModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [0 0 0 2 1 1 0 3 0 3] [3 4 5 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.238 s \n",
            "\n",
            "Accuracy rate for 24.460000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.18      0.97      0.30      1010\n",
            "           4       0.15      0.25      0.19       982\n",
            "           5       0.67      0.19      0.29       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.61      0.61      0.61      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.28      0.42      0.34      1009\n",
            "\n",
            "    accuracy                           0.24     10000\n",
            "   macro avg       0.19      0.24      0.17     10000\n",
            "weighted avg       0.18      0.24      0.17     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   0 592 307   6   0   1   0  74]\n",
            " [  0   0   0 777 349   7   0   0   0   2]\n",
            " [  0   0   0 771  46   0   0  17   0 198]\n",
            " [  0   0   0 975   1   4   0  14   0  16]\n",
            " [  0   0   0 287 249  15   0  89   0 342]\n",
            " [  0   0   0 540  71 166   0   4   0 111]\n",
            " [  0   0   0 440 384  12   0   0   0 122]\n",
            " [  0   0   0 173  40   0   0 630   0 185]\n",
            " [  0   0   0 742 137  35   0  20   0  40]\n",
            " [  0   0   0 247  79   2   0 255   0 426]]\n",
            "--------------------------------\n",
            "val predicted: (59990,) ['3' '3' '9' ... '3' '3' '4']\n",
            "probabilities: (59990, 5) \n",
            " [0 0 4 ... 0 0 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [0 0 0 2 5 1 2 3 2 5] [3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.211 s \n",
            "\n",
            "Accuracy rate for 40.240000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.25      0.90      0.39      1010\n",
            "           4       0.49      0.73      0.59       982\n",
            "           5       0.61      0.09      0.15       892\n",
            "           6       0.67      0.64      0.65       958\n",
            "           7       0.79      0.74      0.76      1028\n",
            "           8       0.32      0.48      0.38       974\n",
            "           9       0.34      0.47      0.40      1009\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.35      0.41      0.33     10000\n",
            "weighted avg       0.34      0.40      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   0 444  18  35 142  22   4 315]\n",
            " [  0   0   0 539  25   0   6   0 557   8]\n",
            " [  0   0   0 609  65   0  83  40  31 204]\n",
            " [  0   0   0 905   5   3   5  10  55  27]\n",
            " [  0   0   0  92 720   0   9  25  33 103]\n",
            " [  0   0   0 420 132  76  38   2 104 120]\n",
            " [  0   0   0 177 111   0 612   1  12  45]\n",
            " [  0   0   0  76  46   0   0 765  89  52]\n",
            " [  0   0   0 331 104  10  24   5 471  29]\n",
            " [  0   0   0  68 234   1   0 104 127 475]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) ['3' '3' '9' ... '3' '6' '8']\n",
            "probabilities: (59980, 7) \n",
            " [0 0 6 ... 0 3 5]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [3 5 0 2 5 2 2 3 2 6] [0 1 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.209 s \n",
            "\n",
            "Accuracy rate for 50.260000 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.37      0.52       980\n",
            "           1       0.86      0.51      0.64      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.25      0.93      0.39      1010\n",
            "           4       0.48      0.75      0.58       982\n",
            "           5       0.68      0.30      0.42       892\n",
            "           6       0.72      0.70      0.71       958\n",
            "           7       0.76      0.74      0.75      1028\n",
            "           8       0.42      0.39      0.41       974\n",
            "           9       0.81      0.33      0.47      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.59      0.50      0.49     10000\n",
            "weighted avg       0.59      0.50      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[365   0   0 438  32  66  47  25   5   2]\n",
            " [  0 575   0 383   4   0   4   0 169   0]\n",
            " [  2   5   0 705 131   3 112  45  26   3]\n",
            " [  0   5   0 939   6   2   6   8  40   4]\n",
            " [  4  16   0 119 735   0  15  29  29  35]\n",
            " [ 14  14   0 382 121 268  37   3  47   6]\n",
            " [  6   8   0 187  63  23 667   0   4   0]\n",
            " [  4  16   0  91  53   0   1 758  79  26]\n",
            " [ 17  12   0 422  71  30  30   8 382   2]\n",
            " [  8  15   0  82 324   3   1 116 123 337]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) ['3' '3' '4' ... '3' '6' '4']\n",
            "probabilities: (59970, 9) \n",
            " [2 2 3 ... 2 5 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [4 5 1 3 5 4 2 8 2 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.278 s \n",
            "\n",
            "Accuracy rate for 48.340000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.31      0.45       980\n",
            "           1       0.78      0.56      0.65      1135\n",
            "           2       0.08      0.02      0.04      1032\n",
            "           3       0.29      0.90      0.43      1010\n",
            "           4       0.42      0.85      0.56       982\n",
            "           5       0.58      0.29      0.39       892\n",
            "           6       0.71      0.65      0.68       958\n",
            "           7       0.88      0.53      0.66      1028\n",
            "           8       0.40      0.41      0.41       974\n",
            "           9       0.70      0.31      0.43      1009\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.57      0.48      0.47     10000\n",
            "weighted avg       0.57      0.48      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[304   0 179 350   5  85  45   8   0   4]\n",
            " [  0 634   0 176   4   0   5   0 316   0]\n",
            " [ 11   8  25 631 153   4 137  13  42   8]\n",
            " [  1  23   1 907  15   4   8   7  33  11]\n",
            " [  6  20  16  45 831   0  11  21  14  18]\n",
            " [ 14  35   3 434  57 261  28   6  42  12]\n",
            " [ 15   9  75 107  90  31 621   2   7   1]\n",
            " [  1  29   7  72 215   1   0 544  83  76]\n",
            " [  6  25   6 411  49  53  23   4 396   1]\n",
            " [  4  29   1  48 547   8   0  15  46 311]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) ['3' '3' '4' ... '3' '6' '4']\n",
            "probabilities: (59960, 10) \n",
            " [3 3 4 ... 3 6 4]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 4  5  3  6  6  6  2 10  2  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.278 s \n",
            "\n",
            "Accuracy rate for 51.360000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.72      0.78       980\n",
            "           1       0.74      0.61      0.67      1135\n",
            "           2       0.36      0.27      0.31      1032\n",
            "           3       0.48      0.78      0.60      1010\n",
            "           4       0.32      0.91      0.48       982\n",
            "           5       0.69      0.10      0.17       892\n",
            "           6       0.77      0.51      0.61       958\n",
            "           7       0.95      0.35      0.51      1028\n",
            "           8       0.38      0.54      0.45       974\n",
            "           9       0.58      0.31      0.40      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.61      0.51      0.50     10000\n",
            "weighted avg       0.61      0.51      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[705   0  98  81  18  21  25   3   4  25]\n",
            " [  0 690  38   5  27   0   4   0 371   0]\n",
            " [ 35  12 281  83 377   5  77   6 150   6]\n",
            " [ 12  21  35 791  58   4   7   2  70  10]\n",
            " [  6  18  10   9 896   0   6   2  10  25]\n",
            " [ 28  65  36 421  82  88  20   3 130  19]\n",
            " [ 33   6 224  23 166   5 488   3   6   4]\n",
            " [  3  29  39   4 385   0   0 362  74 132]\n",
            " [ 12  61  13 189 159   4   7   1 522   6]\n",
            " [  5  28   5  25 604   0   0   1  28 313]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59950, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 5  5  6  6  6 12  2 10  2  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.265 s \n",
            "\n",
            "Accuracy rate for 50.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.81      0.74       980\n",
            "           1       0.69      0.61      0.65      1135\n",
            "           2       0.54      0.09      0.15      1032\n",
            "           3       0.48      0.73      0.58      1010\n",
            "           4       0.31      0.90      0.46       982\n",
            "           5       0.69      0.07      0.13       892\n",
            "           6       0.78      0.55      0.65       958\n",
            "           7       0.92      0.37      0.53      1028\n",
            "           8       0.37      0.55      0.44       974\n",
            "           9       0.58      0.34      0.43      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.61      0.50      0.48     10000\n",
            "weighted avg       0.61      0.51      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[797   1   9  73  18  18  23   4   7  30]\n",
            " [  4 693   0   3  31   0   4   0 399   1]\n",
            " [121  24  91  85 469   0  73   6 156   7]\n",
            " [ 62  24   2 742  51   0   7   5  89  28]\n",
            " [  0  20  19  17 886   0   6   5  12  17]\n",
            " [ 47  71   7 403 108  66  21   7 148  14]\n",
            " [ 53  17  15  41 286   4 529   3   7   3]\n",
            " [  5  43  13   8 368   2   0 383  71 135]\n",
            " [ 70  76   2 150 114   3  11   2 540   6]\n",
            " [  7  35  10  31 554   2   0   1  30 339]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59940, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 5 10  7  6  6 13  3 10  4  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.250 s \n",
            "\n",
            "Accuracy rate for 51.270000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.69      0.72       980\n",
            "           1       0.92      0.58      0.71      1135\n",
            "           2       0.41      0.10      0.16      1032\n",
            "           3       0.48      0.77      0.59      1010\n",
            "           4       0.31      0.90      0.46       982\n",
            "           5       0.59      0.10      0.18       892\n",
            "           6       0.75      0.66      0.70       958\n",
            "           7       0.92      0.33      0.48      1028\n",
            "           8       0.36      0.53      0.43       974\n",
            "           9       0.53      0.44      0.49      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.60      0.51      0.49     10000\n",
            "weighted avg       0.61      0.51      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[678   0   4 105  10  28  62   4   4  85]\n",
            " [  0 660   8   5  66   1   5   0 390   0]\n",
            " [ 74  14 106  55 484   3  98   6 184   8]\n",
            " [ 30   8   6 779  41   0  16   3 107  20]\n",
            " [  1   4  17   9 883   6   3   4  20  35]\n",
            " [ 35   8  21 466 101  92  21  10 111  27]\n",
            " [ 40   2  13  24 183  10 629   1  45  11]\n",
            " [  1   8  52   3 409   3   0 339  20 193]\n",
            " [ 45   6  25 153 208   7   4   2 513  11]\n",
            " [  2   9   4  23 488   5   0   1  29 448]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) ['3' '0' '4' ... '3' '6' '4']\n",
            "probabilities: (59930, 10) \n",
            " [3 0 4 ... 3 6 4]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 6 10  8  6  6 19  4 10  5  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.324 s \n",
            "\n",
            "Accuracy rate for 52.380000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       980\n",
            "           1       0.83      0.76      0.79      1135\n",
            "           2       0.56      0.11      0.19      1032\n",
            "           3       0.49      0.76      0.59      1010\n",
            "           4       0.29      0.91      0.44       982\n",
            "           5       0.88      0.06      0.11       892\n",
            "           6       0.82      0.50      0.62       958\n",
            "           7       0.90      0.34      0.50      1028\n",
            "           8       0.42      0.60      0.49       974\n",
            "           9       0.48      0.30      0.37      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.65      0.52      0.49     10000\n",
            "weighted avg       0.65      0.52      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[821   1   3  62  10   1  12   8   5  57]\n",
            " [  0 857   1   3  71   0   1   1 201   0]\n",
            " [ 39  49 117  79 523   1  67   8 136  13]\n",
            " [ 20  16  12 769  35   0   8   6 123  21]\n",
            " [  0   7   8  13 896   0   2   3  37  16]\n",
            " [ 65  29  14 419  97  53  12   8 174  21]\n",
            " [ 45   8  16  41 316   3 481   3  32  13]\n",
            " [  1  24  25   5 427   1   0 353  11 181]\n",
            " [  3  14   9 166 185   1   3   2 587   4]\n",
            " [  5  22   5  24 556   0   0   1  92 304]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) ['3' '0' '4' ... '3' '4' '4']\n",
            "probabilities: (59920, 10) \n",
            " [3 0 4 ... 3 4 4]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 6 10  9  6  6 24  7 11  5  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.330 s \n",
            "\n",
            "Accuracy rate for 47.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.76      0.80       980\n",
            "           1       0.91      0.62      0.74      1135\n",
            "           2       0.50      0.08      0.13      1032\n",
            "           3       0.44      0.76      0.55      1010\n",
            "           4       0.26      0.91      0.40       982\n",
            "           5       0.84      0.11      0.20       892\n",
            "           6       0.79      0.28      0.42       958\n",
            "           7       0.90      0.29      0.44      1028\n",
            "           8       0.39      0.58      0.47       974\n",
            "           9       0.47      0.34      0.40      1009\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.63      0.47      0.45     10000\n",
            "weighted avg       0.64      0.48      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[746   0   1 133   8   7  11   7   6  61]\n",
            " [  0 701   0   9 130   1   0   1 293   0]\n",
            " [ 33  23  78 101 584   0  46   9 144  14]\n",
            " [  5   4  18 766  47   0   8   2 135  25]\n",
            " [  1   3   7  15 891   0   0   3  29  33]\n",
            " [ 31  11   6 458  96  99   6   4 154  27]\n",
            " [ 57   3  37  88 444   4 273   5  35  12]\n",
            " [  5  11   3   7 470   5   0 297  11 219]\n",
            " [  2   3   3 157 234   1   3   0 566   5]\n",
            " [  3  10   3  22 546   1   0   1  75 348]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) ['3' '0' '4' ... '3' '4' '4']\n",
            "probabilities: (59910, 10) \n",
            " [3 0 4 ... 3 4 4]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6 10  9  8  6 30  7 12  5  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.286 s \n",
            "\n",
            "Accuracy rate for 49.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       980\n",
            "           1       0.77      0.77      0.77      1135\n",
            "           2       0.69      0.09      0.15      1032\n",
            "           3       0.48      0.73      0.58      1010\n",
            "           4       0.27      0.94      0.41       982\n",
            "           5       0.82      0.15      0.25       892\n",
            "           6       0.66      0.48      0.56       958\n",
            "           7       0.97      0.20      0.34      1028\n",
            "           8       0.50      0.63      0.55       974\n",
            "           9       0.36      0.22      0.28      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.64      0.49      0.47     10000\n",
            "weighted avg       0.64      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[703   0   1 127   9  16  83   0   4  37]\n",
            " [  0 871   0  18  92   0   1   0 153   0]\n",
            " [ 34  70  88 103 549   0  79   0 102   7]\n",
            " [  8  55  10 738  40   1  33   1  92  32]\n",
            " [  0   9   6   2 920   0   1   0  28  16]\n",
            " [ 36  34   4 386 106 134  24   4 138  26]\n",
            " [ 17   9   6  23 424   2 460   0  11   6]\n",
            " [  4  30  10   5 485   8   3 209   5 269]\n",
            " [  6  27   1 102 208   2  13   0 611   4]\n",
            " [  2  25   2  23 638   1   1   2  88 227]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) ['3' '0' '4' ... '3' '4' '4']\n",
            "probabilities: (59900, 10) \n",
            " [3 0 4 ... 3 4 4]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 6 10  9 10  6 37  7 13  5  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.255 s \n",
            "\n",
            "Accuracy rate for 49.840000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       980\n",
            "           1       0.83      0.70      0.76      1135\n",
            "           2       0.45      0.07      0.13      1032\n",
            "           3       0.53      0.81      0.64      1010\n",
            "           4       0.26      0.90      0.40       982\n",
            "           5       1.00      0.03      0.05       892\n",
            "           6       0.81      0.35      0.49       958\n",
            "           7       0.96      0.25      0.40      1028\n",
            "           8       0.42      0.64      0.51       974\n",
            "           9       0.42      0.27      0.33      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.65      0.49      0.46     10000\n",
            "weighted avg       0.65      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[895   2   4  15   7   0  20   1   5  31]\n",
            " [  0 797   0   5 132   0   1   0 200   0]\n",
            " [ 65  57  76  41 563   0  46   2 177   5]\n",
            " [ 12  10   3 815  40   0   2   2 114  12]\n",
            " [  2   4  15  18 883   0   0   0  33  27]\n",
            " [ 60  27   5 427 111  25  10   4 185  38]\n",
            " [ 56   6  46  40 417   0 336   2  48   7]\n",
            " [ 10  24  12   8 455   0   0 259  12 248]\n",
            " [  4  11   2 117 209   0   2   0 624   5]\n",
            " [  6  17   7  47 567   0   0   1  90 274]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) ['3' '0' '4' ... '3' '4' '4']\n",
            "probabilities: (59890, 10) \n",
            " [3 0 4 ... 3 4 4]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 6 10 10 11  6 41 10 13  6  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.311 s \n",
            "\n",
            "Accuracy rate for 49.900000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       980\n",
            "           1       0.81      0.78      0.80      1135\n",
            "           2       0.63      0.05      0.09      1032\n",
            "           3       0.50      0.83      0.62      1010\n",
            "           4       0.25      0.89      0.40       982\n",
            "           5       0.80      0.02      0.04       892\n",
            "           6       0.77      0.31      0.44       958\n",
            "           7       0.86      0.33      0.48      1028\n",
            "           8       0.47      0.50      0.49       974\n",
            "           9       0.41      0.37      0.39      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.64      0.49      0.46     10000\n",
            "weighted avg       0.64      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[821   3   1  23  12   1  12  16   8  83]\n",
            " [  0 886   0   5 136   0   2   0 106   0]\n",
            " [ 43  70  50  76 611   2  55   6 110   9]\n",
            " [ 13  19   3 837  52   1   6   5  52  22]\n",
            " [  1   6   3  18 870   0   0   0  35  49]\n",
            " [ 40  35   6 433  93  20  10  21 150  84]\n",
            " [ 37  10  12  63 463   1 299   7  39  27]\n",
            " [  0  24   2   6 394   0   1 338   6 257]\n",
            " [  9  16   1 179 266   0   2   0 491  10]\n",
            " [  3  24   1  41 516   0   0   1  45 378]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) ['3' '0' '9' ... '3' '4' '9']\n",
            "probabilities: (59880, 10) \n",
            " [3 0 9 ... 3 4 9]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 7 10 10 11  6 46 13 14  6  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.263 s \n",
            "\n",
            "Accuracy rate for 49.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       980\n",
            "           1       0.75      0.81      0.78      1135\n",
            "           2       0.47      0.04      0.07      1032\n",
            "           3       0.45      0.85      0.59      1010\n",
            "           4       0.25      0.90      0.40       982\n",
            "           5       0.91      0.16      0.27       892\n",
            "           6       0.78      0.12      0.21       958\n",
            "           7       0.89      0.36      0.51      1028\n",
            "           8       0.50      0.51      0.50       974\n",
            "           9       0.44      0.21      0.28      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.63      0.49      0.45     10000\n",
            "weighted avg       0.62      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[892   2   2  45   9   1   1  13   4  11]\n",
            " [  0 914   0   7 110   0   0   0 104   0]\n",
            " [ 54 103  38 124 590   2  23   8  81   9]\n",
            " [ 12  31   2 859  49   1   6   2  43   5]\n",
            " [  2  11   8  23 888   1   0   0  41   8]\n",
            " [ 49  29   4 471  92 142   4  10  83   8]\n",
            " [ 61  30  19  94 562   4 119   8  54   7]\n",
            " [ 19  38   0   7 374   3   0 372   7 208]\n",
            " [  3  30   3 218 221   2   0   1 492   4]\n",
            " [  9  35   4  64 615   0   0   5  70 207]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) ['3' '0' '4' ... '3' '4' '9']\n",
            "probabilities: (59870, 10) \n",
            " [3 0 4 ... 3 4 9]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 8 12 10 11  6 47 16 14  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.266 s \n",
            "\n",
            "Accuracy rate for 46.600000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.87      0.82       980\n",
            "           1       0.82      0.70      0.75      1135\n",
            "           2       0.50      0.07      0.13      1032\n",
            "           3       0.46      0.86      0.60      1010\n",
            "           4       0.26      0.88      0.40       982\n",
            "           5       0.79      0.03      0.07       892\n",
            "           6       0.64      0.07      0.13       958\n",
            "           7       0.94      0.27      0.42      1028\n",
            "           8       0.38      0.52      0.43       974\n",
            "           9       0.40      0.32      0.35      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.60      0.46      0.41     10000\n",
            "weighted avg       0.60      0.47      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[855   1   5   8   8   0  38   2   7  56]\n",
            " [  0 795   1  10  61   1   0   0 267   0]\n",
            " [ 46  53  77  71 573   2   2   8 196   4]\n",
            " [ 16  14   6 870  61   0   0   1  26  16]\n",
            " [  4   6   4  26 865   0   0   0  17  60]\n",
            " [ 85  25   2 495  81  31   0   4 115  54]\n",
            " [ 71  15  54  87 563   3  70   3  52  40]\n",
            " [ 14  21   0   9 355   1   0 275 100 253]\n",
            " [  6  24   2 232 202   0   0   0 502   6]\n",
            " [  9  19   2  80 521   1   0   1  56 320]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) ['3' '0' '4' ... '3' '4' '8']\n",
            "probabilities: (59860, 10) \n",
            " [3 0 4 ... 3 4 8]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 8 13 11 11  6 52 17 15  9  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.311 s \n",
            "\n",
            "Accuracy rate for 46.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.92      0.82       980\n",
            "           1       0.72      0.76      0.74      1135\n",
            "           2       0.55      0.06      0.11      1032\n",
            "           3       0.46      0.86      0.60      1010\n",
            "           4       0.26      0.90      0.40       982\n",
            "           5       0.80      0.06      0.11       892\n",
            "           6       0.82      0.12      0.20       958\n",
            "           7       0.96      0.10      0.17      1028\n",
            "           8       0.45      0.46      0.46       974\n",
            "           9       0.36      0.30      0.33      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.61      0.45      0.39     10000\n",
            "weighted avg       0.61      0.46      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[905   1  15  14   7   0  10   0   7  21]\n",
            " [  0 867   1   6  87   0   0   0 174   0]\n",
            " [ 52 123  62  81 577   3   9   0 121   4]\n",
            " [ 16  19   8 872  35   1   1   0  44  14]\n",
            " [ 11   9   0  26 888   0   0   0   3  45]\n",
            " [ 83  37   6 467  63  53   4   0 124  55]\n",
            " [ 96  30  14  88 543   7 111   3  29  37]\n",
            " [ 49  54   0  12 448   1   0  98  21 345]\n",
            " [  6  29   4 258 215   1   0   0 449  12]\n",
            " [ 15  40   2  75 547   0   0   1  24 305]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) ['3' '0' '4' ... '3' '4' '4']\n",
            "probabilities: (59850, 10) \n",
            " [3 0 4 ... 3 4 4]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 8 13 11 11  6 55 18 19  9 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.330 s \n",
            "\n",
            "Accuracy rate for 43.980000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.88      0.81       980\n",
            "           1       0.72      0.53      0.61      1135\n",
            "           2       0.52      0.12      0.20      1032\n",
            "           3       0.47      0.85      0.60      1010\n",
            "           4       0.28      0.91      0.42       982\n",
            "           5       0.52      0.02      0.03       892\n",
            "           6       0.44      0.01      0.01       958\n",
            "           7       0.97      0.06      0.12      1028\n",
            "           8       0.36      0.58      0.45       974\n",
            "           9       0.41      0.39      0.40      1009\n",
            "\n",
            "    accuracy                           0.44     10000\n",
            "   macro avg       0.54      0.44      0.36     10000\n",
            "weighted avg       0.55      0.44      0.37     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[864   2  47  15   6   1   7   0  16  22]\n",
            " [  0 605   2   6  55   0   0   0 467   0]\n",
            " [ 29  77 128  87 519   2   2   0 181   7]\n",
            " [ 10  11  15 858  46   0   0   0  62   8]\n",
            " [ 14   8   1  25 892   0   0   1  10  31]\n",
            " [ 58  36  13 486  79  14   0   0 160  46]\n",
            " [105  24  23 103 587  10   7   1  62  36]\n",
            " [ 69  37   5  12 383   0   0  63  35 424]\n",
            " [  3  11  10 207 170   0   0   0 569   4]\n",
            " [ 10  30   4  44 502   0   0   0  21 398]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) ['3' '0' '4' ... '3' '4' '8']\n",
            "probabilities: (59840, 10) \n",
            " [3 0 4 ... 3 4 8]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 8 14 11 11  6 59 23 19  9 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.299 s \n",
            "\n",
            "Accuracy rate for 46.340000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       980\n",
            "           1       0.93      0.46      0.61      1135\n",
            "           2       0.52      0.11      0.18      1032\n",
            "           3       0.45      0.86      0.59      1010\n",
            "           4       0.28      0.91      0.43       982\n",
            "           5       0.87      0.06      0.12       892\n",
            "           6       0.79      0.26      0.39       958\n",
            "           7       0.95      0.11      0.20      1028\n",
            "           8       0.35      0.54      0.42       974\n",
            "           9       0.42      0.43      0.42      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.64      0.46      0.42     10000\n",
            "weighted avg       0.64      0.46      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[868   0  39  22   8   1   7   0   8  27]\n",
            " [  0 518   2  23  71   1   0   0 520   0]\n",
            " [ 33  17 110  92 559   2  40   1 171   7]\n",
            " [  8   0  13 869  50   1   3   0  45  21]\n",
            " [  6   3   2  32 897   0   0   1  11  30]\n",
            " [ 34   3   9 501  70  55  14   2 150  54]\n",
            " [ 41   2  18  89 500   3 246   2  34  23]\n",
            " [ 43  11   5  12 380   0   1 117  39 420]\n",
            " [  3   0  12 230 195   0   1   0 524   9]\n",
            " [ 10   4   3  49 502   0   0   0  11 430]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) ['3' '0' '4' ... '3' '4' '8']\n",
            "probabilities: (59830, 10) \n",
            " [3 0 4 ... 3 4 8]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 8 16 11 11  8 62 23 20  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.339 s \n",
            "\n",
            "Accuracy rate for 51.030000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       980\n",
            "           1       0.73      0.53      0.61      1135\n",
            "           2       0.75      0.19      0.31      1032\n",
            "           3       0.46      0.88      0.60      1010\n",
            "           4       0.40      0.78      0.53       982\n",
            "           5       0.85      0.04      0.07       892\n",
            "           6       0.79      0.50      0.61       958\n",
            "           7       0.95      0.20      0.33      1028\n",
            "           8       0.32      0.63      0.42       974\n",
            "           9       0.39      0.40      0.40      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.64      0.51      0.47     10000\n",
            "weighted avg       0.64      0.51      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[910   1  17  16   4   0  14   0   9   9]\n",
            " [  0 597   0   9   8   0   1   0 520   0]\n",
            " [ 46  64 199 104 318   2  74   2 210  13]\n",
            " [  8   6   8 891  27   2   5   0  52  11]\n",
            " [  7  19   1  25 770   0   0   6  90  64]\n",
            " [ 44  36   4 488  57  33  28   0 173  29]\n",
            " [112   7  18  78 180   1 477   0  44  41]\n",
            " [ 65  56   8  12 109   0   2 205 137 434]\n",
            " [  3   6  11 249  63   0   6   0 617  19]\n",
            " [ 13  30   0  77 382   1   0   3  99 404]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) ['3' '0' '4' ... '3' '0' '8']\n",
            "probabilities: (59820, 10) \n",
            " [3 0 4 ... 3 0 8]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 9 16 12 12  8 63 23 21 10 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.371 s \n",
            "\n",
            "Accuracy rate for 50.260000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       980\n",
            "           1       0.76      0.47      0.58      1135\n",
            "           2       0.70      0.24      0.36      1032\n",
            "           3       0.46      0.86      0.60      1010\n",
            "           4       0.34      0.80      0.48       982\n",
            "           5       0.89      0.04      0.07       892\n",
            "           6       0.83      0.39      0.53       958\n",
            "           7       0.95      0.27      0.43      1028\n",
            "           8       0.33      0.63      0.43       974\n",
            "           9       0.36      0.38      0.37      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.65      0.50      0.47     10000\n",
            "weighted avg       0.65      0.50      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[921   1  14   9  17   0   5   0   6   7]\n",
            " [  0 529   2  15  22   0   2   1 564   0]\n",
            " [ 22  28 248 156 342   2  34   7 167  26]\n",
            " [ 10   3  13 866  37   1   3   2  64  11]\n",
            " [  3  17   3  14 785   0   0   3  63  94]\n",
            " [ 27  48  13 466  69  32  26   2 182  27]\n",
            " [ 60  14  46  60 366   1 372   1  31   7]\n",
            " [ 43  39   6  16  60   0   2 282 106 474]\n",
            " [  2   4   7 220 107   0   4   0 611  19]\n",
            " [ 13  14   1  43 483   0   0   0  75 380]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) ['3' '0' '4' ... '3' '0' '8']\n",
            "probabilities: (59810, 10) \n",
            " [3 0 4 ... 3 0 8]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 9 16 13 12  8 68 26 22 10 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.309 s \n",
            "\n",
            "Accuracy rate for 47.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       980\n",
            "           1       0.80      0.36      0.50      1135\n",
            "           2       0.52      0.22      0.31      1032\n",
            "           3       0.47      0.85      0.60      1010\n",
            "           4       0.35      0.81      0.49       982\n",
            "           5       0.97      0.04      0.07       892\n",
            "           6       0.88      0.44      0.58       958\n",
            "           7       0.87      0.12      0.21      1028\n",
            "           8       0.29      0.65      0.41       974\n",
            "           9       0.30      0.30      0.30      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.63      0.47      0.43     10000\n",
            "weighted avg       0.63      0.47      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[915   1  28   6  15   0   5   0   6   4]\n",
            " [  0 414   6  29  19   0   1   0 666   0]\n",
            " [ 22  20 232 128 366   0  21  15 198  30]\n",
            " [  9   1  11 861  41   1   3   1  74   8]\n",
            " [  4   8   2  24 793   0   2   1  76  72]\n",
            " [ 28  22  34 461  68  34  22   0 197  26]\n",
            " [ 43   8 116  45 303   0 418   0  25   0]\n",
            " [ 66  35   4  19  66   0   2 121 167 548]\n",
            " [  2   1  16 216  85   0   3   1 635  15]\n",
            " [ 14   7   1  60 517   0   0   0 110 300]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59800, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 9 16 14 12  8 74 28 22 11 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 47.090000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.96      0.85       980\n",
            "           1       0.71      0.53      0.61      1135\n",
            "           2       0.54      0.15      0.24      1032\n",
            "           3       0.47      0.84      0.60      1010\n",
            "           4       0.31      0.87      0.46       982\n",
            "           5       0.83      0.10      0.18       892\n",
            "           6       0.84      0.15      0.26       958\n",
            "           7       0.93      0.16      0.28      1028\n",
            "           8       0.37      0.58      0.45       974\n",
            "           9       0.31      0.33      0.32      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.61      0.47      0.42     10000\n",
            "weighted avg       0.61      0.47      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[939   1  15   4  10   0   0   0   3   8]\n",
            " [  0 603   1   7  28   0   1   0 495   0]\n",
            " [ 43  48 156 140 406   4   9   7 181  38]\n",
            " [ 24   6  11 850  59   4   4   0  38  14]\n",
            " [  5  18   2  15 858   1   0   3  26  54]\n",
            " [ 53  51  21 454  78  89   7   1 107  31]\n",
            " [ 68  18  60  67 546   7 148   2  39   3]\n",
            " [ 80  62   3   9  86   1   6 168  57 556]\n",
            " [  4   9  19 217 139   0   1   0 568  17]\n",
            " [ 13  30   1  44 562   1   0   0  28 330]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) ['3' '0' '4' ... '3' '0' '8']\n",
            "probabilities: (59790, 10) \n",
            " [3 0 4 ... 3 0 8]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 9 16 14 12  8 79 30 22 12 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.333 s \n",
            "\n",
            "Accuracy rate for 47.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87       980\n",
            "           1       0.69      0.53      0.60      1135\n",
            "           2       0.55      0.22      0.32      1032\n",
            "           3       0.45      0.88      0.60      1010\n",
            "           4       0.34      0.83      0.48       982\n",
            "           5       0.77      0.02      0.04       892\n",
            "           6       0.89      0.31      0.46       958\n",
            "           7       0.92      0.20      0.33      1028\n",
            "           8       0.33      0.61      0.43       974\n",
            "           9       0.26      0.22      0.24      1009\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.60      0.48      0.44     10000\n",
            "weighted avg       0.60      0.48      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[910   1  32   6  20   0   2   1   3   5]\n",
            " [  0 604   0  11  12   0   0   0 508   0]\n",
            " [ 22  51 232 122 347   2  13  17 203  23]\n",
            " [ 12   7  13 888  36   1   4   0  43   6]\n",
            " [  5  19   1  32 815   0   0   0  73  37]\n",
            " [ 37  64  22 490  77  17  13   0 153  19]\n",
            " [ 54  18 102  68 360   0 294   1  60   1]\n",
            " [ 66  69   2  11  69   0   1 208  77 525]\n",
            " [  3   7  16 245  94   1   2   0 595  11]\n",
            " [ 14  38   0  92 560   1   0   0  79 225]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59780, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [ 9 16 16 12  8 84 32 23 12 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.337 s \n",
            "\n",
            "Accuracy rate for 43.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.95      0.84       980\n",
            "           1       0.67      0.39      0.50      1135\n",
            "           2       0.67      0.14      0.24      1032\n",
            "           3       0.39      0.91      0.55      1010\n",
            "           4       0.33      0.83      0.47       982\n",
            "           5       0.72      0.07      0.13       892\n",
            "           6       0.89      0.15      0.25       958\n",
            "           7       0.94      0.14      0.25      1028\n",
            "           8       0.28      0.57      0.38       974\n",
            "           9       0.20      0.15      0.17      1009\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.59      0.43      0.38     10000\n",
            "weighted avg       0.59      0.43      0.38     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[928   1   5  29   9   1   1   1   1   4]\n",
            " [  0 448   0  18  10   0   0   0 659   0]\n",
            " [ 39  32 149 220 356   3   7   4 206  16]\n",
            " [ 10   3   3 919  30   3   3   0  34   5]\n",
            " [  5  11   1  33 813   4   0   2  87  26]\n",
            " [ 40  59   9 544  74  64   4   1  91   6]\n",
            " [104  20  22 138 417   8 141   1 106   1]\n",
            " [ 77  68  25  19  74   0   1 148 105 511]\n",
            " [  3   6   6 309  87   1   2   0 558   2]\n",
            " [ 15  23   3 109 587   5   0   0 120 147]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) ['3' '0' '4' ... '3' '0' '8']\n",
            "probabilities: (59770, 10) \n",
            " [3 0 4 ... 3 0 8]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [ 9 16 18 12  8 88 35 23 12 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.308 s \n",
            "\n",
            "Accuracy rate for 47.130000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.95      0.85       980\n",
            "           1       0.73      0.42      0.53      1135\n",
            "           2       0.58      0.08      0.14      1032\n",
            "           3       0.47      0.83      0.60      1010\n",
            "           4       0.31      0.83      0.45       982\n",
            "           5       0.83      0.14      0.24       892\n",
            "           6       0.91      0.20      0.32       958\n",
            "           7       0.84      0.40      0.54      1028\n",
            "           8       0.29      0.64      0.40       974\n",
            "           9       0.34      0.23      0.27      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.61      0.47      0.44     10000\n",
            "weighted avg       0.61      0.47      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[931   1  11   4  18   1   2   3   2   7]\n",
            " [  0 473   0   5  18   0   1   0 637   1]\n",
            " [ 40  31  83 129 407   3   9  48 262  20]\n",
            " [ 18   3   4 839  52   2   5   5  76   6]\n",
            " [  7  13   1  22 814   4   0   8  93  20]\n",
            " [ 59  31  12 433  67 123   1   0 141  25]\n",
            " [ 64  16  30  82 444  12 189   5  98  18]\n",
            " [ 63  43   2  11  84   0   0 411  84 330]\n",
            " [  4   3   0 203 125   2   0   2 620  15]\n",
            " [ 15  31   0  46 587   2   0   5  93 230]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) ['3' '0' '4' ... '3' '2' '4']\n",
            "probabilities: (59760, 10) \n",
            " [3 0 4 ... 3 2 4]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 9 16 18 13  8 94 37 23 12 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.386 s \n",
            "\n",
            "Accuracy rate for 44.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.95      0.86       980\n",
            "           1       0.64      0.43      0.52      1135\n",
            "           2       0.62      0.09      0.15      1032\n",
            "           3       0.50      0.83      0.63      1010\n",
            "           4       0.30      0.86      0.45       982\n",
            "           5       0.75      0.07      0.12       892\n",
            "           6       0.86      0.19      0.31       958\n",
            "           7       0.86      0.12      0.21      1028\n",
            "           8       0.30      0.66      0.41       974\n",
            "           9       0.24      0.21      0.22      1009\n",
            "\n",
            "    accuracy                           0.44     10000\n",
            "   macro avg       0.59      0.44      0.39     10000\n",
            "weighted avg       0.59      0.44      0.39     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[930   1   0  19  15   1   7   1   1   5]\n",
            " [  0 490   0   7  18   0   0   0 619   1]\n",
            " [ 31  67  88 112 424   3  12  15 251  29]\n",
            " [  8   9   2 838  71   2   4   1  69   6]\n",
            " [  4  13   6   9 843   1   1   2  82  21]\n",
            " [ 34  45  10 451  82  60   4   0 183  23]\n",
            " [101  23  28  32 496  11 178   0  85   4]\n",
            " [ 67  69   6  20  91   0   0 126  86 563]\n",
            " [  4   6   1 149 150   2   1   0 646  15]\n",
            " [ 16  38   1  32 591   0   0   1 118 212]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) ['3' '0' '4' ... '9' '0' '8']\n",
            "probabilities: (59750, 10) \n",
            " [3 0 4 ... 9 0 8]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [ 9 16 19 13  8 97 41 25 12 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.317 s \n",
            "\n",
            "Accuracy rate for 44.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.96      0.85       980\n",
            "           1       0.66      0.42      0.51      1135\n",
            "           2       0.58      0.06      0.12      1032\n",
            "           3       0.52      0.80      0.63      1010\n",
            "           4       0.31      0.86      0.45       982\n",
            "           5       0.82      0.04      0.09       892\n",
            "           6       0.87      0.16      0.27       958\n",
            "           7       0.90      0.26      0.40      1028\n",
            "           8       0.29      0.73      0.42       974\n",
            "           9       0.24      0.17      0.20      1009\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.60      0.45      0.39     10000\n",
            "weighted avg       0.59      0.45      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[944   1   0   9  21   0   1   0   1   3]\n",
            " [  0 474   0   5  11   0   1   0 644   0]\n",
            " [ 40  48  66  60 419   2  13  20 333  31]\n",
            " [ 18  10   2 806  79   2   2   0  87   4]\n",
            " [  5  13   3  12 840   0   0   3  90  16]\n",
            " [ 62  53   5 441  92  40   6   0 171  22]\n",
            " [ 87  19  33  50 487   5 152   2 120   3]\n",
            " [ 56  55   3  11  64   0   0 263 128 448]\n",
            " [  8   8   0 108 130   0   0   1 709  10]\n",
            " [ 18  38   1  44 605   0   0   2 130 171]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) ['3' '0' '4' ... '3' '6' '8']\n",
            "probabilities: (59740, 10) \n",
            " [3 0 4 ... 3 6 8]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [ 10  16  19  13   8 101  46  25  12  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.331 s \n",
            "\n",
            "Accuracy rate for 44.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88       980\n",
            "           1       0.72      0.41      0.52      1135\n",
            "           2       0.67      0.11      0.19      1032\n",
            "           3       0.49      0.83      0.62      1010\n",
            "           4       0.31      0.86      0.46       982\n",
            "           5       0.69      0.07      0.13       892\n",
            "           6       0.88      0.17      0.29       958\n",
            "           7       0.92      0.16      0.28      1028\n",
            "           8       0.29      0.72      0.42       974\n",
            "           9       0.18      0.13      0.15      1009\n",
            "\n",
            "    accuracy                           0.44     10000\n",
            "   macro avg       0.60      0.44      0.39     10000\n",
            "weighted avg       0.60      0.44      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[951   1   5   8   8   0   0   0   4   3]\n",
            " [  0 461   0   6   8   0   0   0 660   0]\n",
            " [ 38  33 115  81 403   4  13  12 313  20]\n",
            " [ 11   6   5 843  54   3   1   0  84   3]\n",
            " [  4   9   4  19 847   4   0   1  82  12]\n",
            " [ 38  43  17 473  73  65   9   0 162  12]\n",
            " [ 53  14  18  59 533  12 166   0 101   2]\n",
            " [ 71  40   6  18  74   1   0 168 132 518]\n",
            " [  5   6   0 139 111   0   0   0 701  12]\n",
            " [ 14  23   2  74 609   5   0   1 154 127]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) ['3' '0' '4' ... '3' '2' '4']\n",
            "probabilities: (59730, 10) \n",
            " [3 0 4 ... 3 2 4]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [ 10  16  19  14   8 107  48  25  12  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.376 s \n",
            "\n",
            "Accuracy rate for 46.920000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.87       980\n",
            "           1       0.61      0.41      0.49      1135\n",
            "           2       0.63      0.13      0.21      1032\n",
            "           3       0.47      0.81      0.60      1010\n",
            "           4       0.33      0.82      0.47       982\n",
            "           5       0.60      0.06      0.11       892\n",
            "           6       0.88      0.22      0.35       958\n",
            "           7       0.91      0.43      0.58      1028\n",
            "           8       0.28      0.71      0.40       974\n",
            "           9       0.31      0.12      0.17      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.58      0.47      0.43     10000\n",
            "weighted avg       0.58      0.47      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[953   1   2   2  16   0   2   0   3   1]\n",
            " [  0 468   0   3  10   0   0   0 654   0]\n",
            " [ 37  66 132  76 369   4  15  26 296  11]\n",
            " [ 28  11  10 818  48   7   4   3  78   3]\n",
            " [  5  14   6  39 804   6   0   4  92  12]\n",
            " [ 65  58  23 417  69  56   7   1 192   4]\n",
            " [ 44  24  28  59 428  15 207   4 148   1]\n",
            " [ 64  79   5  26  55   1   0 442 132 224]\n",
            " [  7   9   0 175  78   2   0   0 690  13]\n",
            " [ 20  43   2 120 536   3   0   4 159 122]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59720, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [ 11  16  19  15   8 112  49  25  12  23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.361 s \n",
            "\n",
            "Accuracy rate for 45.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.94      0.86       980\n",
            "           1       0.68      0.45      0.54      1135\n",
            "           2       0.45      0.09      0.15      1032\n",
            "           3       0.46      0.81      0.59      1010\n",
            "           4       0.30      0.86      0.45       982\n",
            "           5       0.60      0.10      0.17       892\n",
            "           6       0.89      0.07      0.14       958\n",
            "           7       0.93      0.46      0.61      1028\n",
            "           8       0.31      0.68      0.42       974\n",
            "           9       0.28      0.11      0.16      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.57      0.46      0.41     10000\n",
            "weighted avg       0.57      0.46      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[921   1  30   3  18   0   1   1   4   1]\n",
            " [  0 510   0   9  11   0   0   0 605   0]\n",
            " [ 46  51  93 107 426   5   5  22 267  10]\n",
            " [ 37   7   7 820  54   7   1   1  74   2]\n",
            " [  1  11   2  32 840   4   0   4  82   6]\n",
            " [ 53  42  39 408  90  87   2   1 160  10]\n",
            " [ 71  24  29  70 568  33  70   3  85   5]\n",
            " [ 33  66   4  36  80   4   0 471  91 243]\n",
            " [  6   5   2 171 112   1   0   1 663  13]\n",
            " [  6  30   2 129 592   5   0   2 130 113]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) ['3' '0' '4' ... '9' '2' '8']\n",
            "probabilities: (59710, 10) \n",
            " [3 0 4 ... 9 2 8]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 11  16  25  15   8 113  51  25  12  24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 43.220000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90       980\n",
            "           1       0.80      0.12      0.21      1135\n",
            "           2       0.57      0.23      0.33      1032\n",
            "           3       0.47      0.82      0.60      1010\n",
            "           4       0.33      0.82      0.47       982\n",
            "           5       0.71      0.13      0.22       892\n",
            "           6       0.76      0.46      0.58       958\n",
            "           7       0.99      0.12      0.21      1028\n",
            "           8       0.25      0.70      0.37       974\n",
            "           9       0.12      0.07      0.09      1009\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.59      0.44      0.40     10000\n",
            "weighted avg       0.59      0.43      0.39     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[883   0   6  32   4   7  44   0   2   2]\n",
            " [  0 136   0  48  26   1   1   0 923   0]\n",
            " [ 11   2 242  86 385   3  43   0 253   7]\n",
            " [  6   0   4 832  62   4   6   0  94   2]\n",
            " [  0   1  36  25 801   3   2   0 101  13]\n",
            " [ 21   2   7 411  76 115  28   0 228   4]\n",
            " [ 22   1  32  51 306  14 445   0  87   0]\n",
            " [ 31  27  74  49  74  10   6 121 142 494]\n",
            " [  2   0   8 144 132   2   4   0 677   5]\n",
            " [  6   0  15 100 594   2   5   1 216  70]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) ['3' '0' '4' ... '8' '5' '4']\n",
            "probabilities: (59700, 10) \n",
            " [3 0 4 ... 8 5 4]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [ 13  16  25  15   8 119  51  27  12  24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.424 s \n",
            "\n",
            "Accuracy rate for 42.450000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.87       980\n",
            "           1       0.65      0.42      0.51      1135\n",
            "           2       0.64      0.16      0.26      1032\n",
            "           3       0.49      0.79      0.60      1010\n",
            "           4       0.27      0.85      0.41       982\n",
            "           5       0.72      0.07      0.12       892\n",
            "           6       0.90      0.12      0.21       958\n",
            "           7       0.97      0.19      0.32      1028\n",
            "           8       0.28      0.65      0.39       974\n",
            "           9       0.13      0.07      0.09      1009\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.59      0.42      0.38     10000\n",
            "weighted avg       0.59      0.42      0.38     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[894   4   2  12  66   1   0   0   0   1]\n",
            " [  1 478   0  12  18   0   0   0 626   0]\n",
            " [ 31  51 166  67 438   2   5   3 258  11]\n",
            " [ 35   7   1 799  78   2   1   0  84   3]\n",
            " [  0   8  12  33 836   2   0   1  81   9]\n",
            " [ 49  58  14 406 119  58   6   1 177   4]\n",
            " [ 36  27  17  50 573  13 113   1 121   7]\n",
            " [ 24  69  34  28 112   0   0 199 118 444]\n",
            " [  5   7   9 132 185   2   0   0 629   5]\n",
            " [ 10  26   6 105 627   0   0   0 162  73]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) ['3' '0' '4' ... '8' '9' '8']\n",
            "probabilities: (59690, 10) \n",
            " [3 0 4 ... 8 9 8]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [ 13  16  25  15  10 121  54  27  12  27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.316 s \n",
            "\n",
            "Accuracy rate for 44.370000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.95      0.86       980\n",
            "           1       0.81      0.31      0.45      1135\n",
            "           2       0.59      0.23      0.33      1032\n",
            "           3       0.48      0.77      0.59      1010\n",
            "           4       0.32      0.83      0.46       982\n",
            "           5       0.64      0.07      0.13       892\n",
            "           6       0.85      0.22      0.35       958\n",
            "           7       0.99      0.22      0.36      1028\n",
            "           8       0.27      0.75      0.40       974\n",
            "           9       0.18      0.10      0.13      1009\n",
            "\n",
            "    accuracy                           0.44     10000\n",
            "   macro avg       0.59      0.44      0.41     10000\n",
            "weighted avg       0.59      0.44      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[932   1   8  19   2  12   1   0   3   2]\n",
            " [  2 350   0  14  26   0   0   0 743   0]\n",
            " [ 41   9 233  71 360   2  12   0 297   7]\n",
            " [ 41   0   2 777  66   2   4   0 116   2]\n",
            " [  3   3  32  23 815   3   0   0  81  22]\n",
            " [ 52   9  19 403  89  64  11   1 234  10]\n",
            " [ 60   9  31  54 429  12 212   1 143   7]\n",
            " [ 31  47  45  31  55   3   7 228 169 412]\n",
            " [ 10   0  11 118 106   1   1   0 726   1]\n",
            " [ 13   3  17 108 594   1   1   0 172 100]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) ['3' '0' '4' ... '8' '2' '8']\n",
            "probabilities: (59680, 10) \n",
            " [3 0 4 ... 8 2 8]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [ 13  16  29  16  10 123  55  28  12  28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.386 s \n",
            "\n",
            "Accuracy rate for 45.900000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       980\n",
            "           1       0.71      0.55      0.62      1135\n",
            "           2       0.41      0.21      0.27      1032\n",
            "           3       0.49      0.71      0.58      1010\n",
            "           4       0.29      0.86      0.43       982\n",
            "           5       0.79      0.09      0.16       892\n",
            "           6       0.83      0.23      0.36       958\n",
            "           7       0.95      0.24      0.39      1028\n",
            "           8       0.33      0.65      0.44       974\n",
            "           9       0.21      0.11      0.15      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.58      0.46      0.43     10000\n",
            "weighted avg       0.58      0.46      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[890   3   1  71   7   2   2   1   1   2]\n",
            " [  0 625   0   6  31   0   0   0 473   0]\n",
            " [ 44  74 212  39 421   1  15   2 222   2]\n",
            " [ 33  20   2 719  99   2   7   1 124   3]\n",
            " [  1  12  31  12 846   2   0   1  52  25]\n",
            " [ 45  37  14 399  93  82  18   4 184  16]\n",
            " [ 47  19  50  42 494  13 219   2  68   4]\n",
            " [ 13  53 178  23  74   1   2 250  74 360]\n",
            " [ 11   8  11  97 203   1   2   0 634   7]\n",
            " [ 11  24  16  54 683   0   0   3 105 113]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) ['3' '0' '4' ... '8' '5' '4']\n",
            "probabilities: (59670, 10) \n",
            " [3 0 4 ... 8 5 4]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [ 13  16  29  16  11 129  55  28  13  30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 45.750000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81       980\n",
            "           1       0.66      0.58      0.62      1135\n",
            "           2       0.50      0.23      0.32      1032\n",
            "           3       0.44      0.83      0.57      1010\n",
            "           4       0.35      0.80      0.49       982\n",
            "           5       0.70      0.09      0.16       892\n",
            "           6       0.88      0.27      0.41       958\n",
            "           7       0.98      0.12      0.22      1028\n",
            "           8       0.28      0.65      0.40       974\n",
            "           9       0.25      0.15      0.19      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.59      0.45      0.42     10000\n",
            "weighted avg       0.58      0.46      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[801   9   0 139  16   4   3   0   4   4]\n",
            " [  1 659   0  30   3   0   0   0 442   0]\n",
            " [ 32  88 241  51 310   4   9   0 295   2]\n",
            " [ 30  25   3 838  29   4   4   0  75   2]\n",
            " [  0  20  17  13 782   2   1   0 111  36]\n",
            " [ 42  51   4 462  67  81  11   1 153  20]\n",
            " [ 44  26  48  62 281  16 255   1 222   3]\n",
            " [ 27  71 151  26  71   2   4 126 150 400]\n",
            " [  6  22  12 214  77   1   2   0 637   3]\n",
            " [  9  35   9  71 580   1   1   0 148 155]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) ['3' '0' '4' ... '3' '5' '8']\n",
            "probabilities: (59660, 10) \n",
            " [3 0 4 ... 3 5 8]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 15  16  30  17  11 132  55  29  14  31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 49.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.86       980\n",
            "           1       0.72      0.71      0.71      1135\n",
            "           2       0.59      0.24      0.34      1032\n",
            "           3       0.51      0.74      0.61      1010\n",
            "           4       0.33      0.84      0.47       982\n",
            "           5       0.62      0.04      0.07       892\n",
            "           6       0.89      0.26      0.40       958\n",
            "           7       0.95      0.23      0.37      1028\n",
            "           8       0.34      0.79      0.47       974\n",
            "           9       0.19      0.10      0.13      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.59      0.49      0.44     10000\n",
            "weighted avg       0.60      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[913   2   0  45  11   0   3   0   6   0]\n",
            " [  0 801   1  16  19   0   0   0 298   0]\n",
            " [ 31  90 246  35 361   4   8   3 251   3]\n",
            " [ 44  26   6 745  49   2   5   1 129   3]\n",
            " [  1  18   9   7 824   2   1   2 103  15]\n",
            " [ 71  46   2 384  71  32  10   1 261  14]\n",
            " [ 29  18  55  40 381   8 245   0 182   0]\n",
            " [ 43  63  87  18  80   2   2 238  97 398]\n",
            " [  8   9   6 113  71   1   0   0 765   1]\n",
            " [  9  33   6  45 631   1   0   5 178 101]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) ['3' '0' '4' ... '3' '5' '3']\n",
            "probabilities: (59650, 10) \n",
            " [3 0 4 ... 3 5 3]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [ 15  16  32  17  11 138  55  29  15  32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.338 s \n",
            "\n",
            "Accuracy rate for 52.290000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85       980\n",
            "           1       0.67      0.94      0.78      1135\n",
            "           2       0.79      0.24      0.37      1032\n",
            "           3       0.46      0.80      0.59      1010\n",
            "           4       0.32      0.87      0.47       982\n",
            "           5       0.64      0.03      0.06       892\n",
            "           6       0.84      0.26      0.40       958\n",
            "           7       0.96      0.37      0.53      1028\n",
            "           8       0.42      0.54      0.47       974\n",
            "           9       0.33      0.17      0.22      1009\n",
            "\n",
            "    accuracy                           0.52     10000\n",
            "   macro avg       0.62      0.51      0.47     10000\n",
            "weighted avg       0.62      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    3    2   41   31    1    1    1    4    0]\n",
            " [   0 1070    0   27   19    0    0    0   19    0]\n",
            " [  28  164  246   54  354    3   24    3  151    5]\n",
            " [  47   47    4  808   48    1    5    3   41    6]\n",
            " [   0   26    5   17  855    2    2    1   60   14]\n",
            " [  68   64    9  430   88   28   15    2  183    5]\n",
            " [  22   24   17   46  471    6  248    0  123    1]\n",
            " [  41   75   21   12  104    2    2  379   69  323]\n",
            " [  12   81    5  252   95    0    0    1  526    2]\n",
            " [   8   41    4   62  630    1    0    4   86  173]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59640, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [ 16  16  33  19  11 143  55  30  15  32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.354 s \n",
            "\n",
            "Accuracy rate for 52.950000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.97      0.81       980\n",
            "           1       0.62      0.93      0.75      1135\n",
            "           2       0.71      0.17      0.28      1032\n",
            "           3       0.56      0.58      0.57      1010\n",
            "           4       0.32      0.83      0.47       982\n",
            "           5       0.57      0.11      0.19       892\n",
            "           6       0.86      0.30      0.45       958\n",
            "           7       0.94      0.41      0.57      1028\n",
            "           8       0.42      0.65      0.51       974\n",
            "           9       0.41      0.26      0.32      1009\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.61      0.52      0.49     10000\n",
            "weighted avg       0.61      0.53      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    3    0    3    6    6    5    0    4    0]\n",
            " [   0 1056    1    2   33    0    0    0   42    1]\n",
            " [  34  182  178   20  373    5   18    8  205    9]\n",
            " [ 118   76    2  588  115   16    4    4   80    7]\n",
            " [   4   24    9    8  815    7    4    5   75   31]\n",
            " [ 155   80    2  284   90   99   13    4  156    9]\n",
            " [  35   36   37   33  340   32  289    2  153    1]\n",
            " [  48   95   15    9   50    3    2  423   65  318]\n",
            " [  17  101    5   78  130    2    2    0  634    5]\n",
            " [  16   45    3   23  565    4    0    4   89  260]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) ['3' '0' '4' ... '3' '5' '8']\n",
            "probabilities: (59630, 10) \n",
            " [3 0 4 ... 3 5 8]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [ 18  16  36  19  12 145  55  30  16  33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.320 s \n",
            "\n",
            "Accuracy rate for 53.540000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.98      0.78       980\n",
            "           1       0.63      0.96      0.76      1135\n",
            "           2       0.77      0.16      0.26      1032\n",
            "           3       0.63      0.59      0.61      1010\n",
            "           4       0.36      0.82      0.50       982\n",
            "           5       0.75      0.05      0.10       892\n",
            "           6       0.86      0.39      0.54       958\n",
            "           7       0.94      0.31      0.47      1028\n",
            "           8       0.41      0.71      0.52       974\n",
            "           9       0.35      0.31      0.33      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.64      0.53      0.49     10000\n",
            "weighted avg       0.64      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 958    4    0    7    4    0    2    0    5    0]\n",
            " [   0 1087    0    1   32    0    0    0   14    1]\n",
            " [  49  204  162   13  343    2   31   10  201   17]\n",
            " [  61   63    0  593   70    4    8    4  189   18]\n",
            " [  17   31   10    3  809    1    4    3   61   43]\n",
            " [ 137   80    2  241   50   48   12    4  300   18]\n",
            " [ 126   37   15   17  245    6  372    1  138    1]\n",
            " [  62   87   19    8   62    1    0  321   16  452]\n",
            " [  24   89    1   42  107    0    3    0  695   13]\n",
            " [  31   42    2   10  552    2    0    0   61  309]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) ['8' '0' '4' ... '9' '5' '8']\n",
            "probabilities: (59620, 10) \n",
            " [8 0 4 ... 9 5 8]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [ 18  16  40  19  12 150  55  30  16  34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.443 s \n",
            "\n",
            "Accuracy rate for 51.490000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.98      0.78       980\n",
            "           1       0.61      0.86      0.71      1135\n",
            "           2       0.56      0.13      0.21      1032\n",
            "           3       0.57      0.70      0.63      1010\n",
            "           4       0.36      0.79      0.49       982\n",
            "           5       0.68      0.06      0.10       892\n",
            "           6       0.83      0.24      0.38       958\n",
            "           7       0.93      0.43      0.59      1028\n",
            "           8       0.36      0.73      0.48       974\n",
            "           9       0.35      0.14      0.20      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.59      0.51      0.46     10000\n",
            "weighted avg       0.59      0.51      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[957   1   5   9   2   0   3   0   3   0]\n",
            " [  0 976   0   3  10   0   0   0 145   1]\n",
            " [ 59 191 136  21 293   1  28  25 273   5]\n",
            " [ 80  40   2 710  52   4   7   2 104   9]\n",
            " [  9  28  19   5 779   4   1   2 107  28]\n",
            " [152  77  11 348  48  50   7   1 192   6]\n",
            " [105  44  45  25 270   8 233   0 223   5]\n",
            " [ 71 124   8  18  53   3   0 447  88 216]\n",
            " [ 32  63   1  73  83   2   1   0 715   4]\n",
            " [ 21  55  16  43 585   2   0   2 139 146]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59610, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 18  17  45  21  12 152  55  30  16  34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 50.770000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.99      0.77       980\n",
            "           1       0.67      0.69      0.68      1135\n",
            "           2       0.70      0.19      0.29      1032\n",
            "           3       0.47      0.66      0.55      1010\n",
            "           4       0.34      0.84      0.48       982\n",
            "           5       0.69      0.08      0.15       892\n",
            "           6       0.82      0.33      0.47       958\n",
            "           7       0.95      0.48      0.64      1028\n",
            "           8       0.36      0.69      0.48       974\n",
            "           9       0.32      0.09      0.15      1009\n",
            "\n",
            "    accuracy                           0.51     10000\n",
            "   macro avg       0.59      0.50      0.46     10000\n",
            "weighted avg       0.60      0.51      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[966   1   1   0   4   1   3   0   4   0]\n",
            " [  0 779   2   5  54   0   0   0 295   0]\n",
            " [ 44 124 192  80 350   2  22  11 204   3]\n",
            " [124  17   4 663  68  15  12   5 100   2]\n",
            " [ 12  13   4  30 822   4   3   0  71  23]\n",
            " [177  51   6 300  71  75  17   5 186   4]\n",
            " [ 89  19  11  32 310  10 316   0 162   9]\n",
            " [ 94  91  44  27  61   1   3 495  56 156]\n",
            " [ 16  24   7 132 109   0   8   2 674   2]\n",
            " [ 20  37   5 137 599   1   0   4 111  95]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) ['3' '0' '4' ... '3' '2' '8']\n",
            "probabilities: (59600, 10) \n",
            " [3 0 4 ... 3 2 8]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [ 18  17  47  21  13 154  58  30  17  35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.379 s \n",
            "\n",
            "Accuracy rate for 54.840000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.98      0.77       980\n",
            "           1       0.68      0.83      0.75      1135\n",
            "           2       0.68      0.23      0.35      1032\n",
            "           3       0.46      0.72      0.56      1010\n",
            "           4       0.35      0.85      0.50       982\n",
            "           5       0.65      0.05      0.10       892\n",
            "           6       0.85      0.34      0.49       958\n",
            "           7       0.92      0.66      0.77      1028\n",
            "           8       0.44      0.64      0.52       974\n",
            "           9       0.54      0.10      0.16      1009\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.62      0.54      0.50     10000\n",
            "weighted avg       0.62      0.55      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[961   1   2   0   6   0   2   2   6   0]\n",
            " [  0 947   1   7  68   0   1   1 110   0]\n",
            " [ 42 139 239  92 336   2  21  19 139   3]\n",
            " [ 84  22   7 726  44  17   5  12  85   8]\n",
            " [  9  14  11  30 839   3   8   2  49  17]\n",
            " [171  62  23 318  67  48  14  10 172   7]\n",
            " [104  24  17  33 348   1 330   1  98   2]\n",
            " [ 60  87  31  32  46   2   0 676  51  43]\n",
            " [ 20  52   8 170  92   0   5   2 620   5]\n",
            " [ 55  41  14 181 533   1   0  11  75  98]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) ['3' '0' '4' ... '5' '2' '8']\n",
            "probabilities: (59590, 10) \n",
            " [3 0 4 ... 5 2 8]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [ 18  17  48  24  15 154  60  30  19  35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.405 s \n",
            "\n",
            "Accuracy rate for 50.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.97      0.80       980\n",
            "           1       0.62      0.66      0.64      1135\n",
            "           2       0.79      0.21      0.33      1032\n",
            "           3       0.57      0.77      0.65      1010\n",
            "           4       0.40      0.79      0.53       982\n",
            "           5       0.58      0.08      0.13       892\n",
            "           6       0.84      0.10      0.18       958\n",
            "           7       0.95      0.43      0.60      1028\n",
            "           8       0.28      0.76      0.41       974\n",
            "           9       0.47      0.18      0.26      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.62      0.50      0.45     10000\n",
            "weighted avg       0.62      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[954   2   0   2  14   3   2   0   2   1]\n",
            " [  0 750   0   4   0   0   0   0 381   0]\n",
            " [ 39 144 212  31 214   3  10  10 364   5]\n",
            " [ 32  18   4 778  14   3   0   5 152   4]\n",
            " [  7  16   1   7 771   3   3   2 146  26]\n",
            " [134  75  10 314  39  67   2   4 237  10]\n",
            " [138  40  11  42 281  32  97   0 315   2]\n",
            " [ 62  86  24  21  99   4   0 446 134 152]\n",
            " [ 26  39   3 120  36   0   2   1 744   3]\n",
            " [ 27  36   4  52 482   1   0   2 222 183]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) ['3' '0' '4' ... '5' '2' '8']\n",
            "probabilities: (59580, 10) \n",
            " [3 0 4 ... 5 2 8]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [ 18  18  50  24  16 157  61  30  19  37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.488 s \n",
            "\n",
            "Accuracy rate for 47.300000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.98      0.81       980\n",
            "           1       0.64      0.70      0.67      1135\n",
            "           2       0.65      0.18      0.29      1032\n",
            "           3       0.51      0.75      0.61      1010\n",
            "           4       0.34      0.79      0.47       982\n",
            "           5       0.66      0.10      0.17       892\n",
            "           6       0.80      0.10      0.18       958\n",
            "           7       0.97      0.35      0.52      1028\n",
            "           8       0.26      0.64      0.37       974\n",
            "           9       0.28      0.08      0.13      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.58      0.47      0.42     10000\n",
            "weighted avg       0.58      0.47      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[959   2   2   1  12   0   1   0   3   0]\n",
            " [  0 792   0  35   0   0   0   0 308   0]\n",
            " [ 46 153 190  41 269   4  11   4 310   4]\n",
            " [ 51  26   7 761  22  11   0   2 126   4]\n",
            " [  5  14   4  14 776   3   2   1 143  20]\n",
            " [131  64  23 292  60  88   5   2 227   0]\n",
            " [103  29  16  42 356  21  96   0 292   3]\n",
            " [ 69  84  40  23 129   4   1 361 131 186]\n",
            " [ 17  42   8 206  69   3   4   0 622   3]\n",
            " [ 20  30   2  77 593   0   0   2 200  85]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) ['3' '0' '4' ... '5' '2' '8']\n",
            "probabilities: (59570, 10) \n",
            " [3 0 4 ... 5 2 8]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [ 18  18  54  25  16 162  61  30  19  37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.370 s \n",
            "\n",
            "Accuracy rate for 49.960000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.97      0.82       980\n",
            "           1       0.63      0.76      0.69      1135\n",
            "           2       0.73      0.25      0.37      1032\n",
            "           3       0.50      0.85      0.63      1010\n",
            "           4       0.31      0.85      0.46       982\n",
            "           5       0.81      0.11      0.20       892\n",
            "           6       0.82      0.14      0.24       958\n",
            "           7       0.96      0.31      0.47      1028\n",
            "           8       0.37      0.52      0.43       974\n",
            "           9       0.30      0.17      0.22      1009\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.61      0.49      0.45     10000\n",
            "weighted avg       0.61      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[951   2   0   1  22   1   1   0   2   0]\n",
            " [  0 859   4  36   5   0   0   0 231   0]\n",
            " [ 47 155 258  93 323   2  11   5 119  19]\n",
            " [ 22  21   5 856  30   6   3   1  60   6]\n",
            " [  8  23   2  14 837   1   1   1  54  41]\n",
            " [115  85   3 337  58 101   9   2 178   4]\n",
            " [109  40   3  21 521   7 133   0 120   4]\n",
            " [ 49  84  57  13 140   4   0 318  50 313]\n",
            " [ 20  59  19 252  85   1   4   3 510  21]\n",
            " [ 25  35   1  74 642   1   0   2  56 173]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) ['3' '0' '4' ... '5' '4' '8']\n",
            "probabilities: (59560, 10) \n",
            " [3 0 4 ... 5 4 8]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [ 18  18  56  25  16 165  64  30  20  38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.473 s \n",
            "\n",
            "Accuracy rate for 48.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.98      0.73       980\n",
            "           1       0.63      0.62      0.62      1135\n",
            "           2       0.78      0.09      0.15      1032\n",
            "           3       0.59      0.74      0.66      1010\n",
            "           4       0.35      0.78      0.49       982\n",
            "           5       0.68      0.09      0.17       892\n",
            "           6       0.78      0.24      0.37       958\n",
            "           7       0.94      0.48      0.63      1028\n",
            "           8       0.27      0.68      0.38       974\n",
            "           9       0.51      0.13      0.21      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.61      0.48      0.44     10000\n",
            "weighted avg       0.61      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[963   2   2   2   7   0   2   0   2   0]\n",
            " [  0 700   0  19   0   0   2   0 414   0]\n",
            " [ 70 132  88  49 280   4  21  11 374   3]\n",
            " [105  20   4 745  25  13   7   4  86   1]\n",
            " [ 10  14   1  10 766   2   4   3 152  20]\n",
            " [242  67   6 189  39  84  22   6 237   0]\n",
            " [114  31   4  23 315  15 233   0 222   1]\n",
            " [ 84  76   4  10  78   4   1 490 184  97]\n",
            " [ 35  32   3 163  63   1   5   1 666   5]\n",
            " [ 32  38   1  46 587   0   3   5 166 131]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) ['3' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59550, 10) \n",
            " [3 0 4 ... 8 6 8]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [ 18  18  56  26  16 173  64  30  21  38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.387 s \n",
            "\n",
            "Accuracy rate for 44.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.98      0.70       980\n",
            "           1       0.59      0.64      0.62      1135\n",
            "           2       0.87      0.22      0.35      1032\n",
            "           3       0.91      0.34      0.49      1010\n",
            "           4       0.30      0.84      0.44       982\n",
            "           5       0.59      0.14      0.22       892\n",
            "           6       0.82      0.15      0.26       958\n",
            "           7       0.96      0.11      0.19      1028\n",
            "           8       0.32      0.80      0.46       974\n",
            "           9       0.29      0.20      0.23      1009\n",
            "\n",
            "    accuracy                           0.44     10000\n",
            "   macro avg       0.62      0.44      0.40     10000\n",
            "weighted avg       0.62      0.44      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[963   2   1   0  11   2   0   0   1   0]\n",
            " [  0 727   0   0   5   0   0   0 403   0]\n",
            " [ 57 170 224   2 334   6   6   0 221  12]\n",
            " [238  52   4 343  74  24   8   1 225  41]\n",
            " [  7  14   3   0 829   9   0   0  95  25]\n",
            " [241  80   2  23  70 123  13   2 332   6]\n",
            " [114  39   7   0 528  33 146   0  89   2]\n",
            " [ 74  79  11   0 197   4   0 108 166 389]\n",
            " [ 37  30   5   9  98   4   4   0 783   4]\n",
            " [ 23  31   1   1 620   4   0   1 130 198]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) ['3' '0' '4' ... '8' '2' '8']\n",
            "probabilities: (59540, 10) \n",
            " [3 0 4 ... 8 2 8]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [ 18  18  56  31  16 178  64  30  21  38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.391 s \n",
            "\n",
            "Accuracy rate for 46.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.98      0.77       980\n",
            "           1       0.64      0.57      0.60      1135\n",
            "           2       0.87      0.10      0.18      1032\n",
            "           3       0.45      0.80      0.58      1010\n",
            "           4       0.34      0.83      0.48       982\n",
            "           5       0.74      0.12      0.21       892\n",
            "           6       0.83      0.20      0.33       958\n",
            "           7       0.98      0.23      0.37      1028\n",
            "           8       0.31      0.61      0.41       974\n",
            "           9       0.28      0.17      0.21      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.61      0.46      0.41     10000\n",
            "weighted avg       0.61      0.46      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[962   1   0   1  13   0   2   0   1   0]\n",
            " [  0 646   0  86   4   0   0   0 398   1]\n",
            " [ 64 130 102 113 338   3  21   5 241  15]\n",
            " [ 75  16   0 806  24  12   3   0  65   9]\n",
            " [  6  13   4  31 813   3   1   0  88  23]\n",
            " [189  67   2 310  41 110  11   1 157   4]\n",
            " [ 97  26   4  60 434  14 196   0 125   2]\n",
            " [ 78  50   3  13 108   4   0 238 158 376]\n",
            " [ 26  31   1 252  56   1   3   0 597   7]\n",
            " [ 33  23   1 105 582   1   0   0  92 172]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) ['3' '0' '4' ... '5' '6' '8']\n",
            "probabilities: (59530, 10) \n",
            " [3 0 4 ... 5 6 8]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [ 18  18  65  31  16 178  64  30  21  39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.421 s \n",
            "\n",
            "Accuracy rate for 46.270000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.98      0.85       980\n",
            "           1       0.78      0.32      0.45      1135\n",
            "           2       0.80      0.21      0.33      1032\n",
            "           3       0.43      0.78      0.55      1010\n",
            "           4       0.33      0.81      0.47       982\n",
            "           5       0.71      0.07      0.13       892\n",
            "           6       0.77      0.17      0.27       958\n",
            "           7       0.96      0.48      0.64      1028\n",
            "           8       0.26      0.72      0.38       974\n",
            "           9       0.35      0.10      0.15      1009\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.61      0.46      0.42     10000\n",
            "weighted avg       0.62      0.46      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[962   1   0   1  13   1   0   0   2   0]\n",
            " [  0 361   1 168   0   0   0   1 602   2]\n",
            " [ 40  36 218 118 304   3  18   6 280   9]\n",
            " [ 35   1   7 786  18   4   6   4 144   5]\n",
            " [  5   4   2  36 791   2   3   0 116  23]\n",
            " [ 96  13   3 315  42  63  16   6 332   6]\n",
            " [ 69  13  17  68 458  11 159   0 157   6]\n",
            " [ 48  24  21  22 118   3   0 489 177 126]\n",
            " [ 12   0   2 209  44   1   4   1 701   0]\n",
            " [ 22   8   0 120 576   1   0   4 181  97]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) ['3' '0' '4' ... '8' '6' '8']\n",
            "probabilities: (59520, 10) \n",
            " [3 0 4 ... 8 6 8]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [ 18  18  68  32  16 183  64  31  21  39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.419 s \n",
            "\n",
            "Accuracy rate for 47.300000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.98      0.78       980\n",
            "           1       0.60      0.37      0.46      1135\n",
            "           2       0.81      0.19      0.31      1032\n",
            "           3       0.45      0.79      0.57      1010\n",
            "           4       0.35      0.84      0.50       982\n",
            "           5       0.66      0.11      0.19       892\n",
            "           6       0.85      0.26      0.40       958\n",
            "           7       0.97      0.41      0.57      1028\n",
            "           8       0.29      0.69      0.41       974\n",
            "           9       0.33      0.09      0.14      1009\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.60      0.47      0.43     10000\n",
            "weighted avg       0.60      0.47      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[963   0   0   1  10   2   2   0   2   0]\n",
            " [  0 424   0 145   4   0   1   1 559   1]\n",
            " [ 53  99 198 124 313   3  13   6 215   8]\n",
            " [ 57   7   3 802  21  16   3   1  96   4]\n",
            " [ 10  12   0  28 824   3   3   0  91  11]\n",
            " [131  60   2 290  39  97  17   3 250   3]\n",
            " [148  27   5  55 367  19 247   0  86   4]\n",
            " [ 71  45  35  23 112   4   1 418 173 146]\n",
            " [ 17   5   0 227  53   1   2   1 668   0]\n",
            " [ 31  23   1 107 594   1   1   1 161  89]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) ['3' '0' '4' ... '8' '0' '8']\n",
            "probabilities: (59510, 10) \n",
            " [3 0 4 ... 8 0 8]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 18  18  69  32  17 185  66  35  21  39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.443 s \n",
            "\n",
            "Accuracy rate for 49.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
            "                   penalty='l1', random_state=None, solver='saga', tol=0.1,\n",
            "                   verbose=0, warm_start=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.98      0.77       980\n",
            "           1       0.63      0.77      0.69      1135\n",
            "           2       0.86      0.18      0.30      1032\n",
            "           3       0.49      0.77      0.60      1010\n",
            "           4       0.37      0.75      0.50       982\n",
            "           5       0.58      0.13      0.21       892\n",
            "           6       0.81      0.17      0.29       958\n",
            "           7       0.98      0.27      0.42      1028\n",
            "           8       0.30      0.68      0.42       974\n",
            "           9       0.34      0.14      0.20      1009\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.60      0.48      0.44     10000\n",
            "weighted avg       0.60      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[964   2   0   1   8   3   1   0   1   0]\n",
            " [  0 870   0  24   0   0   0   0 241   0]\n",
            " [ 55 182 190  74 198   6  19   4 294  10]\n",
            " [ 77  40   6 777   9  17   1   1  76   6]\n",
            " [  6  17   1  42 733   9   4   0 140  30]\n",
            " [158  81   1 279  44 117   7   2 202   1]\n",
            " [122  35  16  58 297  40 166   0 222   2]\n",
            " [ 83  72   8  14 156   4   2 278 183 228]\n",
            " [ 22  55   0 195  33   1   3   0 663   2]\n",
            " [ 23  32   0 123 487   3   1   0 196 144]]\n",
            "--------------------------------\n",
            "final active learning accuracies [24.46, 40.239999999999995, 50.260000000000005, 48.339999999999996, 51.35999999999999, 50.660000000000004, 51.27, 52.38, 47.65, 49.61, 49.84, 49.9, 49.230000000000004, 46.6, 46.1, 43.980000000000004, 46.339999999999996, 51.03, 50.260000000000005, 47.23, 47.089999999999996, 47.88, 43.15, 47.13, 44.11, 44.65, 44.440000000000005, 46.92, 45.879999999999995, 43.22, 42.449999999999996, 44.37, 45.9, 45.75, 49.1, 52.290000000000006, 52.949999999999996, 53.54, 51.49, 50.77, 54.84, 50.019999999999996, 47.3, 49.96, 48.66, 44.440000000000005, 46.42, 46.27, 47.3, 49.02]\n",
            "saved Active-learning-experiment-45.pkl /content ['.config', 'Active-learning-experiment-29.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-45.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-8.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-27.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-33.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-7.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-19.pkl', 'Active-learning-experiment-16.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-23.pkl', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-32.pkl', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-10.pkl', 'sample_data']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.46,\n",
            "          40.239999999999995,\n",
            "          50.260000000000005,\n",
            "          48.339999999999996,\n",
            "          51.35999999999999,\n",
            "          50.660000000000004,\n",
            "          51.27,\n",
            "          52.38,\n",
            "          47.65,\n",
            "          49.61,\n",
            "          49.84,\n",
            "          49.9,\n",
            "          49.230000000000004,\n",
            "          46.6,\n",
            "          46.1,\n",
            "          43.980000000000004,\n",
            "          46.339999999999996,\n",
            "          51.03,\n",
            "          50.260000000000005,\n",
            "          47.23,\n",
            "          47.089999999999996,\n",
            "          47.88,\n",
            "          43.15,\n",
            "          47.13,\n",
            "          44.11,\n",
            "          44.65,\n",
            "          44.440000000000005,\n",
            "          46.92,\n",
            "          45.879999999999995,\n",
            "          43.22,\n",
            "          42.449999999999996,\n",
            "          44.37,\n",
            "          45.9,\n",
            "          45.75,\n",
            "          49.1,\n",
            "          52.290000000000006,\n",
            "          52.949999999999996,\n",
            "          53.54,\n",
            "          51.49,\n",
            "          50.77,\n",
            "          54.84,\n",
            "          50.019999999999996,\n",
            "          47.3,\n",
            "          49.96,\n",
            "          48.66,\n",
            "          44.440000000000005,\n",
            "          46.42,\n",
            "          46.27,\n",
            "          47.3,\n",
            "          49.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.2,\n",
            "          63.970000000000006,\n",
            "          57.37,\n",
            "          57.95\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.88,\n",
            "          51.82,\n",
            "          51.54,\n",
            "          57.60999999999999,\n",
            "          58.07,\n",
            "          52.88,\n",
            "          52.76,\n",
            "          52.52,\n",
            "          55.410000000000004,\n",
            "          53.99,\n",
            "          53.7,\n",
            "          54.74,\n",
            "          51.870000000000005,\n",
            "          45.910000000000004,\n",
            "          56.63,\n",
            "          52.89,\n",
            "          54.94,\n",
            "          56.010000000000005,\n",
            "          56.46,\n",
            "          56.52\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          71.8,\n",
            "          65.68\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.08000000000001,\n",
            "          57.67,\n",
            "          57.45,\n",
            "          56.36,\n",
            "          51.31,\n",
            "          53.7,\n",
            "          54.21,\n",
            "          56.38999999999999,\n",
            "          57.54,\n",
            "          57.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.0,\n",
            "          41.6,\n",
            "          51.23,\n",
            "          55.86,\n",
            "          63.160000000000004,\n",
            "          66.11,\n",
            "          70.5,\n",
            "          71.31,\n",
            "          68.54,\n",
            "          70.06,\n",
            "          70.69,\n",
            "          71.07,\n",
            "          71.86,\n",
            "          73.00999999999999,\n",
            "          74.11999999999999,\n",
            "          73.67,\n",
            "          73.76,\n",
            "          74.45,\n",
            "          75.01,\n",
            "          73.98,\n",
            "          74.42,\n",
            "          74.76,\n",
            "          74.88,\n",
            "          76.0,\n",
            "          74.65,\n",
            "          75.6,\n",
            "          75.84,\n",
            "          74.33999999999999,\n",
            "          75.13,\n",
            "          71.78999999999999,\n",
            "          74.11,\n",
            "          74.33,\n",
            "          73.65,\n",
            "          74.15,\n",
            "          73.97,\n",
            "          74.21,\n",
            "          72.57000000000001,\n",
            "          72.57000000000001,\n",
            "          72.33000000000001,\n",
            "          71.61,\n",
            "          71.67999999999999,\n",
            "          70.5,\n",
            "          71.46000000000001,\n",
            "          73.18,\n",
            "          73.61,\n",
            "          72.57000000000001,\n",
            "          72.31,\n",
            "          72.46000000000001,\n",
            "          72.47,\n",
            "          72.76\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.31,\n",
            "          74.14,\n",
            "          73.79,\n",
            "          72.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          45.94,\n",
            "          60.81999999999999,\n",
            "          69.42,\n",
            "          71.08,\n",
            "          69.89,\n",
            "          70.02000000000001,\n",
            "          73.97,\n",
            "          74.13,\n",
            "          73.72,\n",
            "          72.81,\n",
            "          74.22999999999999,\n",
            "          72.96000000000001,\n",
            "          74.48,\n",
            "          75.02,\n",
            "          74.42,\n",
            "          74.17,\n",
            "          73.78,\n",
            "          74.32,\n",
            "          73.06,\n",
            "          73.31\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          74.58,\n",
            "          71.72\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.220000000000006,\n",
            "          65.96,\n",
            "          63.970000000000006,\n",
            "          70.62,\n",
            "          73.63,\n",
            "          75.53,\n",
            "          73.96000000000001,\n",
            "          73.17,\n",
            "          72.50999999999999,\n",
            "          71.74000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.180000000000003,\n",
            "          40.35,\n",
            "          50.01,\n",
            "          57.87,\n",
            "          61.53999999999999,\n",
            "          67.06,\n",
            "          69.54,\n",
            "          72.59,\n",
            "          71.99,\n",
            "          72.97,\n",
            "          71.83,\n",
            "          71.08,\n",
            "          72.68,\n",
            "          73.21,\n",
            "          73.65,\n",
            "          74.3,\n",
            "          74.06,\n",
            "          75.14999999999999,\n",
            "          75.62,\n",
            "          74.69,\n",
            "          74.03,\n",
            "          75.14,\n",
            "          75.5,\n",
            "          75.24,\n",
            "          75.26,\n",
            "          74.81,\n",
            "          75.5,\n",
            "          75.53,\n",
            "          74.85000000000001,\n",
            "          74.3,\n",
            "          76.03,\n",
            "          76.68,\n",
            "          75.82,\n",
            "          75.66000000000001,\n",
            "          75.47,\n",
            "          76.99000000000001,\n",
            "          74.64,\n",
            "          75.27000000000001,\n",
            "          76.57000000000001,\n",
            "          77.31,\n",
            "          76.9,\n",
            "          76.44,\n",
            "          76.53999999999999,\n",
            "          75.77000000000001,\n",
            "          77.25999999999999,\n",
            "          76.31,\n",
            "          76.14999999999999,\n",
            "          76.32,\n",
            "          75.71,\n",
            "          76.1\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          67.81,\n",
            "          73.41,\n",
            "          74.22999999999999,\n",
            "          73.67\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          60.0,\n",
            "          61.91,\n",
            "          66.95,\n",
            "          69.6,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          72.5,\n",
            "          72.68,\n",
            "          73.58,\n",
            "          73.81,\n",
            "          73.59,\n",
            "          73.5,\n",
            "          72.75,\n",
            "          73.72,\n",
            "          73.66,\n",
            "          74.00999999999999,\n",
            "          74.38,\n",
            "          73.42,\n",
            "          73.05,\n",
            "          73.24000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          74.1,\n",
            "          75.67\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          60.309999999999995,\n",
            "          67.99,\n",
            "          68.86,\n",
            "          69.49,\n",
            "          71.48,\n",
            "          72.54,\n",
            "          73.42999999999999,\n",
            "          74.14,\n",
            "          74.46000000000001,\n",
            "          74.11\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.95,\n",
            "          37.769999999999996,\n",
            "          36.39,\n",
            "          31.169999999999998,\n",
            "          33.33,\n",
            "          39.300000000000004,\n",
            "          42.730000000000004,\n",
            "          44.96,\n",
            "          45.97,\n",
            "          46.72,\n",
            "          46.379999999999995,\n",
            "          47.89,\n",
            "          49.120000000000005,\n",
            "          49.08,\n",
            "          48.38,\n",
            "          49.02,\n",
            "          50.96000000000001,\n",
            "          51.51,\n",
            "          52.629999999999995,\n",
            "          53.43,\n",
            "          53.400000000000006,\n",
            "          52.62,\n",
            "          53.33,\n",
            "          52.72,\n",
            "          53.169999999999995,\n",
            "          54.55,\n",
            "          55.230000000000004,\n",
            "          57.37,\n",
            "          57.56,\n",
            "          58.64,\n",
            "          59.61,\n",
            "          58.550000000000004,\n",
            "          59.48,\n",
            "          58.96,\n",
            "          59.230000000000004,\n",
            "          60.29,\n",
            "          60.35,\n",
            "          60.940000000000005,\n",
            "          60.660000000000004,\n",
            "          60.17,\n",
            "          60.69,\n",
            "          60.8,\n",
            "          62.06,\n",
            "          63.89,\n",
            "          63.28,\n",
            "          63.839999999999996,\n",
            "          63.67,\n",
            "          63.71,\n",
            "          63.980000000000004,\n",
            "          63.92\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.10000000000001,\n",
            "          73.02,\n",
            "          73.33,\n",
            "          72.53\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.730000000000004,\n",
            "          45.42,\n",
            "          46.589999999999996,\n",
            "          49.2,\n",
            "          50.44,\n",
            "          53.239999999999995,\n",
            "          57.08,\n",
            "          57.879999999999995,\n",
            "          60.47,\n",
            "          62.480000000000004,\n",
            "          60.68,\n",
            "          61.78,\n",
            "          61.18,\n",
            "          61.0,\n",
            "          59.84,\n",
            "          62.91,\n",
            "          62.99,\n",
            "          63.56,\n",
            "          64.05999999999999,\n",
            "          65.28\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          80.9,\n",
            "          81.05\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.98,\n",
            "          62.150000000000006,\n",
            "          62.67,\n",
            "          61.28,\n",
            "          60.5,\n",
            "          59.29,\n",
            "          60.480000000000004,\n",
            "          60.17,\n",
            "          60.86,\n",
            "          59.550000000000004\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          24.610000000000003,\n",
            "          39.07,\n",
            "          52.59,\n",
            "          60.88,\n",
            "          61.24000000000001,\n",
            "          67.75999999999999,\n",
            "          72.24000000000001,\n",
            "          74.92,\n",
            "          78.81,\n",
            "          79.96,\n",
            "          81.24,\n",
            "          82.33,\n",
            "          83.39999999999999,\n",
            "          85.04,\n",
            "          84.06,\n",
            "          85.28999999999999,\n",
            "          84.85000000000001,\n",
            "          85.45,\n",
            "          86.29,\n",
            "          86.78,\n",
            "          87.19,\n",
            "          87.11,\n",
            "          88.28,\n",
            "          88.01,\n",
            "          88.49000000000001,\n",
            "          88.3,\n",
            "          89.01,\n",
            "          89.29,\n",
            "          89.67,\n",
            "          90.22,\n",
            "          90.2,\n",
            "          90.22,\n",
            "          90.53,\n",
            "          91.07,\n",
            "          90.64,\n",
            "          90.96,\n",
            "          91.17,\n",
            "          91.47999999999999,\n",
            "          91.64999999999999,\n",
            "          91.74,\n",
            "          91.96,\n",
            "          91.63,\n",
            "          91.86,\n",
            "          91.9,\n",
            "          91.79,\n",
            "          91.9,\n",
            "          92.23,\n",
            "          92.08,\n",
            "          92.41,\n",
            "          92.54\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.8,\n",
            "          83.47,\n",
            "          89.21,\n",
            "          91.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.74999999999999,\n",
            "          66.17,\n",
            "          70.77,\n",
            "          77.29,\n",
            "          81.23,\n",
            "          82.98,\n",
            "          86.08,\n",
            "          88.09,\n",
            "          88.42,\n",
            "          88.94999999999999,\n",
            "          89.01,\n",
            "          89.88000000000001,\n",
            "          90.82000000000001,\n",
            "          91.28,\n",
            "          91.4,\n",
            "          92.01,\n",
            "          92.36999999999999,\n",
            "          91.9,\n",
            "          92.80000000000001,\n",
            "          93.22\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.06,\n",
            "          90.36\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          54.059999999999995,\n",
            "          71.72,\n",
            "          78.44,\n",
            "          83.62,\n",
            "          86.50999999999999,\n",
            "          88.63,\n",
            "          89.85,\n",
            "          91.10000000000001,\n",
            "          91.59,\n",
            "          91.78\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.419999999999998,\n",
            "          37.04,\n",
            "          42.42,\n",
            "          58.76,\n",
            "          64.44,\n",
            "          65.27,\n",
            "          67.69,\n",
            "          70.04,\n",
            "          71.91,\n",
            "          73.61,\n",
            "          73.45,\n",
            "          75.73,\n",
            "          76.29,\n",
            "          78.66,\n",
            "          79.88,\n",
            "          79.59,\n",
            "          79.9,\n",
            "          81.11,\n",
            "          81.39999999999999,\n",
            "          81.71000000000001,\n",
            "          81.55,\n",
            "          82.54,\n",
            "          82.36,\n",
            "          82.41000000000001,\n",
            "          82.89999999999999,\n",
            "          83.2,\n",
            "          84.34,\n",
            "          84.52,\n",
            "          85.04,\n",
            "          85.46000000000001,\n",
            "          84.94,\n",
            "          85.69,\n",
            "          85.39999999999999,\n",
            "          85.61999999999999,\n",
            "          85.64,\n",
            "          85.97,\n",
            "          86.13,\n",
            "          86.14,\n",
            "          86.33999999999999,\n",
            "          86.31,\n",
            "          86.95,\n",
            "          86.85000000000001,\n",
            "          87.03,\n",
            "          87.38,\n",
            "          87.39,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          87.68,\n",
            "          87.64999999999999,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.36,\n",
            "          83.22,\n",
            "          86.61,\n",
            "          88.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          40.47,\n",
            "          51.01,\n",
            "          64.7,\n",
            "          72.8,\n",
            "          76.29,\n",
            "          75.97,\n",
            "          78.34,\n",
            "          79.21000000000001,\n",
            "          81.67,\n",
            "          81.62,\n",
            "          82.82000000000001,\n",
            "          83.03,\n",
            "          84.53,\n",
            "          85.19,\n",
            "          85.39,\n",
            "          85.59,\n",
            "          86.63,\n",
            "          86.53,\n",
            "          87.07000000000001,\n",
            "          87.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.99,\n",
            "          87.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          58.599999999999994,\n",
            "          66.18,\n",
            "          75.63,\n",
            "          79.12,\n",
            "          82.32000000000001,\n",
            "          83.25,\n",
            "          84.36,\n",
            "          84.54,\n",
            "          85.55,\n",
            "          86.94\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.46,\n",
            "          26.52,\n",
            "          27.750000000000004,\n",
            "          28.32,\n",
            "          32.58,\n",
            "          34.42,\n",
            "          37.730000000000004,\n",
            "          37.89,\n",
            "          38.5,\n",
            "          40.43,\n",
            "          46.910000000000004,\n",
            "          44.56,\n",
            "          44.75,\n",
            "          49.14,\n",
            "          49.2,\n",
            "          51.44,\n",
            "          51.9,\n",
            "          51.190000000000005,\n",
            "          52.790000000000006,\n",
            "          52.669999999999995,\n",
            "          55.17999999999999,\n",
            "          56.21000000000001,\n",
            "          56.88999999999999,\n",
            "          58.02,\n",
            "          57.940000000000005,\n",
            "          58.01,\n",
            "          58.8,\n",
            "          59.67,\n",
            "          60.79,\n",
            "          69.84,\n",
            "          69.94,\n",
            "          71.21,\n",
            "          71.02000000000001,\n",
            "          71.88,\n",
            "          72.24000000000001,\n",
            "          72.64,\n",
            "          73.58,\n",
            "          73.7,\n",
            "          75.27000000000001,\n",
            "          75.28,\n",
            "          75.78,\n",
            "          75.67,\n",
            "          76.34,\n",
            "          76.42,\n",
            "          76.63,\n",
            "          77.47,\n",
            "          77.32,\n",
            "          77.95,\n",
            "          78.52,\n",
            "          78.44\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.64,\n",
            "          78.97,\n",
            "          82.8,\n",
            "          82.92\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          52.190000000000005,\n",
            "          66.83,\n",
            "          68.82000000000001,\n",
            "          72.3,\n",
            "          71.36,\n",
            "          71.93,\n",
            "          72.02,\n",
            "          73.66,\n",
            "          73.11,\n",
            "          74.53999999999999,\n",
            "          76.14,\n",
            "          74.75,\n",
            "          74.41,\n",
            "          74.85000000000001,\n",
            "          75.21,\n",
            "          76.05,\n",
            "          76.09,\n",
            "          75.62,\n",
            "          75.0,\n",
            "          75.07000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.14,\n",
            "          85.28\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.849999999999994,\n",
            "          66.17,\n",
            "          68.55,\n",
            "          73.15,\n",
            "          74.16,\n",
            "          77.57,\n",
            "          78.94,\n",
            "          80.39,\n",
            "          78.41,\n",
            "          80.45\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          23.97,\n",
            "          34.5,\n",
            "          42.51,\n",
            "          50.09,\n",
            "          53.31,\n",
            "          67.80000000000001,\n",
            "          72.57000000000001,\n",
            "          76.67,\n",
            "          77.62,\n",
            "          79.01,\n",
            "          79.86,\n",
            "          80.84,\n",
            "          81.82000000000001,\n",
            "          81.89,\n",
            "          83.88,\n",
            "          84.03,\n",
            "          84.53,\n",
            "          84.54,\n",
            "          84.82,\n",
            "          84.99,\n",
            "          85.11,\n",
            "          85.98,\n",
            "          86.08,\n",
            "          86.0,\n",
            "          86.50999999999999,\n",
            "          86.45,\n",
            "          86.75,\n",
            "          86.50999999999999,\n",
            "          86.18,\n",
            "          86.4,\n",
            "          86.42999999999999,\n",
            "          86.4,\n",
            "          86.3,\n",
            "          86.77,\n",
            "          86.7,\n",
            "          86.82,\n",
            "          86.78,\n",
            "          86.83999999999999,\n",
            "          86.7,\n",
            "          86.92999999999999,\n",
            "          87.26,\n",
            "          87.62,\n",
            "          87.83,\n",
            "          87.76,\n",
            "          88.11,\n",
            "          88.16000000000001,\n",
            "          88.13,\n",
            "          87.91,\n",
            "          88.0,\n",
            "          88.01\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.74,\n",
            "          84.41,\n",
            "          86.76,\n",
            "          87.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          48.74,\n",
            "          61.33,\n",
            "          68.51,\n",
            "          76.42,\n",
            "          79.34,\n",
            "          81.43,\n",
            "          83.39999999999999,\n",
            "          84.61999999999999,\n",
            "          84.17,\n",
            "          84.88,\n",
            "          85.86,\n",
            "          86.72999999999999,\n",
            "          86.66,\n",
            "          87.55,\n",
            "          87.94,\n",
            "          88.74,\n",
            "          88.91,\n",
            "          88.9,\n",
            "          88.99000000000001,\n",
            "          89.18\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.66,\n",
            "          86.14\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          66.58,\n",
            "          80.08,\n",
            "          81.42,\n",
            "          85.28,\n",
            "          86.69,\n",
            "          87.0,\n",
            "          86.33999999999999,\n",
            "          87.19,\n",
            "          87.94999999999999,\n",
            "          88.46000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          32.9,\n",
            "          42.53,\n",
            "          53.580000000000005,\n",
            "          57.120000000000005,\n",
            "          64.66,\n",
            "          69.74000000000001,\n",
            "          71.8,\n",
            "          73.27,\n",
            "          75.63,\n",
            "          76.98,\n",
            "          77.4,\n",
            "          78.44,\n",
            "          78.47,\n",
            "          79.14999999999999,\n",
            "          79.23,\n",
            "          79.62,\n",
            "          79.86999999999999,\n",
            "          80.43,\n",
            "          81.5,\n",
            "          81.73,\n",
            "          82.43,\n",
            "          82.78999999999999,\n",
            "          83.45,\n",
            "          83.87,\n",
            "          83.93,\n",
            "          83.87,\n",
            "          84.1,\n",
            "          84.57000000000001,\n",
            "          84.6,\n",
            "          84.54,\n",
            "          84.48,\n",
            "          85.22,\n",
            "          85.39999999999999,\n",
            "          85.52,\n",
            "          85.46000000000001,\n",
            "          85.77,\n",
            "          85.71,\n",
            "          86.07000000000001,\n",
            "          85.97,\n",
            "          86.00999999999999,\n",
            "          86.29,\n",
            "          86.18,\n",
            "          86.49,\n",
            "          86.64,\n",
            "          86.64,\n",
            "          86.53999999999999,\n",
            "          86.64,\n",
            "          86.72999999999999,\n",
            "          86.89,\n",
            "          87.02\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.27,\n",
            "          84.8,\n",
            "          86.02,\n",
            "          86.89\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          49.04,\n",
            "          62.35000000000001,\n",
            "          68.04,\n",
            "          73.72999999999999,\n",
            "          76.63,\n",
            "          78.67,\n",
            "          79.77,\n",
            "          81.73,\n",
            "          83.59,\n",
            "          84.13000000000001,\n",
            "          84.81,\n",
            "          84.63000000000001,\n",
            "          85.08,\n",
            "          85.96000000000001,\n",
            "          86.29,\n",
            "          86.57000000000001,\n",
            "          87.18,\n",
            "          87.36,\n",
            "          87.46000000000001,\n",
            "          87.72\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.69,\n",
            "          86.83999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          65.33,\n",
            "          74.72999999999999,\n",
            "          78.69,\n",
            "          82.0,\n",
            "          84.82,\n",
            "          86.37,\n",
            "          86.89,\n",
            "          87.12,\n",
            "          87.64999999999999,\n",
            "          87.8\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "{'SvmModel': {'RandomSelection': {'250': [[84.69, 86.83999999999999]], '125': [[79.27, 84.8, 86.02, 86.89]], '50': [[65.33, 74.72999999999999, 78.69, 82.0, 84.82, 86.37, 86.89, 87.12, 87.64999999999999, 87.8]], '25': [[49.04, 62.35000000000001, 68.04, 73.72999999999999, 76.63, 78.67, 79.77, 81.73, 83.59, 84.13000000000001, 84.81, 84.63000000000001, 85.08, 85.96000000000001, 86.29, 86.57000000000001, 87.18, 87.36, 87.46000000000001, 87.72]], '10': [[32.9, 42.53, 53.580000000000005, 57.120000000000005, 64.66, 69.74000000000001, 71.8, 73.27, 75.63, 76.98, 77.4, 78.44, 78.47, 79.14999999999999, 79.23, 79.62, 79.86999999999999, 80.43, 81.5, 81.73, 82.43, 82.78999999999999, 83.45, 83.87, 83.93, 83.87, 84.1, 84.57000000000001, 84.6, 84.54, 84.48, 85.22, 85.39999999999999, 85.52, 85.46000000000001, 85.77, 85.71, 86.07000000000001, 85.97, 86.00999999999999, 86.29, 86.18, 86.49, 86.64, 86.64, 86.53999999999999, 86.64, 86.72999999999999, 86.89, 87.02]]}, 'MarginSamplingSelection': {'250': [[83.66, 86.14]], '125': [[75.74, 84.41, 86.76, 87.86]], '50': [[66.58, 80.08, 81.42, 85.28, 86.69, 87.0, 86.33999999999999, 87.19, 87.94999999999999, 88.46000000000001]], '25': [[48.74, 61.33, 68.51, 76.42, 79.34, 81.43, 83.39999999999999, 84.61999999999999, 84.17, 84.88, 85.86, 86.72999999999999, 86.66, 87.55, 87.94, 88.74, 88.91, 88.9, 88.99000000000001, 89.18]], '10': [[23.97, 34.5, 42.51, 50.09, 53.31, 67.80000000000001, 72.57000000000001, 76.67, 77.62, 79.01, 79.86, 80.84, 81.82000000000001, 81.89, 83.88, 84.03, 84.53, 84.54, 84.82, 84.99, 85.11, 85.98, 86.08, 86.0, 86.50999999999999, 86.45, 86.75, 86.50999999999999, 86.18, 86.4, 86.42999999999999, 86.4, 86.3, 86.77, 86.7, 86.82, 86.78, 86.83999999999999, 86.7, 86.92999999999999, 87.26, 87.62, 87.83, 87.76, 88.11, 88.16000000000001, 88.13, 87.91, 88.0, 88.01]]}, 'EntropySelection': {'250': [[84.14, 85.28]], '125': [[74.64, 78.97, 82.8, 82.92]], '50': [[62.849999999999994, 66.17, 68.55, 73.15, 74.16, 77.57, 78.94, 80.39, 78.41, 80.45]], '25': [[52.190000000000005, 66.83, 68.82000000000001, 72.3, 71.36, 71.93, 72.02, 73.66, 73.11, 74.53999999999999, 76.14, 74.75, 74.41, 74.85000000000001, 75.21, 76.05, 76.09, 75.62, 75.0, 75.07000000000001]], '10': [[23.46, 26.52, 27.750000000000004, 28.32, 32.58, 34.42, 37.730000000000004, 37.89, 38.5, 40.43, 46.910000000000004, 44.56, 44.75, 49.14, 49.2, 51.44, 51.9, 51.190000000000005, 52.790000000000006, 52.669999999999995, 55.17999999999999, 56.21000000000001, 56.88999999999999, 58.02, 57.940000000000005, 58.01, 58.8, 59.67, 60.79, 69.84, 69.94, 71.21, 71.02000000000001, 71.88, 72.24000000000001, 72.64, 73.58, 73.7, 75.27000000000001, 75.28, 75.78, 75.67, 76.34, 76.42, 76.63, 77.47, 77.32, 77.95, 78.52, 78.44]]}}, 'RfModel': {'RandomSelection': {'250': [[84.99, 87.14]], '125': [[71.36, 83.22, 86.61, 88.81]], '50': [[58.599999999999994, 66.18, 75.63, 79.12, 82.32000000000001, 83.25, 84.36, 84.54, 85.55, 86.94]], '25': [[40.47, 51.01, 64.7, 72.8, 76.29, 75.97, 78.34, 79.21000000000001, 81.67, 81.62, 82.82000000000001, 83.03, 84.53, 85.19, 85.39, 85.59, 86.63, 86.53, 87.07000000000001, 87.0]], '10': [[31.419999999999998, 37.04, 42.42, 58.76, 64.44, 65.27, 67.69, 70.04, 71.91, 73.61, 73.45, 75.73, 76.29, 78.66, 79.88, 79.59, 79.9, 81.11, 81.39999999999999, 81.71000000000001, 81.55, 82.54, 82.36, 82.41000000000001, 82.89999999999999, 83.2, 84.34, 84.52, 85.04, 85.46000000000001, 84.94, 85.69, 85.39999999999999, 85.61999999999999, 85.64, 85.97, 86.13, 86.14, 86.33999999999999, 86.31, 86.95, 86.85000000000001, 87.03, 87.38, 87.39, 87.46000000000001, 87.64, 87.68, 87.64999999999999, 88.01]]}, 'MarginSamplingSelection': {'250': [[83.06, 90.36]], '125': [[71.8, 83.47, 89.21, 91.49000000000001]], '50': [[54.059999999999995, 71.72, 78.44, 83.62, 86.50999999999999, 88.63, 89.85, 91.10000000000001, 91.59, 91.78]], '25': [[51.74999999999999, 66.17, 70.77, 77.29, 81.23, 82.98, 86.08, 88.09, 88.42, 88.94999999999999, 89.01, 89.88000000000001, 90.82000000000001, 91.28, 91.4, 92.01, 92.36999999999999, 91.9, 92.80000000000001, 93.22]], '10': [[24.610000000000003, 39.07, 52.59, 60.88, 61.24000000000001, 67.75999999999999, 72.24000000000001, 74.92, 78.81, 79.96, 81.24, 82.33, 83.39999999999999, 85.04, 84.06, 85.28999999999999, 84.85000000000001, 85.45, 86.29, 86.78, 87.19, 87.11, 88.28, 88.01, 88.49000000000001, 88.3, 89.01, 89.29, 89.67, 90.22, 90.2, 90.22, 90.53, 91.07, 90.64, 90.96, 91.17, 91.47999999999999, 91.64999999999999, 91.74, 91.96, 91.63, 91.86, 91.9, 91.79, 91.9, 92.23, 92.08, 92.41, 92.54]]}, 'EntropySelection': {'250': [[80.9, 81.05]], '125': [[77.10000000000001, 73.02, 73.33, 72.53]], '50': [[58.98, 62.150000000000006, 62.67, 61.28, 60.5, 59.29, 60.480000000000004, 60.17, 60.86, 59.550000000000004]], '25': [[41.730000000000004, 45.42, 46.589999999999996, 49.2, 50.44, 53.239999999999995, 57.08, 57.879999999999995, 60.47, 62.480000000000004, 60.68, 61.78, 61.18, 61.0, 59.84, 62.91, 62.99, 63.56, 64.05999999999999, 65.28]], '10': [[33.95, 37.769999999999996, 36.39, 31.169999999999998, 33.33, 39.300000000000004, 42.730000000000004, 44.96, 45.97, 46.72, 46.379999999999995, 47.89, 49.120000000000005, 49.08, 48.38, 49.02, 50.96000000000001, 51.51, 52.629999999999995, 53.43, 53.400000000000006, 52.62, 53.33, 52.72, 53.169999999999995, 54.55, 55.230000000000004, 57.37, 57.56, 58.64, 59.61, 58.550000000000004, 59.48, 58.96, 59.230000000000004, 60.29, 60.35, 60.940000000000005, 60.660000000000004, 60.17, 60.69, 60.8, 62.06, 63.89, 63.28, 63.839999999999996, 63.67, 63.71, 63.980000000000004, 63.92]]}}, 'LogModel': {'RandomSelection': {'250': [[74.1, 75.67]], '125': [[67.81, 73.41, 74.22999999999999, 73.67]], '50': [[60.309999999999995, 67.99, 68.86, 69.49, 71.48, 72.54, 73.42999999999999, 74.14, 74.46000000000001, 74.11]], '25': [[60.0, 61.91, 66.95, 69.6, 71.21, 71.02000000000001, 72.5, 72.68, 73.58, 73.81, 73.59, 73.5, 72.75, 73.72, 73.66, 74.00999999999999, 74.38, 73.42, 73.05, 73.24000000000001]], '10': [[31.180000000000003, 40.35, 50.01, 57.87, 61.53999999999999, 67.06, 69.54, 72.59, 71.99, 72.97, 71.83, 71.08, 72.68, 73.21, 73.65, 74.3, 74.06, 75.14999999999999, 75.62, 74.69, 74.03, 75.14, 75.5, 75.24, 75.26, 74.81, 75.5, 75.53, 74.85000000000001, 74.3, 76.03, 76.68, 75.82, 75.66000000000001, 75.47, 76.99000000000001, 74.64, 75.27000000000001, 76.57000000000001, 77.31, 76.9, 76.44, 76.53999999999999, 75.77000000000001, 77.25999999999999, 76.31, 76.14999999999999, 76.32, 75.71, 76.1]]}, 'MarginSamplingSelection': {'250': [[74.58, 71.72]], '125': [[73.31, 74.14, 73.79, 72.86]], '50': [[58.220000000000006, 65.96, 63.970000000000006, 70.62, 73.63, 75.53, 73.96000000000001, 73.17, 72.50999999999999, 71.74000000000001]], '25': [[45.94, 60.81999999999999, 69.42, 71.08, 69.89, 70.02000000000001, 73.97, 74.13, 73.72, 72.81, 74.22999999999999, 72.96000000000001, 74.48, 75.02, 74.42, 74.17, 73.78, 74.32, 73.06, 73.31]], '10': [[36.0, 41.6, 51.23, 55.86, 63.160000000000004, 66.11, 70.5, 71.31, 68.54, 70.06, 70.69, 71.07, 71.86, 73.00999999999999, 74.11999999999999, 73.67, 73.76, 74.45, 75.01, 73.98, 74.42, 74.76, 74.88, 76.0, 74.65, 75.6, 75.84, 74.33999999999999, 75.13, 71.78999999999999, 74.11, 74.33, 73.65, 74.15, 73.97, 74.21, 72.57000000000001, 72.57000000000001, 72.33000000000001, 71.61, 71.67999999999999, 70.5, 71.46000000000001, 73.18, 73.61, 72.57000000000001, 72.31, 72.46000000000001, 72.47, 72.76]]}, 'EntropySelection': {'250': [[71.8, 65.68]], '125': [[71.2, 63.970000000000006, 57.37, 57.95]], '50': [[66.08000000000001, 57.67, 57.45, 56.36, 51.31, 53.7, 54.21, 56.38999999999999, 57.54, 57.78]], '25': [[51.88, 51.82, 51.54, 57.60999999999999, 58.07, 52.88, 52.76, 52.52, 55.410000000000004, 53.99, 53.7, 54.74, 51.870000000000005, 45.910000000000004, 56.63, 52.89, 54.94, 56.010000000000005, 56.46, 56.52]], '10': [[24.46, 40.239999999999995, 50.260000000000005, 48.339999999999996, 51.35999999999999, 50.660000000000004, 51.27, 52.38, 47.65, 49.61, 49.84, 49.9, 49.230000000000004, 46.6, 46.1, 43.980000000000004, 46.339999999999996, 51.03, 50.260000000000005, 47.23, 47.089999999999996, 47.88, 43.15, 47.13, 44.11, 44.65, 44.440000000000005, 46.92, 45.879999999999995, 43.22, 42.449999999999996, 44.37, 45.9, 45.75, 49.1, 52.290000000000006, 52.949999999999996, 53.54, 51.49, 50.77, 54.84, 50.019999999999996, 47.3, 49.96, 48.66, 44.440000000000005, 46.42, 46.27, 47.3, 49.02]]}}}\n",
            "{'LogModel': {'EntropySelection': {'10': [[24.46, 40.239999999999995, 50.260000000000005, 48.339999999999996, 51.35999999999999, 50.660000000000004, 51.27, 52.38, 47.65, 49.61, 49.84, 49.9, 49.230000000000004, 46.6, 46.1, 43.980000000000004, 46.339999999999996, 51.03, 50.260000000000005, 47.23, 47.089999999999996, 47.88, 43.15, 47.13, 44.11, 44.65, 44.440000000000005, 46.92, 45.879999999999995, 43.22, 42.449999999999996, 44.37, 45.9, 45.75, 49.1, 52.290000000000006, 52.949999999999996, 53.54, 51.49, 50.77, 54.84, 50.019999999999996, 47.3, 49.96, 48.66, 44.440000000000005, 46.42, 46.27, 47.3, 49.02]], '125': [[71.2, 63.970000000000006, 57.37, 57.95]], '25': [[51.88, 51.82, 51.54, 57.60999999999999, 58.07, 52.88, 52.76, 52.52, 55.410000000000004, 53.99, 53.7, 54.74, 51.870000000000005, 45.910000000000004, 56.63, 52.89, 54.94, 56.010000000000005, 56.46, 56.52]], '250': [[71.8, 65.68]], '50': [[66.08000000000001, 57.67, 57.45, 56.36, 51.31, 53.7, 54.21, 56.38999999999999, 57.54, 57.78]]}, 'MarginSamplingSelection': {'10': [[36.0, 41.6, 51.23, 55.86, 63.160000000000004, 66.11, 70.5, 71.31, 68.54, 70.06, 70.69, 71.07, 71.86, 73.00999999999999, 74.11999999999999, 73.67, 73.76, 74.45, 75.01, 73.98, 74.42, 74.76, 74.88, 76.0, 74.65, 75.6, 75.84, 74.33999999999999, 75.13, 71.78999999999999, 74.11, 74.33, 73.65, 74.15, 73.97, 74.21, 72.57000000000001, 72.57000000000001, 72.33000000000001, 71.61, 71.67999999999999, 70.5, 71.46000000000001, 73.18, 73.61, 72.57000000000001, 72.31, 72.46000000000001, 72.47, 72.76]], '125': [[73.31, 74.14, 73.79, 72.86]], '25': [[45.94, 60.81999999999999, 69.42, 71.08, 69.89, 70.02000000000001, 73.97, 74.13, 73.72, 72.81, 74.22999999999999, 72.96000000000001, 74.48, 75.02, 74.42, 74.17, 73.78, 74.32, 73.06, 73.31]], '250': [[74.58, 71.72]], '50': [[58.220000000000006, 65.96, 63.970000000000006, 70.62, 73.63, 75.53, 73.96000000000001, 73.17, 72.50999999999999, 71.74000000000001]]}, 'RandomSelection': {'10': [[31.180000000000003, 40.35, 50.01, 57.87, 61.53999999999999, 67.06, 69.54, 72.59, 71.99, 72.97, 71.83, 71.08, 72.68, 73.21, 73.65, 74.3, 74.06, 75.14999999999999, 75.62, 74.69, 74.03, 75.14, 75.5, 75.24, 75.26, 74.81, 75.5, 75.53, 74.85000000000001, 74.3, 76.03, 76.68, 75.82, 75.66000000000001, 75.47, 76.99000000000001, 74.64, 75.27000000000001, 76.57000000000001, 77.31, 76.9, 76.44, 76.53999999999999, 75.77000000000001, 77.25999999999999, 76.31, 76.14999999999999, 76.32, 75.71, 76.1]], '125': [[67.81, 73.41, 74.22999999999999, 73.67]], '25': [[60.0, 61.91, 66.95, 69.6, 71.21, 71.02000000000001, 72.5, 72.68, 73.58, 73.81, 73.59, 73.5, 72.75, 73.72, 73.66, 74.00999999999999, 74.38, 73.42, 73.05, 73.24000000000001]], '250': [[74.1, 75.67]], '50': [[60.309999999999995, 67.99, 68.86, 69.49, 71.48, 72.54, 73.42999999999999, 74.14, 74.46000000000001, 74.11]]}}, 'RfModel': {'EntropySelection': {'10': [[33.95, 37.769999999999996, 36.39, 31.169999999999998, 33.33, 39.300000000000004, 42.730000000000004, 44.96, 45.97, 46.72, 46.379999999999995, 47.89, 49.120000000000005, 49.08, 48.38, 49.02, 50.96000000000001, 51.51, 52.629999999999995, 53.43, 53.400000000000006, 52.62, 53.33, 52.72, 53.169999999999995, 54.55, 55.230000000000004, 57.37, 57.56, 58.64, 59.61, 58.550000000000004, 59.48, 58.96, 59.230000000000004, 60.29, 60.35, 60.940000000000005, 60.660000000000004, 60.17, 60.69, 60.8, 62.06, 63.89, 63.28, 63.839999999999996, 63.67, 63.71, 63.980000000000004, 63.92]], '125': [[77.10000000000001, 73.02, 73.33, 72.53]], '25': [[41.730000000000004, 45.42, 46.589999999999996, 49.2, 50.44, 53.239999999999995, 57.08, 57.879999999999995, 60.47, 62.480000000000004, 60.68, 61.78, 61.18, 61.0, 59.84, 62.91, 62.99, 63.56, 64.05999999999999, 65.28]], '250': [[80.9, 81.05]], '50': [[58.98, 62.150000000000006, 62.67, 61.28, 60.5, 59.29, 60.480000000000004, 60.17, 60.86, 59.550000000000004]]}, 'MarginSamplingSelection': {'10': [[24.610000000000003, 39.07, 52.59, 60.88, 61.24000000000001, 67.75999999999999, 72.24000000000001, 74.92, 78.81, 79.96, 81.24, 82.33, 83.39999999999999, 85.04, 84.06, 85.28999999999999, 84.85000000000001, 85.45, 86.29, 86.78, 87.19, 87.11, 88.28, 88.01, 88.49000000000001, 88.3, 89.01, 89.29, 89.67, 90.22, 90.2, 90.22, 90.53, 91.07, 90.64, 90.96, 91.17, 91.47999999999999, 91.64999999999999, 91.74, 91.96, 91.63, 91.86, 91.9, 91.79, 91.9, 92.23, 92.08, 92.41, 92.54]], '125': [[71.8, 83.47, 89.21, 91.49000000000001]], '25': [[51.74999999999999, 66.17, 70.77, 77.29, 81.23, 82.98, 86.08, 88.09, 88.42, 88.94999999999999, 89.01, 89.88000000000001, 90.82000000000001, 91.28, 91.4, 92.01, 92.36999999999999, 91.9, 92.80000000000001, 93.22]], '250': [[83.06, 90.36]], '50': [[54.059999999999995, 71.72, 78.44, 83.62, 86.50999999999999, 88.63, 89.85, 91.10000000000001, 91.59, 91.78]]}, 'RandomSelection': {'10': [[31.419999999999998, 37.04, 42.42, 58.76, 64.44, 65.27, 67.69, 70.04, 71.91, 73.61, 73.45, 75.73, 76.29, 78.66, 79.88, 79.59, 79.9, 81.11, 81.39999999999999, 81.71000000000001, 81.55, 82.54, 82.36, 82.41000000000001, 82.89999999999999, 83.2, 84.34, 84.52, 85.04, 85.46000000000001, 84.94, 85.69, 85.39999999999999, 85.61999999999999, 85.64, 85.97, 86.13, 86.14, 86.33999999999999, 86.31, 86.95, 86.85000000000001, 87.03, 87.38, 87.39, 87.46000000000001, 87.64, 87.68, 87.64999999999999, 88.01]], '125': [[71.36, 83.22, 86.61, 88.81]], '25': [[40.47, 51.01, 64.7, 72.8, 76.29, 75.97, 78.34, 79.21000000000001, 81.67, 81.62, 82.82000000000001, 83.03, 84.53, 85.19, 85.39, 85.59, 86.63, 86.53, 87.07000000000001, 87.0]], '250': [[84.99, 87.14]], '50': [[58.599999999999994, 66.18, 75.63, 79.12, 82.32000000000001, 83.25, 84.36, 84.54, 85.55, 86.94]]}}, 'SvmModel': {'EntropySelection': {'10': [[23.46, 26.52, 27.750000000000004, 28.32, 32.58, 34.42, 37.730000000000004, 37.89, 38.5, 40.43, 46.910000000000004, 44.56, 44.75, 49.14, 49.2, 51.44, 51.9, 51.190000000000005, 52.790000000000006, 52.669999999999995, 55.17999999999999, 56.21000000000001, 56.88999999999999, 58.02, 57.940000000000005, 58.01, 58.8, 59.67, 60.79, 69.84, 69.94, 71.21, 71.02000000000001, 71.88, 72.24000000000001, 72.64, 73.58, 73.7, 75.27000000000001, 75.28, 75.78, 75.67, 76.34, 76.42, 76.63, 77.47, 77.32, 77.95, 78.52, 78.44]], '125': [[74.64, 78.97, 82.8, 82.92]], '25': [[52.190000000000005, 66.83, 68.82000000000001, 72.3, 71.36, 71.93, 72.02, 73.66, 73.11, 74.53999999999999, 76.14, 74.75, 74.41, 74.85000000000001, 75.21, 76.05, 76.09, 75.62, 75.0, 75.07000000000001]], '250': [[84.14, 85.28]], '50': [[62.849999999999994, 66.17, 68.55, 73.15, 74.16, 77.57, 78.94, 80.39, 78.41, 80.45]]}, 'MarginSamplingSelection': {'10': [[23.97, 34.5, 42.51, 50.09, 53.31, 67.80000000000001, 72.57000000000001, 76.67, 77.62, 79.01, 79.86, 80.84, 81.82000000000001, 81.89, 83.88, 84.03, 84.53, 84.54, 84.82, 84.99, 85.11, 85.98, 86.08, 86.0, 86.50999999999999, 86.45, 86.75, 86.50999999999999, 86.18, 86.4, 86.42999999999999, 86.4, 86.3, 86.77, 86.7, 86.82, 86.78, 86.83999999999999, 86.7, 86.92999999999999, 87.26, 87.62, 87.83, 87.76, 88.11, 88.16000000000001, 88.13, 87.91, 88.0, 88.01]], '125': [[75.74, 84.41, 86.76, 87.86]], '25': [[48.74, 61.33, 68.51, 76.42, 79.34, 81.43, 83.39999999999999, 84.61999999999999, 84.17, 84.88, 85.86, 86.72999999999999, 86.66, 87.55, 87.94, 88.74, 88.91, 88.9, 88.99000000000001, 89.18]], '250': [[83.66, 86.14]], '50': [[66.58, 80.08, 81.42, 85.28, 86.69, 87.0, 86.33999999999999, 87.19, 87.94999999999999, 88.46000000000001]]}, 'RandomSelection': {'10': [[32.9, 42.53, 53.580000000000005, 57.120000000000005, 64.66, 69.74000000000001, 71.8, 73.27, 75.63, 76.98, 77.4, 78.44, 78.47, 79.14999999999999, 79.23, 79.62, 79.86999999999999, 80.43, 81.5, 81.73, 82.43, 82.78999999999999, 83.45, 83.87, 83.93, 83.87, 84.1, 84.57000000000001, 84.6, 84.54, 84.48, 85.22, 85.39999999999999, 85.52, 85.46000000000001, 85.77, 85.71, 86.07000000000001, 85.97, 86.00999999999999, 86.29, 86.18, 86.49, 86.64, 86.64, 86.53999999999999, 86.64, 86.72999999999999, 86.89, 87.02]], '125': [[79.27, 84.8, 86.02, 86.89]], '25': [[49.04, 62.35000000000001, 68.04, 73.72999999999999, 76.63, 78.67, 79.77, 81.73, 83.59, 84.13000000000001, 84.81, 84.63000000000001, 85.08, 85.96000000000001, 86.29, 86.57000000000001, 87.18, 87.36, 87.46000000000001, 87.72]], '250': [[84.69, 86.83999999999999]], '50': [[65.33, 74.72999999999999, 78.69, 82.0, 84.82, 86.37, 86.89, 87.12, 87.64999999999999, 87.8]]}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT9kYxtP381F"
      },
      "source": [
        "Independently, we trained several models using a train-test split of 60K-10K, the results indicate that the upper-bound for RF, SVM and LOG are 97., 94. and 92.47, respectively.\n",
        "\n",
        "The following graphs show that the random forest classifier paired with the margin-selection method and k=10 is the best configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXoHDRLArYjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ce9275-0af8-42cd-abde-176aaf7314ce"
      },
      "source": [
        "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
        "    for model_object in models:\n",
        "      for selection_function in selection_functions:\n",
        "        for idx, k in enumerate(Ks):\n",
        "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "            for i in range(1, repeats):\n",
        "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "            mean = Sum / repeats\n",
        "            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\n",
        "    ax.legend()\n",
        "    ax.set_xlim([50,500])\n",
        "    ax.set_ylim([40,100])\n",
        "    ax.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "models_str = ['SvmModel', 'RfModel', 'LogModel']\n",
        "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection']\n",
        "Ks_str = ['250','125','50','25','10'] \n",
        "repeats = 1\n",
        "random_forest_upper_bound = 97.\n",
        "svm_upper_bound = 94.\n",
        "log_upper_bound = 92.47\n",
        "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "print('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny0_f1nyOi3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8a5a95-c33a-4e57-e339-e43f454d78af"
      },
      "source": [
        "\n",
        "print('So which is the best sample selection function? margin sampling is the winner!')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'], selection_functions_str    , Ks_str, 1)\n",
        "print()\n",
        "print('So which is the best k? k=10 is the winner')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'] , ['MarginSamplingSelection'], Ks_str, 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So which is the best sample selection function? margin sampling is the winner!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "So which is the best k? k=10 is the winner\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z82imfIIPoJd"
      },
      "source": [
        "I would like to thank Moshe Hadad for his valueable critique regarding PEP8 and Shay Zweig for his proof-reading and comments.\n",
        "\n",
        "Ori Cohen has done his PhD in computer science in the fields of machine learning, brain-computer-interface and neurobiology.\n",
        "\n",
        "[1] Shay Yehezkel, *High Dimensional Statistical Process Control and Application*, M.Sc Thesis.\n",
        "\n",
        "[2] Ilhan, Hamza Osman, and Mehmet Fatih Amasyali. \"[*Active Learning as a Way of Increasing Accuracy*](http://www.ijcte.org/papers/910-AC0013.pdf).\" International Journal of Computer Theory and Engineering 6, no. 6 (2014): 460.\n",
        "\n",
        "[3] Stefan Hosein [*Active Learning: Curious AI Algorithms*](https://www.datacamp.com/community/tutorials/active-learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiRcnlZVUpRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931908ff-9c19-4446-dea5-b845e7dc1c30"
      },
      "source": [
        "#@title Executed code for the experiment with output.\n",
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, \\\n",
        "    GradientBoostingClassifier\n",
        "\n",
        "trainset_size = 60000  # ie., testset_size = 10000\n",
        "max_queried = 500\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def download():\n",
        "    mnist = fetch_mldata('MNIST original')\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('MNIST:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "    return (X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
        "                              class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class GmmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gaussian Mixture Model'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training gaussian mixture model...')\n",
        "        pca = PCA(n_components=75).fit(X_train)  # ,whiten=True).fit(X_train)\n",
        "        reduced_train_data = pca.transform(X_train)\n",
        "        reduced_test_data = pca.transform(X_test)\n",
        "        reduced_val_data = pca.transform(X_val)\n",
        "        print ('PCA: explained_variance_ratio_',\n",
        "               np.sum(pca.explained_variance_ratio_))\n",
        "        self.classifier = GaussianMixture(n_components=10, covariance_type='full')\n",
        "        self.classifier.fit(reduced_train_data)\n",
        "        self.test_y_predicted = \\\n",
        "            self.classifier.predict(reduced_test_data)\n",
        "        self.val_y_predicted = self.classifier.predict(reduced_val_data)\n",
        "        return (reduced_train_data, reduced_val_data,\n",
        "                reduced_test_data, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Multinominal Logistic Regression' \n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training multinomial logistic regression')\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight,\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class GbcModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boosting Classifier'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training gradient boosting...')\n",
        "        parm = {\n",
        "            'n_estimators': 1200,\n",
        "            'max_depth': 3,\n",
        "            'subsample': 0.5,\n",
        "            'learning_rate': 0.01,\n",
        "            'min_samples_leaf': 1,\n",
        "            'random_state': 3,\n",
        "            }\n",
        "        self.classifier = GradientBoostingClassifier(**parm)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
        "        print ('Val   set:', X_val.shape)\n",
        "        print ('Test  set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
        "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(trainset_size,\n",
        "                                   initial_labeled_samples,\n",
        "                                   replace=False)\n",
        "    print ()\n",
        "    print ('initial random chosen samples', permutation.shape),\n",
        "#            permutation)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    bin_count = np.bincount(y_train.astype('int64'))\n",
        "    unique = np.unique(y_train.astype('int64'))\n",
        "    print (\n",
        "        'initial train set:',\n",
        "        X_train.shape,\n",
        "        y_train.shape,\n",
        "        'unique(labels):',\n",
        "        bin_count,\n",
        "        unique,\n",
        "        )\n",
        "    return (permutation, X_train, y_train)\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class BaseSelectionFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        random_state = check_random_state(0)\n",
        "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
        "\n",
        "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class MinStdSelection(BaseSelectionFunction):\n",
        "\n",
        "    # select the samples where the std is smallest - i.e., there is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        std = np.std(probas_val * 100, axis=1)\n",
        "        selection = std.argsort()[:initial_labeled_samples]\n",
        "        selection = selection.astype('int64')\n",
        "\n",
        "#     print('std',std.shape,std)\n",
        "#     print()\n",
        "#     print('selection',selection, selection.shape, std[selection])\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class MarginSamplingSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
        "        values = rev[:, 0] - rev[:, 1]\n",
        "        selection = np.argsort(values)[:initial_labeled_samples]\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
        "        return selection\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "\n",
        "      \n",
        "# ====================================================================================================\n",
        "\n",
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
        "        self.initial_labeled_samples = initial_labeled_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_k_random_samples(self.initial_labeled_samples,\n",
        "                                 X_train_full, y_train_full)\n",
        "        self.queried = self.initial_labeled_samples\n",
        "        self.samplecount = [self.initial_labeled_samples]\n",
        "\n",
        "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        print ()\n",
        "\n",
        "        # normalize data\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
        "        # print(fpfn)\n",
        "        # self.fpfncount = []\n",
        "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
        "\n",
        "        while self.queried < max_queried:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            print ('val predicted:',\n",
        "                   self.clf_model.val_y_predicted.shape,\n",
        "                   self.clf_model.val_y_predicted)\n",
        "            print ('probabilities:', probas_val.shape, '\\n',\n",
        "                   np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "\n",
        "            uncertain_samples = \\\n",
        "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        " \n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "\n",
        "            print ('trainset before', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            print ('trainset after', X_train.shape, y_train.shape)\n",
        "            self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            bin_count = np.bincount(y_train.astype('int64'))\n",
        "            unique = np.unique(y_train.astype('int64'))\n",
        "            print (\n",
        "                'updated train set:',\n",
        "                X_train.shape,\n",
        "                y_train.shape,\n",
        "                'unique(labels):',\n",
        "                bin_count,\n",
        "                unique,\n",
        "                )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            print ('val set:', X_val.shape, y_val.shape)\n",
        "            print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.initial_labeled_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('final active learning accuracies',\n",
        "               self.clf_model.accuracies)\n",
        "\n",
        "\n",
        "# get MNIST\n",
        "\n",
        "(X, y) = download()\n",
        "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
        "print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "print ('test :', X_test.shape, y_test.shape)\n",
        "classes = len(np.unique(y))\n",
        "print ('unique classes', classes)\n",
        "\n",
        "def pickle_save(fname, data):\n",
        "  filehandler = open(fname,\"wb\")\n",
        "  pickle.dump(data,filehandler)\n",
        "  filehandler.close() \n",
        "  print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][k] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][k].append(alg.clf_model.accuracies)\n",
        "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    pickle_save(fname, d)\n",
        "                    if count % 5 == 0:\n",
        "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    print ()\n",
        "                    print ('---------------------------- FINISHED ---------------------------')\n",
        "                    print ()\n",
        "    return d\n",
        "\n",
        "max_queried = 500\n",
        "# max_queried = 20\n",
        "\n",
        "repeats = 1\n",
        "\n",
        "models = [SvmModel, RfModel, LogModel]#, GbcModel]\n",
        "# models = [RfModel, SvmModel]\n",
        "\n",
        "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection]#, MinStdSelection]\n",
        "# selection_functions = [MarginSamplingSelection]\n",
        "\n",
        "Ks = [250,125,50,25,10]\n",
        "# Ks = [10]\n",
        "\n",
        "d = {}\n",
        "stopped_at = -1\n",
        "\n",
        "# stopped_at = 73\n",
        "# d = pickle_load('Active-learning-experiment-'+ str(stopped_at) +'.pkl')  \n",
        "# print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n",
        "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-1b8c5dc6131f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'fetch_mldata'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jea0AHlpe18z"
      },
      "source": [
        "#@title Manual assignment of the dictionary json dump to a variable, these are the results from the previous cell.\n",
        "\n",
        "d = {\n",
        "  \"LogModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          36.620000000000005,\n",
        "          46.79,\n",
        "          47.49,\n",
        "          49.96,\n",
        "          51.59,\n",
        "          54.25,\n",
        "          49.43,\n",
        "          55.510000000000005,\n",
        "          52.88,\n",
        "          50.89,\n",
        "          53.04,\n",
        "          52.42,\n",
        "          52.410000000000004,\n",
        "          50.949999999999996,\n",
        "          48.699999999999996,\n",
        "          48.89,\n",
        "          51.160000000000004,\n",
        "          47.68,\n",
        "          46.1,\n",
        "          48.91,\n",
        "          50.739999999999995,\n",
        "          53.080000000000005,\n",
        "          54.790000000000006,\n",
        "          50.88,\n",
        "          53.790000000000006,\n",
        "          56.05,\n",
        "          54.06999999999999,\n",
        "          57.85,\n",
        "          54.279999999999994,\n",
        "          55.86,\n",
        "          57.43000000000001,\n",
        "          47.57,\n",
        "          53.480000000000004,\n",
        "          55.21,\n",
        "          53.32,\n",
        "          54.98,\n",
        "          52.51,\n",
        "          54.39000000000001,\n",
        "          55.88999999999999,\n",
        "          54.61,\n",
        "          55.69,\n",
        "          54.510000000000005,\n",
        "          52.559999999999995,\n",
        "          53.66,\n",
        "          56.089999999999996,\n",
        "          54.230000000000004,\n",
        "          51.77,\n",
        "          52.629999999999995,\n",
        "          55.00000000000001,\n",
        "          48.97\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          59.050000000000004,\n",
        "          52.849999999999994,\n",
        "          54.71,\n",
        "          55.16,\n",
        "          52.349999999999994,\n",
        "          53.94,\n",
        "          53.43,\n",
        "          51.480000000000004,\n",
        "          45.94,\n",
        "          48.92,\n",
        "          48.55,\n",
        "          44.51,\n",
        "          50.72,\n",
        "          48.29,\n",
        "          49.69,\n",
        "          53.61,\n",
        "          49.91,\n",
        "          50.12,\n",
        "          50.59,\n",
        "          52.66\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          61.82,\n",
        "          60.31999999999999,\n",
        "          54.03,\n",
        "          57.220000000000006,\n",
        "          58.67,\n",
        "          57.11000000000001,\n",
        "          53.18000000000001,\n",
        "          57.76,\n",
        "          55.08,\n",
        "          53.42\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          69.07,\n",
        "          62.660000000000004,\n",
        "          58.93000000000001,\n",
        "          60.5\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.77,\n",
        "          63.23\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          33.269999999999996,\n",
        "          56.63,\n",
        "          57.709999999999994,\n",
        "          61.82,\n",
        "          64.57000000000001,\n",
        "          67.43,\n",
        "          69.24,\n",
        "          69.76,\n",
        "          69.87,\n",
        "          71.05,\n",
        "          73.27,\n",
        "          71.35000000000001,\n",
        "          70.75,\n",
        "          72.61,\n",
        "          71.23,\n",
        "          72.57000000000001,\n",
        "          72.38,\n",
        "          73.17,\n",
        "          73.94,\n",
        "          73.44000000000001,\n",
        "          72.26,\n",
        "          72.78,\n",
        "          73.68,\n",
        "          72.75,\n",
        "          73.79,\n",
        "          73.91,\n",
        "          72.39,\n",
        "          71.72,\n",
        "          74.39,\n",
        "          73.09,\n",
        "          73.39,\n",
        "          73.25,\n",
        "          72.8,\n",
        "          74.51,\n",
        "          72.15,\n",
        "          72.08,\n",
        "          71.78,\n",
        "          73.69,\n",
        "          73.19,\n",
        "          73.00999999999999,\n",
        "          72.68,\n",
        "          71.67,\n",
        "          72.71,\n",
        "          74.11,\n",
        "          73.06,\n",
        "          74.33999999999999,\n",
        "          72.56,\n",
        "          72.64,\n",
        "          72.35000000000001,\n",
        "          72.86\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          41.980000000000004,\n",
        "          52.12,\n",
        "          65.4,\n",
        "          64.84,\n",
        "          65.10000000000001,\n",
        "          64.14,\n",
        "          65.86999999999999,\n",
        "          66.99000000000001,\n",
        "          70.11,\n",
        "          70.44,\n",
        "          67.21000000000001,\n",
        "          71.17,\n",
        "          70.33,\n",
        "          70.12,\n",
        "          71.6,\n",
        "          70.3,\n",
        "          68.16,\n",
        "          69.51,\n",
        "          69.59,\n",
        "          70.85000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          62.8,\n",
        "          70.19,\n",
        "          68.39,\n",
        "          71.65,\n",
        "          69.44,\n",
        "          70.94,\n",
        "          70.7,\n",
        "          70.14,\n",
        "          71.17,\n",
        "          70.21\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          71.11,\n",
        "          72.42,\n",
        "          72.0,\n",
        "          72.81\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.76,\n",
        "          73.76\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.61,\n",
        "          50.36000000000001,\n",
        "          53.1,\n",
        "          59.74,\n",
        "          62.7,\n",
        "          64.03999999999999,\n",
        "          64.25,\n",
        "          61.629999999999995,\n",
        "          66.47,\n",
        "          68.0,\n",
        "          65.75999999999999,\n",
        "          65.0,\n",
        "          65.27,\n",
        "          66.46,\n",
        "          66.99000000000001,\n",
        "          66.86,\n",
        "          67.28,\n",
        "          66.72,\n",
        "          67.10000000000001,\n",
        "          68.33,\n",
        "          69.25,\n",
        "          69.69999999999999,\n",
        "          69.32000000000001,\n",
        "          67.72,\n",
        "          69.87,\n",
        "          68.69,\n",
        "          68.83,\n",
        "          70.00999999999999,\n",
        "          69.65,\n",
        "          70.19,\n",
        "          71.41,\n",
        "          70.53,\n",
        "          70.15,\n",
        "          68.74,\n",
        "          70.0,\n",
        "          68.24,\n",
        "          68.92,\n",
        "          67.91,\n",
        "          69.17999999999999,\n",
        "          68.87,\n",
        "          69.02000000000001,\n",
        "          70.00999999999999,\n",
        "          70.47,\n",
        "          71.83,\n",
        "          70.78,\n",
        "          70.61,\n",
        "          71.33,\n",
        "          70.91,\n",
        "          71.0,\n",
        "          71.78999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          46.63,\n",
        "          57.86,\n",
        "          62.019999999999996,\n",
        "          70.61,\n",
        "          72.74000000000001,\n",
        "          69.82000000000001,\n",
        "          69.6,\n",
        "          70.81,\n",
        "          70.82000000000001,\n",
        "          69.49,\n",
        "          71.46000000000001,\n",
        "          71.48,\n",
        "          72.04,\n",
        "          72.11,\n",
        "          72.65,\n",
        "          73.09,\n",
        "          73.72,\n",
        "          73.86,\n",
        "          74.69,\n",
        "          73.72999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          68.38,\n",
        "          66.14999999999999,\n",
        "          70.45,\n",
        "          72.68,\n",
        "          72.31,\n",
        "          72.33000000000001,\n",
        "          73.44000000000001,\n",
        "          71.78999999999999,\n",
        "          73.11999999999999,\n",
        "          70.84\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          68.95,\n",
        "          68.53,\n",
        "          71.67,\n",
        "          73.09\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.11,\n",
        "          74.56\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "  \"RfModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          37.519999999999996,\n",
        "          42.53,\n",
        "          51.42,\n",
        "          49.03,\n",
        "          49.25,\n",
        "          52.01,\n",
        "          51.41,\n",
        "          51.89,\n",
        "          53.04,\n",
        "          55.48,\n",
        "          56.989999999999995,\n",
        "          56.720000000000006,\n",
        "          56.93,\n",
        "          55.169999999999995,\n",
        "          56.26,\n",
        "          55.64,\n",
        "          54.769999999999996,\n",
        "          54.98,\n",
        "          54.06999999999999,\n",
        "          53.71,\n",
        "          53.21,\n",
        "          52.800000000000004,\n",
        "          53.54,\n",
        "          52.72,\n",
        "          52.65,\n",
        "          51.849999999999994,\n",
        "          51.67,\n",
        "          51.89,\n",
        "          52.54,\n",
        "          53.03,\n",
        "          56.06,\n",
        "          56.26,\n",
        "          55.669999999999995,\n",
        "          60.17,\n",
        "          60.480000000000004,\n",
        "          59.9,\n",
        "          58.97,\n",
        "          60.019999999999996,\n",
        "          59.81999999999999,\n",
        "          59.86,\n",
        "          59.95,\n",
        "          62.970000000000006,\n",
        "          63.7,\n",
        "          62.94,\n",
        "          62.19,\n",
        "          62.019999999999996,\n",
        "          63.89,\n",
        "          62.150000000000006,\n",
        "          60.17,\n",
        "          62.39\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          44.21,\n",
        "          39.2,\n",
        "          37.57,\n",
        "          35.82,\n",
        "          36.120000000000005,\n",
        "          33.64,\n",
        "          32.09,\n",
        "          32.1,\n",
        "          32.28,\n",
        "          30.759999999999998,\n",
        "          31.230000000000004,\n",
        "          29.34,\n",
        "          26.419999999999998,\n",
        "          27.05,\n",
        "          26.58,\n",
        "          23.23,\n",
        "          24.0,\n",
        "          23.7,\n",
        "          21.58,\n",
        "          23.84\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          63.85999999999999,\n",
        "          60.309999999999995,\n",
        "          59.760000000000005,\n",
        "          59.89,\n",
        "          59.160000000000004,\n",
        "          59.519999999999996,\n",
        "          57.9,\n",
        "          59.74,\n",
        "          57.06,\n",
        "          59.91\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          75.02,\n",
        "          74.36,\n",
        "          72.39999999999999,\n",
        "          72.08\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          84.39999999999999,\n",
        "          81.82000000000001\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          25.72,\n",
        "          38.83,\n",
        "          53.99,\n",
        "          57.53,\n",
        "          62.39,\n",
        "          66.58,\n",
        "          64.23,\n",
        "          67.5,\n",
        "          72.75,\n",
        "          76.35,\n",
        "          77.31,\n",
        "          77.96,\n",
        "          78.17,\n",
        "          80.67,\n",
        "          81.76,\n",
        "          83.63000000000001,\n",
        "          85.26,\n",
        "          85.37,\n",
        "          85.82,\n",
        "          85.76,\n",
        "          86.00999999999999,\n",
        "          87.01,\n",
        "          87.45,\n",
        "          87.83,\n",
        "          88.64999999999999,\n",
        "          88.1,\n",
        "          87.92999999999999,\n",
        "          89.21,\n",
        "          89.57000000000001,\n",
        "          90.34,\n",
        "          91.12,\n",
        "          90.86,\n",
        "          91.17,\n",
        "          91.53999999999999,\n",
        "          91.84,\n",
        "          91.75999999999999,\n",
        "          91.07,\n",
        "          91.36,\n",
        "          91.22,\n",
        "          91.88,\n",
        "          92.0,\n",
        "          91.97,\n",
        "          91.7,\n",
        "          92.12,\n",
        "          92.28,\n",
        "          92.57,\n",
        "          92.63,\n",
        "          92.55,\n",
        "          92.80000000000001,\n",
        "          92.75999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          39.050000000000004,\n",
        "          51.85999999999999,\n",
        "          67.30000000000001,\n",
        "          74.29,\n",
        "          74.42999999999999,\n",
        "          80.15,\n",
        "          83.55,\n",
        "          83.58,\n",
        "          86.24000000000001,\n",
        "          87.22999999999999,\n",
        "          87.89,\n",
        "          88.42999999999999,\n",
        "          88.94,\n",
        "          90.06,\n",
        "          89.57000000000001,\n",
        "          90.03999999999999,\n",
        "          90.03999999999999,\n",
        "          91.14,\n",
        "          91.86,\n",
        "          91.79\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          62.99,\n",
        "          75.07000000000001,\n",
        "          75.38,\n",
        "          83.96000000000001,\n",
        "          87.89,\n",
        "          89.62,\n",
        "          89.7,\n",
        "          91.47999999999999,\n",
        "          91.84,\n",
        "          92.49000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          76.4,\n",
        "          85.66,\n",
        "          90.22,\n",
        "          92.13\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          81.26,\n",
        "          87.98\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          36.01,\n",
        "          43.34,\n",
        "          53.94,\n",
        "          58.02,\n",
        "          60.97,\n",
        "          66.44,\n",
        "          68.63,\n",
        "          70.8,\n",
        "          72.08,\n",
        "          73.58,\n",
        "          73.63,\n",
        "          74.0,\n",
        "          74.2,\n",
        "          75.52,\n",
        "          75.41,\n",
        "          75.81,\n",
        "          75.98,\n",
        "          77.97,\n",
        "          77.5,\n",
        "          80.15,\n",
        "          79.81,\n",
        "          81.13,\n",
        "          80.87,\n",
        "          80.58999999999999,\n",
        "          80.86,\n",
        "          81.26,\n",
        "          82.26,\n",
        "          82.44,\n",
        "          82.75,\n",
        "          82.92,\n",
        "          83.76,\n",
        "          83.50999999999999,\n",
        "          85.05,\n",
        "          85.50999999999999,\n",
        "          85.13,\n",
        "          86.02,\n",
        "          86.02,\n",
        "          86.5,\n",
        "          86.09,\n",
        "          85.83,\n",
        "          86.9,\n",
        "          86.46000000000001,\n",
        "          86.38,\n",
        "          86.88,\n",
        "          87.09,\n",
        "          87.87,\n",
        "          87.47,\n",
        "          87.59,\n",
        "          87.74,\n",
        "          87.78\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          51.64,\n",
        "          60.72,\n",
        "          65.45,\n",
        "          70.28999999999999,\n",
        "          72.94,\n",
        "          76.08,\n",
        "          77.51,\n",
        "          77.78,\n",
        "          79.35,\n",
        "          80.39,\n",
        "          81.6,\n",
        "          81.17,\n",
        "          82.73,\n",
        "          84.28,\n",
        "          84.15,\n",
        "          85.2,\n",
        "          86.13,\n",
        "          86.78,\n",
        "          86.95,\n",
        "          87.59\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          56.86,\n",
        "          69.43,\n",
        "          71.87,\n",
        "          75.68,\n",
        "          80.01,\n",
        "          82.06,\n",
        "          84.5,\n",
        "          85.92,\n",
        "          86.76,\n",
        "          87.32\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          71.5,\n",
        "          82.39,\n",
        "          85.76,\n",
        "          87.56\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.19,\n",
        "          88.14999999999999\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "  \"SvmModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          35.93,\n",
        "          35.97,\n",
        "          40.33,\n",
        "          39.39,\n",
        "          41.349999999999994,\n",
        "          42.99,\n",
        "          46.23,\n",
        "          46.18,\n",
        "          47.260000000000005,\n",
        "          52.5,\n",
        "          52.400000000000006,\n",
        "          51.25999999999999,\n",
        "          51.690000000000005,\n",
        "          51.800000000000004,\n",
        "          53.18000000000001,\n",
        "          53.82,\n",
        "          55.88999999999999,\n",
        "          56.120000000000005,\n",
        "          57.269999999999996,\n",
        "          59.41,\n",
        "          59.95,\n",
        "          62.629999999999995,\n",
        "          61.339999999999996,\n",
        "          63.88,\n",
        "          65.34,\n",
        "          65.77,\n",
        "          66.9,\n",
        "          67.96,\n",
        "          68.27,\n",
        "          67.44,\n",
        "          68.45,\n",
        "          68.63,\n",
        "          68.0,\n",
        "          68.47,\n",
        "          68.77,\n",
        "          68.8,\n",
        "          69.17,\n",
        "          68.97,\n",
        "          69.33,\n",
        "          69.67999999999999,\n",
        "          69.95,\n",
        "          70.34,\n",
        "          70.47,\n",
        "          71.19,\n",
        "          71.97,\n",
        "          72.26,\n",
        "          72.06,\n",
        "          71.98,\n",
        "          72.55,\n",
        "          72.78999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          50.33,\n",
        "          51.59,\n",
        "          56.599999999999994,\n",
        "          60.24,\n",
        "          61.57,\n",
        "          63.5,\n",
        "          66.74,\n",
        "          68.19,\n",
        "          68.02,\n",
        "          69.8,\n",
        "          75.88000000000001,\n",
        "          77.24,\n",
        "          78.09,\n",
        "          79.38,\n",
        "          80.4,\n",
        "          80.99,\n",
        "          80.28999999999999,\n",
        "          80.12,\n",
        "          79.75999999999999,\n",
        "          80.36999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          64.55,\n",
        "          68.75,\n",
        "          71.34,\n",
        "          74.11999999999999,\n",
        "          75.96000000000001,\n",
        "          77.03999999999999,\n",
        "          76.85,\n",
        "          79.19,\n",
        "          80.51,\n",
        "          80.99\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          78.4,\n",
        "          78.21000000000001,\n",
        "          80.08,\n",
        "          81.0\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.11,\n",
        "          84.53\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.86,\n",
        "          37.6,\n",
        "          46.23,\n",
        "          58.41,\n",
        "          60.34,\n",
        "          65.98,\n",
        "          65.01,\n",
        "          69.86,\n",
        "          72.28999999999999,\n",
        "          74.65,\n",
        "          76.24,\n",
        "          77.37,\n",
        "          77.59,\n",
        "          78.7,\n",
        "          79.06,\n",
        "          80.06,\n",
        "          81.21000000000001,\n",
        "          82.32000000000001,\n",
        "          83.17,\n",
        "          83.78,\n",
        "          84.6,\n",
        "          84.58,\n",
        "          84.47,\n",
        "          85.07000000000001,\n",
        "          85.64,\n",
        "          85.75,\n",
        "          85.7,\n",
        "          86.18,\n",
        "          86.58,\n",
        "          86.50999999999999,\n",
        "          86.71,\n",
        "          87.09,\n",
        "          86.91,\n",
        "          87.13,\n",
        "          87.42999999999999,\n",
        "          87.75,\n",
        "          87.97,\n",
        "          88.23,\n",
        "          88.23,\n",
        "          88.22,\n",
        "          88.16000000000001,\n",
        "          88.03,\n",
        "          88.38000000000001,\n",
        "          88.39,\n",
        "          88.64,\n",
        "          88.98,\n",
        "          89.05999999999999,\n",
        "          89.34,\n",
        "          89.3,\n",
        "          89.52\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          50.160000000000004,\n",
        "          63.73,\n",
        "          70.14,\n",
        "          74.4,\n",
        "          78.99000000000001,\n",
        "          80.36999999999999,\n",
        "          82.76,\n",
        "          84.35000000000001,\n",
        "          85.78,\n",
        "          86.61999999999999,\n",
        "          87.46000000000001,\n",
        "          87.64,\n",
        "          88.08,\n",
        "          88.75,\n",
        "          88.68,\n",
        "          89.02,\n",
        "          89.39,\n",
        "          89.57000000000001,\n",
        "          89.66,\n",
        "          89.8\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          59.099999999999994,\n",
        "          69.91000000000001,\n",
        "          75.66000000000001,\n",
        "          81.41000000000001,\n",
        "          82.69,\n",
        "          85.07000000000001,\n",
        "          85.92,\n",
        "          86.89,\n",
        "          87.8,\n",
        "          87.6\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          79.45,\n",
        "          84.1,\n",
        "          86.36,\n",
        "          88.16000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          84.58,\n",
        "          87.38\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.009999999999998,\n",
        "          33.54,\n",
        "          48.67,\n",
        "          57.34,\n",
        "          61.68,\n",
        "          64.75999999999999,\n",
        "          69.28,\n",
        "          71.97,\n",
        "          73.2,\n",
        "          74.03,\n",
        "          75.08,\n",
        "          76.01,\n",
        "          76.55,\n",
        "          77.42999999999999,\n",
        "          77.75,\n",
        "          79.72,\n",
        "          80.78,\n",
        "          81.62,\n",
        "          81.8,\n",
        "          82.03,\n",
        "          81.82000000000001,\n",
        "          82.72,\n",
        "          82.94,\n",
        "          83.03,\n",
        "          83.72,\n",
        "          83.81,\n",
        "          83.72,\n",
        "          83.95,\n",
        "          84.38,\n",
        "          85.02,\n",
        "          85.36,\n",
        "          85.65,\n",
        "          85.26,\n",
        "          85.37,\n",
        "          85.37,\n",
        "          85.19,\n",
        "          85.18,\n",
        "          85.61999999999999,\n",
        "          85.47,\n",
        "          85.61999999999999,\n",
        "          85.78,\n",
        "          86.00999999999999,\n",
        "          86.05000000000001,\n",
        "          85.96000000000001,\n",
        "          85.96000000000001,\n",
        "          86.0,\n",
        "          86.24000000000001,\n",
        "          86.6,\n",
        "          86.66,\n",
        "          86.81\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          51.449999999999996,\n",
        "          67.88,\n",
        "          72.25,\n",
        "          77.82,\n",
        "          79.19,\n",
        "          80.32000000000001,\n",
        "          81.19,\n",
        "          81.91000000000001,\n",
        "          82.67999999999999,\n",
        "          82.89,\n",
        "          82.89,\n",
        "          83.05,\n",
        "          83.91999999999999,\n",
        "          84.69,\n",
        "          84.77,\n",
        "          84.66,\n",
        "          85.0,\n",
        "          85.3,\n",
        "          85.79,\n",
        "          86.08\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          56.38999999999999,\n",
        "          72.92999999999999,\n",
        "          78.44,\n",
        "          81.0,\n",
        "          82.73,\n",
        "          83.52000000000001,\n",
        "          84.35000000000001,\n",
        "          85.17,\n",
        "          86.17,\n",
        "          86.66\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          73.76,\n",
        "          83.52000000000001,\n",
        "          85.6,\n",
        "          86.44\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.02000000000001,\n",
        "          85.64\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}